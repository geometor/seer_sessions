{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import Counter, deque\n\n\"\"\"\nTransformation Rule Description:\n\n1.  Initialize the output grid as an identical copy of the input grid.\n2.  Determine the background color: This is the most frequent color in the input grid, excluding red (color 2).\n3.  Identify all distinct contiguous groups (objects) of pixels in the input grid using a method like Breadth-First Search (BFS). Store each object's color and the set of its pixel coordinates.\n4.  Separate the identified objects into two categories: 'red_objects' (color 2) and 'reflectable_objects' (neither red nor background color).\n5.  Classify each 'red_object' based on its shape:\n    - 'H' (Horizontal Line): Height is 1, Width > 1.\n    - 'V' (Vertical Line): Width is 1, Height > 1.\n    - 'P' (Point): Height is 1, Width is 1.\n    (Height/Width calculated from the min/max row/column of the object's pixels).\n6.  Create a mapping from red pixel coordinates to the classified red object they belong to.\n7.  Iterate through each 'reflectable_object'.\n8.  For each reflectable object, check if any of its pixels are cardinally adjacent to any pixel belonging to a 'red_object'.\n9.  If a reflectable object pixel `(r, c)` is adjacent to a red pixel `(nr, nc)`:\n    a.  Identify the specific red object associated with `(nr, nc)` using the mapping created earlier. Get its classification ('H', 'V', or 'P').\n    b.  Determine the reflection type based on the classification: Vertical for 'H', Horizontal for 'V' or 'P'.\n    c.  Iterate through *all* pixels `(orig_r, orig_c)` of the current reflectable object.\n    d.  Calculate the reflected coordinates `(rr, rc)` based on the reflection type and the coordinates of the *adjacent red pixel* `(nr, nc)` that triggered the reflection:\n        *   Vertical Reflection (across row `nr`): `rr = nr + (nr - orig_r)`, `rc = orig_c`.\n        *   Horizontal Reflection (across col `nc`): `rr = orig_r`, `rc = nc + (nc - orig_c)`.\n    e.  Check if the calculated `(rr, rc)` is within the grid boundaries.\n    f.  If `(rr, rc)` is within bounds AND the pixel at `output_grid[rr, rc]` currently holds the background color, update `output_grid[rr, rc]` with the color of the reflectable object.\n    g. Once a reflection is triggered and processed for a reflectable object (due to adjacency with *one* red pixel), stop checking its other pixels for adjacency and move to the next reflectable object. (Assumption: An object is reflected only once based on its first detected adjacency).\n10. Return the modified output grid as a list of lists.\n\"\"\"\n\ndef find_background_color(grid):\n    \"\"\"Finds the most frequent color in the grid, excluding red (2).\"\"\"\n    counts = Counter(grid.flatten())\n    if 2 in counts:\n        del counts[2] # Exclude red\n\n    if not counts:\n        all_counts = Counter(grid.flatten())\n        if 0 in all_counts: return 0\n        if grid.size > 0:\n            # Find most frequent among all if no non-red exists or only red exists\n            non_red_counts = Counter(c for c in grid.flatten() if c != 2)\n            if non_red_counts:\n                return non_red_counts.most_common(1)[0][0]\n            # If truly only red, pick an arbitrary background like 0, though ARC tasks usually have backgrounds.\n            return 0\n        return 0 # Default fallback for empty grid\n\n    return counts.most_common(1)[0][0]\n\ndef is_within_bounds(grid_shape, r, c):\n    \"\"\"Checks if coordinates (r, c) are within the grid boundaries.\"\"\"\n    height, width = grid_shape\n    return 0 <= r < height and 0 <= c < width\n\ndef find_connected_components(grid):\n    \"\"\"Finds all contiguous objects (connected components) in the grid.\"\"\"\n    height, width = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n\n    for r in range(height):\n        for c in range(width):\n            if not visited[r, c]:\n                color = grid[r, c]\n                component_pixels = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                component_pixels.add((r, c))\n\n                while q:\n                    row, col = q.popleft()\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        if is_within_bounds((height, width), nr, nc) and \\\n                           not visited[nr, nc] and \\\n                           grid[nr, nc] == color:\n                            visited[nr, nc] = True\n                            component_pixels.add((nr, nc))\n                            q.append((nr, nc))\n\n                if component_pixels:\n                    objects.append({'color': color, 'pixels': component_pixels})\n    return objects\n\ndef classify_red_object(pixels):\n    \"\"\"Classifies a red object based on its pixel coordinates.\"\"\"\n    if not pixels:\n        return None # Should not happen for valid objects\n\n    rows = [r for r, c in pixels]\n    cols = [c for r, c in pixels]\n    min_r, max_r = min(rows), max(rows)\n    min_c, max_c = min(cols), max(cols)\n\n    height = max_r - min_r + 1\n    width = max_c - min_c + 1\n\n    if height == 1 and width > 1:\n        return 'H' # Horizontal Line\n    elif width == 1 and height > 1:\n        return 'V' # Vertical Line\n    elif height == 1 and width == 1:\n        return 'P' # Point\n    else:\n        # Handle blocks or other shapes - Treat as 'P' for reflection?\n        # Or base on adjacency? Examples only show lines/points as mirrors.\n        # Let's default to 'P' (horizontal reflection) for blocks for now.\n         return 'P'\n\n\ndef transform(input_grid):\n    # Convert to numpy array\n    input_grid_np = np.array(input_grid, dtype=int)\n    height, width = input_grid_np.shape\n    grid_shape = (height, width)\n\n    # 1. Initialize output_grid as a copy\n    output_grid = np.copy(input_grid_np)\n\n    # 2. Determine background color\n    background_color = find_background_color(input_grid_np)\n\n    # 3. Find all connected components (objects)\n    all_objects = find_connected_components(input_grid_np)\n\n    # 4. Separate objects\n    red_objects = []\n    reflectable_objects = []\n    red_pixel_map = {} # Map: red pixel coord -> its object info\n\n    for obj in all_objects:\n        if obj['color'] == 2:\n            # 5. Classify Red Objects\n            classification = classify_red_object(obj['pixels'])\n            obj['classification'] = classification\n            red_objects.append(obj)\n            # 6. Create red pixel map\n            for pixel in obj['pixels']:\n                red_pixel_map[pixel] = obj\n        elif obj['color'] != background_color:\n            reflectable_objects.append(obj)\n\n    # 7. Iterate through reflectable objects\n    for r_obj in reflectable_objects:\n        obj_color = r_obj['color']\n        obj_pixels = r_obj['pixels']\n        reflection_triggered = False\n        \n        # 8. Check for adjacency to any red pixel\n        for r, c in obj_pixels:\n            if reflection_triggered: # Only reflect once per object\n                break\n            for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                nr, nc = r + dr, c + dc\n\n                # 9. If adjacent to a red pixel\n                if is_within_bounds(grid_shape, nr, nc) and input_grid_np[nr, nc] == 2:\n                    # 9a. Identify the red object and its classification\n                    if (nr, nc) in red_pixel_map:\n                        adjacent_red_obj = red_pixel_map[(nr, nc)]\n                        red_classification = adjacent_red_obj['classification']\n                        reflection_triggered = True # Mark that reflection should happen\n\n                        # 9b. Determine reflection type\n                        reflect_vertically = (red_classification == 'H')\n\n                        # 9c. Iterate through ALL pixels of the reflectable object\n                        for orig_r, orig_c in obj_pixels:\n                            # 9d. Calculate reflected coordinates based on adjacent red pixel (nr, nc)\n                            rr, rc = -1, -1\n                            if reflect_vertically:\n                                rr = nr + (nr - orig_r)\n                                rc = orig_c\n                            else: # Reflect horizontally\n                                rr = orig_r\n                                rc = nc + (nc - orig_c)\n\n                            # 9e. Check bounds\n                            if is_within_bounds(grid_shape, rr, rc):\n                                # 9f. Update output grid if background\n                                if output_grid[rr, rc] == background_color:\n                                    output_grid[rr, rc] = obj_color\n                        \n                        # 9g. Break neighbor check once reflection is done for this object\n                        break \n            # Break pixel loop once reflection is triggered\n            if reflection_triggered:\n                break\n\n    # 11. Return the modified grid as list of lists\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 18329,
    "candidates_token_count": 2365,
    "total_token_count": 20694,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 29.852493,
  "retries": 1
}