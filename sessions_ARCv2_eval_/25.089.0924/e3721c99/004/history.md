
## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 4 4 4 0 3 3 3 0 1 1 1 1 1 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0
0 4 4 4 0 3 0 3 0 1 0 1 0 1 0 2 0 2 0 2 0 2 0 0 0 0 0 0 0 0
0 4 4 4 0 3 3 3 0 1 1 1 1 1 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 5 5 5 0 0 0 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 5 5 0 5 5 0 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 5 5 0 5 5 0 5 5 0 0 0 0 0 0 0 0 0 0 5 5 5 5 5 5 0 0 0 0
0 0 0 5 5 5 5 0 0 0 0 0 5 5 0 0 0 0 0 5 5 0 0 0 5 5 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 5 5 5 0 0 0 0 5 5 5 5 5 5 5 0 0 0 0 0
0 0 0 0 0 0 0 0 0 5 5 5 5 5 0 0 0 5 5 0 0 0 5 5 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 5 5 5 5 0 0 0 0 5 5 5 5 5 5 5 0 0 0 0 0 0
0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 5 5 5 0 0 0 0 0 0 0 0 0
0 0 0 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 5 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 5 5 5 5 0 0 0 0 0 0 0 5 5 0 0 0 0 0 0 0 0 5 5 5 5 0 0
0 0 0 5 5 5 0 0 0 0 0 0 5 5 5 5 5 0 0 0 0 0 5 5 5 0 5 5 0 0
0 0 0 0 0 0 0 0 0 0 0 0 5 0 5 0 5 0 0 0 0 5 5 5 5 0 0 5 0 0
0 0 0 0 0 0 5 5 5 5 0 0 5 5 5 5 5 5 0 0 0 5 5 0 5 5 5 5 0 0
0 0 0 0 0 5 5 5 0 5 0 0 5 0 5 5 5 0 0 0 0 5 5 0 0 5 5 5 0 0
0 0 0 5 5 5 5 5 0 5 0 0 5 5 5 0 0 0 0 0 0 0 5 5 5 5 5 0 0 0
0 0 5 5 5 5 0 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 5 5 0 5 0 5 5 5 0 0 0 0 0 0 0 5 5 5 0 0 0 0 0 0 0 0 0 0
0 0 5 5 5 5 5 5 5 5 0 0 0 0 0 0 5 5 5 5 5 5 0 0 0 0 0 0 0 0
0 0 5 5 0 5 5 5 5 0 0 0 0 0 0 0 5 5 5 5 5 5 0 0 0 0 0 0 0 0
0 0 0 5 5 5 5 5 0 0 0 0 0 0 0 0 0 5 5 5 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 4 4 4 0 3 3 3 0 1 1 1 1 1 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0
0 4 4 4 0 3 0 3 0 1 0 1 0 1 0 2 0 2 0 2 0 2 0 0 0 0 0 0 0 0
0 4 4 4 0 3 3 3 0 1 1 1 1 1 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 3 3 3 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 3 3 0 3 3 0 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 3 3 0 3 3 0 4 4 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0
0 0 0 3 3 3 3 0 0 0 0 0 4 4 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 4 4 4 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0
0 0 0 0 0 0 0 0 0 4 4 4 4 4 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 4 4 4 4 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0
0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0
0 0 0 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 3 3 3 3 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 1 1 1 1 0 0
0 0 0 3 3 3 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0 0 1 1 1 0 1 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 2 0 0 0 0 1 1 1 1 0 0 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 0 0 0 1 1 0 1 1 1 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 2 0 0 0 0 1 1 0 0 1 1 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 4 4 4 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 4 4 4 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0 0
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 2 2 2 0 3 3 3 0 1 0 0 0 0 0 0 0 0 5 5 0 0 0 0 0 0 0 0 0 0
0 2 2 2 0 3 0 3 0 1 0 0 0 0 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0
0 2 2 2 0 3 3 3 0 1 0 0 0 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1 0 0 0 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1 0 0 0 0 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0
1 1 1 1 1 1 1 1 1 1 0 0 0 0 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 5 5 5 5 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 5 0 0
0 0 0 0 0 0 0 0 0 0 5 5 5 0 0 0 0 0 0 0 5 5 5 5 5 5 5 5 0 0
0 0 0 0 0 0 0 0 0 0 0 5 5 0 0 0 0 0 0 0 5 5 5 0 0 5 5 5 0 0
0 0 0 0 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 5 5 5 0 0 0 5 5 5 5 0
0 0 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 5 5 5 0 0 0 5 5 5 5 0
0 0 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 5 5 0 0 0 5 5 5 5 0
0 0 5 5 5 5 5 5 5 0 0 0 5 5 5 5 0 0 0 0 5 5 5 5 5 5 5 5 0 0
0 5 5 5 5 5 5 5 5 0 0 0 5 5 5 0 0 0 0 0 0 5 5 0 0 0 0 0 0 0
0 0 5 5 5 5 5 5 0 0 0 0 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 5 5 0 0 0 0 0 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 5 5 5 5 0 0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 5 5 5 0 0 0 0 0 5 5 0 5 5 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 5 5 5 0 0 0 0 0 5 0 0 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 5 0 0 0 0 0 0
0 0 0 0 5 0 0 5 5 0 0 0 5 0 0 0 0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 5 5 0 0 5 0 0 0 5 5 5 5 5 5 5 0 0 5 5 5 5 0 0 0 0 0 0
0 0 0 5 5 0 5 5 0 0 0 5 0 5 0 0 5 5 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 5 5 5 5 0 0 0 5 0 5 0 0 5 5 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 5 0 0 0 0 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 2 2 2 0 3 3 3 0 1 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0
0 2 2 2 0 3 0 3 0 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0
0 2 2 2 0 3 3 3 0 1 0 0 0 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0
1 1 1 1 1 1 1 1 1 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0
0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0
0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 3 3 3 0 0 3 3 3 0 0
0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 0 0 0 3 3 3 3 0
0 0 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 3 3 3 0 0 0 3 3 3 3 0
0 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 3 3 3 3 0
0 0 2 2 2 2 2 2 2 0 0 0 2 2 2 2 0 0 0 0 3 3 3 3 3 3 3 3 0 0
0 2 2 2 2 2 2 2 2 0 0 0 2 2 2 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0
0 0 2 2 2 2 2 2 0 0 0 0 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 2 0 0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 0 0 0 0 0 3 3 3 3 3 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 3 3 0 3 3 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 3 0 0 3 3 0 0 0 0 0
0 0 0 0 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0 0
0 0 0 0 3 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 0 0 0 0 0
0 0 0 3 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 0 0 0 0 0 0
0 0 0 3 3 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

Okay, let's break down the task presented in the examples.

**Perception**

1.  **Grid Structure:** The input and output grids are the same size (30x30 in the examples). The input grid generally seems divided into three conceptual parts:
    *   An upper region containing several small, distinct, colored shapes (yellow, green, blue, red) on a white background. These appear to serve as "reference patterns" or "keys".
    *   A single horizontal line made of blue pixels acting as a separator.
    *   A lower region (or sometimes other regions, like the top-right in example 2) containing multiple shapes made of gray pixels, also on a white background. Some non-gray shapes might also exist outside the reference area.
2.  **Reference Shapes:** The colored shapes in the upper region (e.g., yellow '4', green '3', blue '1', red '2' in example 1) have distinct forms and colors.
3.  **Target Shapes:** The gray shapes are the primary targets for transformation. Their forms vary; some seem to visually match the reference shapes, while others do not.
4.  **Transformation:** The core transformation happens to the gray shapes.
    *   Gray shapes in the input that *match* the form of one of the reference shapes are "recolored" in the output grid using the color of the matching reference shape.
    *   Gray shapes in the input that *do not match* the form of any reference shape are effectively "erased" â€“ replaced by the white background color in the output grid.
5.  **Invariance:** The reference shapes themselves, the blue separator line, and any other non-gray, non-white pixels in the input seem to remain unchanged in the output grid. The transformation specifically targets only the gray pixels that form contiguous shapes.

**Facts**


```yaml
Input:
  Grid: 2D array of integers (colors).
  Background: white (0).
  Reference_Area: Typically the upper part of the grid.
  Separator: A horizontal line of blue (1) pixels often present.
  Target_Color: gray (5).

Objects:
  - Type: Reference_Shape
    Properties:
      - Color: yellow (4), green (3), blue (1), red (2) etc. (non-gray, non-white)
      - Location: Typically in the Reference_Area.
      - Form: A specific pattern/arrangement of pixels.
      - Contiguous: Pixels of the same color form a connected component.
  - Type: Target_Shape
    Properties:
      - Color: gray (5)
      - Location: Anywhere in the grid except potentially overlapping the exact pixels of a reference shape.
      - Form: A specific pattern/arrangement of pixels.
      - Contiguous: Pixels of the same color form a connected component.
  - Type: Separator_Line
    Properties:
      - Color: blue (1)
      - Form: Horizontal line.
  - Type: Background
    Properties:
      - Color: white (0)

Relationships:
  - Form_Matching: A Target_Shape's form can match a Reference_Shape's form. Form comparison ignores color and absolute position, focusing on the relative arrangement of pixels within the shape.

Actions:
  1. Identify_References: Find all Reference_Shapes in the input grid, noting their form and color.
  2. Identify_Targets: Find all Target_Shapes (contiguous gray areas) in the input grid, noting their form and location.
  3. Compare_Forms: For each Target_Shape, compare its form against the forms of all Reference_Shapes.
  4. Recolor_Matched_Targets: If a Target_Shape's form matches a Reference_Shape's form, replace the gray pixels of the Target_Shape with the color of the matching Reference_Shape in the output grid.
  5. Erase_Unmatched_Targets: If a Target_Shape's form does not match any Reference_Shape's form, replace the gray pixels of the Target_Shape with the background color (white, 0) in the output grid.
  6. Preserve_Others: Copy all non-gray pixels from the input grid to the output grid.

Output:
  Grid: A modified version of the input grid where gray shapes are either recolored based on matching reference shapes or erased.
```


**Natural Language Program**

1.  Initialize the output grid as a copy of the input grid.
2.  Identify the "reference shapes": Locate all distinct, contiguous, non-white, non-gray shapes in the input grid (typically found in the upper region). For each reference shape, store its unique form (relative pixel pattern) and its color.
3.  Identify all "target shapes": Locate all distinct, contiguous shapes made of gray (5) pixels in the input grid. For each target shape, determine its form (relative pixel pattern) and the coordinates of its pixels.
4.  Iterate through each identified gray target shape:
    a.  Compare the form of the current gray target shape with the forms of all identified reference shapes.
    b.  Check if an exact match in form is found between the target shape and any reference shape.
    c.  If a match is found with a reference shape:
        i.  Retrieve the color of the matching reference shape.
        ii. For every pixel coordinate belonging to the current gray target shape, update the corresponding pixel in the *output grid* to this retrieved color.
    d.  If no match is found with any reference shape:
        i.  For every pixel coordinate belonging to the current gray target shape, update the corresponding pixel in the *output grid* to the background color (white, 0).
5.  Return the modified output grid. (Pixels that were not part of any gray shape remain unchanged from the initial copy).
```python
import numpy as np
from collections import deque

"""
Transformation rule:
1. Identify distinct contiguous shapes of non-white (0) and non-gray (5) colors in the input grid. These are "reference shapes". Store their relative pixel patterns (forms) and colors.
2. Identify distinct contiguous shapes of gray (5) color in the input grid. These are "target shapes".
3. For each target shape:
    a. Compare its relative pixel pattern (form) with the forms of all reference shapes.
    b. If a match is found with a reference shape, change the color of all pixels belonging to that target shape in the output grid to the color of the matching reference shape.
    c. If no match is found, change the color of all pixels belonging to that target shape in the output grid to the background color (white, 0).
4. All pixels not part of a gray target shape retain their original color in the output grid.
"""

def find_objects(grid, colors_to_find):
    """
    Finds all contiguous objects of specified colors in the grid.

    Args:
        grid (np.array): The input grid.
        colors_to_find (set): A set of color values to search for.

    Returns:
        list: A list of dictionaries, where each dictionary represents an object
              and contains:
              'color': The color of the object.
              'pixels': A list of (row, col) tuples for the object's pixels.
              'form': A tuple of sorted (row, col) tuples representing the
                      relative pixel coordinates (canonical form).
    """
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    objects = []
    
    for r in range(rows):
        for c in range(cols):
            color = grid[r, c]
            if color in colors_to_find and not visited[r, c]:
                obj_pixels = []
                q = deque([(r, c)])
                visited[r, c] = True
                min_r, min_c = r, c
                
                # Use BFS to find all connected pixels of the same color
                while q:
                    row, col = q.popleft()
                    obj_pixels.append((row, col))
                    min_r = min(min_r, row)
                    min_c = min(min_c, col)
                    
                    # Check 4 neighbors (up, down, left, right)
                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                        nr, nc = row + dr, col + dc
                        if 0 <= nr < rows and 0 <= nc < cols and \
                           not visited[nr, nc] and grid[nr, nc] == color:
                            visited[nr, nc] = True
                            q.append((nr, nc))
                            
                # Calculate relative coordinates (form)
                relative_pixels = sorted([(p_r - min_r, p_c - min_c) for p_r, p_c in obj_pixels])
                form = tuple(relative_pixels) # Use tuple for hashability
                
                objects.append({
                    'color': color,
                    'pixels': obj_pixels,
                    'form': form
                })
                
    return objects

def transform(input_grid):
    """
    Applies the transformation rule to the input grid.
    """
    # Initialize output_grid as a copy of the input
    output_grid = np.copy(input_grid)
    rows, cols = input_grid.shape

    # 1. Identify reference shapes (all non-white, non-gray colors)
    all_colors = set(np.unique(input_grid))
    reference_colors = all_colors - {0, 5} # Exclude white (0) and gray (5)
    
    # Handle edge case where there are no reference colors
    if not reference_colors:
        # If no references, all gray shapes become white
        reference_objects = []
    else:
        reference_objects = find_objects(input_grid, reference_colors)
    
    # Store reference forms and their colors
    reference_forms = {obj['form']: obj['color'] for obj in reference_objects}

    # 2. Identify target shapes (gray color 5)
    target_objects = find_objects(input_grid, {5})

    # 3. Iterate through target shapes and apply transformations
    for target_obj in target_objects:
        target_form = target_obj['form']
        matched = False
        
        # Check if the target form matches any reference form
        if target_form in reference_forms:
            # Match found: Recolor target shape with reference color
            new_color = reference_forms[target_form]
            for r, c in target_obj['pixels']:
                if 0 <= r < rows and 0 <= c < cols: # Ensure coordinates are valid
                     output_grid[r, c] = new_color
            matched = True
            
        if not matched:
            # No match found: Erase target shape (set to white 0)
            for r, c in target_obj['pixels']:
                 if 0 <= r < rows and 0 <= c < cols: # Ensure coordinates are valid
                    output_grid[r, c] = 0

    # 4. Pixels not part of a gray shape retain their original color (already handled by copying)
    return output_grid
```
```python
import numpy as np
from collections import deque

"""
Transformation Rule:
1. Identify "reference patterns": These are small, contiguous shapes of non-white (0), non-gray (5) colors. Exclude large structures like long lines (e.g., the blue separator often seen). Store each pattern's color, dimensions (height, width), and its 'form' - the set of relative coordinates of its colored pixels from its top-left corner.
2. Initialize the output grid as a copy of the input grid.
3. Create a boolean mask (`processed_mask`) of the same dimensions as the grid, initialized to False. This tracks pixels successfully colored by a pattern match.
4. Iterate through every possible top-left anchor position (r, c) in the input grid.
5. For each anchor (r, c):
    a. Iterate through each identified reference pattern.
    b. Check if a sub-grid of the pattern's dimensions, starting at (r, c), can fit within the input grid boundaries.
    c. If it fits, extract this sub-grid from the input grid.
    d. Compare the pattern of *gray* pixels within the sub-grid to the 'form' of the reference pattern. A match occurs if:
        i. For every relative coordinate (dr, dc) present in the reference pattern's form, the corresponding pixel `sub_grid[dr, dc]` is gray (5).
        ii. For every relative coordinate (dr, dc) *not* present in the reference pattern's form (within the pattern's bounding box), the corresponding pixel `sub_grid[dr, dc]` is *not* gray (5).
    e. If an exact match is found:
        i. Get the color of the matching reference pattern.
        ii. For each relative coordinate (dr, dc) in the reference pattern's form:
            - Calculate the absolute coordinate `(abs_r, abs_c) = (r + dr, c + dc)`.
            - Update the `output_grid[abs_r, abs_c]` to the pattern's color.
            - Mark `processed_mask[abs_r, abs_c] = True`.
        iii. Break the inner loop (stop checking other patterns for this anchor (r, c)), as a region can only match one pattern starting at a specific anchor.
6. After checking all anchors, perform a final cleanup: Iterate through the `output_grid`. If any pixel `(r, c)` is still gray (5) AND `processed_mask[r, c]` is False, change `output_grid[r, c]` to white (0).
7. Return the modified output grid.
"""

def find_objects_with_details(grid, colors_to_find):
    """
    Finds contiguous objects of specified colors, returning details including form.

    Args:
        grid (np.array): The input grid.
        colors_to_find (set): A set of color values to search for.

    Returns:
        list: A list of dictionaries, where each dictionary represents an object
              and contains:
              'color': The color of the object.
              'pixels': A set of (row, col) tuples for the object's pixels.
              'min_r', 'min_c': Coordinates of the top-left corner.
              'height', 'width': Dimensions of the bounding box.
              'form': A set of (dr, dc) relative coordinates from the top-left.
    """
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    objects = []

    for r in range(rows):
        for c in range(cols):
            color = grid[r, c]
            if color in colors_to_find and not visited[r, c]:
                obj_pixels_list = []
                q = deque([(r, c)])
                visited[r, c] = True
                min_r, min_c = r, c
                max_r, max_c = r, c

                # BFS to find all connected pixels
                while q:
                    row, col = q.popleft()
                    obj_pixels_list.append((row, col))
                    min_r = min(min_r, row)
                    min_c = min(min_c, col)
                    max_r = max(max_r, row)
                    max_c = max(max_c, col)

                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                        nr, nc = row + dr, col + dc
                        if 0 <= nr < rows and 0 <= nc < cols and \
                           not visited[nr, nc] and grid[nr, nc] == color:
                            visited[nr, nc] = True
                            q.append((nr, nc))

                # Calculate properties
                obj_pixels_set = set(obj_pixels_list)
                height = max_r - min_r + 1
                width = max_c - min_c + 1
                form = set((p_r - min_r, p_c - min_c) for p_r, p_c in obj_pixels_set)

                objects.append({
                    'color': color,
                    'pixels': obj_pixels_set,
                    'min_r': min_r,
                    'min_c': min_c,
                    'height': height,
                    'width': width,
                    'form': form
                })

    return objects

def filter_reference_patterns(objects, grid_rows, grid_cols):
    """Filters potential objects to identify true reference patterns."""
    patterns = []
    # Heuristic threshold to exclude large lines/structures
    # Exclude if object spans full grid width/height or is just very large
    max_reasonable_dim = max(grid_rows, grid_cols) * 0.8

    for obj in objects:
        is_separator_line = (
            obj['color'] == 1 and # Assuming blue lines are separators
            (obj['width'] >= max_reasonable_dim or obj['height'] >= max_reasonable_dim)
        )
        # Add other filtering conditions if needed (e.g., minimum size)
        is_too_small = len(obj['pixels']) < 2 # Exclude single pixels? Maybe not needed for this task.

        if not is_separator_line: # and not is_too_small:
             patterns.append(obj)
    return patterns


def transform(input_grid):
    """
    Applies the template-matching transformation rule to the input grid.
    """
    rows, cols = input_grid.shape
    output_grid = np.copy(input_grid)
    processed_mask = np.zeros_like(input_grid, dtype=bool)

    # 1. & 2. Identify and filter reference patterns
    all_colors = set(np.unique(input_grid))
    potential_ref_colors = all_colors - {0, 5} # Exclude white (0) and gray (5)
    if not potential_ref_colors: # Handle case with no references
        reference_patterns = []
    else:
        potential_objects = find_objects_with_details(input_grid, potential_ref_colors)
        reference_patterns = filter_reference_patterns(potential_objects, rows, cols)

    # 3. Iterate through grid anchors and try to match patterns
    for r in range(rows):
        for c in range(cols):
            # Optimization: Can skip if input[r,c] is not gray?
            # No, because a pattern might start here even if the top-left isn't gray,
            # but the *anchor point* logic implies we only *start* checking if the anchor
            # pixel could potentially be part of a match. Let's stick to the plan:
            # check every r,c as a potential top-left corner.

            for pattern in reference_patterns:
                p_h, p_w = pattern['height'], pattern['width']
                p_form = pattern['form']
                p_color = pattern['color']

                # Check bounds: Can the pattern fit starting at (r, c)?
                if r + p_h <= rows and c + p_w <= cols:
                    # Extract sub-grid
                    sub_grid = input_grid[r : r + p_h, c : c + p_w]

                    # Compare sub-grid's gray pixels to pattern form
                    match = True
                    pixels_to_color = [] # Store coords relative to (r,c) for this match

                    for dr in range(p_h):
                        for dc in range(p_w):
                            sub_pixel_is_gray = (sub_grid[dr, dc] == 5)
                            coord_in_form = ((dr, dc) in p_form)

                            if coord_in_form:
                                if not sub_pixel_is_gray:
                                    match = False
                                    break
                                else:
                                     # Only store the coordinates that should be colored
                                     pixels_to_color.append((dr, dc))
                            elif sub_pixel_is_gray: # Pixel is gray but shouldn't be based on pattern
                                match = False
                                break
                        if not match:
                            break

                    # If match found, update output and mask
                    if match:
                        for dr, dc in pixels_to_color: # Use the stored coordinates
                            abs_r, abs_c = r + dr, c + dc
                            # Check if not already processed by another pattern match
                            # This prevents overwriting parts of successful previous matches
                            # anchored elsewhere, which might happen with overlapping patterns.
                            # Only color if the target pixel in output is still gray
                            if output_grid[abs_r, abs_c] == 5:
                                output_grid[abs_r, abs_c] = p_color
                                processed_mask[abs_r, abs_c] = True

                        # Break from pattern loop for this anchor (r,c)
                        # Assumes only one pattern can match starting at a given anchor
                        break
            # End pattern loop
        # End col loop
    # End row loop

    # 4. Final cleanup: Change remaining, unprocessed gray pixels to white
    for r in range(rows):
        for c in range(cols):
            if output_grid[r, c] == 5 and not processed_mask[r, c]:
                output_grid[r, c] = 0

    return output_grid
```
