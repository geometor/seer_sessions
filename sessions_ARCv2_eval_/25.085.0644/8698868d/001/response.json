{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import Counter, defaultdict\nimport itertools\n\n\"\"\"\nNatural Language Program:\n1.  **Analyze Input:** Scan the input grid to identify the distinct colors present.\n2.  **Identify Placeholder Color:** Determine the 'placeholder' color (P). This is the color used for internal frame patterns and often surrounds standalone 'content' shapes. It's frequently the most common color after potential background/border colors, or acts as a separator.\n3.  **Find Objects:** Locate all contiguous regions of non-placeholder colors.\n4.  **Categorize Objects:**\n    a.  **Frame Objects:** Identify objects that form a rectangular border around an internal area filled entirely with the placeholder color (P). Note their border color (C_frame), bounding box, and the relative coordinates of the internal P pattern.\n    b.  **Content Objects:** Identify solid, contiguous objects of a single color (C_content) different from P, typically located within larger areas dominated by P. Note their color (C_content) and approximate location/region.\n5.  **Pair Frame and Content Objects:** Establish a one-to-one mapping between Frame objects and Content objects based on their relative spatial positions or the locations of the regions they occupy (e.g., horizontal alignment, quadrant mapping).\n6.  **Transform Frame Objects:** For each matched pair (Frame, Content):\n    a.  Create a new grid representing the transformed frame, using the Frame's original dimensions.\n    b.  Fill the border pixels with the Frame's border color (C_frame).\n    c.  Fill the interior pixels corresponding to the Frame's original internal P pattern with the Content object's color (C_content).\n7.  **Assemble Output:** Arrange the transformed Frame objects in a new grid, maintaining the same relative spatial arrangement they had in the input grid. The output grid's size is determined by the bounding box encompassing all transformed frames.\n\"\"\"\n\ndef find_contiguous_regions(grid, colors_to_find=None, ignore_colors=None):\n    \"\"\"Finds all contiguous regions for specified colors.\"\"\"\n    height, width = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    regions = defaultdict(list)\n\n    for r in range(height):\n        for c in range(width):\n            color = grid[r, c]\n            if visited[r, c]:\n                continue\n            \n            valid_color = True\n            if colors_to_find is not None and color not in colors_to_find:\n                valid_color = False\n            if ignore_colors is not None and color in ignore_colors:\n                valid_color = False\n\n            if not valid_color:\n                visited[r,c] = True # Mark as visited even if ignored/not sought\n                continue\n\n            region_coords = []\n            q = [(r, c)]\n            visited[r, c] = True\n            region_color = color\n\n            while q:\n                row, col = q.pop(0)\n                region_coords.append((row, col))\n\n                for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                    nr, nc = row + dr, col + dc\n                    if 0 <= nr < height and 0 <= nc < width and \\\n                       not visited[nr, nc] and grid[nr, nc] == region_color:\n                        visited[nr, nc] = True\n                        q.append((nr, nc))\n            \n            regions[region_color].append(set(region_coords))\n\n    return regions\n\ndef get_bounding_box(coords):\n    \"\"\"Calculates the bounding box of a set of coordinates.\"\"\"\n    if not coords:\n        return None\n    rows = [r for r, c in coords]\n    cols = [c for r, c in coords]\n    return min(rows), min(cols), max(rows), max(cols)\n\ndef get_relative_coords(coords, r_offset, c_offset):\n    \"\"\"Converts absolute coordinates to relative coordinates.\"\"\"\n    return set((r - r_offset, c - c_offset) for r, c in coords)\n\ndef determine_placeholder_color(grid, potential_frame_colors, potential_content_colors):\n    \"\"\"Heuristic to determine the placeholder color.\"\"\"\n    height, width = grid.shape\n    counts = Counter(grid.flatten())\n    \n    # Exclude colors known to be part of frames or content\n    exclude_colors = set(potential_frame_colors) | set(potential_content_colors)\n    \n    # Often the placeholder separates things, look for colors with high counts that aren't frames/content\n    most_common_non_object = None\n    max_count = -1\n    \n    sorted_counts = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n\n    for color, count in sorted_counts:\n        if color not in exclude_colors:\n             # Simple heuristic: highest count non-object color\n             # More advanced: color that forms large connected regions separating objects\n             # For now, let's try the most frequent non-frame/content color\n             # Let's refine: often it's the background separating frames, or the internal fill.\n             # Let's check if this color forms the largest connected region.\n             regions = find_contiguous_regions(grid, colors_to_find=[color])\n             if regions[color]:\n                 largest_region_size = max(len(r) for r in regions[color])\n                 # If it forms a significant background/separator region\n                 if largest_region_size > (height*width) * 0.1 or largest_region_size > 10: # Adjust threshold needed\n                     return color # Assume this is the placeholder\n\n\n    # Fallback if the above fails (e.g., small examples)\n    if sorted_counts:\n        for color, count in sorted_counts:\n             if color not in exclude_colors:\n                 return color # Take the most frequent non-frame/content\n\n    # If all colors are frame/content (unlikely), maybe return most frequent overall? Risky.\n    # Let's specifically check the fill color of potential frames identified earlier.\n    # This requires finding frames first, which needs the placeholder. Circular dependency.\n    \n    # Let's try another heuristic: color that is NOT on the edge of the grid\n    # This assumes placeholder isn't the absolute background touching edges.\n    \n    edge_colors = set(grid[0,:]) | set(grid[-1,:]) | set(grid[:,0]) | set(grid[:,-1])\n    \n    for color, count in sorted_counts:\n        if color not in exclude_colors and color not in edge_colors:\n            return color # Most frequent non-frame/content color that doesn't touch the edge\n\n    # Final desperate fallback: most frequent color overall.\n    if sorted_counts:\n        return sorted_counts[0][0]\n        \n    return 0 # Default to white if grid is empty or uniform?\n\n\ndef analyze_objects(grid, placeholder_color):\n    \"\"\"Identifies and categorizes frame and content objects.\"\"\"\n    height, width = grid.shape\n    all_regions = find_contiguous_regions(grid, ignore_colors={placeholder_color})\n    \n    frames = []\n    contents = []\n    potential_frame_colors = set()\n    potential_content_colors = set()\n\n    # First pass to identify potential types and colors\n    obj_id_counter = 0\n    all_objects_found = []\n    for color, regions_list in all_regions.items():\n        for region_coords in regions_list:\n             min_r, min_c, max_r, max_c = get_bounding_box(region_coords)\n             obj_height = max_r - min_r + 1\n             obj_width = max_c - min_c + 1\n             \n             is_potential_frame = False\n             internal_pattern_coords = set()\n             # Check if it forms a border around a placeholder region\n             if obj_height > 2 and obj_width > 2:\n                 is_border = True\n                 has_internal_placeholder = False\n                 for r in range(min_r + 1, max_r):\n                     for c in range(min_c + 1, max_c):\n                         coord = (r, c)\n                         if coord not in region_coords:\n                             if grid[r,c] == placeholder_color:\n                                 has_internal_placeholder = True\n                                 internal_pattern_coords.add(coord)\n                             else: # Internal pixel is neither border nor placeholder\n                                 is_border = False\n                                 break\n                     if not is_border: break\n                 \n                 # Check if border pixels are present\n                 border_present = False\n                 for r, c in region_coords:\n                     if r == min_r or r == max_r or c == min_c or c == max_c:\n                         border_present = True\n                         break\n                 \n                 if is_border and has_internal_placeholder and border_present:\n                     is_potential_frame = True\n\n             obj_data = {\n                 \"id\": obj_id_counter,\n                 \"color\": color,\n                 \"coords\": region_coords,\n                 \"bounds\": (min_r, min_c, max_r, max_c),\n                 \"is_potential_frame\": is_potential_frame,\n                 \"internal_placeholder_coords\": internal_pattern_coords if is_potential_frame else None,\n             }\n             all_objects_found.append(obj_data)\n             obj_id_counter += 1\n             \n             if is_potential_frame:\n                 potential_frame_colors.add(color)\n             else:\n                 # Assume non-frames are content for now\n                 potential_content_colors.add(color)\n\n    # Refine placeholder using identified potential frame/content colors\n    actual_placeholder_color = determine_placeholder_color(grid, potential_frame_colors, potential_content_colors)\n    \n    # Second pass to finalize categorization using the refined placeholder color\n    frames = []\n    contents = []\n    for obj in all_objects_found:\n        is_frame_final = False\n        internal_pattern_relative = None\n        \n        if obj[\"is_potential_frame\"]:\n            # Re-verify internal pattern with the actual placeholder color\n            min_r, min_c, max_r, max_c = obj[\"bounds\"]\n            all_internal_are_placeholder = True\n            verified_internal_coords = set()\n            if min_r+1 <= max_r-1 and min_c+1 <= max_c-1: # Check if there's an interior\n                for r in range(min_r + 1, max_r):\n                    for c in range(min_c + 1, max_c):\n                        if (r,c) not in obj[\"coords\"]: # If it's an internal pixel\n                             if grid[r,c] == actual_placeholder_color:\n                                 verified_internal_coords.add((r,c))\n                             else:\n                                 all_internal_are_placeholder = False\n                                 break\n                    if not all_internal_are_placeholder: break\n                \n                if all_internal_are_placeholder and verified_internal_coords: # Must have some placeholder inside\n                    is_frame_final = True\n                    internal_pattern_relative = get_relative_coords(verified_internal_coords, min_r, min_c)\n\n        if is_frame_final:\n            frames.append({\n                \"color\": obj[\"color\"],\n                \"bounds\": obj[\"bounds\"],\n                \"internal_pattern\": internal_pattern_relative,\n                \"height\": obj[\"bounds\"][2] - obj[\"bounds\"][0] + 1,\n                \"width\": obj[\"bounds\"][3] - obj[\"bounds\"][1] + 1,\n            })\n        else:\n            # Add objects that are confirmed *not* frames (using the final placeholder) to contents\n             min_r, min_c, max_r, max_c = obj[\"bounds\"]\n             center_r = (min_r + max_r) / 2\n             center_c = (min_c + max_c) / 2\n             contents.append({\n                \"color\": obj[\"color\"],\n                \"bounds\": obj[\"bounds\"],\n                \"center\": (center_r, center_c) # Use center for pairing\n            })\n            \n    return frames, contents, actual_placeholder_color\n\n\ndef pair_frames_contents(frames, contents, grid_shape):\n    \"\"\"Pairs frames and contents based on spatial relationship.\"\"\"\n    \n    if not frames or not contents:\n        return {}\n\n    # Simple case: if equal number, try pairing by order (e.g., top-to-bottom, left-to-right)\n    if len(frames) == len(contents):\n        # Sort frames and contents based on position (e.g., top-left corner)\n        sorted_frames = sorted(frames, key=lambda f: (f['bounds'][0], f['bounds'][1]))\n        sorted_contents = sorted(contents, key=lambda c: (c['bounds'][0], c['bounds'][1]))\n        \n        # Check if simple horizontal pairing works (like Ex1)\n        # Requires frames and contents to be roughly horizontally aligned in pairs\n        # This is too specific, let's try a more general region approach inspired by Ex2\n\n    # Region-based pairing (inspired by Ex2)\n    height, width = grid_shape\n    mid_r, mid_c = height // 2, width // 2\n\n    def get_region(bounds):\n        min_r, min_c, max_r, max_c = bounds\n        center_r = (min_r + max_r) / 2\n        center_c = (min_c + max_c) / 2\n        \n        if center_r < mid_r and center_c < mid_c: return \"TL\"\n        if center_r < mid_r and center_c >= mid_c: return \"TR\"\n        if center_r >= mid_r and center_c < mid_c: return \"BL\"\n        if center_r >= mid_r and center_c >= mid_c: return \"BR\"\n        # Add center/middle if needed, but quadrant might be enough\n\n    frame_regions = {get_region(f['bounds']): f for f in frames}\n    content_regions = {get_region(c['bounds']): c for c in contents}\n\n    pairing = {}\n\n    # Define the mapping based on example 2: Content Region -> Frame Region\n    region_map = {\n        \"TR\": \"TL\", # Content in TR maps to Frame in TL\n        \"BR\": \"TR\", # Content in BR maps to Frame in TR\n        \"BL\": \"ML\", # Content in BL maps to Frame in ML (Need to adjust region definition if ML needed)\n        \"MR\": \"MR\"  # Content in MR maps to Frame in MR (Need to adjust region definition if MR needed)\n    }\n    \n    # Let's reconsider Ex1: Left Frame (Blue), Left Content (Red). Right Frame (Yellow), Right Content (Green).\n    # If we use regions:\n    # Ex1: Blue Frame ~TL, Red Content ~BL. Yellow Frame ~TR, Green Content ~BR.\n    # Mapping: Content BL -> Frame TL, Content BR -> Frame TR.\n    \n    # Combined Hypothesis: Content location determines target Frame location.\n    mapping_rule = {}\n    if len(frames) == 2 and len(contents) == 2: # Likely Ex1 structure\n        # Assuming frames are roughly T/B or L/R aligned, and contents are too.\n        f_sorted = sorted(frames, key=lambda f: (f['bounds'][1], f['bounds'][0])) # Sort Left-to-Right\n        c_sorted = sorted(contents, key=lambda c: (c['bounds'][1], c['bounds'][0])) # Sort Left-to-Right\n        if len(f_sorted) == len(c_sorted): # Should be true here\n             for i in range(len(f_sorted)):\n                 pairing[f_sorted[i]['color'], tuple(f_sorted[i]['bounds'])] = c_sorted[i] # Pair frame with content at same index\n             return pairing\n\n    elif len(frames) > 0 and len(contents) > 0: # Try quadrant mapping (like Ex2 structure)\n        # Redefine regions more carefully if needed, e.g., 3x3 grid instead of 2x2\n        # For now, stick to 4 quadrants TL, TR, BL, BR\n        # Define the mapping based on observations (Ex1 & Ex2 combined logic attempt)\n        # Content Region -> Target Frame Region\n        region_map = { \n             \"BL\": \"TL\", # Ex1 Red -> Blue\n             \"BR\": \"TR\", # Ex1 Green -> Yellow & Ex2 Orange -> Green\n             \"TR\": \"TL\", # Ex2 Maroon -> Yellow (This contradicts Ex1 TR->TR!)\n             # Let's assume Ex2 mapping is dominant if > 2 pairs\n             # Ex2: Content TR -> Frame TL; Content BR -> Frame TR; Content BL -> Frame ML; Content MR -> Frame MR\n             # The regions ML and MR need better definition. Maybe relative to placeholder areas?\n             # This pairing logic is complex and task-specific.\n             # Let's use a simple proximity pairing for now as a fallback/alternative.\n             \n        # Proximity pairing: find the closest content for each frame\n        paired_contents = set()\n        for frame in frames:\n            frame_center_r = (frame['bounds'][0] + frame['bounds'][2]) / 2\n            frame_center_c = (frame['bounds'][1] + frame['bounds'][3]) / 2\n            \n            min_dist = float('inf')\n            best_content = None\n            \n            for content in contents:\n                content_id = (content['color'], tuple(content['bounds']))\n                if content_id in paired_contents:\n                    continue # Skip already paired content\n                    \n                dist = ((frame_center_r - content['center'][0])**2 + \n                        (frame_center_c - content['center'][1])**2)**0.5\n                \n                if dist < min_dist:\n                    min_dist = dist\n                    best_content = content\n            \n            if best_content:\n                 pairing[(frame['color'], tuple(frame['bounds']))] = best_content\n                 paired_contents.add((best_content['color'], tuple(best_content['bounds'])))\n\n        return pairing\n        \n    return {} # No pairing possible\n\n\ndef transform_frame(frame_data, content_color):\n    \"\"\"Creates the transformed frame grid.\"\"\"\n    height = frame_data['height']\n    width = frame_data['width']\n    border_color = frame_data['color']\n    internal_pattern = frame_data['internal_pattern']\n    \n    # Initialize with border color\n    transformed = np.full((height, width), border_color, dtype=int)\n    \n    # Fill internal pattern with content color\n    if internal_pattern:\n        for r_rel, c_rel in internal_pattern:\n             # Ensure relative coords are within bounds (should be by definition)\n             if 0 <= r_rel < height and 0 <= c_rel < width:\n                 transformed[r_rel, c_rel] = content_color\n                 \n    return transformed\n\ndef assemble_output(transformed_frames_map, original_frames):\n    \"\"\"Assembles the final output grid.\"\"\"\n    if not transformed_frames_map:\n        # Handle cases where no frames were found or transformed\n        # Maybe return an empty grid or based on task specifics?\n        # Let's assume at least one frame is expected if the input has them.\n        # If input truly had no frames, maybe return empty 1x1 grid?\n        return np.array([[0]], dtype=int) # Default fallback\n\n    # Find overall bounding box of original frames to determine layout\n    all_min_r, all_min_c = float('inf'), float('inf')\n    all_max_r, all_max_c = float('-inf'), float('-inf')\n    \n    for frame in original_frames:\n        min_r, min_c, max_r, max_c = frame['bounds']\n        all_min_r = min(all_min_r, min_r)\n        all_min_c = min(all_min_c, min_c)\n        all_max_r = max(all_max_r, max_r)\n        all_max_c = max(all_max_c, max_c)\n        \n    # Calculate output dimensions based on relative positions\n    output_height = 0\n    output_width = 0\n    frame_rel_positions = {}\n\n    for frame in original_frames:\n        frame_key = (frame['color'], tuple(frame['bounds']))\n        if frame_key in transformed_frames_map:\n            transformed_grid = transformed_frames_map[frame_key]\n            h, w = transformed_grid.shape\n            rel_r = frame['bounds'][0] - all_min_r\n            rel_c = frame['bounds'][1] - all_min_c\n            frame_rel_positions[frame_key] = (rel_r, rel_c)\n            output_height = max(output_height, rel_r + h)\n            output_width = max(output_width, rel_c + w)\n\n    # Create output grid (use a common background color? Example 1 output uses frame colors, Example 2 too)\n    # It seems the output grid contains *only* the transformed frames.\n    # Initialize with a color not present? Or determine dominant background if frames overlap?\n    # Let's initialize with 0 (white) and overwrite. If frames overlap, the later one wins.\n    output_grid = np.full((output_height, output_width), 0, dtype=int) # Use 0 as default background\n\n    # Place transformed frames (sort by original position to handle potential overlaps consistently?)\n    sorted_original_frames = sorted(original_frames, key=lambda f: (f['bounds'][0], f['bounds'][1]))\n\n    for frame in sorted_original_frames:\n        frame_key = (frame['color'], tuple(frame['bounds']))\n        if frame_key in transformed_frames_map:\n            transformed_grid = transformed_frames_map[frame_key]\n            h, w = transformed_grid.shape\n            rel_r, rel_c = frame_rel_positions[frame_key]\n            output_grid[rel_r:rel_r+h, rel_c:rel_c+w] = transformed_grid\n\n    return output_grid\n\n\ndef transform(input_grid):\n    \"\"\"\n    Transforms the input grid by identifying 'frame' objects and 'content' objects.\n    The internal pattern of each frame (made of a placeholder color) is replaced \n    by the color of a corresponding content object, based on their spatial relationship.\n    The transformed frames are then assembled into the output grid, maintaining their\n    relative positions.\n    \"\"\"\n    input_grid = np.array(input_grid, dtype=int)\n    height, width = input_grid.shape\n\n    # 1. Analyze objects to find frames, contents, and placeholder color\n    frames, contents, placeholder_color = analyze_objects(input_grid, None) # Pass None first, placeholder determined inside\n\n    if not frames or not contents:\n         # If no frames or no contents found, the transformation likely doesn't apply\n         # Return maybe an empty grid or the input? Task description unclear.\n         # Based on examples, output is derived from frames. No frames -> empty output?\n         print(\"Warning: No frames or contents found.\")\n         # Let's try returning a 1x1 black grid as a default signal\n         return np.array([[0]], dtype=int) \n\n    # 2. Pair frames with contents\n    pairing = pair_frames_contents(frames, contents, input_grid.shape)\n    \n    if not pairing:\n        print(\"Warning: Could not pair frames and contents.\")\n        return np.array([[0]], dtype=int) \n\n\n    # 3. Transform each frame based on its paired content\n    transformed_frames = {}\n    original_frame_map = {(f['color'], tuple(f['bounds'])): f for f in frames}\n\n    for frame_key, content_data in pairing.items():\n        if frame_key in original_frame_map:\n            original_frame_data = original_frame_map[frame_key]\n            content_color = content_data['color']\n            transformed_grid = transform_frame(original_frame_data, content_color)\n            transformed_frames[frame_key] = transformed_grid\n        else:\n             print(f\"Warning: Frame key {frame_key} from pairing not found in original frames.\")\n\n\n    # 4. Assemble the output grid\n    output_grid = assemble_output(transformed_frames, frames)\n\n    return output_grid.tolist() # Return as list of lists per requirement\n\n\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 5696,
    "candidates_token_count": 5809,
    "total_token_count": 11505,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 143.552736
}