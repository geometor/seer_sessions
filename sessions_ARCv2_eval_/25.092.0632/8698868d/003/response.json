{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nIdentify distinct colored shapes (frames) separated by a background/noise color. \nGroup these frames into two sets (Targets and Sources) based on spatial arrangement \nand potentially other properties like noise presence or size. Pair Target frames \nwith Source frames based on relative position within their groups. For each Target \nframe, replace pixels matching the noise color *within its bounding box* with the \nsolid color of its paired Source frame. Assemble the modified Target frames into \nthe output grid, maintaining their relative spatial arrangement.\n\"\"\"\n\n# --- Helper Function: Find Objects ---\ndef find_objects(grid):\n    \"\"\"\n    Finds all contiguous objects of the same color in the grid.\n    Uses Breadth-First Search (BFS).\n\n    Args:\n        grid (np.array): The input grid.\n\n    Returns:\n        list: A list of dictionaries, where each dictionary represents an object\n              with keys 'color', 'coords' (set of (r, c) tuples),\n              'bbox' (min_r, max_r, min_c, max_c), and 'size'.\n    \"\"\"\n    height, width = grid.shape\n    visited = np.zeros((height, width), dtype=bool)\n    objects = []\n    for r in range(height):\n        for c in range(width):\n            if not visited[r, c]:\n                color = grid[r, c]\n                coords = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                min_r, max_r, min_c, max_c = r, r, c, c\n\n                while q:\n                    row, col = q.popleft()\n                    coords.add((row, col))\n                    min_r = min(min_r, row)\n                    max_r = max(max_r, row)\n                    min_c = min(min_c, col)\n                    max_c = max(max_c, col)\n\n                    # Check neighbors (4-connectivity)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        if 0 <= nr < height and 0 <= nc < width and \\\n                           not visited[nr, nc] and grid[nr, nc] == color:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n\n                if len(coords) > 0:\n                    objects.append({\n                        'color': color,\n                        'coords': coords,\n                        'bbox': (min_r, max_r, min_c, max_c),\n                        'size': len(coords)\n                    })\n    return objects\n\n# --- Helper Function: Determine Noise Color ---\ndef determine_noise_color(grid, objects):\n    \"\"\"\n    Determines the noise/background color using heuristics.\n    Checks for colors frequently appearing inside the bounding boxes of other objects,\n    but not part of the object itself. Falls back to most frequent color if needed.\n\n    Args:\n        grid (np.array): The input grid.\n        objects (list): List of objects found by find_objects.\n\n    Returns:\n        int: The determined noise color.\n    \"\"\"\n    counts_inside_others = {}\n    non_noise_candidate_objects = [obj for obj in objects if obj['size'] > 1] # Ignore single pixels initially\n\n    for obj in non_noise_candidate_objects:\n        min_r, max_r, min_c, max_c = obj['bbox']\n        obj_color = obj['color']\n        # Check pixels *within* bbox but *not* part of the object\n        for r in range(min_r, max_r + 1):\n            for c in range(min_c, max_c + 1):\n                if (r, c) not in obj['coords']:\n                    pixel_color = grid[r, c]\n                    # Ensure this 'inside' pixel isn't part of another known large object\n                    is_part_of_other_obj = False\n                    for other_obj in non_noise_candidate_objects:\n                         # Check if the pixel belongs to another object AND that object isn't the current one\n                        if other_obj['color'] != obj_color and (r, c) in other_obj['coords']:\n                            is_part_of_other_obj = True\n                            break\n                    if not is_part_of_other_obj:\n                         counts_inside_others[pixel_color] = counts_inside_others.get(pixel_color, 0) + 1\n\n    if counts_inside_others:\n        # The color most frequently found *inside* other objects is likely the noise\n        noise_color = max(counts_inside_others, key=counts_inside_others.get)\n    else:\n        # Fallback: most frequent color overall\n        colors, counts = np.unique(grid, return_counts=True)\n        # Exclude the color of the largest object if possible, as background is often most frequent\n        largest_obj_color = -1\n        if objects:\n             objects.sort(key=lambda o: o['size'], reverse=True)\n             largest_obj_color = objects[0]['color']\n        \n        sorted_indices = np.argsort(counts)[::-1]\n        noise_color = colors[sorted_indices[0]]\n        if noise_color == largest_obj_color and len(colors) > 1:\n            # If most frequent is the largest object, pick the second most frequent\n            if len(sorted_indices) > 1:\n                 noise_color = colors[sorted_indices[1]]\n            # If only one color besides largest, that must be it (or maybe grid is just one object?)\n            # This fallback needs care, but the primary heuristic should work for the examples.\n\n    return noise_color\n\n# --- Main Transformation Function ---\ndef transform(input_grid):\n    \"\"\"\n    Transforms the input grid by identifying target and source frames,\n    filling noise in target frames using source frame colors, and\n    reassembling the modified target frames.\n    \"\"\"\n    grid = np.array(input_grid, dtype=int)\n    height, width = grid.shape\n\n    # 1. Find all distinct objects\n    all_objects = find_objects(grid)\n\n    # 2. Determine the noise color\n    if not all_objects: return grid.tolist() # Handle empty grid case\n    noise_color = determine_noise_color(grid, all_objects)\n\n    # 3. Filter out noise objects and get primary shapes\n    shapes = [obj for obj in all_objects if obj['color'] != noise_color]\n    if not shapes: return grid.tolist() # No non-noise shapes found\n\n    # 4. Group shapes into Targets and Sources\n    #    Heuristic: Divide spatially (e.g., top vs bottom half)\n    #    Refinement: Identify target group (contains noise, or larger objects)\n    shapes.sort(key=lambda o: (o['bbox'][0], o['bbox'][2])) # Sort by position\n    \n    targets = []\n    sources = []\n    \n    # Try splitting by median row of shape origins\n    median_row = np.median([s['bbox'][0] for s in shapes])\n    group1 = [s for s in shapes if s['bbox'][0] < median_row]\n    group2 = [s for s in shapes if s['bbox'][0] >= median_row]\n\n    # If split is uneven, try simple first half / second half\n    if len(group1) != len(group2) or not group1:\n        mid_point = len(shapes) // 2\n        group1 = shapes[:mid_point]\n        group2 = shapes[mid_point:]\n    \n    if len(group1) != len(group2) or not group1:\n         # Cannot form two equal groups, fallback or error\n         # For this problem, examples suggest equal groups are expected.\n         # If logic fails, returning original might be safest in ARC.\n         # print(\"Warning: Could not divide shapes into two equal groups.\")\n         return grid.tolist() \n\n    # Determine which group is Target (contains noise within bbox)\n    group1_has_noise = False\n    for obj in group1:\n        min_r, max_r, min_c, max_c = obj['bbox']\n        for r in range(min_r, max_r + 1):\n            for c in range(min_c, max_c + 1):\n                if grid[r,c] == noise_color and (r,c) not in obj['coords']:\n                     # Check if noise belongs to another non-noise shape within bbox? (Less strict here)\n                     is_other_shape = False\n                     for other in shapes:\n                         if other != obj and (r,c) in other['coords']:\n                             is_other_shape = True\n                             break\n                     if not is_other_shape:\n                        group1_has_noise = True\n                        break\n            if group1_has_noise: break\n    \n    group2_has_noise = False\n    for obj in group2:\n        min_r, max_r, min_c, max_c = obj['bbox']\n        for r in range(min_r, max_r + 1):\n            for c in range(min_c, max_c + 1):\n                 if grid[r,c] == noise_color and (r,c) not in obj['coords']:\n                     is_other_shape = False\n                     for other in shapes:\n                         if other != obj and (r,c) in other['coords']:\n                             is_other_shape = True\n                             break\n                     if not is_other_shape:\n                         group2_has_noise = True\n                         break\n            if group2_has_noise: break\n\n    # Assign Target/Source based on noise presence\n    if group1_has_noise and not group2_has_noise:\n        targets = group1\n        sources = group2\n    elif group2_has_noise and not group1_has_noise:\n        targets = group2\n        sources = group1\n    else: # Ambiguous case (both/neither have noise, or noise detection failed)\n          # Use size heuristic (seen in Example 2 analysis)\n          avg_size1 = sum(s['size'] for s in group1) / len(group1)\n          avg_size2 = sum(s['size'] for s in group2) / len(group2)\n          if avg_size1 >= avg_size2: # Default to group1 if equal\n              targets = group1\n              sources = group2\n          else:\n              targets = group2\n              sources = group1\n\n    # Ensure sorting within groups for consistent pairing\n    targets.sort(key=lambda o: (o['bbox'][0], o['bbox'][2]))\n    sources.sort(key=lambda o: (o['bbox'][0], o['bbox'][2]))\n\n    # 5. Modify Target Frames\n    modified_targets_data = []\n    for target, source in zip(targets, sources):\n        min_r, max_r, min_c, max_c = target['bbox']\n        filler_color = source['color']\n\n        # Extract subgrid based on target's bounding box\n        subgrid = grid[min_r:max_r+1, min_c:max_c+1].copy()\n\n        # Replace noise pixels within this subgrid\n        subgrid[subgrid == noise_color] = filler_color\n\n        modified_targets_data.append({\n            'bbox': target['bbox'], # Store original bbox for layout\n            'subgrid': subgrid\n        })\n\n    # 6. Assemble Output Grid\n    if not modified_targets_data:\n        return grid.tolist() # Should not happen if groups were found\n\n    # Calculate relative positions and final grid size\n    min_target_r = min(t['bbox'][0] for t in modified_targets_data)\n    min_target_c = min(t['bbox'][2] for t in modified_targets_data)\n\n    max_output_r = 0\n    max_output_c = 0\n    output_layout = []\n\n    for data in modified_targets_data:\n        bbox = data['bbox']\n        subgrid = data['subgrid']\n        h, w = subgrid.shape\n        # Position relative to the top-leftmost target's origin\n        rel_r = bbox[0] - min_target_r\n        rel_c = bbox[2] - min_target_c\n\n        output_layout.append({\n            'rel_r': rel_r,\n            'rel_c': rel_c,\n            'subgrid': subgrid,\n            'h': h,\n            'w': w\n        })\n        # Update max dimensions needed\n        max_output_r = max(max_output_r, rel_r + h)\n        max_output_c = max(max_output_c, rel_c + w)\n\n    # Create and populate the output grid\n    # Initialize with 0 (white), assuming it's not a significant color in outputs\n    output_grid = np.zeros((max_output_r, max_output_c), dtype=int)\n\n    for layout_info in output_layout:\n        r, c = layout_info['rel_r'], layout_info['rel_c']\n        h, w = layout_info['h'], layout_info['w']\n        subgrid = layout_info['subgrid']\n        output_grid[r:r+h, c:c+w] = subgrid\n\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 26209,
    "candidates_token_count": 3178,
    "total_token_count": 29387,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 33.763154,
  "retries": 1
}