{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom typing import List, Tuple, Dict, Set\n\n\"\"\"\nIdentify all distinct objects (connected groups of non-white pixels) in the input grid. \nDetermine the color of each object. \nFind the median color value among the unique object colors. \nLocate the object in the input grid that corresponds to this median color. \nCalculate the minimal bounding box containing this object. \nExtract the subgrid defined by this bounding box from the input grid to create the output grid.\n\"\"\"\n\ndef find_objects(grid: np.ndarray) -> Dict[int, List[Tuple[int, int]]]:\n    \"\"\"\n    Finds all distinct objects (contiguous non-background pixels of the same color) \n    in the grid using Breadth-First Search (BFS).\n    Assumes 4-connectivity (up, down, left, right).\n\n    Args:\n        grid: The input numpy array representing the grid.\n\n    Returns:\n        A dictionary where keys are the object colors and values are lists of \n        (row, col) tuples representing the pixels belonging to that object.\n    \"\"\"\n    height, width = grid.shape\n    visited: Set[Tuple[int, int]] = set()\n    objects: Dict[int, List[Tuple[int, int]]] = {}\n\n    for r in range(height):\n        for c in range(width):\n            if (r, c) in visited or grid[r, c] == 0:\n                continue\n\n            color = grid[r, c]\n            obj_pixels: List[Tuple[int, int]] = []\n            q: List[Tuple[int, int]] = [(r, c)]\n            visited.add((r, c))\n\n            while q:\n                row, col = q.pop(0)\n                obj_pixels.append((row, col))\n\n                # Explore neighbors (4-connectivity)\n                for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                    nr, nc = row + dr, col + dc\n                    if 0 <= nr < height and 0 <= nc < width and \\\n                       (nr, nc) not in visited and grid[nr, nc] == color:\n                        visited.add((nr, nc))\n                        q.append((nr, nc))\n            \n            # Store the found object pixels, merging if color already exists (shouldn't happen with distinct objects assumption)\n            if color not in objects:\n                 objects[color] = []\n            objects[color].extend(obj_pixels) # Using extend might be incorrect if objects of the same color aren't connected, but description implies distinct objects. Let's stick to the definition.\n            # If the problem implies separate regions of the same color are different objects, the logic needs adjustment.\n            # However, based on examples, it seems each color represents one distinct object. So storing by color directly is okay.\n            # If colors could repeat for *different* objects, we'd need a different structure, like List[Tuple[int, List[Tuple[int, int]]]].\n            # Given the median logic, it seems likely we only care about the unique colors present.\n\n    return objects\n\ndef get_bounding_box(pixels: List[Tuple[int, int]]) -> Tuple[int, int, int, int]:\n    \"\"\"\n    Calculates the minimum bounding box for a list of pixel coordinates.\n\n    Args:\n        pixels: A list of (row, col) tuples.\n\n    Returns:\n        A tuple (min_row, max_row, min_col, max_col).\n    \"\"\"\n    if not pixels:\n        return (0, 0, 0, 0) # Should not happen with valid objects\n\n    rows = [r for r, c in pixels]\n    cols = [c for r, c in pixels]\n    \n    min_row = min(rows)\n    max_row = max(rows)\n    min_col = min(cols)\n    max_col = max(cols)\n\n    return min_row, max_row, min_col, max_col\n\ndef transform(input_grid: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Transforms the input grid according to the specified rules:\n    1. Finds all objects.\n    2. Gets their colors.\n    3. Finds the median color.\n    4. Selects the object with the median color.\n    5. Extracts its bounding box.\n    \"\"\"\n    # 1. Identify all distinct objects and their colors\n    objects_by_color = find_objects(input_grid)\n    \n    # 2. Get the unique object colors\n    object_colors = list(objects_by_color.keys())\n    \n    # 3. Sort the colors and find the median\n    # Assuming exactly 3 objects as observed in training examples\n    if len(object_colors) != 3:\n         # Fallback or error handling if assumption is wrong\n         # For now, let's proceed assuming 3. If test cases fail, revisit.\n         print(f\"Warning: Expected 3 objects, found {len(object_colors)}. Using median logic anyway.\")\n         if not object_colors:\n             return np.array([[]]) # Return empty if no objects\n         object_colors.sort()\n         median_index = len(object_colors) // 2\n         median_color = object_colors[median_index]\n\n    else:\n        object_colors.sort()\n        median_color = object_colors[1] # Median of 3 sorted numbers is the middle one\n\n    # 4. Get the pixels of the object with the median color\n    median_object_pixels = objects_by_color[median_color]\n    \n    # 5. Calculate the bounding box for the median object\n    min_row, max_row, min_col, max_col = get_bounding_box(median_object_pixels)\n    \n    # 6. Extract the subgrid defined by the bounding box\n    # Note: Slicing is exclusive of the end index, so add 1 to max values\n    output_grid = input_grid[min_row : max_row + 1, min_col : max_col + 1]\n    \n    return output_grid\n\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 2775,
    "candidates_token_count": 1423,
    "total_token_count": 4198,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 14.665149
}