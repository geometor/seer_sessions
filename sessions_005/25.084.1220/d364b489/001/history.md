
## train_1

**input:**
```
0 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0
1 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1
```


**output:**
```
0 0 0 0 7 1 6 0 0 0
2 0 0 0 0 8 0 0 0 0
1 6 0 0 0 0 0 0 0 2
8 0 0 0 0 0 0 0 7 1
0 0 0 0 0 2 0 0 0 8
0 0 0 0 7 1 6 0 0 0
0 0 0 0 0 8 0 0 0 0
0 0 2 0 0 0 0 0 0 0
0 7 1 6 0 0 0 0 0 2
0 0 8 0 0 0 0 0 7 1
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1
0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 2 0 0 0
0 0 0 0 0 7 1 6 0 0
0 0 0 0 0 0 8 0 0 2
0 0 0 0 0 0 0 0 7 1
0 0 0 2 0 0 0 0 0 8
0 0 7 1 6 0 0 0 0 0
0 0 0 8 0 0 0 2 0 0
0 0 0 0 0 0 7 1 6 0
0 2 0 0 0 0 0 8 0 0
7 1 6 0 0 0 0 0 0 0
```

Okay, let's analyze the task based on the provided examples.

## Perception

1.  **Input/Output Grids:** Both input and output grids have the same dimensions (10x10 in the examples).
2.  **Colors:** The input grids contain only white (0) and blue (1) pixels. The output grids contain white (0), blue (1), red (2), orange (7), magenta (6), and azure (8) pixels.
3.  **Persistence:** The blue (1) pixels from the input grid remain in the same positions in the output grid.
4.  **Transformation:** New colored pixels (red, orange, magenta, azure) appear in the output grid. Their positions are relative to the positions of the blue (1) pixels in the input.
5.  **Pattern:** Around each blue pixel at location `(r, c)`, a specific pattern of four colored pixels is placed, provided the target location is within the grid boundaries and is currently white (0). The pattern is:
    *   Red (2) at `(r-1, c)` (one step above)
    *   Orange (7) at `(r, c-1)` (one step left)
    *   Magenta (6) at `(r, c+1)` (one step right)
    *   Azure (8) at `(r+1, c)` (one step below)
6.  **Boundary Handling:** If a part of the pattern falls outside the grid dimensions, that part is simply omitted.
7.  **Overlap Handling:** Based on the examples, it appears that pattern pixels are only placed onto cells that are initially white (0) in the input grid (or equivalently, white in the output grid before placing the pattern for the current blue pixel). This prevents overwriting existing blue pixels or parts of patterns generated by other blue pixels.

## Facts


```yaml
task_type: pattern_application
input_grid:
  description: A 2D grid containing primarily white pixels (0) and a sparse distribution of blue pixels (1).
  properties:
    - dimensions: variable (e.g., 10x10)
    - pixel_colors: [0, 1]
output_grid:
  description: A 2D grid derived from the input grid, with the original blue pixels preserved and additional colored pixels added around them.
  properties:
    - dimensions: same as input grid
    - pixel_colors: [0, 1, 2, 6, 7, 8]
objects:
  - type: pixel
    properties:
      - color: A value from 0-9.
      - position: (row, column) coordinates.
  - type: pattern
    description: A specific arrangement of colored pixels relative to a central point.
    properties:
      - shape: '+' shape (excluding center)
      - colors: [red(2), orange(7), magenta(6), azure(8)]
      - relative_positions:
          - red: (-1, 0)
          - orange: (0, -1)
          - magenta: (0, +1)
          - azure: (+1, 0)
actions:
  - name: find_pixels
    input: input_grid, color_value (blue=1)
    output: list of coordinates [(r1, c1), (r2, c2), ...]
  - name: apply_pattern
    input: target_grid, center_coordinate (r, c), pattern_definition
    output: modified_target_grid
    constraints:
      - Only apply pattern pixel if target coordinate is within grid bounds.
      - Only apply pattern pixel if target cell color is white (0).
relationships:
  - The output grid is initialized as a copy of the input grid.
  - Each blue pixel (1) in the input grid acts as an anchor point for placing the pattern in the output grid.
  - The position of each pattern pixel in the output is relative to the position of its corresponding blue anchor pixel.
```


## Natural Language Program

1.  Create a copy of the input grid; this will be the basis for the output grid.
2.  Identify the coordinates `(r, c)` of all blue (1) pixels in the input grid.
3.  For each identified blue pixel coordinate `(r, c)`:
    a.  Define the relative positions and colors of the pattern pixels:
        i.   `(-1, 0)`: red (2)
        ii.  `(0, -1)`: orange (7)
        iii. `(0, +1)`: magenta (6)
        iv.  `(+1, 0)`: azure (8)
    b.  For each relative position `(dr, dc)` and corresponding color `col` in the pattern:
        i.   Calculate the target absolute coordinate `(tr, tc) = (r + dr, c + dc)`.
        ii.  Check if the target coordinate `(tr, tc)` is within the bounds of the grid.
        iii. If the target coordinate is within bounds, check if the pixel at `(tr, tc)` in the *current state* of the output grid is white (0).
        iv.  If the coordinate is within bounds AND the pixel at that location is white (0), update the pixel at `(tr, tc)` in the output grid to the pattern color `col`.
4.  Return the final modified output grid.
