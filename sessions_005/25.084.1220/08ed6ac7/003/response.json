{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom typing import List, Dict, Tuple\n\n\"\"\"\nProcesses a grid by identifying columns containing gray pixels (5).\nThese columns are ranked based first on the count of gray pixels (ascending)\nand secondarily by their column index (ascending).\nThe gray pixels in each ranked column are then replaced with a specific color\nbased on their rank: Rank 1 -> Yellow (4), Rank 2 -> Green (3),\nRank 3 -> Red (2), Rank 4 -> Blue (1). All other pixels remain unchanged.\nAssumes exactly four such columns exist.\n\"\"\"\n\ndef _find_and_rank_gray_columns(input_grid: np.ndarray) -> List[Dict]:\n    \"\"\"\n    Identifies columns containing gray pixels, counts them, and ranks the columns.\n\n    Args:\n        input_grid: A numpy array representing the input grid.\n\n    Returns:\n        A sorted list of dictionaries, each containing 'index' (column index)\n        and 'count' (number of gray pixels) for relevant columns. The list is\n        sorted by count (ascending) and then index (ascending).\n    \"\"\"\n    gray_columns_info = []\n    height, width = input_grid.shape\n    gray_color = 5\n\n    # 1. Identify Target Columns: Find columns with gray pixels and count them.\n    for col_idx in range(width):\n        column = input_grid[:, col_idx]\n        gray_count = np.sum(column == gray_color)\n        if gray_count > 0:\n            gray_columns_info.append({'index': col_idx, 'count': gray_count})\n\n    # 2. Rank Columns: Sort by count (asc) then index (asc).\n    #    The lambda function returns a tuple for sorting: (count, index)\n    sorted_columns = sorted(gray_columns_info, key=lambda x: (x['count'], x['index']))\n\n    return sorted_columns\n\ndef transform(input_grid: List[List[int]]) -> List[List[int]]:\n    \"\"\"\n    Applies the transformation rule to the input grid.\n\n    Args:\n        input_grid: A list of lists representing the input grid.\n\n    Returns:\n        A list of lists representing the transformed output grid.\n    \"\"\"\n    # Convert input to numpy array for easier processing\n    input_np = np.array(input_grid, dtype=int)\n\n    # Initialize output_grid as a copy of the input\n    output_grid = np.copy(input_np)\n    height = input_np.shape[0]\n    gray_color = 5\n\n    # Steps 1 & 2: Identify and Rank gray columns\n    ranked_columns = _find_and_rank_gray_columns(input_np)\n\n    # 3. Determine Replacement Colors based on rank (0-based index from sorted list)\n    #    Rank 1 (index 0) -> Yellow (4)\n    #    Rank 2 (index 1) -> Green (3)\n    #    Rank 3 (index 2) -> Red (2)\n    #    Rank 4 (index 3) -> Blue (1)\n    #    We assume there will always be exactly 4 columns based on examples.\n    rank_to_color = {\n        0: 4, # Rank 1 -> Yellow\n        1: 3, # Rank 2 -> Green\n        2: 2, # Rank 3 -> Red\n        3: 1  # Rank 4 -> Blue\n    }\n\n    # 4. Apply Transformation: Iterate through ranked columns and replace gray pixels\n    for rank_idx, col_info in enumerate(ranked_columns):\n        col_index = col_info['index']\n        # Get the replacement color for the current rank\n        replacement_color = rank_to_color.get(rank_idx)\n\n        if replacement_color is not None:\n            # Iterate through rows of this specific column\n            for row_idx in range(height):\n                # Check if the pixel in the *original* input grid was gray\n                if input_np[row_idx, col_index] == gray_color:\n                    # Replace the gray pixel with the determined color in the output grid\n                    output_grid[row_idx, col_index] = replacement_color\n        # else: handle cases where rank_idx might be outside 0-3 if assumption is wrong (optional, not needed based on examples)\n\n    # Convert back to list of lists for the expected output format\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 7226,
    "candidates_token_count": 1029,
    "total_token_count": 8255,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 11.780316
}