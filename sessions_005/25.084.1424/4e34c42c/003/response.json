{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nThis program transforms an input grid based on identifying specific non-background objects and arranging them according to certain criteria.\n\n1.  Identify the background color (most frequent color).\n2.  Find all distinct objects (contiguous non-background pixels using 8-way connectivity).\n3.  Determine a selection criterion:\n    - 'maroon_adj': Objects adjacent (8-way) to maroon (9) pixels.\n    - 'azure_contain': Objects containing azure (8) pixels.\n    Only one criterion will apply per grid.\n4.  Select objects matching the criterion.\n5.  Calculate the bounding box for each selected object:\n    - If 'maroon_adj', include the object pixels AND adjacent maroon pixels.\n    - If 'azure_contain', include ONLY the object pixels.\n6.  Determine assembly order based on the minimum column index of the object's original pixels:\n    - If 'maroon_adj', sort right-to-left (descending min_col).\n    - If 'azure_contain', sort left-to-right (ascending min_col).\n7.  Extract the subgrids corresponding to the calculated bounding boxes.\n8.  Concatenate the extracted subgrids horizontally in the determined order to form the output grid.\n\"\"\"\n\n# --- Helper Functions ---\n\ndef find_most_frequent_color(grid):\n    \"\"\"Finds the most frequent color (integer value) in the grid.\"\"\"\n    unique, counts = np.unique(grid, return_counts=True)\n    if not unique.size:\n        return 0 # Default background if grid is empty\n    return unique[np.argmax(counts)]\n\ndef find_objects(grid, background_color):\n    \"\"\"\n    Finds all distinct objects (contiguous non-background pixels) using 8-way connectivity.\n    Returns a list of objects, where each object is represented by a list of its pixel coordinates [(r1, c1), (r2, c2), ...].\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n    \n    # Define 8 neighbors (relative coordinates)\n    neighbors = [(-1, -1), (-1, 0), (-1, 1),\n                 (0, -1),          (0, 1),\n                 (1, -1), (1, 0), (1, 1)]\n\n    for r in range(rows):\n        for c in range(cols):\n            if grid[r, c] != background_color and not visited[r, c]:\n                # Start BFS to find a new object\n                current_object_pixels = []\n                q = deque([(r, c)])\n                visited[r, c] = True\n                \n                while q:\n                    curr_r, curr_c = q.popleft()\n                    current_object_pixels.append((curr_r, curr_c))\n                    \n                    # Explore neighbors\n                    for dr, dc in neighbors:\n                        nr, nc = curr_r + dr, curr_c + dc\n                        \n                        # Check bounds\n                        if 0 <= nr < rows and 0 <= nc < cols:\n                            # Check if neighbor is part of an object and not visited\n                            if grid[nr, nc] != background_color and not visited[nr, nc]:\n                                visited[nr, nc] = True\n                                q.append((nr, nc))\n                                \n                if current_object_pixels:\n                    objects.append(np.array(current_object_pixels)) # Store as numpy array for easier slicing later\n                    \n    return objects\n\ndef get_adjacent_pixels_of_color(grid, obj_pixels_set, target_color):\n    \"\"\"\n    Finds all pixels of target_color adjacent (8-way) to any pixel in obj_pixels_set.\n    Args:\n        grid (np.array): The input grid.\n        obj_pixels_set (set): A set of (r, c) tuples representing the object's pixels.\n        target_color (int): The color to search for in adjacent cells.\n    Returns:\n        set: A set of (r, c) tuples for adjacent pixels of target_color.\n    \"\"\"\n    rows, cols = grid.shape\n    adjacent_coords = set()\n    neighbors = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n\n    for r, c in obj_pixels_set:\n        for dr, dc in neighbors:\n            nr, nc = r + dr, c + dc\n            if 0 <= nr < rows and 0 <= nc < cols:\n                # Check if the neighbor has the target color AND is not part of the object itself\n                if grid[nr, nc] == target_color and (nr, nc) not in obj_pixels_set:\n                    adjacent_coords.add((nr, nc))\n    return adjacent_coords\n\ndef check_adjacency(grid, obj_pixels_set, adj_color):\n    \"\"\"Checks if any pixel of the object is adjacent (8-way) to the adj_color.\"\"\"\n    rows, cols = grid.shape\n    neighbors = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n    for r, c in obj_pixels_set:\n        for dr, dc in neighbors:\n            nr, nc = r + dr, c + dc\n            if 0 <= nr < rows and 0 <= nc < cols and grid[nr, nc] == adj_color:\n                 # Ensure the adjacent pixel isn't part of the object itself (relevant if obj can contain adj_color)\n                 if (nr, nc) not in obj_pixels_set:\n                     return True\n    return False\n\ndef check_containment(grid, obj_pixels, contain_color):\n    \"\"\"Checks if any pixel within the object has the contain_color.\"\"\"\n    for r, c in obj_pixels:\n        if grid[r, c] == contain_color:\n            return True\n    return False\n\ndef get_bounding_box(pixels):\n    \"\"\"Calculates the bounding box (min_r, min_c, max_r, max_c) for a set of pixel coordinates.\"\"\"\n    if not pixels: # Handle empty list/set\n        return None\n    \n    pixels_np = np.array(list(pixels)) # Convert set or list of tuples to numpy array\n    if pixels_np.size == 0:\n        return None\n        \n    min_row = np.min(pixels_np[:, 0])\n    min_col = np.min(pixels_np[:, 1])\n    max_row = np.max(pixels_np[:, 0])\n    max_col = np.max(pixels_np[:, 1])\n    return min_row, min_col, max_row, max_col\n\n# --- Main Transformation Function ---\n\ndef transform(input_grid):\n    \"\"\"\n    Transforms the input grid by selecting objects based on adjacency to maroon (9)\n    or containment of azure (8), calculating their bounding boxes (conditionally\n    including adjacent maroon), sorting them (right-to-left for maroon, left-to-right\n    for azure), and concatenating their extracted subgrids horizontally.\n    \"\"\"\n    input_np = np.array(input_grid, dtype=int)\n    if input_np.size == 0:\n        return [] # Handle empty input\n\n    # 1. Identify background color\n    background_color = find_most_frequent_color(input_np)\n\n    # 2. Identify all distinct non-background objects\n    # Objects are returned as a list of numpy arrays, each array containing [(r,c), ...] coordinates\n    all_objects = find_objects(input_np, background_color)\n\n    if not all_objects:\n        return [] # No objects found\n\n    target_objects_info = []\n    criterion = None # 'maroon_adj' or 'azure_contain'\n    maroon_color = 9\n    azure_color = 8\n\n    # 3 & 4. Determine selection rule and filter objects\n    objects_with_maroon_adj = []\n    objects_with_azure_contain = []\n\n    for idx, obj_pixels in enumerate(all_objects):\n        if obj_pixels.size == 0:\n            continue\n        \n        obj_pixels_set = set(map(tuple, obj_pixels)) # Use set for faster lookups\n\n        # Check for maroon adjacency\n        if check_adjacency(input_np, obj_pixels_set, maroon_color):\n            objects_with_maroon_adj.append(idx)\n            \n        # Check for azure containment\n        if check_containment(input_np, obj_pixels, azure_color):\n             objects_with_azure_contain.append(idx)\n\n    # Determine the criterion based on which list is non-empty\n    target_indices = []\n    if objects_with_maroon_adj:\n        criterion = 'maroon_adj'\n        target_indices = objects_with_maroon_adj\n    elif objects_with_azure_contain:\n        criterion = 'azure_contain'\n        target_indices = objects_with_azure_contain\n    else:\n        # No matching objects found based on the known criteria\n        return []\n\n    # 5. Calculate bounding boxes for target objects\n    for obj_idx in target_indices:\n        obj_pixels = all_objects[obj_idx]\n        obj_pixels_set = set(map(tuple, obj_pixels)) # Convert to set for efficiency\n\n        if criterion == 'maroon_adj':\n            # Include adjacent maroon pixels in the bounding box calculation\n            adj_maroon_pixels_set = get_adjacent_pixels_of_color(input_np, obj_pixels_set, maroon_color)\n            all_pixels_for_bbox = obj_pixels_set.union(adj_maroon_pixels_set)\n            bbox = get_bounding_box(all_pixels_for_bbox)\n        elif criterion == 'azure_contain':\n            # Bounding box includes only the object pixels\n            bbox = get_bounding_box(obj_pixels_set)\n        else: # Should not happen if target_indices is populated\n             continue\n\n        if bbox:\n            # Calculate min_col based on the *original object pixels* for sorting\n            min_r_obj, min_c_obj, max_r_obj, max_c_obj = get_bounding_box(obj_pixels_set)\n            \n            target_objects_info.append({\n                \"index\": obj_idx,\n                \"bbox\": bbox, # Bbox used for extraction\n                \"min_col_obj\": min_c_obj # Min col of original object used for sorting\n            })\n\n    # 6. Determine assembly order\n    if criterion == 'maroon_adj':\n        # Sort descending by min_col_obj (right-to-left)\n        target_objects_info.sort(key=lambda x: x['min_col_obj'], reverse=True)\n    elif criterion == 'azure_contain':\n        # Sort ascending by min_col_obj (left-to-right)\n        target_objects_info.sort(key=lambda x: x['min_col_obj'], reverse=False)\n\n    # 7. Extract subgrids\n    extracted_subgrids = []\n    for obj_info in target_objects_info:\n        min_r, min_c, max_r, max_c = obj_info['bbox']\n        # Extract using the calculated bounding box\n        subgrid = input_np[min_r : max_r + 1, min_c : max_c + 1]\n        extracted_subgrids.append(subgrid)\n\n    # 8. Concatenate horizontally\n    if not extracted_subgrids:\n        return [] \n\n    # Check if all subgrids have the same height before concatenating\n    first_height = extracted_subgrids[0].shape[0]\n    if not all(sg.shape[0] == first_height for sg in extracted_subgrids):\n        # This case indicates a potential issue in logic or assumptions, \n        # as examples suggested consistent heights. Return empty for now.\n        print(f\"Warning: Subgrids have different heights: {[sg.shape for sg in extracted_subgrids]}\")\n        return []\n\n    try:\n        output_np = np.concatenate(extracted_subgrids, axis=1)\n    except ValueError as e:\n        # Fallback in case concatenation fails unexpectedly\n        print(f\"Error concatenating subgrids: {e}\")\n        return []\n\n    # Convert final numpy array back to list of lists\n    output_grid = output_np.tolist()\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 6121,
    "candidates_token_count": 2973,
    "total_token_count": 9094,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 28.153354
}