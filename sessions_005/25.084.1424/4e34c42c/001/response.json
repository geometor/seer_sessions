{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom scipy.ndimage import label, find_objects, binary_dilation, generate_binary_structure\n\ndef find_most_frequent_color(grid):\n    \"\"\"Finds the most frequent color in the grid.\"\"\"\n    unique, counts = np.unique(grid, return_counts=True)\n    return unique[np.argmax(counts)]\n\ndef get_object_pixels(labeled_grid, obj_label):\n    \"\"\"Gets the coordinates of pixels belonging to a specific object label.\"\"\"\n    return np.argwhere(labeled_grid == obj_label)\n\ndef get_bounding_box(pixels):\n    \"\"\"Calculates the bounding box (min_row, min_col, max_row, max_col) for a set of pixels.\"\"\"\n    if not pixels.size:\n        return None\n    min_row = np.min(pixels[:, 0])\n    min_col = np.min(pixels[:, 1])\n    max_row = np.max(pixels[:, 0])\n    max_col = np.max(pixels[:, 1])\n    return min_row, min_col, max_row, max_col\n\ndef check_adjacency(grid, obj_pixels, adj_color):\n    \"\"\"Checks if any pixel of the object is adjacent (including diagonals) to the adj_color.\"\"\"\n    rows, cols = grid.shape\n    for r, c in obj_pixels:\n        for dr in [-1, 0, 1]:\n            for dc in [-1, 0, 1]:\n                if dr == 0 and dc == 0:\n                    continue\n                nr, nc = r + dr, c + dc\n                if 0 <= nr < rows and 0 <= nc < cols and grid[nr, nc] == adj_color:\n                    return True\n    return False\n\ndef get_adjacent_pixels(grid, obj_pixels, adj_color):\n    \"\"\"Finds all pixels of adj_color adjacent (including diagonals) to the object pixels.\"\"\"\n    rows, cols = grid.shape\n    adjacent_coords = set()\n    for r, c in obj_pixels:\n        for dr in [-1, 0, 1]:\n            for dc in [-1, 0, 1]:\n                if dr == 0 and dc == 0:\n                    continue\n                nr, nc = r + dr, c + dc\n                if 0 <= nr < rows and 0 <= nc < cols and grid[nr, nc] == adj_color:\n                    adjacent_coords.add((nr, nc))\n    return np.array(list(adjacent_coords)) if adjacent_coords else np.empty((0, 2), dtype=int)\n\n\ndef check_containment(grid, obj_pixels, contain_color):\n    \"\"\"Checks if any pixel within the object has the contain_color.\"\"\"\n    for r, c in obj_pixels:\n        if grid[r, c] == contain_color:\n            return True\n    return False\n\ndef transform(input_grid):\n    \"\"\"\n    Identifies distinct non-background objects in the input grid.\n    Determines a selection criterion based on either adjacency to maroon (9)\n    or containment of azure (8) pixels within the objects.\n    Selects objects matching the criterion.\n    Calculates the bounding box for each selected object. If the criterion is\n    maroon adjacency, the bounding box includes the object pixels and any\n    adjacent maroon pixels. Otherwise, it includes only the object pixels.\n    Sorts the selected objects based on their original horizontal position:\n    right-to-left if the criterion involves maroon, left-to-right otherwise.\n    Extracts the subgrids corresponding to the bounding boxes.\n    Concatenates the extracted subgrids horizontally in the determined order\n    to form the output grid.\n    \"\"\"\n    input_np = np.array(input_grid, dtype=int)\n    rows, cols = input_np.shape\n\n    # 1. Identify background color\n    background_color = find_most_frequent_color(input_np)\n\n    # 2. Identify all distinct non-background objects\n    mask = input_np != background_color\n    # Use 8-connectivity (including diagonals)\n    structure = generate_binary_structure(2, 2)\n    labeled_grid, num_objects = label(mask, structure=structure)\n\n    target_objects_info = []\n    criterion = None # 'maroon_adj' or 'azure_contain'\n\n    # 3 & 4. Determine selection rule and filter objects\n    objects_with_maroon_adj = []\n    objects_with_azure_contain = []\n\n    for i in range(1, num_objects + 1):\n        obj_pixels = get_object_pixels(labeled_grid, i)\n        if obj_pixels.size == 0:\n            continue\n\n        if check_adjacency(input_np, obj_pixels, 9): # Check for maroon (9) adjacency\n             objects_with_maroon_adj.append(i)\n        if check_containment(input_np, obj_pixels, 8): # Check for azure (8) containment\n            objects_with_azure_contain.append(i)\n\n    # Determine the criterion based on which list is non-empty\n    # Prioritize maroon adjacency if both potentially apply? Examples suggest one rule per task.\n    target_labels = []\n    if objects_with_maroon_adj:\n        criterion = 'maroon_adj'\n        target_labels = objects_with_maroon_adj\n    elif objects_with_azure_contain:\n        criterion = 'azure_contain'\n        target_labels = objects_with_azure_contain\n    else:\n        # No matching objects found based on the known criteria\n        # This case might need refinement based on more examples,\n        # for now return empty or original grid? Let's return empty.\n        return []\n\n\n    # 5. Calculate bounding boxes for target objects\n    for obj_label in target_labels:\n        obj_pixels = get_object_pixels(labeled_grid, obj_label)\n\n        if criterion == 'maroon_adj':\n            # Include adjacent maroon pixels in the bounding box calculation\n            adj_maroon_pixels = get_adjacent_pixels(input_np, obj_pixels, 9)\n            all_pixels_for_bbox = np.vstack((obj_pixels, adj_maroon_pixels)) if adj_maroon_pixels.size > 0 else obj_pixels\n            bbox = get_bounding_box(all_pixels_for_bbox)\n        elif criterion == 'azure_contain':\n            # Bounding box includes only the object pixels\n            bbox = get_bounding_box(obj_pixels)\n        else: # Should not happen if target_labels is populated\n             continue\n\n        if bbox:\n            min_r, min_c, max_r, max_c = bbox\n            # Store bounding box and the leftmost column for sorting\n            target_objects_info.append({\n                \"label\": obj_label,\n                \"bbox\": bbox,\n                \"min_col\": min_c # Use min_col of the *object itself* for sorting origin\n            })\n\n    # 6. Determine assembly order\n    if criterion == 'maroon_adj':\n        # Sort descending by min_col (right-to-left)\n        target_objects_info.sort(key=lambda x: x['min_col'], reverse=True)\n    elif criterion == 'azure_contain':\n        # Sort ascending by min_col (left-to-right)\n        target_objects_info.sort(key=lambda x: x['min_col'], reverse=False)\n\n    # 7. Extract subgrids\n    extracted_subgrids = []\n    for obj_info in target_objects_info:\n        min_r, min_c, max_r, max_c = obj_info['bbox']\n        subgrid = input_np[min_r : max_r + 1, min_c : max_c + 1]\n        extracted_subgrids.append(subgrid)\n\n    # 8. Concatenate horizontally\n    if not extracted_subgrids:\n        # Handle cases where no target objects were found or extracted\n        return [] # Or maybe return input_grid? The examples suggest a transformation occurs.\n\n    # Ensure all subgrids have the same height before concatenating.\n    # Find the maximum height among all subgrids.\n    # Pad shorter subgrids. This wasn't explicitly observed but might be needed.\n    # Let's assume they naturally have the same height based on the examples.\n    # Example 1 output height = 5. BBox for right obj: (11, 20, 15, 22) -> height 5. BBox for left obj: (6, 6, 10, 15) -> height 5. OK.\n    # Example 2 output height = 5. BBox for left obj: (15, 5, 17, 7) -> height 3?? Error in manual bbox calculation?\n    # Let's re-examine example 2 object bounding boxes.\n    # Obj 1 (left): Contains azure(8) at (24, 7), (25, 7), (26, 7). Pixels range row 23-27, col 2-7. BBox (23, 2, 27, 7). Height 5.\n    # Obj 2 (middle): Contains azure(8) at (2, 10), (3, 10), (4, 10). Pixels range row 1-5, col 10-16. BBox (1, 10, 5, 16). Height 5.\n    # Obj 3 (right): Contains azure(8) at (16, 11). NO, azure is not in this object.\n    # Let's re-read the description. Ah, the objects in example 2 ARE the ones containing azure.\n    # Obj near bottom left: rows 23-27, cols 2-7. Contains azure at col 7. BBox (23, 2, 27, 7). Height 5.\n    # Obj near top right: rows 1-5, cols 10-16. Contains azure at col 10. BBox (1, 10, 5, 16). Height 5.\n    # Ok, heights match.\n\n    try:\n        output_np = np.concatenate(extracted_subgrids, axis=1)\n    except ValueError as e:\n        # This might happen if heights don't match, indicating an issue in logic or assumptions.\n        print(f\"Error concatenating subgrids: {e}\")\n        print(f\"Subgrid shapes: {[sg.shape for sg in extracted_subgrids]}\")\n        # Handle error case, maybe return empty grid or raise exception\n        return []\n\n\n    # Convert final numpy array back to list of lists\n    output_grid = output_np.tolist()\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 4911,
    "candidates_token_count": 2527,
    "total_token_count": 7438,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 86.268014
}