
## train_1

**input:**
```
4 7 1 3 7 7 7 9 6 4 7 7 7 7 7 7
7 7 7 3 7 7 7 4 5 9 7 7 0 0 0 7
2 7 7 3 7 7 7 0 0 0 7 7 0 4 0 7
3 3 3 3 7 7 7 0 0 0 7 7 0 0 1 7
7 7 7 7 7 7 7 6 5 0 7 7 0 2 0 7
7 7 7 7 7 7 7 7 7 7 7 7 0 0 0 7
7 7 7 0 0 0 0 9 0 0 5 7 7 7 7 7
7 7 7 0 0 9 0 2 9 0 0 7 7 7 0 0
7 7 7 2 0 0 0 0 0 0 0 7 7 7 1 4
7 7 7 0 0 1 0 4 0 0 8 7 7 7 0 0
7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 0
0 0 0 0 0 0 0 1 7 0 0 0 0 7 0 0
9 5 0 9 0 0 8 6 7 9 0 0 8 7 6 0
0 4 2 6 0 0 0 0 7 0 6 0 5 7 0 0
2 0 0 0 6 0 0 0 7 0 0 0 0 7 0 0
7 7 7 7 7 7 7 7 7 0 2 2 0 7 0 8
```


**output:**
```
4 7 1 3 7 7 7 9 6 4 7 7 7 7 7 7
7 7 7 3 7 7 7 4 5 9 7 7 7 7 7 7
2 7 7 3 7 7 7 0 0 0 7 7 7 7 7 7
3 3 3 3 7 7 7 0 0 0 7 7 7 7 7 7
7 7 7 7 7 7 7 6 5 0 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 0 0
7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 4
7 7 7 7 7 7 7 7 7 7 7 7 7 7 0 0
7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 0
7 7 7 7 7 7 7 7 7 0 0 0 0 7 0 0
7 7 7 7 7 7 7 7 7 9 0 0 8 7 6 0
7 7 7 7 7 7 7 7 7 0 6 0 5 7 0 0
7 7 7 7 7 7 7 7 7 0 0 0 0 7 0 0
7 7 7 7 7 7 7 7 7 0 2 2 0 7 0 8
```


## train_2

**input:**
```
7 9 7 3 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 3 7 7 0 0 0 7 7 7 0 0 0 7
5 7 6 3 7 7 1 0 0 7 7 7 6 0 4 7
3 3 3 3 7 7 0 5 0 7 7 7 0 0 0 7
7 7 7 7 7 7 0 0 0 7 7 7 0 9 0 7
7 7 7 7 7 7 2 0 6 7 7 7 0 0 0 7
7 7 7 7 7 7 0 0 0 7 7 7 0 8 0 7
7 7 7 7 7 7 7 7 7 7 7 7 0 0 0 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 0 0 0 1 0 0 0 7 7 7 7 7 7 7 7
7 0 0 0 0 0 5 0 7 7 7 7 7 7 7 7
7 0 9 0 8 0 0 0 7 7 7 0 0 0 0 9
7 0 0 0 0 0 4 0 7 7 7 0 6 0 0 0
7 0 2 0 4 0 0 0 7 7 7 0 0 0 0 0
7 7 7 7 7 7 7 7 7 7 7 0 0 5 1 0
7 7 7 7 7 7 7 7 7 7 7 8 0 0 0 0
```


**output:**
```
7 9 7 3 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 3 7 7 0 0 0 7 7 7 0 0 0 7
5 7 6 3 7 7 1 0 0 7 7 7 6 0 4 7
3 3 3 3 7 7 0 5 0 7 7 7 0 0 0 7
7 7 7 7 7 7 0 0 0 7 7 7 0 9 0 7
7 7 7 7 7 7 2 0 6 7 7 7 0 0 0 7
7 7 7 7 7 7 0 0 0 7 7 7 0 8 0 7
7 7 7 7 7 7 7 7 7 7 7 7 0 0 0 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 0 0 0 1 0 0 0 7 7 7 7 7 7 7 7
7 0 0 0 0 0 5 0 7 7 7 7 7 7 7 7
7 0 9 0 8 0 0 0 7 7 7 7 7 7 7 7
7 0 0 0 0 0 4 0 7 7 7 7 7 7 7 7
7 0 2 0 4 0 0 0 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
```


## train_3

**input:**
```
7 6 7 3 7 7 7 7 7 7 7 7 7 7 7 7
1 7 7 3 7 7 7 0 8 0 0 0 5 0 0 0
7 7 8 3 7 7 7 0 5 0 0 6 0 0 0 0
3 3 3 3 7 7 7 4 0 0 0 0 0 8 0 0
7 7 7 7 7 7 7 9 0 0 6 0 0 0 4 0
7 0 0 0 0 0 7 0 0 0 0 5 9 0 5 0
7 5 2 2 0 0 7 9 0 0 0 0 8 0 0 0
7 0 0 1 0 0 7 1 0 0 2 0 0 0 0 6
7 0 0 5 5 0 7 7 7 7 7 7 7 7 7 7
7 0 0 0 9 0 7 7 7 0 9 0 0 7 7 7
7 0 0 0 6 0 7 7 7 0 0 0 0 7 7 7
7 7 7 7 7 7 7 7 7 8 0 0 0 7 7 7
7 7 6 1 0 0 0 0 7 0 0 0 0 7 0 0
7 7 0 2 0 0 0 0 7 0 0 0 0 7 0 0
7 7 0 8 0 0 0 0 7 7 7 7 7 7 0 0
7 7 7 7 7 7 7 7 7 7 7 7 7 7 0 0
```


**output:**
```
7 6 7 3 7 7 7 7 7 7 7 7 7 7 7 7
1 7 7 3 7 7 7 7 7 7 7 7 7 7 7 7
7 7 8 3 7 7 7 7 7 7 7 7 7 7 7 7
3 3 3 3 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 0 0 0 0 0 7 7 7 7 7 7 7 7 7 7
7 5 2 2 0 0 7 7 7 7 7 7 7 7 7 7
7 0 0 1 0 0 7 7 7 7 7 7 7 7 7 7
7 0 0 5 5 0 7 7 7 7 7 7 7 7 7 7
7 0 0 0 9 0 7 7 7 0 9 0 0 7 7 7
7 0 0 0 6 0 7 7 7 0 0 0 0 7 7 7
7 7 7 7 7 7 7 7 7 8 0 0 0 7 7 7
7 7 7 7 7 7 7 7 7 0 0 0 0 7 0 0
7 7 7 7 7 7 7 7 7 0 0 0 0 7 0 0
7 7 7 7 7 7 7 7 7 7 7 7 7 7 0 0
7 7 7 7 7 7 7 7 7 7 7 7 7 7 0 0
```

Okay, let's analyze the task examples.

**Perception of the Elements:**

1.  **Grid Structure:** All examples use a 16x16 grid.
2.  **Background Color:** The predominant color in both input and output grids is orange (7). This appears to be the background color.
3.  **Other Colors:** Various other colors (white, blue, red, green, yellow, gray, magenta, orange, azure, maroon) appear as pixels or small clusters within the orange background.
4.  **Transformation:** The core transformation involves changing certain non-orange pixels to the orange background color. Not all non-orange pixels are changed; some remain the same in the output.
5.  **Key Difference:** The pixels that are changed to orange seem to be those that are "internal" or "isolated" from the grid's border by the orange background color. Pixels of any non-orange color that are on the border, or connected to the border through a path of other non-orange pixels (including diagonally adjacent), seem to remain unchanged. Pixels or connected groups of non-orange pixels that are completely surrounded by orange pixels are changed to orange.

**YAML Facts:**


```yaml
task_context:
  grid_size: 16x16 (consistent across examples)
  background_color: 7 (orange)
  primary_action: Selective color replacement

elements:
  - type: pixel_group
    description: Contiguous regions of non-background pixels (colors 0-6, 8-9).
    properties:
      - color: Various (non-orange)
      - connectivity: Can be connected horizontally, vertically, or diagonally.
      - location: Can be anywhere in the grid.
      - relationship_to_border: A group can touch the grid border or be fully internal.

transformation:
  - operation: identify_background
    description: Determine the background color (orange, 7).
  - operation: identify_target_pixels
    description: Find all pixels that are not the background color.
  - operation: connectivity_analysis
    source: Grid border
    path_constraint: Path must consist only of non-background pixels.
    connectivity_type: Adjacency (including diagonals)
    goal: Identify all non-background pixels reachable from the border via a path of non-background pixels. Let's call these "border_connected" pixels.
  - operation: apply_change
    target: Non-background pixels that are *not* border_connected.
    action: Change the color of these pixels to the background color (orange, 7).
    condition: Pixel is non-background AND not border_connected.
  - operation: preserve_pixels
    target: Background pixels AND non-background pixels that *are* border_connected.
    action: Keep their original color.

input_output_relationship:
  - description: The output grid is derived from the input grid by replacing isolated non-background pixels (those not connected to the border via other non-background pixels) with the background color. Pixels connected to the border retain their original color.
```


**Natural Language Program:**

1.  Identify the background color, which is orange (7).
2.  Create a copy of the input grid to serve as the basis for the output grid.
3.  Initialize a set or list, `border_connected_pixels`, to store the coordinates of non-background pixels connected to the border.
4.  Initialize a queue or stack for a search algorithm (like Breadth-First Search or Depth-First Search) with the coordinates of all non-background pixels located on the grid's border (row 0, last row, column 0, or last column). Add these initial border pixels to `border_connected_pixels`.
5.  While the search queue/stack is not empty:
    a.  Dequeue/pop a pixel coordinate `(r, c)`.
    b.  Examine its 8 neighbors (horizontal, vertical, and diagonal).
    c.  For each neighbor `(nr, nc)`:
        i.  Check if `(nr, nc)` is within the grid boundaries.
        ii. Check if the pixel at `(nr, nc)` in the input grid is *not* the background color (not orange).
        iii. Check if `(nr, nc)` has *not* already been added to `border_connected_pixels`.
        iv. If all conditions (i, ii, iii) are met, add `(nr, nc)` to `border_connected_pixels` and enqueue/push it onto the search queue/stack.
6.  Iterate through every pixel `(r, c)` in the input grid.
7.  If the pixel `(r, c)` is *not* the background color (not orange) AND its coordinate `(r, c)` is *not* present in the `border_connected_pixels` set:
    a.  Change the color of the pixel at `(r, c)` in the output grid to the background color (orange, 7).
8.  All other pixels (background pixels and border-connected non-background pixels) retain their original color in the output grid (already handled by copying the input initially and only modifying the non-connected ones).
9.  Return the modified output grid.
```python
import numpy as np
from collections import deque

"""
Transformation Rule Description:

1. Identify the background color, which is orange (7).
2. Find all non-background pixels (any color other than 7) that are located on the grid's border (top/bottom row, left/right column).
3. Starting from these border non-background pixels, perform a search (e.g., Breadth-First Search or Depth-First Search) to identify all other non-background pixels that are connected to them through a path of adjacent (including diagonals) non-background pixels. Mark these reachable pixels as "border-connected".
4. Create the output grid by initially copying the input grid.
5. Iterate through every pixel in the input grid. If a pixel is non-background AND it was *not* marked as "border-connected" in step 3, change its color in the output grid to the background color (orange, 7).
6. Pixels that were originally the background color or were non-background but marked as "border-connected" retain their original color in the output grid.
7. Return the modified output grid.

Essentially, the transformation preserves non-background pixels (and shapes formed by them) that touch or are connected to the grid's border, while removing (filling with background color) any non-background pixels or shapes completely surrounded by the background color.
"""

def transform(input_grid):
    """
    Transforms the input grid by removing non-background pixels that are not connected 
    to the grid border via a path of other non-background pixels.

    Args:
        input_grid (list of list of int): The input grid.

    Returns:
        list of list of int: The transformed output grid.
    """
    # Convert input to numpy array for efficient operations
    input_np = np.array(input_grid, dtype=int)
    output_np = np.copy(input_np)
    H, W = input_np.shape
    bg_color = 7

    # Set to store coordinates of non-background pixels connected to the border
    connected_pixels = set()
    # Queue for BFS
    queue = deque()

    # Initialize the search with non-background pixels on the border
    for r in range(H):
        for c in range(W):
            if r == 0 or r == H - 1 or c == 0 or c == W - 1:
                if input_np[r, c] != bg_color and (r, c) not in connected_pixels:
                    connected_pixels.add((r, c))
                    queue.append((r, c))

    # Perform BFS to find all connected non-background pixels
    while queue:
        r, c = queue.popleft()

        # Check 8 neighbors (including diagonals)
        for dr in [-1, 0, 1]:
            for dc in [-1, 0, 1]:
                if dr == 0 and dc == 0:
                    continue # Skip self

                nr, nc = r + dr, c + dc

                # Check boundaries
                if 0 <= nr < H and 0 <= nc < W:
                    # Check if neighbor is non-background and not already visited/connected
                    if input_np[nr, nc] != bg_color and (nr, nc) not in connected_pixels:
                        connected_pixels.add((nr, nc))
                        queue.append((nr, nc))

    # Iterate through the grid and change non-connected non-background pixels to background
    for r in range(H):
        for c in range(W):
            # If a pixel is not background AND it's not in the connected set
            if input_np[r, c] != bg_color and (r, c) not in connected_pixels:
                # Change it to background color in the output grid
                output_np[r, c] = bg_color

    # Convert numpy array back to list of lists
    output_grid = output_np.tolist()
    return output_grid
```
