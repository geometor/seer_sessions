{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\nIdentifies strictly isolated single non-background pixels as 'markers'.\nUses the top-most, left-most marker to define a reference column ('ref_col').\nThe reference marker stays in place.\nOther isolated markers are moved horizontally to the 'ref_col', keeping their original row.\nAll other non-background components ('objects' - multi-pixel or non-isolated single pixel) are shifted horizontally.\nThe shift amount for an object is calculated so that its center column (rounded mean of pixel columns) aligns with the 'ref_col'.\nThe internal structure of objects is preserved.\nThis rule is derived from Examples 1 and 3 and may not apply to all cases (like Example 2).\n\"\"\"\n\nimport numpy as np\nfrom collections import Counter, deque\n\ndef find_background(grid: np.ndarray) -> int:\n    \"\"\"Finds the most frequent color, assumed to be the background.\"\"\"\n    colors, counts = np.unique(grid, return_counts=True)\n    return colors[np.argmax(counts)]\n\ndef find_components(grid: np.ndarray, background_color: int) -> list[dict]:\n    \"\"\"\n    Finds all connected components of non-background pixels using BFS (8-way connectivity).\n    Returns a list of dictionaries, each representing a component with its pixels and size.\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    components = []\n    component_id_counter = 0\n\n    for r in range(rows):\n        for c in range(cols):\n            if grid[r, c] != background_color and not visited[r, c]:\n                component_pixels = []\n                q = deque([(r, c)])\n                visited[r, c] = True\n                \n                while q:\n                    row, col = q.popleft()\n                    component_pixels.append((row, col))\n                    \n                    # Check 8 neighbors (including diagonals)\n                    for dr in [-1, 0, 1]:\n                        for dc in [-1, 0, 1]:\n                            if dr == 0 and dc == 0: continue\n                            nr, nc = row + dr, col + dc\n                            \n                            if 0 <= nr < rows and 0 <= nc < cols and \\\n                               grid[nr, nc] != background_color and not visited[nr, nc]:\n                                visited[nr, nc] = True\n                                q.append((nr, nc))\n                \n                if component_pixels:\n                    components.append({\n                        'id': component_id_counter,\n                        'pixels': sorted(component_pixels), # Sort for consistency\n                        'size': len(component_pixels)\n                    })\n                    component_id_counter += 1\n    return components\n\ndef is_isolated(pixel_coord: tuple[int, int], all_non_bg_coords: set[tuple[int, int]], rows: int, cols: int) -> bool:\n    \"\"\"Checks if a single pixel has no non-background neighbors (8-way).\"\"\"\n    r, c = pixel_coord\n    for dr in [-1, 0, 1]:\n        for dc in [-1, 0, 1]:\n            if dr == 0 and dc == 0: continue\n            nr, nc = r + dr, c + dc\n            # Check if neighbor is within bounds AND is a non-background pixel\n            if 0 <= nr < rows and 0 <= nc < cols and (nr, nc) in all_non_bg_coords:\n                return False # Found a non-background neighbor\n    return True # No non-background neighbors found\n\ndef get_component_center_col(component_pixels: list[tuple[int, int]]) -> int:\n    \"\"\"Calculates the center column by rounding the mean of column indices.\"\"\"\n    if not component_pixels: return -1\n    cols = [c for r, c in component_pixels]\n    return int(round(np.mean(cols)))\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Applies the transformation rule: align objects and non-reference markers \n    to the reference marker's column.\n    \"\"\"\n    input_np = np.array(input_grid, dtype=int)\n    rows, cols = input_np.shape\n\n    # 1. Find background color\n    background_color = find_background(input_np)\n\n    # 2. Find all non-background coordinates for isolation checks\n    all_non_bg_coords = set()\n    for r in range(rows):\n        for c in range(cols):\n            if input_np[r, c] != background_color:\n                all_non_bg_coords.add((r, c))\n\n    if not all_non_bg_coords:\n        return input_grid # Empty grid or all background\n\n    # 3. Find all connected components\n    all_components = find_components(input_np, background_color)\n    if not all_components:\n         return input_grid # Should not happen if all_non_bg_coords is not empty\n\n    # 4. Identify isolated markers and objects\n    isolated_markers = [] # Stores {'id': comp_id, 'pixel': (r,c), 'color': color}\n    objects = [] # Stores component dictionaries {'id': comp_id, 'pixels': [...], 'size': size}\n    \n    for comp in all_components:\n        if comp['size'] == 1:\n            pixel_coord = comp['pixels'][0]\n            # Check for strict isolation (no non-bg neighbors at all)\n            if is_isolated(pixel_coord, all_non_bg_coords - {pixel_coord}, rows, cols):\n                 isolated_markers.append({\n                     'id': comp['id'], \n                     'pixel': pixel_coord, \n                     'color': input_np[pixel_coord]\n                 })\n            else:\n                 # Non-isolated single pixel, treat as object\n                 objects.append(comp) \n        else:\n            # Multi-pixel component, treat as object\n            objects.append(comp)\n\n    # 5. Determine reference marker and column\n    if not isolated_markers:\n        # No isolated markers found, apply no transformation based on derived rule\n        # (Could potentially define a fallback rule here if needed)\n        return input_grid \n\n    # Sort markers by row, then column to find the top-most, left-most\n    isolated_markers.sort(key=lambda m: m['pixel']) \n    ref_marker = isolated_markers[0]\n    ref_col = ref_marker['pixel'][1]\n    \n    # 6. Initialize output grid\n    output_np = np.full_like(input_np, background_color)\n\n    # 7. Place reference marker\n    ref_r, ref_c = ref_marker['pixel']\n    output_np[ref_r, ref_c] = ref_marker['color']\n\n    # 8. Place other isolated markers\n    for marker in isolated_markers[1:]:\n        r, _ = marker['pixel'] # Original row\n        color = marker['color']\n        new_c = ref_col\n        if 0 <= r < rows and 0 <= new_c < cols:\n            output_np[r, new_c] = color\n\n    # 9. Move objects\n    for obj_comp in objects:\n        obj_pixels = obj_comp['pixels']\n        center_col = get_component_center_col(obj_pixels)\n        \n        if center_col == -1: continue # Should not happen for valid objects\n\n        dx = ref_col - center_col\n\n        # Apply shift to each pixel of the object\n        for (r, c) in obj_pixels:\n            new_c = c + dx\n            # Check bounds before writing to output\n            if 0 <= r < rows and 0 <= new_c < cols:\n                output_np[r, new_c] = input_np[r, c] # Use original color\n\n    # 10. Return result\n    return output_np.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "citation_metadata": {
        "citation_sources": [
          {
            "start_index": 5293,
            "end_index": 5625,
            "uri": "https://github.com/abhisheksol/competivity-programming",
            "license_": ""
          }
        ]
      },
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 24106,
    "candidates_token_count": 2809,
    "total_token_count": 26915,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 23.02484,
  "retries": 1
}