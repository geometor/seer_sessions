
## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 8 5 5 5 8 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0
0 8 5 5 5 8 0 0 0 2 1 1 1 2 0 8 8 8 8 8 0 0
0 8 5 5 5 8 0 0 0 2 1 1 1 2 0 8 3 3 3 8 0 0
0 8 8 8 8 8 0 0 0 2 1 1 1 2 0 8 3 3 3 8 0 0
0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 8 3 3 3 8 0 0
0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 8 8 8 8 8 0 0
0 0 0 0 2 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 3 3 3 2 0 0 0 0 2 2 2 2 2 0 0 0 0
0 0 0 0 2 3 3 3 2 0 0 0 0 2 9 9 9 2 0 0 0 0
0 0 0 0 2 2 2 2 2 0 0 0 0 2 9 9 9 2 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 2 9 9 9 2 0 0 0 0
2 2 2 2 2 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0
2 6 6 6 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
2 6 6 6 2 0 0 0 0 0 0 0 8 8 8 8 8 0 0 0 0 0
2 6 6 6 2 2 2 2 2 2 0 0 8 4 4 4 8 0 0 0 0 0
2 2 2 2 2 2 4 4 4 2 0 0 8 4 4 4 8 0 0 0 0 0
0 0 0 0 0 2 4 4 4 2 0 0 8 4 4 4 8 0 0 0 0 0
0 0 0 0 0 2 4 4 4 2 0 0 8 8 8 8 8 0 0 0 0 0
0 0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
8 5 5 5 8 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2
8 5 5 5 8 8 8 8 8 8 0 0 0 0 0 0 0 2 1 1 1 2
8 5 5 5 8 8 3 3 3 8 0 0 0 0 0 0 0 2 1 1 1 2
8 8 8 8 8 8 3 3 3 8 0 0 0 0 0 0 0 2 1 1 1 2
0 0 0 0 0 8 3 3 3 8 0 0 0 0 0 0 0 2 2 2 2 2
0 0 0 0 0 8 8 8 8 8 0 0 2 2 2 2 2 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 3 3 3 2 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 3 3 3 2 2 2 2 2 2
0 0 0 0 0 0 0 0 0 0 0 0 2 3 3 3 2 2 9 9 9 2
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 9 9 9 2
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 9 9 9 2
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2
0 0 0 0 0 0 0 0 0 0 0 0 2 6 6 6 2 0 0 0 0 0
8 8 8 8 8 0 0 0 0 0 0 0 2 6 6 6 2 0 0 0 0 0
8 4 4 4 8 0 0 0 0 0 0 0 2 6 6 6 2 2 2 2 2 2
8 4 4 4 8 0 0 0 0 0 0 0 2 2 2 2 2 2 4 4 4 2
8 4 4 4 8 0 0 0 0 0 0 0 0 0 0 0 0 2 4 4 4 2
8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 2 4 4 4 2
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_2

**input:**
```
4 4 4 4 4 4 4 4 2 2 2 2 2 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 4 4 2 5 5 5 2 4 4 4 4 4 4 4 4 4
4 4 8 8 8 8 8 4 2 5 5 5 2 4 2 2 2 2 2 4 4 4
4 4 8 9 9 9 8 4 2 5 5 5 2 4 2 3 3 3 2 4 4 4
4 4 8 9 9 9 8 4 2 2 2 2 2 4 2 3 3 3 2 4 4 4
4 4 8 9 9 9 8 4 4 4 4 4 4 4 2 3 3 3 2 4 4 4
4 4 8 8 8 8 8 4 4 4 4 4 4 4 2 2 2 2 2 4 4 4
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
8 8 8 8 8 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 4
8 3 3 3 8 4 4 4 4 4 4 4 4 4 4 4 2 6 6 6 2 4
8 3 3 3 8 4 4 4 4 4 4 4 4 4 4 4 2 6 6 6 2 4
8 3 3 3 8 4 4 4 4 4 4 4 4 4 4 4 2 6 6 6 2 4
8 8 8 8 8 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 4
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
4 4 8 8 8 8 8 4 4 4 4 4 4 4 2 2 2 2 2 4 4 4
4 4 8 1 1 1 8 4 4 4 4 4 4 4 2 1 1 1 2 4 4 4
4 4 8 1 1 1 8 4 8 8 8 8 8 4 2 1 1 1 2 4 4 4
4 4 8 1 1 1 8 4 8 6 6 6 8 4 2 1 1 1 2 4 4 4
4 4 8 8 8 8 8 4 8 6 6 6 8 4 2 2 2 2 2 4 4 4
4 4 4 4 4 4 4 4 8 6 6 6 8 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 4 4 8 8 8 8 8 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
```


**output:**
```
4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 4 4 4 4 4
4 4 4 4 4 4 4 4 4 4 4 4 2 5 5 5 2 4 4 4 4 4
8 8 8 8 8 4 4 4 4 4 4 4 2 5 5 5 2 2 2 2 2 2
8 9 9 9 8 4 4 4 4 4 4 4 2 5 5 5 2 2 3 3 3 2
8 9 9 9 8 4 4 4 4 4 4 4 2 2 2 2 2 2 3 3 3 2
8 9 9 9 8 4 4 4 4 4 4 4 4 4 4 4 4 2 3 3 3 2
8 8 8 8 8 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
8 8 8 8 8 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2
8 3 3 3 8 4 4 4 4 4 4 4 4 4 4 4 4 2 6 6 6 2
8 3 3 3 8 4 4 4 4 4 4 4 4 4 4 4 4 2 6 6 6 2
8 3 3 3 8 4 4 4 4 4 4 4 4 4 4 4 4 2 6 6 6 2
8 8 8 8 8 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
8 8 8 8 8 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2
8 1 1 1 8 4 4 4 4 4 4 4 4 4 4 4 4 2 1 1 1 2
8 1 1 1 8 8 8 8 8 8 4 4 4 4 4 4 4 2 1 1 1 2
8 1 1 1 8 8 6 6 6 8 4 4 4 4 4 4 4 2 1 1 1 2
8 8 8 8 8 8 6 6 6 8 4 4 4 4 4 4 4 2 2 2 2 2
4 4 4 4 4 8 6 6 6 8 4 4 4 4 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 4 4 4 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
```


## train_3

**input:**
```
1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1
1 1 1 8 8 8 8 8 1 1 1 1 2 3 3 3 2 1 1 1 1 1
1 1 1 8 2 2 2 8 1 1 1 1 2 3 3 3 2 1 1 1 1 1
1 1 1 8 2 2 2 8 1 1 1 1 2 3 3 3 2 1 1 1 1 1
1 1 1 8 2 2 2 8 1 1 1 1 2 2 2 2 2 1 1 1 1 1
1 1 1 8 8 8 8 8 1 1 1 1 8 8 8 8 8 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 8 6 6 6 8 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 8 6 6 6 8 1 1 1 1 1
1 1 2 2 2 2 2 1 1 1 1 1 8 6 6 6 8 1 1 1 1 1
1 1 2 5 5 5 2 1 1 1 1 1 8 8 8 8 8 1 1 1 1 1
1 1 2 5 5 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 2 5 5 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 2 2 2 2 2 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 4 4 4 2 1 1 1
1 1 1 1 1 1 1 8 8 8 8 8 1 1 2 4 4 4 2 1 1 1
1 1 1 1 1 1 1 8 3 3 3 8 1 1 2 4 4 4 2 1 1 1
1 1 1 1 1 1 1 8 3 3 3 8 1 1 2 2 2 2 2 1 1 1
1 1 1 1 1 1 1 8 3 3 3 8 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
```


**output:**
```
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2
8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 3 2
8 2 2 2 8 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 3 2
8 2 2 2 8 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 3 2
8 2 2 2 8 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2
8 8 8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 8 6 6 6 8 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 8 6 6 6 8 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 8 6 6 6 8 1 1 2 2 2 2 2 1 1 1 1 1
1 1 1 1 1 8 8 8 8 8 1 1 2 5 5 5 2 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 2 5 5 5 2 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 2 5 5 5 2 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 4 4 4 2
8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 2 4 4 4 2
8 3 3 3 8 1 1 1 1 1 1 1 1 1 1 1 1 2 4 4 4 2
8 3 3 3 8 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2
8 3 3 3 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
```

Okay, let's analyze the provided examples.

**Perception of Task Elements:**

1.  **Input/Output Grids:** Both input and output grids have the same dimensions and the same background color (white in example 1, yellow in example 2, blue in example 1).
2.  **Objects:** The grids contain multiple distinct objects. These objects consist of a rectangular frame (1 pixel thick) of a specific color, enclosing a solid rectangular core of a different color.
3.  **Object Frames:** The frame colors observed are consistently either azure (8) or red (2).
4.  **Object Cores:** The core colors vary (gray, blue, green, maroon, magenta, yellow, etc.).
5.  **Transformation:** The core transformation involves changing the horizontal position of these objects. The objects themselves (frame, core color, shape) remain unchanged.
6.  **Movement Rule:** The direction of movement depends solely on the *frame color* of the object:
    *   Objects with an **azure (8)** frame move horizontally to the **left edge** of the grid.
    *   Objects with a **red (2)** frame move horizontally to the **right edge** of the grid.
7.  **Constraints:** The vertical position of each object remains unchanged. Objects move until their relevant edge (left for azure, right for red) touches the grid boundary. The background is preserved.

**YAML Facts:**


```yaml
task_description: "Move rectangular objects horizontally based on their frame color."
grid_properties:
  background_color:
    description: "The dominant color of the grid, preserved in the output."
    value_in_example_1: 0 # white
    value_in_example_2: 4 # yellow
    value_in_example_3: 1 # blue
  dimensions:
    description: "Height and width remain constant between input and output."
    value_in_example_1: [22, 22]
    value_in_example_2: [22, 24]
    value_in_example_3: [22, 22]
objects:
  - type: "Framed Rectangle"
    description: "A solid rectangle (core) surrounded by a 1-pixel thick frame."
    properties:
      - frame_color:
          description: "The color of the 1-pixel border."
          values_observed: [2, 8] # red, azure
      - core_color:
          description: "The color of the solid inner rectangle."
          values_observed: [1, 3, 4, 5, 6, 9] # blue, green, yellow, gray, magenta, maroon
      - location:
          description: "The bounding box coordinates in the input grid."
      - shape:
          description: "The dimensions (height, width) of the object, which remain constant."
    action:
      description: "Translate the object horizontally based on its frame color, preserving its vertical position and internal structure."
      rule:
        - if: "frame_color is azure (8)"
          then: "Move the object left until its leftmost column is 0."
        - if: "frame_color is red (2)"
          then: "Move the object right until its rightmost column matches the grid's width - 1."
relationships:
  - description: "Objects move independently of each other."
  - description: "The background pixels remain unchanged except where overwritten by moved objects."
  - description: "Objects do not appear to overlap in the final output in the examples."
```


**Natural Language Program:**

1.  Initialize an output grid with the same dimensions and background color as the input grid.
2.  Identify all distinct objects in the input grid. An object is characterized by a rectangular frame (1 pixel thick) of either azure (8) or red (2), enclosing a solid rectangle of a different color.
3.  For each identified object:
    a.  Record its original pixel values and its bounding box coordinates (top row, bottom row, left column, right column).
    b.  Determine the object's frame color.
    c.  Calculate the target horizontal position:
        i.  If the frame color is azure (8), the target left column is 0.
        ii. If the frame color is red (2), the target left column is `grid_width - object_width`.
    d.  Determine the target top row, which is the same as the original top row.
    e.  Copy the recorded pixel values of the object onto the output grid, starting at the calculated target top row and target left column.
4.  Return the completed output grid.
```python
import numpy as np
from collections import deque

"""
Identifies rectangular objects in the input grid characterized by a 1-pixel thick frame of either azure (8) or red (2), enclosing a solid rectangular core of a different color.
Moves these objects horizontally based on their frame color:
- Objects with an azure (8) frame are moved to the left edge (column 0).
- Objects with a red (2) frame are moved to the right edge (last column).
The vertical position and internal structure of the objects remain unchanged.
The background pixels are preserved, except where overwritten by moved objects.
"""

def find_objects(grid, background_color):
    """
    Finds all framed rectangular objects in the grid.

    Args:
        grid (np.array): The input grid.
        background_color (int): The background color.

    Returns:
        list: A list of dictionaries, each representing an object with keys:
              'bbox': (min_r, min_c, max_r, max_c)
              'frame_color': The color of the frame (2 or 8)
              'subgrid': A numpy array containing the object's pixels.
    """
    height, width = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    objects = []

    for r in range(height):
        for c in range(width):
            # Look for potential frame pixels (red or azure) that haven't been visited
            if grid[r, c] in [2, 8] and not visited[r, c]:
                frame_color = grid[r, c]
                
                # Use BFS to find all connected pixels of the *same* frame color
                q = deque([(r, c)])
                frame_pixels = set([(r,c)])
                component_visited = set([(r, c)])
                min_r, min_c, max_r, max_c = r, c, r, c

                while q:
                    curr_r, curr_c = q.popleft()
                    min_r = min(min_r, curr_r)
                    min_c = min(min_c, curr_c)
                    max_r = max(max_r, curr_r)
                    max_c = max(max_c, curr_c)

                    # Explore 8 neighbors (including diagonals for connectivity check)
                    for dr in [-1, 0, 1]:
                        for dc in [-1, 0, 1]:
                            if dr == 0 and dc == 0:
                                continue
                            nr, nc = curr_r + dr, curr_c + dc
                            
                            if 0 <= nr < height and 0 <= nc < width and \
                               grid[nr, nc] == frame_color and (nr, nc) not in component_visited:
                                component_visited.add((nr, nc))
                                frame_pixels.add((nr, nc))
                                q.append((nr, nc))

                # Basic check: Potential object size must be at least 3x3
                obj_h = max_r - min_r + 1
                obj_w = max_c - min_c + 1
                if obj_h < 3 or obj_w < 3:
                    # Mark these pixels as visited to avoid reprocessing
                    for fr, fc in frame_pixels:
                        visited[fr, fc] = True
                    continue # Too small to be a framed object

                # Verify frame structure and solid core
                is_valid_object = True
                core_color = -1 # Sentinel value
                core_pixels = set()

                for ir in range(min_r, max_r + 1):
                    for ic in range(min_c, max_c + 1):
                        pixel_pos = (ir, ic)
                        pixel_val = grid[ir, ic]

                        # Check if it's on the border (frame)
                        is_border = (ir == min_r or ir == max_r or ic == min_c or ic == max_c)

                        if is_border:
                            if pixel_pos not in frame_pixels: # Should be part of the found frame component
                                is_valid_object = False
                                break
                            if pixel_val != frame_color: # Should have the correct frame color
                                 is_valid_object = False
                                 break
                        else: # Inner pixel (core)
                            if pixel_val == frame_color or pixel_val == background_color: # Core cannot be frame or background color
                                is_valid_object = False
                                break
                            if core_color == -1: # First core pixel found
                                core_color = pixel_val
                            elif pixel_val != core_color: # Core must be solid color
                                is_valid_object = False
                                break
                            core_pixels.add(pixel_pos)
                    if not is_valid_object:
                        break
                
                # Ensure the core isn't empty if the object is larger than 2x2 (which it must be)
                if core_color == -1:
                     is_valid_object = False

                # Add the object if valid
                if is_valid_object:
                    # Extract the subgrid
                    subgrid = grid[min_r:max_r+1, min_c:max_c+1]
                    objects.append({
                        'bbox': (min_r, min_c, max_r, max_c),
                        'frame_color': frame_color,
                        'subgrid': subgrid
                    })
                    # Mark all object pixels (frame and core) as visited
                    all_object_pixels = frame_pixels.union(core_pixels)
                    for orr, occ in all_object_pixels:
                         if 0 <= orr < height and 0 <= occ < width:
                            visited[orr, occ] = True
                else:
                    # Mark only the initially found frame component pixels as visited
                    # This handles cases where we find frame-colored pixels that are not part of a valid object
                    for fr, fc in frame_pixels:
                       visited[fr, fc] = True


    return objects


def transform(input_grid):
    """
    Moves framed rectangular objects horizontally based on their frame color.

    Args:
        input_grid (list of lists): The input grid represented as a list of lists.

    Returns:
        list of lists: The transformed grid.
    """
    input_np = np.array(input_grid, dtype=int)
    height, width = input_np.shape

    # Determine background color (assuming it's the color at [0, 0])
    background_color = input_np[0, 0]

    # Initialize output grid with background color
    output_grid = np.full_like(input_np, background_color)

    # Find all framed objects
    objects = find_objects(input_np, background_color)

    # Process each object
    for obj in objects:
        min_r, min_c, max_r, max_c = obj['bbox']
        frame_color = obj['frame_color']
        subgrid = obj['subgrid']
        obj_h, obj_w = subgrid.shape

        # Calculate new horizontal position
        new_c = 0
        if frame_color == 8: # Azure frame moves left
            new_c = 0
        elif frame_color == 2: # Red frame moves right
            new_c = width - obj_w
        
        # Vertical position remains the same
        new_r = min_r

        # Place the object onto the output grid
        # Ensure slicing bounds are within the grid dimensions
        end_r = min(new_r + obj_h, height)
        end_c = min(new_c + obj_w, width)
        subgrid_h = end_r - new_r
        subgrid_w = end_c - new_c
        
        if new_r < height and new_c < width and subgrid_h > 0 and subgrid_w > 0:
             output_grid[new_r:end_r, new_c:end_c] = subgrid[0:subgrid_h, 0:subgrid_w]


    return output_grid.tolist()
```
```python
import numpy as np
from collections import deque

"""
Identifies specific rectangular objects within the input grid and moves them horizontally.
Objects are defined as having a 1-pixel thick frame of either azure (8) or red (2),
enclosing a solid rectangular core of a different color (not the frame color and not the background color).
The size must be at least 3x3.

Transformation Steps:
1. Copy the input grid to create the output grid.
2. Identify the background color.
3. Find all qualifying framed rectangular objects.
4. For each found object:
    a. Erase the object from its original position in the output grid by filling its bounding box with the background color.
    b. Calculate the new horizontal position based on the frame color:
        - Azure (8) frames move to the left edge (column 0).
        - Red (2) frames move to the right edge (last column).
    c. Draw the object's original pixel data at its new position in the output grid.
5. Return the modified output grid.

Static elements (pixels not part of the identified movable objects) remain unchanged.
"""

def find_objects(grid, background_color):
    """
    Finds all framed rectangular objects in the grid matching the criteria.

    Args:
        grid (np.array): The input grid.
        background_color (int): The background color.

    Returns:
        list: A list of dictionaries, each representing an object with keys:
              'bbox': (min_r, min_c, max_r, max_c) - Original bounding box
              'frame_color': The color of the frame (2 or 8)
              'subgrid': A numpy array containing the object's pixels.
    """
    height, width = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    objects = []

    for r in range(height):
        for c in range(width):
            # Look for potential frame pixels (red or azure) that haven't been visited
            # and are not the background color (handles cases where frame color might match background)
            if grid[r, c] in [2, 8] and grid[r, c] != background_color and not visited[r, c]:
                frame_color = grid[r, c]
                
                # Use BFS to find all connected pixels of the *same* frame color
                # This helps identify the extent of a potential frame
                q = deque([(r, c)])
                frame_pixels = set([(r,c)]) # Store pixels belonging to this potential frame component
                component_visited = set([(r, c)]) # Track visited during this specific BFS
                min_r_bfs, min_c_bfs, max_r_bfs, max_c_bfs = r, c, r, c

                while q:
                    curr_r, curr_c = q.popleft()
                    min_r_bfs = min(min_r_bfs, curr_r)
                    min_c_bfs = min(min_c_bfs, curr_c)
                    max_r_bfs = max(max_r_bfs, curr_r)
                    max_c_bfs = max(max_c_bfs, curr_c)

                    # Explore 8 neighbors for connectivity
                    for dr in [-1, 0, 1]:
                        for dc in [-1, 0, 1]:
                            if dr == 0 and dc == 0:
                                continue
                            nr, nc = curr_r + dr, curr_c + dc
                            
                            # Check bounds and if neighbor has the same frame color and wasn't visited in this BFS
                            if 0 <= nr < height and 0 <= nc < width and \
                               grid[nr, nc] == frame_color and (nr, nc) not in component_visited:
                                component_visited.add((nr, nc))
                                frame_pixels.add((nr, nc))
                                q.append((nr, nc))

                # Define the bounding box based on the BFS extent
                min_r, min_c, max_r, max_c = min_r_bfs, min_c_bfs, max_r_bfs, max_c_bfs
                obj_h = max_r - min_r + 1
                obj_w = max_c - min_c + 1

                # Basic size check
                if obj_h < 3 or obj_w < 3:
                    # Mark only the BFS-found pixels as visited globally to avoid reprocessing this invalid component
                    for fr, fc in frame_pixels:
                        visited[fr, fc] = True
                    continue 

                # Verify the strict rectangular frame structure and solid core
                is_valid_object = True
                core_color = -1 # Sentinel value
                core_pixels = set() # Track core pixels for marking visited later

                for ir in range(min_r, max_r + 1):
                    for ic in range(min_c, max_c + 1):
                        pixel_val = grid[ir, ic]
                        # Check if it's on the border of the bounding box (potential frame)
                        is_border = (ir == min_r or ir == max_r or ic == min_c or ic == max_c)

                        if is_border:
                            if pixel_val != frame_color: # All border pixels MUST be the frame color
                                is_valid_object = False
                                break
                        else: # Inner pixel (potential core)
                            # Core cannot be frame or background color
                            if pixel_val == frame_color or pixel_val == background_color: 
                                is_valid_object = False
                                break
                            # Check for solid color core
                            if core_color == -1: # First core pixel found
                                core_color = pixel_val
                            elif pixel_val != core_color: # Core must be solid (same color)
                                is_valid_object = False
                                break
                            core_pixels.add((ir,ic)) # Add to core set if valid so far
                    if not is_valid_object:
                        break # Exit inner loop if invalid
                
                # Final check: ensure a core color was actually found (handles hollow shapes)
                if core_color == -1:
                     is_valid_object = False

                # If all checks pass, it's a valid object
                if is_valid_object:
                    # Extract the object's pixel data
                    subgrid = grid[min_r:max_r+1, min_c:max_c+1]
                    objects.append({
                        'bbox': (min_r, min_c, max_r, max_c),
                        'frame_color': frame_color,
                        'subgrid': subgrid
                    })
                    # Mark all pixels within the valid object's bounding box as visited globally
                    for ir in range(min_r, max_r + 1):
                        for ic in range(min_c, max_c + 1):
                            visited[ir, ic] = True
                else:
                     # Mark only the BFS-found pixels as visited globally if it wasn't a valid object
                    for fr, fc in frame_pixels:
                       visited[fr, fc] = True

    return objects


def transform(input_grid):
    """
    Applies the transformation rule to the input grid.
    """
    # Convert input to numpy array for easier manipulation
    input_np = np.array(input_grid, dtype=int)
    height, width = input_np.shape

    # Initialize output grid as a copy of the input
    output_grid = np.copy(input_np)

    # Determine background color (assume top-left is representative)
    background_color = input_np[0, 0]

    # Find all qualifying framed objects
    objects_to_move = find_objects(input_np, background_color)

    # Process each identified object
    for obj in objects_to_move:
        min_r, min_c, max_r, max_c = obj['bbox']
        frame_color = obj['frame_color']
        subgrid = obj['subgrid']
        obj_h, obj_w = subgrid.shape

        # Erase the object from its original position in the output grid
        output_grid[min_r:max_r+1, min_c:max_c+1] = background_color

        # Calculate new horizontal position
        new_c = 0 # Default for azure
        if frame_color == 2: # Red frame moves right
            new_c = width - obj_w
        
        # Vertical position remains the same
        new_r = min_r

        # Draw the object at its new position
        # Ensure slicing bounds are within the grid dimensions (should be fine if width calculation is correct)
        end_r = new_r + obj_h
        end_c = new_c + obj_w
        
        # Check bounds before drawing (safety measure)
        if 0 <= new_r < height and end_r <= height and 0 <= new_c < width and end_c <= width:
             output_grid[new_r:end_r, new_c:end_c] = subgrid

    # Convert the final numpy array back to a list of lists
    return output_grid.tolist()
```
