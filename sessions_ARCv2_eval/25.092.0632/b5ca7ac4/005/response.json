{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nIdentifies specific rectangular objects within the input grid and moves them horizontally based on their frame color.\n\nObjects are defined as having:\n1.  A minimum size of 3x3.\n2.  A 1-pixel thick, perfectly rectangular frame of either azure (8) or red (2).\n3.  A solid rectangular core completely enclosed by the frame.\n4.  The core color must be different from both the frame color and the grid's background color.\n\nTransformation Steps:\n1.  Determine the background color of the input grid (assumed from the top-left corner).\n2.  Initialize an output grid of the same dimensions, filled entirely with the background color.\n3.  Find all qualifying framed rectangular objects in the input grid.\n4.  For each found object:\n    a.  Determine its frame color and its original pixel data (subgrid).\n    b.  Keep its original vertical position (top row).\n    c.  Calculate the new horizontal position (left column) based on the frame color:\n        - Azure (8) frames move to the left edge (column 0).\n        - Red (2) frames move to the right edge (last column).\n    d.  Draw the object's original pixel data (subgrid) onto the output grid at its new calculated position.\n5.  Return the completed output grid. Pixels not part of any moved object remain as the background color.\n\"\"\"\n\ndef _find_objects(grid, background_color):\n    \"\"\"\n    Internal helper function to find all framed rectangular objects matching the criteria.\n\n    Args:\n        grid (np.array): The input grid.\n        background_color (int): The background color.\n\n    Returns:\n        list: A list of dictionaries, each representing an object with keys:\n              'bbox': (min_r, min_c, max_r, max_c) - Original bounding box\n              'frame_color': The color of the frame (2 or 8)\n              'subgrid': A numpy array containing the object's pixels.\n    \"\"\"\n    height, width = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n\n    for r in range(height):\n        for c in range(width):\n            # Potential starting pixel for a frame? Must be Red(2) or Azure(8), not background, and not visited\n            if grid[r, c] in [2, 8] and grid[r, c] != background_color and not visited[r, c]:\n                frame_color = grid[r, c]\n                \n                # --- Step 1: BFS to find connected component of the frame color ---\n                q = deque([(r, c)])\n                component_pixels = set([(r, c)]) # Pixels belonging to this connected component\n                component_visited_bfs = set([(r, c)]) # Track visited *during this specific BFS*\n                min_r_bfs, min_c_bfs, max_r_bfs, max_c_bfs = r, c, r, c\n\n                while q:\n                    curr_r, curr_c = q.popleft()\n                    min_r_bfs = min(min_r_bfs, curr_r)\n                    min_c_bfs = min(min_c_bfs, curr_c)\n                    max_r_bfs = max(max_r_bfs, curr_r)\n                    max_c_bfs = max(max_c_bfs, curr_c)\n\n                    # Explore 8 neighbors (cardinal + diagonal)\n                    for dr in [-1, 0, 1]:\n                        for dc in [-1, 0, 1]:\n                            if dr == 0 and dc == 0:\n                                continue\n                            nr, nc = curr_r + dr, curr_c + dc\n                            \n                            # Check bounds, same color, and not visited in *this* BFS run\n                            if 0 <= nr < height and 0 <= nc < width and \\\n                               grid[nr, nc] == frame_color and (nr, nc) not in component_visited_bfs:\n                                component_visited_bfs.add((nr, nc))\n                                component_pixels.add((nr, nc))\n                                q.append((nr, nc))\n                \n                # --- Step 2: Define Bounding Box and Basic Size Check ---\n                min_r, min_c, max_r, max_c = min_r_bfs, min_c_bfs, max_r_bfs, max_c_bfs\n                obj_h = max_r - min_r + 1\n                obj_w = max_c - min_c + 1\n\n                # Must be at least 3x3 to have a frame and core\n                if obj_h < 3 or obj_w < 3:\n                    # Mark the found component pixels as globally visited and continue\n                    for fr, fc in component_pixels:\n                         if 0 <= fr < height and 0 <= fc < width: # boundary check just in case\n                            visited[fr, fc] = True\n                    continue \n\n                # --- Step 3: Validate Frame and Core Structure ---\n                is_valid_object = True\n                core_color = -1 # Sentinel value, indicates core color not yet found\n                \n                # Check every pixel within the bounding box derived from the BFS component\n                for ir in range(min_r, max_r + 1):\n                    for ic in range(min_c, max_c + 1):\n                        pixel_val = grid[ir, ic]\n                        is_on_border = (ir == min_r or ir == max_r or ic == min_c or ic == max_c)\n\n                        if is_on_border:\n                            # Border pixels MUST match the frame color found\n                            if pixel_val != frame_color:\n                                is_valid_object = False\n                                break\n                        else: # Inner pixel (potential core)\n                            # Core pixel cannot be the frame color or the background color\n                            if pixel_val == frame_color or pixel_val == background_color:\n                                is_valid_object = False\n                                break\n                            # Check for solid core color consistency\n                            if core_color == -1: # First valid core pixel found\n                                core_color = pixel_val\n                            elif pixel_val != core_color: # Subsequent core pixels must match\n                                is_valid_object = False\n                                break\n                    if not is_valid_object:\n                        break # Exit outer loop if invalidity found\n\n                # Final check: a core color must have been identified (not hollow)\n                if core_color == -1:\n                     is_valid_object = False\n\n                # --- Step 4: Process Valid/Invalid Object ---\n                if is_valid_object:\n                    # Extract the object's pixel data (subgrid)\n                    subgrid = grid[min_r:max_r+1, min_c:max_c+1]\n                    objects.append({\n                        'bbox': (min_r, min_c, max_r, max_c),\n                        'frame_color': frame_color,\n                        'subgrid': subgrid\n                    })\n                    # Mark all pixels *within the bounding box* of the valid object as globally visited\n                    visited[min_r:max_r+1, min_c:max_c+1] = True\n                else:\n                    # If validation failed, only mark the specific pixels found in the initial BFS component as visited\n                    # This prevents marking large areas based on an invalid structure\n                    for fr, fc in component_pixels:\n                         if 0 <= fr < height and 0 <= fc < width:\n                            visited[fr, fc] = True\n\n    return objects\n\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rule to the input grid. Finds framed objects\n    (red or azure frame, solid different-colored core) and moves them\n    horizontally to the grid edges based on frame color (azure->left, red->right),\n    preserving vertical position.\n\n    Args:\n        input_grid (list of lists): The input grid represented as a list of lists.\n\n    Returns:\n        list of lists: The transformed grid.\n    \"\"\"\n    # Convert input to numpy array for efficient processing\n    input_np = np.array(input_grid, dtype=int)\n    height, width = input_np.shape\n\n    # Determine background color (assuming top-left pixel is representative)\n    # Add simple check in case top-left is part of an object frame\n    background_color = input_np[0,0]\n    if background_color in [2, 8]: # if top-left is frame color, check neighbor\n        if width > 1:\n            background_color = input_np[0,1]\n        elif height > 1:\n            background_color = input_np[1,0]\n        # If still ambiguous, default might be needed, but examples suggest simple check is okay.\n        # A more robust method would be mode calculation, but let's stick to simple for now.\n\n    # Initialize the output grid filled with the background color\n    output_grid = np.full_like(input_np, background_color)\n\n    # Find all qualifying framed objects in the input grid\n    objects_to_move = _find_objects(input_np, background_color)\n\n    # Process each identified object\n    for obj in objects_to_move:\n        min_r, _, _, _ = obj['bbox'] # Only need original top row\n        frame_color = obj['frame_color']\n        subgrid = obj['subgrid']\n        obj_h, obj_w = subgrid.shape\n\n        # Calculate new target horizontal position (column)\n        new_c = 0 # Default target: left edge (for azure frame)\n        if frame_color == 2: # Red frame moves to the right edge\n            new_c = width - obj_w\n        \n        # Vertical position remains unchanged from the original object's top row\n        new_r = min_r\n\n        # Calculate the slice boundaries for placing the object in the output grid\n        end_r = new_r + obj_h\n        end_c = new_c + obj_w\n\n        # Place (draw) the object's subgrid onto the output grid at the new position\n        # Basic bounds check before assignment (though logic should prevent out-of-bounds)\n        if 0 <= new_r < height and end_r <= height and 0 <= new_c < width and end_c <= width:\n             output_grid[new_r:end_r, new_c:end_c] = subgrid\n\n    # Convert the final numpy array back to a standard list of lists for the output\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 23705,
    "candidates_token_count": 2452,
    "total_token_count": 26157,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 29.935767,
  "retries": 1
}