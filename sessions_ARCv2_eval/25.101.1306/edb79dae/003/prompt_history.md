
## train_1

**input:**
```
1 1 4 4 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
1 1 1 4 8 8 1 8 1 8 8 3 8 3 8 8 8 8 8 8 8 8 8 8
1 1 4 4 8 8 1 1 1 8 8 3 3 3 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 1 8 8 8 3 3 3 8 8 8 8 8 8 8 8 8 8
3 3 2 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
3 3 3 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
3 3 2 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 3 3 3 8 1 1 1 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 3 3 3 8 1 1 1 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 3 3 3 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 8 8 8 8 3 3 3 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 8 8 8 8 3 3 3 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 8 8 8 8 3 3 3 8 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 8 8 8 8 8 3 3 3 8 1 1 1 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 3 3 3 8 1 1 1 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 3 3 3 8 1 1 1 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 8 8
```


**output:**
```
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 2 8 2 8 4 8 4 8 2 8 2 8 4 8 4 8 5
5 8 2 2 2 8 4 4 4 8 2 2 2 8 4 4 4 8 5
5 8 2 2 2 8 8 4 8 8 2 2 2 8 8 4 8 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 2 8 2 8 4 8 4 8 8 8 8 8 2 8 2 8 5
5 8 2 2 2 8 4 4 4 8 8 8 8 8 2 2 2 8 5
5 8 2 2 2 8 8 4 8 8 8 8 8 8 2 2 2 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 8 8 8 8 2 8 2 8 4 8 4 8 4 8 4 8 5
5 8 8 8 8 8 2 2 2 8 4 4 4 8 4 4 4 8 5
5 8 8 8 8 8 2 2 2 8 8 4 8 8 8 4 8 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
```


## train_2

**input:**
```
2 2 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
2 2 2 4 1 1 2 2 2 2 1 3 3 3 3 1 1 6 6 6 6 1 1
2 2 4 4 1 1 2 2 2 2 1 1 3 3 1 1 1 6 6 1 1 1 1
1 1 1 1 1 1 2 1 2 2 1 3 3 3 3 1 1 6 6 1 1 1 1
3 3 8 8 1 1 2 1 2 2 1 3 1 1 3 1 1 6 6 6 6 1 1
3 3 3 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
3 3 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
6 6 7 7 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
6 6 6 7 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
6 6 7 7 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
1 1 1 1 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
```


**output:**
```
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 1 4 4 4 4 1 7 7 7 7 1 8 8 8 8 1 5
5 1 4 4 4 4 1 7 7 1 1 1 1 8 8 1 1 5
5 1 4 1 4 4 1 7 7 1 1 1 8 8 8 8 1 5
5 1 4 1 4 4 1 7 7 7 7 1 8 1 1 8 1 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 1 8 8 8 8 1 4 4 4 4 1 7 7 7 7 1 5
5 1 1 8 8 1 1 4 4 4 4 1 7 7 1 1 1 5
5 1 8 8 8 8 1 4 1 4 4 1 7 7 1 1 1 5
5 1 8 1 1 8 1 4 1 4 4 1 7 7 7 7 1 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
```

Okay, let's analyze the provided examples to understand the transformation logic.

**Perception**

1.  **Input Structure**: The input grids contain two main distinct regions:
    *   An area in the top-left containing small, usually rectangular blocks of color, often arranged in adjacent pairs. These seem to act as a "key" or "legend".
    *   A larger rectangular frame made of gray (5) pixels, typically located elsewhere in the grid. This frame encloses various patterns or objects made of different colors.
    *   There's a background/separator color used both in the "key" area and within the gray frame, although this color might differ between the two regions in some cases (need to verify). In `train_1`, azure (8) is prevalent both outside and inside the frame. In `train_2`, blue (1) is prevalent both outside (in the key area) and inside the frame.

2.  **Output Structure**: The output grid is significantly smaller than the input. It appears to directly correspond to the gray frame and its contents from the input. The output retains the gray frame structure. The patterns inside the frame are present but their colors have changed.

3.  **Transformation**: The core transformation involves:
    *   **Identifying the target area**: Locating the gray (5) frame in the input.
    *   **Cropping**: Extracting the subgrid corresponding to the bounding box of the gray frame. The output dimensions match this cropped area.
    *   **Identifying color mapping rules**: Analyzing the adjacent color pairs in the "key" area (outside the gray frame) to determine how colors should be transformed. Each pair `(Color A, Color B)` implies that pixels of `Color A` inside the frame should become `Color B` in the output.
    *   **Identifying invariant colors**: The gray (5) frame color remains unchanged. The background/separator color used within the frame (which is usually the same as the separator color in the key area) also remains unchanged.
    *   **Applying the mapping**: Iterating through the pixels of the cropped (frame) area and applying the derived color mappings, leaving the frame and background colors as they are.

**Facts**


```yaml
elements:
  - object: Frame
    properties:
      - color: gray (5)
      - shape: rectangle
      - role: defines the region of interest for the output

  - object: MappingKeyArea
    properties:
      - location: outside the Frame's bounding box
      - contains: MappingPairs and SeparatorPixels

  - object: MappingPair
    properties:
      - structure: two adjacent, distinct colored blocks (often rectangles)
      - role: defines a color transformation rule (color_A -> color_B)
      - location: within MappingKeyArea

  - object: InnerContent
    properties:
      - location: inside the Frame
      - composition: pixels potentially subject to color transformation
      - includes: BackgroundPixels

  - object: SeparatorPixel / BackgroundPixel
    properties:
      - color: varies by task (e.g., azure(8) in train_1, blue(1) in train_2)
      - location: separates MappingPairs in MappingKeyArea, acts as background/separator within InnerContent
      - behavior: remains unchanged during transformation

actions:
  - name: locate_frame
    input: input_grid
    output: bounding_box_of_gray_frame

  - name: extract_mapping_rules
    input: input_grid, frame_bounding_box
    process: scan area outside frame_bounding_box for adjacent color blocks (MappingPairs)
    output: dictionary_of_color_maps {color_A: color_B, ...}

  - name: identify_invariant_background
    input: input_grid, frame_bounding_box
    process: determine the dominant non-mapping color in the MappingKeyArea (outside the frame)
    output: invariant_background_color

  - name: crop_region
    input: input_grid, frame_bounding_box
    output: cropped_subgrid

  - name: apply_transformation
    input: cropped_subgrid, color_maps, invariant_background_color, frame_color (gray 5)
    process: iterate through cropped_subgrid pixels, apply color_maps, keep invariant_background_color and frame_color unchanged
    output: output_grid

relationships:
  - The Frame's bounding box determines the area to be cropped and transformed.
  - The MappingPairs outside the Frame define the color changes applied inside the Frame.
  - The SeparatorPixel color found outside the Frame identifies the color that remains unchanged inside the Frame (along with the Frame color itself).
  - The dimensions of the output grid are identical to the dimensions of the Frame's bounding box in the input.
```


**Natural Language Program**

1.  **Find the Frame**: Scan the input grid to identify the largest contiguous rectangular object composed solely of gray (5) pixels. Determine its bounding box (top-left and bottom-right coordinates).
2.  **Extract Mapping Rules and Invariant Background**:
    *   Examine the region of the input grid *outside* the Frame's bounding box.
    *   Identify pairs of distinctly colored, adjacent rectangular objects (typically small, like 2x2 or 1xN). For each pair `(Object A, Object B)` with `Color A` and `Color B`, record a mapping rule: `Color A` transforms to `Color B`.
    *   Identify the color that acts as a separator or background in this outside region, distinct from the colors in the mapping pairs. This is the `invariant_background_color`.
3.  **Crop**: Create a new grid by copying the portion of the input grid defined by the Frame's bounding box (including the frame itself).
4.  **Transform Colors**: Iterate through each pixel `(r, c)` in the cropped grid:
    *   Get the `current_color` of the pixel.
    *   If `current_color` is gray (5) (the frame color), keep it as gray (5) in the output.
    *   If `current_color` is the `invariant_background_color`, keep it as `invariant_background_color` in the output.
    *   If `current_color` matches the key (`Color A`) in any identified mapping rule (`Color A -> Color B`), change the pixel's color to the corresponding value (`Color B`) in the output.
    *   (Assumption: Any other color encountered inside the frame will be part of a mapping rule).
5.  **Output**: The resulting transformed grid is the final output.
```python
import numpy as np
from collections import Counter

"""
Transforms the input grid based on color mapping rules derived from key blocks outside a gray frame.

The transformation logic involves several steps:
1. Identifying a rectangular frame made of a specific color (gray, value 5) in the input grid by finding the minimum and maximum row and column indices of pixels with this color.
2. Locating key-value color pairs outside this frame by examining adjacent pixels. The logic prioritizes horizontal (left->right) adjacency, then vertical (top->down) adjacency to establish a mapping rule (Color A -> Color B). The frame color and the determined background color are ignored when searching for these pairs.
3. Determining the background color that should remain invariant during the transformation. This is identified as the most frequent color found in the area outside the frame, excluding the frame color itself and any colors that become part of a mapping rule (either as a key or a value). Fallback mechanisms are included if this primary identification method is ambiguous or fails.
4. Cropping the input grid to the exact region defined by the frame's bounding box (inclusive).
5. Creating the output grid by applying the derived mapping rules to the pixels within this cropped region. Pixels matching a key color (Color A) are changed to the corresponding value color (Color B). The frame color (5) and the identified invariant background color are preserved in their original positions. Any other pixel colors within the frame that are not part of the mapping rules also remain unchanged.
"""

def find_frame_bbox(grid_np: np.ndarray, frame_color: int = 5) -> tuple[int, int, int, int] | None:
    """
    Finds the bounding box coordinates (min_row, min_col, max_row, max_col) 
    of the pixels matching the specified frame color using their minimum and maximum indices.
    Returns None if the frame color is not present in the grid.
    """
    # Find all coordinates where the grid matches the frame color
    coords = np.argwhere(grid_np == frame_color)
    
    # If no coordinates are found, the frame color doesn't exist; return None
    if coords.size == 0:
        return None 
        
    # Determine the minimum and maximum row and column indices from the coordinates
    r_min, c_min = coords.min(axis=0)
    r_max, c_max = coords.max(axis=0)
    
    # Return the bounding box coordinates
    return (r_min, c_min, r_max, c_max)


def find_mapping_rules_and_background(grid_np: np.ndarray, frame_bbox: tuple[int, int, int, int] | None, frame_color: int = 5) -> tuple[dict[int, int], int]:
    """
    Identifies color mapping rules (as a dictionary {key_color: value_color}) 
    and the invariant background color (as an integer) by analyzing the region 
    of the grid outside the provided frame bounding box.
    """
    rows, cols = grid_np.shape
    
    # If the frame bounding box is not provided, return default empty mappings and background color 0
    if frame_bbox is None:
         print("Warning: Frame bounding box is None in find_mapping_rules. Returning defaults.")
         return {}, 0 

    r_min, c_min, r_max, c_max = frame_bbox

    outside_colors_counter = Counter()
    outside_coords = []
    # Iterate through each cell of the grid
    for r in range(rows):
        for c in range(cols):
            # Determine if the current cell is outside the frame's bounding box
            is_outside = not (r >= r_min and r <= r_max and c >= c_min and c <= c_max)
            if is_outside:
                color = grid_np[r, c]
                # Count the frequency of non-frame colors outside the frame
                if color != frame_color:
                    outside_colors_counter[color] += 1
                # Store the coordinates of all cells outside the frame
                outside_coords.append((r, c))

    # --- Determine Potential Background Color ---
    potential_background = -1
    # Sort the counted outside colors by frequency (descending) and then by color value (ascending)
    sorted_colors = sorted(outside_colors_counter.items(), key=lambda item: (-item[1], item[0]))
    # The most frequent color is the initial candidate for the background
    if sorted_colors:
        potential_background = sorted_colors[0][0] 
    else:
        # If no non-frame colors were found outside, default the background to 0
        potential_background = 0 

    # --- Find Mapping Rules by Checking Adjacency ---
    mappings = {} # Dictionary to store color_a -> color_b mappings
    mapped_colors = set() # Set to track colors involved in any mapping (key or value)
    processed_pairs = set() # Set to track unique pairs (a,b) to avoid redundant checks

    # Iterate through the coordinates identified as being outside the frame
    for r, c in outside_coords:
        color_a = grid_np[r, c]
        # Skip if the color is the frame color, the potential background, or already a mapping key
        if color_a == frame_color or color_a == potential_background or color_a in mappings:
            continue

        # Check the neighbor to the right
        if c + 1 < cols:
             nr, nc = r, c + 1
             # Check if the right neighbor is also outside the frame
             is_neighbor_outside = not (nr >= r_min and nr <= r_max and nc >= c_min and nc <= c_max)
             if is_neighbor_outside:
                 color_b = grid_np[nr, nc]
                 # Check if color_b is a valid target for mapping (different from A, not frame, not background)
                 if color_b != color_a and color_b != frame_color and color_b != potential_background:
                     # Create a sorted tuple to uniquely identify the pair regardless of order
                     pair = tuple(sorted((color_a, color_b)))
                     # If this pair hasn't been processed and color_a hasn't been mapped yet
                     if pair not in processed_pairs and color_a not in mappings:
                         # Establish the mapping A -> B (horizontal priority)
                         mappings[color_a] = color_b
                         mapped_colors.add(color_a)
                         mapped_colors.add(color_b)
                         processed_pairs.add(pair)
                         # Once color_a is mapped, move to the next coordinate in outside_coords
                         continue 

        # If no horizontal mapping was found, check the neighbor below
        if r + 1 < rows:
             nr, nc = r + 1, c
             # Check if the bottom neighbor is also outside the frame
             is_neighbor_outside = not (nr >= r_min and nr <= r_max and nc >= c_min and nc <= c_max)
             if is_neighbor_outside:
                  color_b = grid_np[nr, nc]
                  # Check if color_b is a valid target for mapping
                  if color_b != color_a and color_b != frame_color and color_b != potential_background:
                      pair = tuple(sorted((color_a, color_b)))
                      # If this pair hasn't been processed and color_a hasn't been mapped yet
                      if pair not in processed_pairs and color_a not in mappings:
                           # Establish the mapping A -> B (vertical)
                           mappings[color_a] = color_b
                           mapped_colors.add(color_a)
                           mapped_colors.add(color_b)
                           processed_pairs.add(pair)
                           # Loop continues to the next coordinate

    # --- Finalize Background Color ---
    actual_background = potential_background
    # If the initial potential background color was used in a mapping
    if potential_background in mapped_colors:
        actual_background = -1 # Reset the background color
        # Find the next most frequent outside color that *wasn't* mapped
        for color, count in sorted_colors: 
            if color not in mapped_colors:
                actual_background = color
                break # Found a suitable background color

        # Fallback if all outside non-frame colors were involved in mappings
        if actual_background == -1:
            # Check inside the frame (excluding the border) for the most frequent color
            # that isn't the frame color and wasn't mapped.
            inside_counter = Counter()
            # Check if frame has an interior (width and height > 1 pixel excluding borders)
            if r_max > r_min and c_max > c_min: 
                 for r_in in range(r_min + 1, r_max):
                     for c_in in range(c_min + 1, c_max):
                         color = grid_np[r_in, c_in]
                         # Count frequency if not frame color and not already mapped
                         if color != frame_color and color not in mapped_colors:
                             inside_counter[color] += 1
            
            # Sort the inside colors by frequency
            sorted_inside = sorted(inside_counter.items(), key=lambda item: (-item[1], item[0]))
            if sorted_inside:
                 # The most frequent unmapped inside color becomes the background
                 actual_background = sorted_inside[0][0] 
            else:
                # If no suitable background found via any method, default to 0
                print("Warning: Could not determine a definitive background color. Defaulting to 0.")
                actual_background = 0 

    # Return the final mapping rules and the determined background color
    return mappings, actual_background


def transform(input_grid: list[list[int]]) -> list[list[int]]:
    """
    Transforms the input grid according to ARC task logic:
    1. Finds a gray (5) frame.
    2. Derives color mapping rules from adjacent color blocks outside the frame.
    3. Determines the invariant background color.
    4. Crops the grid to the frame's boundaries.
    5. Applies the mappings to the cropped area, preserving frame and background colors.
    """
    # Convert the input list of lists to a NumPy array for efficient operations
    input_np = np.array(input_grid, dtype=int)
    frame_color = 5 # Define the color designated as the frame

    # Step 1: Find the bounding box of the gray frame
    frame_bbox = find_frame_bbox(input_np, frame_color)

    # If no frame is detected, return the original input grid as per ARC convention
    if frame_bbox is None:
        # print("Warning: No frame (color 5) found. Returning input grid unchanged.")
        return input_grid

    r_min, c_min, r_max, c_max = frame_bbox

    # Step 2: Determine the color mapping rules and the invariant background color
    mappings, invariant_background = find_mapping_rules_and_background(input_np, frame_bbox, frame_color)

    # Step 3: Crop the input grid to the area defined by the frame's bounding box.
    # Create a copy to avoid modifying the original input array slice.
    output_np = input_np[r_min:r_max + 1, c_min:c_max + 1].copy()
    output_h, output_w = output_np.shape # Get dimensions of the output grid

    # Step 4: Apply the transformation rules to the cropped grid (output_np)
    for r_out in range(output_h):
        for c_out in range(output_w):
            current_color = output_np[r_out, c_out]

            # Check conditions and apply transformations:
            # If the color is the frame color, do nothing.
            if current_color == frame_color:
                continue 
            # If the color is the invariant background, do nothing.
            elif current_color == invariant_background:
                continue 
            # If the color is a key in the mappings dictionary, change it to the mapped value.
            elif current_color in mappings:
                output_np[r_out, c_out] = mappings[current_color]
            # Otherwise (color is not frame, not background, not a mapping key), it remains unchanged.
            
    # Convert the transformed NumPy array back to a standard Python list of lists
    output_grid = output_np.tolist()

    # Return the final transformed grid
    return output_grid
```

Previous Code:
```python
import numpy as np
from collections import Counter

"""
Transforms the input grid based on color mapping rules derived from key blocks outside a gray frame.

The transformation logic involves several steps:
1. Identifying a rectangular frame made of a specific color (gray, value 5) in the input grid by finding the minimum and maximum row and column indices of pixels with this color.
2. Locating key-value color pairs outside this frame by examining adjacent pixels. The logic prioritizes horizontal (left->right) adjacency, then vertical (top->down) adjacency to establish a mapping rule (Color A -> Color B). The frame color and the determined background color are ignored when searching for these pairs.
3. Determining the background color that should remain invariant during the transformation. This is identified as the most frequent color found in the area outside the frame, excluding the frame color itself and any colors that become part of a mapping rule (either as a key or a value). Fallback mechanisms are included if this primary identification method is ambiguous or fails.
4. Cropping the input grid to the exact region defined by the frame's bounding box (inclusive).
5. Creating the output grid by applying the derived mapping rules to the pixels within this cropped region. Pixels matching a key color (Color A) are changed to the corresponding value color (Color B). The frame color (5) and the identified invariant background color are preserved in their original positions. Any other pixel colors within the frame that are not part of the mapping rules also remain unchanged.
"""

def find_frame_bbox(grid_np: np.ndarray, frame_color: int = 5) -> tuple[int, int, int, int] | None:
    """
    Finds the bounding box coordinates (min_row, min_col, max_row, max_col) 
    of the pixels matching the specified frame color using their minimum and maximum indices.
    Returns None if the frame color is not present in the grid.
    """
    # Find all coordinates where the grid matches the frame color
    coords = np.argwhere(grid_np == frame_color)
    
    # If no coordinates are found, the frame color doesn't exist; return None
    if coords.size == 0:
        return None 
        
    # Determine the minimum and maximum row and column indices from the coordinates
    r_min, c_min = coords.min(axis=0)
    r_max, c_max = coords.max(axis=0)
    
    # Return the bounding box coordinates
    return (r_min, c_min, r_max, c_max)


def find_mapping_rules_and_background(grid_np: np.ndarray, frame_bbox: tuple[int, int, int, int] | None, frame_color: int = 5) -> tuple[dict[int, int], int]:
    """
    Identifies color mapping rules (as a dictionary {key_color: value_color}) 
    and the invariant background color (as an integer) by analyzing the region 
    of the grid outside the provided frame bounding box.
    """
    rows, cols = grid_np.shape
    
    # If the frame bounding box is not provided, return default empty mappings and background color 0
    if frame_bbox is None:
         print("Warning: Frame bounding box is None in find_mapping_rules. Returning defaults.")
         return {}, 0 

    r_min, c_min, r_max, c_max = frame_bbox

    outside_colors_counter = Counter()
    outside_coords = []
    # Iterate through each cell of the grid
    for r in range(rows):
        for c in range(cols):
            # Determine if the current cell is outside the frame's bounding box
            is_outside = not (r >= r_min and r <= r_max and c >= c_min and c <= c_max)
            if is_outside:
                color = grid_np[r, c]
                # Count the frequency of non-frame colors outside the frame
                if color != frame_color:
                    outside_colors_counter[color] += 1
                # Store the coordinates of all cells outside the frame
                outside_coords.append((r, c))

    # --- Determine Potential Background Color ---
    potential_background = -1
    # Sort the counted outside colors by frequency (descending) and then by color value (ascending)
    sorted_colors = sorted(outside_colors_counter.items(), key=lambda item: (-item[1], item[0]))
    # The most frequent color is the initial candidate for the background
    if sorted_colors:
        potential_background = sorted_colors[0][0] 
    else:
        # If no non-frame colors were found outside, default the background to 0
        potential_background = 0 

    # --- Find Mapping Rules by Checking Adjacency ---
    mappings = {} # Dictionary to store color_a -> color_b mappings
    mapped_colors = set() # Set to track colors involved in any mapping (key or value)
    processed_pairs = set() # Set to track unique pairs (a,b) to avoid redundant checks

    # Iterate through the coordinates identified as being outside the frame
    for r, c in outside_coords:
        color_a = grid_np[r, c]
        # Skip if the color is the frame color, the potential background, or already a mapping key
        if color_a == frame_color or color_a == potential_background or color_a in mappings:
            continue

        # Check the neighbor to the right
        if c + 1 < cols:
             nr, nc = r, c + 1
             # Check if the right neighbor is also outside the frame
             is_neighbor_outside = not (nr >= r_min and nr <= r_max and nc >= c_min and nc <= c_max)
             if is_neighbor_outside:
                 color_b = grid_np[nr, nc]
                 # Check if color_b is a valid target for mapping (different from A, not frame, not background)
                 if color_b != color_a and color_b != frame_color and color_b != potential_background:
                     # Create a sorted tuple to uniquely identify the pair regardless of order
                     pair = tuple(sorted((color_a, color_b)))
                     # If this pair hasn't been processed and color_a hasn't been mapped yet
                     if pair not in processed_pairs and color_a not in mappings:
                         # Establish the mapping A -> B (horizontal priority)
                         mappings[color_a] = color_b
                         mapped_colors.add(color_a)
                         mapped_colors.add(color_b)
                         processed_pairs.add(pair)
                         # Once color_a is mapped, move to the next coordinate in outside_coords
                         continue 

        # If no horizontal mapping was found, check the neighbor below
        if r + 1 < rows:
             nr, nc = r + 1, c
             # Check if the bottom neighbor is also outside the frame
             is_neighbor_outside = not (nr >= r_min and nr <= r_max and nc >= c_min and nc <= c_max)
             if is_neighbor_outside:
                  color_b = grid_np[nr, nc]
                  # Check if color_b is a valid target for mapping
                  if color_b != color_a and color_b != frame_color and color_b != potential_background:
                      pair = tuple(sorted((color_a, color_b)))
                      # If this pair hasn't been processed and color_a hasn't been mapped yet
                      if pair not in processed_pairs and color_a not in mappings:
                           # Establish the mapping A -> B (vertical)
                           mappings[color_a] = color_b
                           mapped_colors.add(color_a)
                           mapped_colors.add(color_b)
                           processed_pairs.add(pair)
                           # Loop continues to the next coordinate

    # --- Finalize Background Color ---
    actual_background = potential_background
    # If the initial potential background color was used in a mapping
    if potential_background in mapped_colors:
        actual_background = -1 # Reset the background color
        # Find the next most frequent outside color that *wasn't* mapped
        for color, count in sorted_colors: 
            if color not in mapped_colors:
                actual_background = color
                break # Found a suitable background color

        # Fallback if all outside non-frame colors were involved in mappings
        if actual_background == -1:
            # Check inside the frame (excluding the border) for the most frequent color
            # that isn't the frame color and wasn't mapped.
            inside_counter = Counter()
            # Check if frame has an interior (width and height > 1 pixel excluding borders)
            if r_max > r_min and c_max > c_min: 
                 for r_in in range(r_min + 1, r_max):
                     for c_in in range(c_min + 1, c_max):
                         color = grid_np[r_in, c_in]
                         # Count frequency if not frame color and not already mapped
                         if color != frame_color and color not in mapped_colors:
                             inside_counter[color] += 1
            
            # Sort the inside colors by frequency
            sorted_inside = sorted(inside_counter.items(), key=lambda item: (-item[1], item[0]))
            if sorted_inside:
                 # The most frequent unmapped inside color becomes the background
                 actual_background = sorted_inside[0][0] 
            else:
                # If no suitable background found via any method, default to 0
                print("Warning: Could not determine a definitive background color. Defaulting to 0.")
                actual_background = 0 

    # Return the final mapping rules and the determined background color
    return mappings, actual_background


def transform(input_grid: list[list[int]]) -> list[list[int]]:
    """
    Transforms the input grid according to ARC task logic:
    1. Finds a gray (5) frame.
    2. Derives color mapping rules from adjacent color blocks outside the frame.
    3. Determines the invariant background color.
    4. Crops the grid to the frame's boundaries.
    5. Applies the mappings to the cropped area, preserving frame and background colors.
    """
    # Convert the input list of lists to a NumPy array for efficient operations
    input_np = np.array(input_grid, dtype=int)
    frame_color = 5 # Define the color designated as the frame

    # Step 1: Find the bounding box of the gray frame
    frame_bbox = find_frame_bbox(input_np, frame_color)

    # If no frame is detected, return the original input grid as per ARC convention
    if frame_bbox is None:
        # print("Warning: No frame (color 5) found. Returning input grid unchanged.")
        return input_grid

    r_min, c_min, r_max, c_max = frame_bbox

    # Step 2: Determine the color mapping rules and the invariant background color
    mappings, invariant_background = find_mapping_rules_and_background(input_np, frame_bbox, frame_color)

    # Step 3: Crop the input grid to the area defined by the frame's bounding box.
    # Create a copy to avoid modifying the original input array slice.
    output_np = input_np[r_min:r_max + 1, c_min:c_max + 1].copy()
    output_h, output_w = output_np.shape # Get dimensions of the output grid

    # Step 4: Apply the transformation rules to the cropped grid (output_np)
    for r_out in range(output_h):
        for c_out in range(output_w):
            current_color = output_np[r_out, c_out]

            # Check conditions and apply transformations:
            # If the color is the frame color, do nothing.
            if current_color == frame_color:
                continue 
            # If the color is the invariant background, do nothing.
            elif current_color == invariant_background:
                continue 
            # If the color is a key in the mappings dictionary, change it to the mapped value.
            elif current_color in mappings:
                output_np[r_out, c_out] = mappings[current_color]
            # Otherwise (color is not frame, not background, not a mapping key), it remains unchanged.
            
    # Convert the transformed NumPy array back to a standard Python list of lists
    output_grid = output_np.tolist()

    # Return the final transformed grid
    return output_grid
```
Results for code_00.py:

Train Set Results:

## Example 1:
Input:
```
1 1 4 4 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
1 1 1 4 8 8 1 8 1 8 8 3 8 3 8 8 8 8 8 8 8 8 8 8
1 1 4 4 8 8 1 1 1 8 8 3 3 3 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 1 8 8 8 3 3 3 8 8 8 8 8 8 8 8 8 8
3 3 2 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
3 3 3 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
3 3 2 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 3 3 3 8 1 1 1 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 3 3 3 8 1 1 1 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 3 3 3 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 8 8 8 8 3 3 3 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 8 8 8 8 3 3 3 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 8 8 8 8 3 3 3 8 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 8 8 8 8 8 3 3 3 8 1 1 1 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 3 3 3 8 1 1 1 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 3 3 3 8 1 1 1 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 8 8
```
Expected Output:
```
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 2 8 2 8 4 8 4 8 2 8 2 8 4 8 4 8 5
5 8 2 2 2 8 4 4 4 8 2 2 2 8 4 4 4 8 5
5 8 2 2 2 8 8 4 8 8 2 2 2 8 8 4 8 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 2 8 2 8 4 8 4 8 8 8 8 8 2 8 2 8 5
5 8 2 2 2 8 4 4 4 8 8 8 8 8 2 2 2 8 5
5 8 2 2 2 8 8 4 8 8 8 8 8 8 2 2 2 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 8 8 8 8 2 8 2 8 4 8 4 8 4 8 4 8 5
5 8 8 8 8 8 2 2 2 8 4 4 4 8 4 4 4 8 5
5 8 8 8 8 8 2 2 2 8 8 4 8 8 8 4 8 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
```
Transformed Output:
```
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 2 2 2 8 4 4 4 8 2 2 2 8 4 4 4 8 5
5 8 2 2 2 8 4 4 4 8 2 2 2 8 4 4 4 8 5
5 8 2 2 2 8 4 4 4 8 2 2 2 8 4 4 4 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 2 2 2 8 4 4 4 8 8 8 8 8 2 2 2 8 5
5 8 2 2 2 8 4 4 4 8 8 8 8 8 2 2 2 8 5
5 8 2 2 2 8 4 4 4 8 8 8 8 8 2 2 2 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 8 8 8 8 2 2 2 8 4 4 4 8 4 4 4 8 5
5 8 8 8 8 8 2 2 2 8 4 4 4 8 4 4 4 8 5
5 8 8 8 8 8 2 2 2 8 4 4 4 8 4 4 4 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
```
Match: False
Pixels Off: 20
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 14.035087719298247

## Example 2:
Input:
```
2 2 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
2 2 2 4 1 1 2 2 2 2 1 3 3 3 3 1 1 6 6 6 6 1 1
2 2 4 4 1 1 2 2 2 2 1 1 3 3 1 1 1 6 6 1 1 1 1
1 1 1 1 1 1 2 1 2 2 1 3 3 3 3 1 1 6 6 1 1 1 1
3 3 8 8 1 1 2 1 2 2 1 3 1 1 3 1 1 6 6 6 6 1 1
3 3 3 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
3 3 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
6 6 7 7 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
6 6 6 7 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
6 6 7 7 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
1 1 1 1 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
```
Expected Output:
```
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 1 4 4 4 4 1 7 7 7 7 1 8 8 8 8 1 5
5 1 4 4 4 4 1 7 7 1 1 1 1 8 8 1 1 5
5 1 4 1 4 4 1 7 7 1 1 1 8 8 8 8 1 5
5 1 4 1 4 4 1 7 7 7 7 1 8 1 1 8 1 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 1 8 8 8 8 1 4 4 4 4 1 7 7 7 7 1 5
5 1 1 8 8 1 1 4 4 4 4 1 7 7 1 1 1 5
5 1 8 8 8 8 1 4 1 4 4 1 7 7 1 1 1 5
5 1 8 1 1 8 1 4 1 4 4 1 7 7 7 7 1 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
```
Transformed Output:
```
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 1 4 4 4 4 1 7 7 7 7 1 8 8 8 8 1 5
5 1 4 4 4 4 1 7 7 7 7 1 8 8 8 8 1 5
5 1 4 4 4 4 1 7 7 7 7 1 8 8 8 8 1 5
5 1 4 4 4 4 1 7 7 7 7 1 8 8 8 8 1 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 1 8 8 8 8 1 4 4 4 4 1 7 7 7 7 1 5
5 1 8 8 8 8 1 4 4 4 4 1 7 7 7 7 1 5
5 1 8 8 8 8 1 4 4 4 4 1 7 7 7 7 1 5
5 1 8 8 8 8 1 4 4 4 4 1 7 7 7 7 1 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
```
Match: False
Pixels Off: 20
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 17.09401709401709
**General Assessment and Strategy**

The initial analysis correctly identified the core components: a gray frame defining the output area, a key area outside the frame providing color mapping rules, and an invariant background color. The initial code successfully implemented frame finding, cropping, background identification, and basic pixel-wise color mapping based on adjacent key pairs.

However, the results show that a simple pixel-wise mapping is insufficient. The errors indicate that the *shape* or internal structure of the colored objects within the frame changes during the transformation, with some pixels becoming the background color.

The refined hypothesis is that the key area *also* contains "template" objects. For each color `A` that maps to color `B`, there's a corresponding template object outside the frame, composed of color `A` and the background color. This template defines the exact shape and internal pattern (including background pixels) of the output object. When a contiguous block of color `A` is found *inside* the frame, it is replaced by its corresponding template shape, substituting `A` with `B` and keeping the background pixels from the template. The placement seems to align with the top-left corner of the original block within the frame, and the dimensions of the output block are determined by the template.

The strategy is to:
1.  Refine the logic for analyzing the key area to extract not only the `A -> B` mapping pairs but also the associated template shape for each color `A`.
2.  Modify the transformation step to identify contiguous blocks of color `A` inside the frame.
3.  For each block, retrieve the corresponding template, perform the `A -> B` color substitution on it, and write this resulting pattern into the output grid at the block's location.

**Gather Metrics**

We will use code execution to verify the components of the refined hypothesis for `train_1`.



*code_execution:*
```python
import numpy as np
from collections import Counter

# --- Data for train_1 ---
input_grid_1 = [
    [1, 1, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
    [1, 1, 1, 4, 8, 8, 1, 8, 1, 8, 8, 3, 8, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
    [1, 1, 4, 4, 8, 8, 1, 1, 1, 8, 8, 3, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
    [8, 8, 8, 8, 8, 8, 8, 1, 8, 8, 8, 3, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
    [3, 3, 2, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
    [3, 3, 3, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
    [3, 3, 2, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
    [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
    [8, 8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8],
    [8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 3, 3, 3, 8, 1, 1, 1, 8, 3, 3, 3, 8, 1, 1, 1, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 3, 3, 3, 8, 1, 1, 1, 8, 3, 3, 3, 8, 1, 1, 1, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 3, 3, 3, 8, 1, 1, 1, 8, 3, 3, 3, 8, 1, 1, 1, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 3, 3, 3, 8, 1, 1, 1, 8, 8, 8, 8, 8, 3, 3, 3, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 3, 3, 3, 8, 1, 1, 1, 8, 8, 8, 8, 8, 3, 3, 3, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 3, 3, 3, 8, 1, 1, 1, 8, 8, 8, 8, 8, 3, 3, 3, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 8, 8, 8, 8, 3, 3, 3, 8, 1, 1, 1, 8, 1, 1, 1, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 8, 8, 8, 8, 3, 3, 3, 8, 1, 1, 1, 8, 1, 1, 1, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 8, 8, 8, 8, 3, 3, 3, 8, 1, 1, 1, 8, 1, 1, 1, 8, 5, 8, 8],
    [8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 8],
    [8, 8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8]
]
input_np_1 = np.array(input_grid_1)
frame_color = 5

# --- Helper Function: Find Frame ---
def find_frame_bbox(grid_np: np.ndarray, frame_color: int = 5) -> tuple[int, int, int, int] | None:
    coords = np.argwhere(grid_np == frame_color)
    if coords.size == 0: return None
    r_min, c_min = coords.min(axis=0)
    r_max, c_max = coords.max(axis=0)
    # Basic check for rectangularity (all frame pixels on the border)
    is_rect = True
    for r, c in coords:
        if not (r == r_min or r == r_max or c == c_min or c == c_max):
            is_rect = False
            break
    # More robust check might be needed for complex cases
    return (r_min, c_min, r_max, c_max) if is_rect else None

# --- Helper Function: Find Contiguous Blocks ---
def find_contiguous_blocks(grid, target_colors):
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    blocks = {} # {color: [(r, c, h, w, block_array)]}

    for r in range(rows):
        for c in range(cols):
            color = grid[r, c]
            if color in target_colors and not visited[r, c]:
                block_coords = []
                q = [(r, c)]
                visited[r, c] = True
                min_r, min_c = r, c
                max_r, max_c = r, c

                while q:
                    curr_r, curr_c = q.pop(0)
                    block_coords.append((curr_r, curr_c))
                    min_r, min_c = min(min_r, curr_r), min(min_c, curr_c)
                    max_r, max_c = max(max_r, curr_r), max(max_c, curr_c)

                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                        nr, nc = curr_r + dr, curr_c + dc
                        if 0 <= nr < rows and 0 <= nc < cols and \
                           not visited[nr, nc] and grid[nr, nc] == color:
                            visited[nr, nc] = True
                            q.append((nr, nc))

                h = max_r - min_r + 1
                w = max_c - min_c + 1
                block_arr = grid[min_r:max_r+1, min_c:max_c+1] # This captures the bounding box, might contain other colors if not rectangular

                # Refine block_arr to only contain the actual block pixels relative to top-left
                relative_coords = [(br - min_r, bc - min_c) for br, bc in block_coords]
                refined_block_arr = np.full((h, w), -1) # Use -1 or another placeholder
                for rr, rc in relative_coords:
                    refined_block_arr[rr, rc] = color

                if color not in blocks: blocks[color] = []
                blocks[color].append({'r': min_r, 'c': min_c, 'h': h, 'w': w, 'coords': block_coords, 'array': block_arr, 'refined_array': refined_block_arr})
    return blocks

# --- Helper Function: Find Contiguous Blocks with Background ---
def find_template_blocks(grid, target_colors, background_color):
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    blocks = {} # {color: [(r, c, h, w, block_array)]}
    allowed_colors = set(target_colors) | {background_color}

    for r in range(rows):
        for c in range(cols):
            color = grid[r, c]
            # Start search from a target_color pixel
            if color in target_colors and not visited[r, c]:
                component_coords = []
                q = [(r, c)]
                visited[r, c] = True
                min_r, min_c = r, c
                max_r, max_c = r, c
                has_target_color = {color} # Track which target colors are in this component

                while q:
                    curr_r, curr_c = q.pop(0)
                    component_coords.append((curr_r, curr_c))
                    min_r, min_c = min(min_r, curr_r), min(min_c, curr_c)
                    max_r, max_c = max(max_r, curr_r), max(max_c, curr_c)

                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                        nr, nc = curr_r + dr, curr_c + dc
                        if 0 <= nr < rows and 0 <= nc < cols and \
                           not visited[nr, nc] and grid[nr, nc] in allowed_colors:
                            visited[nr, nc] = True
                            q.append((nr, nc))
                            if grid[nr, nc] in target_colors:
                                has_target_color.add(grid[nr, nc])

                # Only consider components that contain exactly ONE target color
                if len(has_target_color) == 1:
                    primary_color = list(has_target_color)[0]
                    h = max_r - min_r + 1
                    w = max_c - min_c + 1
                    block_arr = grid[min_r:max_r+1, min_c:max_c+1].copy() # Bounding box subgrid

                    # Ensure only primary and background colors are present
                    valid_template = True
                    for comp_r, comp_c in component_coords:
                        if grid[comp_r, comp_c] not in [primary_color, background_color]:
                            valid_template = False
                            break
                    if not valid_template:
                         continue # Skip this component

                    if primary_color not in blocks: blocks[primary_color] = []
                    # Store the bounding box version as the template
                    blocks[primary_color].append({'r': min_r, 'c': min_c, 'h': h, 'w': w, 'array': block_arr})
                # else: # Component has multiple target colors or only background, ignore
                    # print(f"Skipping component at ({r},{c}) with colors: {has_target_color}")
                    # pass # Reset visited status? No, keep visited.


    # Select the largest template for each color
    final_templates = {}
    for color, template_list in blocks.items():
        if template_list:
            largest_template = max(template_list, key=lambda t: t['array'].size)
            final_templates[color] = largest_template['array']

    return final_templates


# --- Analysis for train_1 ---
print("--- Analyzing Train Example 1 ---")
frame_bbox_1 = find_frame_bbox(input_np_1, frame_color)
print(f"Frame BBox: {frame_bbox_1}")

if frame_bbox_1:
    r_min, c_min, r_max, c_max = frame_bbox_1
    rows, cols = input_np_1.shape
    outside_colors_counter = Counter()
    outside_coords = []
    for r in range(rows):
        for c in range(cols):
            is_outside = not (r >= r_min and r <= r_max and c >= c_min and c <= c_max)
            if is_outside:
                color = input_np_1[r, c]
                if color != frame_color:
                    outside_colors_counter[color] += 1
                outside_coords.append((r, c))

    sorted_colors = sorted(outside_colors_counter.items(), key=lambda item: (-item[1], item[0]))
    potential_background = sorted_colors[0][0] if sorted_colors else 0
    print(f"Most frequent outside color (potential background): {potential_background}") # Should be 8

    # Find mapping pairs (simple adjacency check)
    mappings = {}
    processed_pairs = set()
    for r, c in outside_coords:
        color_a = input_np_1[r, c]
        if color_a == frame_color or color_a == potential_background or color_a in mappings: continue
        # Check right
        if c + 1 < cols:
            nr, nc = r, c + 1
            is_neighbor_outside = not (nr >= r_min and nr <= r_max and nc >= c_min and nc <= c_max)
            if is_neighbor_outside:
                color_b = input_np_1[nr, nc]
                if color_b != color_a and color_b != frame_color and color_b != potential_background:
                     pair = tuple(sorted((color_a, color_b)))
                     if pair not in processed_pairs and color_a not in mappings:
                         # Simple heuristic: assume smaller blocks map from larger blocks if sizes differ? No, just adjacency.
                         # Let's assume left maps to right for now.
                         mappings[color_a] = color_b
                         processed_pairs.add(pair)
                         continue # Skip vertical check if horizontal found
        # Check down
        if r + 1 < rows:
             nr, nc = r + 1, c
             is_neighbor_outside = not (nr >= r_min and nr <= r_max and nc >= c_min and nc <= c_max)
             if is_neighbor_outside:
                  color_b = input_np_1[nr, nc]
                  if color_b != color_a and color_b != frame_color and color_b != potential_background:
                      pair = tuple(sorted((color_a, color_b)))
                      if pair not in processed_pairs and color_a not in mappings:
                          # Assume top maps to bottom
                          mappings[color_a] = color_b
                          processed_pairs.add(pair)

    # Refine mappings based on block adjacency (using the found pairs)
    # Keys: 1 maps to 4? Or 4 maps to 1? 3 maps to 2? Or 2 maps to 3?
    # Look at pairs: (1,4) found near (0,2). (3,2) found near (4,0).
    # Assume the first color in the pair is the key:
    final_mappings = {}
    mapped_colors = set()
    # Manually identify from visual inspection for train_1: (1,4) and (3,2) are the pairs.
    # Let's assume the order seen (left-to-right, top-to-bottom preference) matters.
    # Pair at (0,0) is 1, (0,2) is 4 -> 1 maps to 4?
    # Pair at (4,0) is 3, (4,2) is 2 -> 3 maps to 2?
    final_mappings = {1: 4, 3: 2} # Based on visual inspection and hypothesis
    mapped_colors = {1, 4, 3, 2}
    print(f"Deduced Mappings: {final_mappings}")

    # Determine actual background
    actual_background = -1
    for color, count in sorted_colors:
        if color not in mapped_colors:
            actual_background = color
            break
    if actual_background == -1: actual_background = potential_background # Fallback
    print(f"Final Background Color: {actual_background}") # Should be 8

    # Find templates outside frame
    outside_grid_np = input_np_1.copy()
    # Mask the inside of the frame to avoid considering it for templates
    outside_grid_np[r_min:r_max+1, c_min:c_max+1] = -99 # Assign a unique ignored value

    template_colors = final_mappings.keys()
    templates = find_template_blocks(outside_grid_np, template_colors, actual_background)

    print("Found Templates:")
    for color, template in templates.items():
        print(f"  Color {color}:")
        print(template)

    # Find blocks inside frame
    inside_grid_np = input_np_1[r_min:r_max+1, c_min:c_max+1]
    inside_blocks = find_contiguous_blocks(inside_grid_np, template_colors) # Find blocks of colors 1 and 3

    print("Found Blocks Inside Frame:")
    for color, block_list in inside_blocks.items():
        print(f"  Color {color}:")
        for i, block in enumerate(block_list):
            # Print only refined array if it exists and looks okay
             print(f"    Block {i} at ({block['r']}, {block['c']}) - Size ({block['h']}x{block['w']})")
             # print(block.get('refined_array', 'N/A')) # Might be too verbose
             # Check if refined_array exists and contains only the target color or -1
             refined = block.get('refined_array')
             if refined is not None:
                 is_pure = np.all((refined == color) | (refined == -1))
                 print(f"      Pure block (only color {color}): {is_pure}")
                 if not is_pure:
                     print("      Contains other colors in bounding box:")
                     print(block['array']) # Print bounding box if refined isn't pure


else:
    print("No frame found.")


```

*code_execution_result:*
outcome: OUTCOME_OK
```
--- Analyzing Train Example 1 ---
Frame BBox: (np.int64(8), np.int64(3), np.int64(22), np.int64(21))
Most frequent outside color (potential background): 8
Deduced Mappings: {1: 4, 3: 2}
Final Background Color: 8
Found Templates:
Found Blocks Inside Frame:
  Color 3:
    Block 0 at (2, 2) - Size (3x3)
      Pure block (only color 3): True
    Block 1 at (2, 10) - Size (3x3)
      Pure block (only color 3): True
    Block 2 at (6, 2) - Size (3x3)
      Pure block (only color 3): True
    Block 3 at (6, 14) - Size (3x3)
      Pure block (only color 3): True
    Block 4 at (10, 6) - Size (3x3)
      Pure block (only color 3): True
  Color 1:
    Block 0 at (2, 6) - Size (3x3)
      Pure block (only color 1): True
    Block 1 at (2, 14) - Size (3x3)
      Pure block (only color 1): True
    Block 2 at (6, 6) - Size (3x3)
      Pure block (only color 1): True
    Block 3 at (10, 10) - Size (3x3)
      Pure block (only color 1): True
    Block 4 at (10, 14) - Size (3x3)
      Pure block (only color 1): True

```
**Analysis of Metrics:**

*   **Frame Detection:** Correctly identified `(r=8, c=3)` to `(r=22, c=21)`.
*   **Background Color:** Correctly identified as `8` (azure).
*   **Mappings:** Correctly deduced as `1 -> 4` and `3 -> 2`.
*   **Template Finding:** The `find_template_blocks` function seems to have failed or didn't find blocks matching the criteria (composed solely of the target color and background color, outside the frame). This needs revision. Looking at the input `train_1` again, the key area has blocks like `[[1, 8, 1], [1, 1, 1], [8, 1, 8]]` and `[[3, 8, 3], [3, 3, 3], [3, 3, 3]]`. These *are* the templates. My helper function needs to correctly isolate these specific blocks. The current `find_template_blocks` might be too restrictive or flawed in how it explores/validates components.
    *   *Correction Strategy:* The template isn't necessarily the *largest* block, but rather a specific block composed of the source color `A` and the background color, located outside the frame. We need a better way to identify these specific template blocks, perhaps by looking for blocks containing *both* the source color and the background color.
*   **Inside Blocks:** The `find_contiguous_blocks` function correctly identified the locations and sizes of the pure blocks of colors `1` and `3` inside the frame's bounding box. The coordinates are relative to the cropped grid (frame area).

**Revised YAML Facts**


```yaml
elements:
  - object: Frame
    properties:
      - color: gray (5)
      - shape: rectangle (hollow)
      - role: defines the region of interest (ROI) for cropping and output

  - object: MappingKeyArea
    properties:
      - location: outside the Frame's bounding box
      - contains: MappingPairs, TemplateBlocks, SeparatorPixels

  - object: MappingPair
    properties:
      - structure: two adjacent, distinct colored blocks (e.g., A next to B)
      - role: defines a color transformation rule (color_A -> color_B)
      - location: within MappingKeyArea

  - object: TemplateBlock
    properties:
      - structure: a contiguous block composed ONLY of a source color (e.g., color_A from mapping A->B) and the BackgroundColor
      - shape: specific pattern defining the output object's shape
      - role: provides the visual template for a transformed object
      - location: within MappingKeyArea
      - association: one unique TemplateBlock exists for each source color_A in the mappings

  - object: SourceBlock
    properties:
      - structure: a contiguous block of a single source color (e.g., color_A)
      - location: inside the Frame
      - role: input object to be transformed

  - object: BackgroundColor
    properties:
      - color: varies by task (most frequent color in MappingKeyArea excluding frame and mapping colors)
      - role: invariant color, used within TemplateBlocks and fills empty space

actions:
  - name: locate_frame
    input: input_grid
    output: bounding_box_of_gray_frame

  - name: analyze_key_area
    input: input_grid, frame_bounding_box
    process:
      - Identify adjacent blocks to find MappingPairs (A -> B).
      - Determine BackgroundColor (most frequent outside color != frame, A, B).
      - For each source color A, find its corresponding TemplateBlock (contiguous block outside frame made of only A and BackgroundColor).
    output: dictionary_of_color_maps {A: B, ...}, BackgroundColor, dictionary_of_templates {A: template_array, ...}

  - name: crop_to_frame
    input: input_grid, frame_bounding_box
    output: cropped_subgrid (initial state of output)

  - name: locate_source_blocks
    input: cropped_subgrid, source_colors (keys from color_maps)
    output: list_of_source_blocks [{r, c, h, w, color}, ...] (coordinates relative to cropped_subgrid)

  - name: apply_templates
    input: cropped_subgrid, list_of_source_blocks, dictionary_of_templates, dictionary_of_color_maps, BackgroundColor
    process:
      - Create an output grid initialized with BackgroundColor, same size as cropped_subgrid.
      - Copy the gray (5) frame pixels from cropped_subgrid to output grid.
      - For each SourceBlock (color A at r, c):
          - Get the TemplateBlock array for color A.
          - Create the target pattern by replacing A with B (from mapping A->B) in the template array, leaving BackgroundColor unchanged.
          - Place this target pattern onto the output grid, aligning its top-left corner with the SourceBlock's top-left corner (r, c).
    output: final_output_grid

relationships:
  - The Frame defines the output dimensions and boundary.
  - MappingPairs define which colors change (A -> B).
  - BackgroundColor defines the invariant fill color.
  - TemplateBlocks define the *shape* of the output for each transformed color.
  - SourceBlocks inside the frame trigger the application of their corresponding transformed TemplateBlock.
```


**Refined Natural Language Program**

1.  **Find the Frame**: Scan the input grid to identify the rectangular boundary composed of gray (5) pixels. Determine its bounding box (top-left `(r_min, c_min)` and bottom-right `(r_max, c_max)`). If no frame is found, return the input unchanged.
2.  **Analyze Key Area (Outside Frame)**:
    *   Identify pairs of adjacent, distinctly colored blocks outside the frame to establish mapping rules (`Color A -> Color B`). Prioritize horizontal adjacency, then vertical.
    *   Count the frequency of all colors outside the frame, excluding the frame color (5). Determine the `BackgroundColor` as the most frequent color that is not part of any mapping rule (neither `Color A` nor `Color B`).
    *   For each source color `A` identified in the mapping rules: Search outside the frame for a contiguous block composed *only* of `Color A` and the `BackgroundColor`. Store this block's array as the `TemplateBlock` for `Color A`. Assume there is one unique template per source color.
3.  **Initialize Output**: Create a new grid (`output_grid`) with the dimensions determined by the frame's bounding box (`height = r_max - r_min + 1`, `width = c_max - c_min + 1`). Initialize it entirely with the `BackgroundColor`.
4.  **Copy Frame**: Copy the gray (5) pixels forming the frame from the input grid (within the bounding box) to the `output_grid` at their corresponding relative positions.
5.  **Identify and Transform Source Blocks**:
    *   Scan the area *inside* the frame in the input grid (from `(r_min+1, c_min+1)` to `(r_max-1, c_max-1)`).
    *   Identify all contiguous blocks composed of a single source color `A` (where `A` is a key in the mapping rules). Record the top-left corner `(r_src, c_src)` (relative to the frame's top-left `(r_min, c_min)`) for each block found. Use a 'visited' marker to process each block only once.
    *   For each identified `SourceBlock` of `Color A` starting at relative coordinates `(r_rel, c_rel)` (where `r_rel = r_src - r_min`, `c_rel = c_src - c_min`):
        *   Retrieve the `TemplateBlock` array associated with `Color A`.
        *   Let `Color B` be the target color from the mapping `A -> B`.
        *   Iterate through the `TemplateBlock` array. For each pixel:
            *   If the template pixel is `Color A`, place `Color B` in the `output_grid`.
            *   If the template pixel is `BackgroundColor`, place `BackgroundColor` in the `output_grid`.
        *   Place these pixels into the `output_grid`, starting at position `(r_rel, c_rel)`, ensuring placement respects the bounds of the `output_grid`. The dimensions of the placed pattern are determined by the `TemplateBlock`.
6.  **Output**: Return the `output_grid`.
