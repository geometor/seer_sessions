
## train_1

**input:**
```
1 1 4 4 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
1 1 1 4 8 8 1 8 1 8 8 3 8 3 8 8 8 8 8 8 8 8 8 8
1 1 4 4 8 8 1 1 1 8 8 3 3 3 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 1 8 8 8 3 3 3 8 8 8 8 8 8 8 8 8 8
3 3 2 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
3 3 3 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
3 3 2 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 3 3 3 8 1 1 1 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 3 3 3 8 1 1 1 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 3 3 3 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 8 8 8 8 3 3 3 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 8 8 8 8 3 3 3 8 5 8 8
8 8 8 5 8 3 3 3 8 1 1 1 8 8 8 8 8 3 3 3 8 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 8 8 8 8 8 3 3 3 8 1 1 1 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 3 3 3 8 1 1 1 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 3 3 3 8 1 1 1 8 1 1 1 8 5 8 8
8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8
8 8 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 8 8
```


**output:**
```
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 2 8 2 8 4 8 4 8 2 8 2 8 4 8 4 8 5
5 8 2 2 2 8 4 4 4 8 2 2 2 8 4 4 4 8 5
5 8 2 2 2 8 8 4 8 8 2 2 2 8 8 4 8 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 2 8 2 8 4 8 4 8 8 8 8 8 2 8 2 8 5
5 8 2 2 2 8 4 4 4 8 8 8 8 8 2 2 2 8 5
5 8 2 2 2 8 8 4 8 8 8 8 8 8 2 2 2 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 8 8 8 8 8 2 8 2 8 4 8 4 8 4 8 4 8 5
5 8 8 8 8 8 2 2 2 8 4 4 4 8 4 4 4 8 5
5 8 8 8 8 8 2 2 2 8 8 4 8 8 8 4 8 8 5
5 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
```


## train_2

**input:**
```
2 2 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
2 2 2 4 1 1 2 2 2 2 1 3 3 3 3 1 1 6 6 6 6 1 1
2 2 4 4 1 1 2 2 2 2 1 1 3 3 1 1 1 6 6 1 1 1 1
1 1 1 1 1 1 2 1 2 2 1 3 3 3 3 1 1 6 6 1 1 1 1
3 3 8 8 1 1 2 1 2 2 1 3 1 1 3 1 1 6 6 6 6 1 1
3 3 3 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
3 3 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
6 6 7 7 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
6 6 6 7 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
6 6 7 7 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 2 2 2 2 1 6 6 6 6 1 3 3 3 3 1 5
1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 3 3 3 3 1 2 2 2 2 1 6 6 6 6 1 5
1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
1 1 1 1 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
```


**output:**
```
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 1 4 4 4 4 1 7 7 7 7 1 8 8 8 8 1 5
5 1 4 4 4 4 1 7 7 1 1 1 1 8 8 1 1 5
5 1 4 1 4 4 1 7 7 1 1 1 8 8 8 8 1 5
5 1 4 1 4 4 1 7 7 7 7 1 8 1 1 8 1 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 1 8 8 8 8 1 4 4 4 4 1 7 7 7 7 1 5
5 1 1 8 8 1 1 4 4 4 4 1 7 7 1 1 1 5
5 1 8 8 8 8 1 4 1 4 4 1 7 7 1 1 1 5
5 1 8 1 1 8 1 4 1 4 4 1 7 7 7 7 1 5
5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
```

Okay, let's analyze the provided examples to understand the transformation logic.

**Perception**

1.  **Input Structure**: The input grids contain two main distinct regions:
    *   An area in the top-left containing small, usually rectangular blocks of color, often arranged in adjacent pairs. These seem to act as a "key" or "legend".
    *   A larger rectangular frame made of gray (5) pixels, typically located elsewhere in the grid. This frame encloses various patterns or objects made of different colors.
    *   There's a background/separator color used both in the "key" area and within the gray frame, although this color might differ between the two regions in some cases (need to verify). In `train_1`, azure (8) is prevalent both outside and inside the frame. In `train_2`, blue (1) is prevalent both outside (in the key area) and inside the frame.

2.  **Output Structure**: The output grid is significantly smaller than the input. It appears to directly correspond to the gray frame and its contents from the input. The output retains the gray frame structure. The patterns inside the frame are present but their colors have changed.

3.  **Transformation**: The core transformation involves:
    *   **Identifying the target area**: Locating the gray (5) frame in the input.
    *   **Cropping**: Extracting the subgrid corresponding to the bounding box of the gray frame. The output dimensions match this cropped area.
    *   **Identifying color mapping rules**: Analyzing the adjacent color pairs in the "key" area (outside the gray frame) to determine how colors should be transformed. Each pair `(Color A, Color B)` implies that pixels of `Color A` inside the frame should become `Color B` in the output.
    *   **Identifying invariant colors**: The gray (5) frame color remains unchanged. The background/separator color used within the frame (which is usually the same as the separator color in the key area) also remains unchanged.
    *   **Applying the mapping**: Iterating through the pixels of the cropped (frame) area and applying the derived color mappings, leaving the frame and background colors as they are.

**Facts**


```yaml
elements:
  - object: Frame
    properties:
      - color: gray (5)
      - shape: rectangle
      - role: defines the region of interest for the output

  - object: MappingKeyArea
    properties:
      - location: outside the Frame's bounding box
      - contains: MappingPairs and SeparatorPixels

  - object: MappingPair
    properties:
      - structure: two adjacent, distinct colored blocks (often rectangles)
      - role: defines a color transformation rule (color_A -> color_B)
      - location: within MappingKeyArea

  - object: InnerContent
    properties:
      - location: inside the Frame
      - composition: pixels potentially subject to color transformation
      - includes: BackgroundPixels

  - object: SeparatorPixel / BackgroundPixel
    properties:
      - color: varies by task (e.g., azure(8) in train_1, blue(1) in train_2)
      - location: separates MappingPairs in MappingKeyArea, acts as background/separator within InnerContent
      - behavior: remains unchanged during transformation

actions:
  - name: locate_frame
    input: input_grid
    output: bounding_box_of_gray_frame

  - name: extract_mapping_rules
    input: input_grid, frame_bounding_box
    process: scan area outside frame_bounding_box for adjacent color blocks (MappingPairs)
    output: dictionary_of_color_maps {color_A: color_B, ...}

  - name: identify_invariant_background
    input: input_grid, frame_bounding_box
    process: determine the dominant non-mapping color in the MappingKeyArea (outside the frame)
    output: invariant_background_color

  - name: crop_region
    input: input_grid, frame_bounding_box
    output: cropped_subgrid

  - name: apply_transformation
    input: cropped_subgrid, color_maps, invariant_background_color, frame_color (gray 5)
    process: iterate through cropped_subgrid pixels, apply color_maps, keep invariant_background_color and frame_color unchanged
    output: output_grid

relationships:
  - The Frame's bounding box determines the area to be cropped and transformed.
  - The MappingPairs outside the Frame define the color changes applied inside the Frame.
  - The SeparatorPixel color found outside the Frame identifies the color that remains unchanged inside the Frame (along with the Frame color itself).
  - The dimensions of the output grid are identical to the dimensions of the Frame's bounding box in the input.
```


**Natural Language Program**

1.  **Find the Frame**: Scan the input grid to identify the largest contiguous rectangular object composed solely of gray (5) pixels. Determine its bounding box (top-left and bottom-right coordinates).
2.  **Extract Mapping Rules and Invariant Background**:
    *   Examine the region of the input grid *outside* the Frame's bounding box.
    *   Identify pairs of distinctly colored, adjacent rectangular objects (typically small, like 2x2 or 1xN). For each pair `(Object A, Object B)` with `Color A` and `Color B`, record a mapping rule: `Color A` transforms to `Color B`.
    *   Identify the color that acts as a separator or background in this outside region, distinct from the colors in the mapping pairs. This is the `invariant_background_color`.
3.  **Crop**: Create a new grid by copying the portion of the input grid defined by the Frame's bounding box (including the frame itself).
4.  **Transform Colors**: Iterate through each pixel `(r, c)` in the cropped grid:
    *   Get the `current_color` of the pixel.
    *   If `current_color` is gray (5) (the frame color), keep it as gray (5) in the output.
    *   If `current_color` is the `invariant_background_color`, keep it as `invariant_background_color` in the output.
    *   If `current_color` matches the key (`Color A`) in any identified mapping rule (`Color A -> Color B`), change the pixel's color to the corresponding value (`Color B`) in the output.
    *   (Assumption: Any other color encountered inside the frame will be part of a mapping rule).
5.  **Output**: The resulting transformed grid is the final output.
