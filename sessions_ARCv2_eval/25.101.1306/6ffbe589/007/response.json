{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport collections\nimport numpy as np\n\n\"\"\"\nThe transformation identifies all distinct contiguous objects (groups of non-white \npixels using 8-way adjacency) in the input grid. It calculates the size (pixel \ncount) of each object. The object with the largest pixel count is selected as \nthe target. If there's a tie in size, the object whose bounding box has the \nminimum top row index is chosen. If there's still a tie, the one with the \nminimum left column index is chosen. A minimal bounding box is calculated for \nthis target object. The output grid is created by cropping the input grid exactly \nto the dimensions and location of this bounding box. All pixels within this \nbounding box in the input, including background pixels (0), are copied directly \nto the output grid.\n\"\"\"\n\ndef find_objects(grid: list[list[int]], background_color: int = 0) -> list[dict]:\n    \"\"\"\n    Finds all distinct connected objects of non-background pixels in the grid \n    using 8-way adjacency. Calculates size and bounding box for each.\n\n    Args:\n        grid: The input grid (list of lists of integers).\n        background_color: The integer value representing the background.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents an object and contains:\n        - 'coords': A set of (row, col) coordinates of the object's pixels.\n        - 'size': The number of pixels in the object.\n        - 'bbox': A tuple (min_row, max_row, min_col, max_col) for the object.\n        Returns an empty list if the grid is empty or contains no non-background pixels.\n    \"\"\"\n    grid_np = np.array(grid, dtype=int)\n    height, width = grid_np.shape\n    if height == 0 or width == 0: \n        return []\n\n    visited = np.zeros_like(grid_np, dtype=bool)\n    objects = []\n\n    for r in range(height):\n        for c in range(width):\n            # Check if pixel is non-background and not yet visited\n            if grid_np[r, c] != background_color and not visited[r, c]:\n                # Start Breadth-First Search (BFS) for a new object\n                current_object_coords = set()\n                q = collections.deque([(r, c)])\n                visited[r, c] = True\n                obj_size = 0\n                # Initialize bounding box for the current object\n                min_obj_r, max_obj_r = r, r\n                min_obj_c, max_obj_c = c, c\n\n                while q:\n                    row, col = q.popleft()\n                    current_object_coords.add((row, col))\n                    obj_size += 1\n                    # Update bounding box limits during traversal\n                    min_obj_r = min(min_obj_r, row)\n                    max_obj_r = max(max_obj_r, row)\n                    min_obj_c = min(min_obj_c, col)\n                    max_obj_c = max(max_obj_c, col)\n\n                    # Explore 8 neighbors (horizontal, vertical, diagonal)\n                    for dr in [-1, 0, 1]:\n                        for dc in [-1, 0, 1]:\n                            if dr == 0 and dc == 0: \n                                continue # Skip self\n                            \n                            nr, nc = row + dr, col + dc\n\n                            # Check if neighbor is within grid bounds\n                            if 0 <= nr < height and 0 <= nc < width:\n                                # Check if neighbor is part of the object and not visited\n                                if grid_np[nr, nc] != background_color and not visited[nr, nc]:\n                                    visited[nr, nc] = True\n                                    q.append((nr, nc))\n                \n                # Store found object's information\n                if current_object_coords:\n                     objects.append({'coords': current_object_coords, \n                                     'size': obj_size, \n                                     'bbox': (min_obj_r, max_obj_r, min_obj_c, max_obj_c)})\n    return objects\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:  \n    \"\"\"\n    Finds the largest object by pixel count in the input_grid, determines its\n    bounding box, and returns the portion of the input_grid corresponding to that\n    bounding box (cropping).\n    \"\"\"\n    background_color = 0\n    \n    # Step 1: Identify all distinct non-background objects\n    objects = find_objects(input_grid, background_color)\n\n    # Handle case where no non-background objects are found\n    if not objects:\n        return [] \n\n    # Step 2: Select the target object based on size and tie-breaking rules\n    # Sort objects: Primary key size (desc), Secondary key min_row (asc), Tertiary key min_col (asc)\n    # Note: We use negative min_row and min_col because sort is ascending by default.\n    objects.sort(key=lambda obj: (obj['size'], -obj['bbox'][0], -obj['bbox'][2]), reverse=True)\n    \n    # The target object is the first one after sorting\n    target_object_info = objects[0]\n    \n    # Step 3: Get the bounding box of the target object\n    min_r, max_r, min_c, max_c = target_object_info['bbox']\n\n    # Check for invalid bounding box (should not occur if an object was found)\n    if max_r < min_r or max_c < min_c:\n         return [] \n\n    # Step 4: Crop the input grid using the bounding box coordinates\n    # Slicing input_grid[min_r:max_r+1] gets rows from min_r up to max_r.\n    # Slicing row[min_c:max_c+1] gets columns from min_c up to max_c for each selected row.\n    output_grid = [row[min_c : max_c + 1] for row in input_grid[min_r : max_r + 1]]\n    \n    # Step 5: Return the cropped subgrid\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 53572,
    "candidates_token_count": 5080,
    "total_token_count": 58652,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 42.418256,
  "retries": 1
}