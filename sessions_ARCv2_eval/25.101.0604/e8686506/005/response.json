{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import Counter\nfrom scipy.ndimage import label, find_objects\nimport math\n\n\"\"\"\nTransforms an input grid based on the following rules:\n1. Determine the background color (most frequent pixel value).\n2. Identify all connected non-background objects (8-way connectivity), storing the pixels for each.\n3. Calculate the bounding box and area for each object.\n4. Find the object(s) with the maximum bounding box area (\"frame objects\").\n5. Determine the combined bounding box enclosing all frame objects. This defines the output grid's frame.\n6. Identify all non-background objects that are NOT frame objects (\"non-frame objects\") and collect all pixels belonging to them.\n7. Create the output grid with the dimensions of the combined frame bounding box.\n8. Populate the output grid:\n    - If a pixel within the frame corresponds to a non-background pixel in the input, copy its color.\n    - If a pixel within the frame corresponds to a background pixel in the input:\n        - Find the pixel among all non-frame pixels that is closest (Euclidean distance) to the input pixel's coordinates.\n        - Tie-breaking for closest pixel: minimum distance -> minimum color -> minimum row -> minimum column.\n        - Fill the output pixel with the color of this closest non-frame pixel.\n    - Handle the case where no non-frame pixels exist (e.g., fill with background color).\n\"\"\"\n\ndef find_background_color(grid: np.ndarray) -> int:\n    \"\"\"Finds the most frequent value in the grid.\"\"\"\n    counts = Counter(grid.flatten())\n    if not counts:\n        return -1 # Indicate error or empty grid\n    # Find the value with the highest count.\n    background_color = counts.most_common(1)[0][0]\n    return background_color\n\ndef find_objects_and_pixels(grid: np.ndarray, background_color: int) -> tuple[dict, np.ndarray, int]:\n    \"\"\"\n    Finds connected non-background objects, calculates their properties,\n    and returns the labeled array and number of features.\n    Properties: bbox, area, color, list of pixels (r, c).\n    \"\"\"\n    non_bg_mask = grid != background_color\n    # Define 8-way connectivity\n    structure = np.ones((3, 3), dtype=bool)\n    labeled_array, num_features = label(non_bg_mask, structure=structure)\n\n    if num_features == 0:\n        return {}, labeled_array, num_features\n\n    object_properties = {}\n    object_slices = find_objects(labeled_array)\n\n    for i in range(num_features):\n        label_id = i + 1\n        obj_slice = object_slices[i]\n        \n        # Bounding Box and Area\n        min_r, max_r = obj_slice[0].start, obj_slice[0].stop\n        min_c, max_c = obj_slice[1].start, obj_slice[1].stop\n        bbox = (min_r, min_c, max_r, max_c)\n        height = max_r - min_r\n        width = max_c - min_c\n        area = height * width\n\n        # Coordinates and Color\n        obj_coords = np.argwhere(labeled_array == label_id)\n        if obj_coords.size == 0:\n            continue \n\n        # Get color from the first pixel of the object (assuming monochromatic objects)\n        obj_color = grid[obj_coords[0][0], obj_coords[0][1]]\n        \n        # Store pixel coordinates (r, c) directly, color is stored once per object\n        pixel_list = [(r, c) for r, c in obj_coords]\n\n        object_properties[label_id] = {\n            'bbox': bbox,\n            'area': area,\n            'color': obj_color,\n            'pixels': pixel_list # List of (r, c) tuples\n        }\n        \n    return object_properties, labeled_array, num_features\n\ndef find_closest_non_frame_pixel_color(target_r: int, target_c: int, non_frame_pixels: list[tuple[int, int, int]], background_color: int) -> int:\n    \"\"\"\n    Finds the color of the closest pixel from the non_frame_pixels list to the target coordinates.\n    Tie-breaking: min distance -> min color -> min row -> min col.\n    non_frame_pixels: List of (row, col, color) tuples.\n    \"\"\"\n    if not non_frame_pixels:\n        # Fallback if there are no non-frame pixels\n        return background_color \n\n    min_dist_sq = float('inf')\n    closest_candidates = [] # Stores (dist_sq, color, r, c) for tie-breaking\n\n    for pr, pc, p_color in non_frame_pixels:\n        dist_sq = (target_r - pr)**2 + (target_c - pc)**2\n        \n        if dist_sq < min_dist_sq:\n            min_dist_sq = dist_sq\n            closest_candidates = [(dist_sq, p_color, pr, pc)]\n        elif dist_sq == min_dist_sq:\n            closest_candidates.append((dist_sq, p_color, pr, pc))\n\n    if not closest_candidates:\n         # Should not happen if non_frame_pixels is not empty\n        return background_color\n\n    # Apply tie-breaking rules by sorting\n    # Sort by: dist_sq (implicitly same), color, row, col\n    closest_candidates.sort(key=lambda x: (x[1], x[2], x[3]))\n\n    # The first element after sorting is the winner\n    return closest_candidates[0][1] # Return the color\n\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:  \n    # Convert input to numpy array\n    if not input_grid or not input_grid[0]:\n        return []\n    input_grid_np = np.array(input_grid, dtype=int)\n    rows, cols = input_grid_np.shape\n\n    # 1. Determine the background color\n    background_color = find_background_color(input_grid_np)\n    if background_color == -1:\n        return [] # Handle empty or problematic input\n\n    # 2 & 3. Find objects, their properties (including pixels), and bounding box areas\n    object_properties, _, num_features = find_objects_and_pixels(input_grid_np, background_color)\n    \n    if num_features == 0:\n         return [] # No non-background objects found\n\n    # 4. Find the maximum bounding box area\n    max_area = 0\n    if object_properties: # Check if dictionary is not empty\n        max_area = max(props['area'] for props in object_properties.values()) if object_properties else 0\n    \n    # 5. Identify frame objects (those with max area)\n    frame_object_labels = {label_id for label_id, props in object_properties.items() if props['area'] == max_area}\n\n    # 6. Identify non-frame objects and collect all their pixels\n    non_frame_pixels = [] # List of (r, c, color)\n    for label_id, props in object_properties.items():\n        if label_id not in frame_object_labels:\n            obj_color = props['color']\n            for r, c in props['pixels']:\n                non_frame_pixels.append((r, c, obj_color))\n\n    # 7. Determine the combined bounding box for frame objects\n    if not frame_object_labels:\n        # Handle case where only non-frame objects exist, or no objects\n        # Based on problem description, frame must be defined by max area objects.\n        # If no frame objects (e.g., all objects have area 0?), return empty or handle differently.\n        # For now, assume max_area > 0 if num_features > 0.\n        # If frame_object_labels is empty despite num_features > 0, it implies an issue.\n         return []\n\n    combined_min_r, combined_min_c = rows, cols\n    combined_max_r, combined_max_c = 0, 0 \n\n    for label_id in frame_object_labels:\n        min_r, min_c, max_r, max_c = object_properties[label_id]['bbox']\n        combined_min_r = min(combined_min_r, min_r)\n        combined_min_c = min(combined_min_c, min_c)\n        combined_max_r = max(combined_max_r, max_r) # max_r is exclusive stop index\n        combined_max_c = max(combined_max_c, max_c) # max_c is exclusive stop index\n        \n    frame_r0, frame_c0 = combined_min_r, combined_min_c\n    frame_height = combined_max_r - combined_min_r\n    frame_width = combined_max_c - combined_min_c\n\n    if frame_height <= 0 or frame_width <= 0:\n        return [] # Invalid frame dimensions calculated\n\n    # 8. Create the output grid\n    output_grid_np = np.full((frame_height, frame_width), background_color, dtype=int) # Initialize with background\n\n    # 9. Check if non_frame_pixels exist (handled within the fill function)\n    \n    # 10 & 11 & 12. Populate the output grid\n    for out_r in range(frame_height):\n        for out_c in range(frame_width):\n            # Corresponding input coordinates\n            in_r = frame_r0 + out_r\n            in_c = frame_c0 + out_c\n\n            # Check bounds just in case\n            if 0 <= in_r < rows and 0 <= in_c < cols:\n                 input_val = input_grid_np[in_r, in_c]\n            else:\n                 # Should not happen with correct frame calculation\n                 continue # Keep background color\n\n            if input_val != background_color:\n                # Copy non-background color from input frame\n                output_grid_np[out_r, out_c] = input_val\n            else:\n                # Find the color of the closest non-frame pixel\n                fill_color = find_closest_non_frame_pixel_color(in_r, in_c, non_frame_pixels, background_color)\n                output_grid_np[out_r, out_c] = fill_color\n\n    # Convert back to list of lists and return\n    output_grid = output_grid_np.tolist()\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 19379,
    "candidates_token_count": 3117,
    "total_token_count": 22496,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 22.885177,
  "retries": 1
}