{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import Counter\nfrom scipy.ndimage import label, find_objects, center_of_mass\nimport math\n\n\"\"\"\nTransforms an input grid based on the following rules:\n1. Determine the background color (most frequent pixel value).\n2. Identify all connected non-background objects (8-way connectivity).\n3. Calculate the bounding box area for each object.\n4. Find the object(s) with the maximum bounding box area (\"frame objects\").\n5. Determine the combined bounding box enclosing all frame objects. This defines the output grid's frame.\n6. Identify all non-background objects that are NOT frame objects (\"non-frame objects\") and calculate their centroids.\n7. Create the output grid with the dimensions of the combined frame bounding box.\n8. Populate the output grid:\n    - If a pixel within the frame corresponds to a non-background pixel in the input, copy its color.\n    - If a pixel within the frame corresponds to a background pixel in the input, fill it with the color of the non-frame object whose centroid is closest (Euclidean distance) to the input pixel's coordinates.\n    - Tie-breaking for closest centroid: minimum distance -> minimum object color -> minimum centroid row -> minimum centroid column.\n\"\"\"\n\ndef find_background_color(grid: np.ndarray) -> int:\n    \"\"\"Finds the most frequent value in the grid.\"\"\"\n    counts = Counter(grid.flatten())\n    if not counts:\n        # Default or raise error for empty grid - return -1 for now\n        return -1 \n    # Find the value with the highest count.\n    background_color = counts.most_common(1)[0][0]\n    return background_color\n\ndef calculate_object_properties(labeled_array: np.ndarray, num_features: int, grid: np.ndarray) -> dict:\n    \"\"\"\n    Calculates properties (bounding box, area, centroid, color) for each labeled object.\n    Assumes objects are monochromatic.\n    \"\"\"\n    object_properties = {}\n    object_slices = find_objects(labeled_array)\n\n    for i in range(num_features):\n        label_id = i + 1\n        obj_slice = object_slices[i]\n        \n        # Bounding Box and Area\n        min_r, max_r = obj_slice[0].start, obj_slice[0].stop\n        min_c, max_c = obj_slice[1].start, obj_slice[1].stop\n        bbox = (min_r, min_c, max_r, max_c)\n        height = max_r - min_r\n        width = max_c - min_c\n        area = height * width\n\n        # Coordinates and Color\n        obj_coords = np.argwhere(labeled_array == label_id)\n        if obj_coords.size == 0:\n            continue # Should not happen with valid labels/slices\n\n        # Get color from the first pixel of the object\n        # Assumes monochromatic objects\n        obj_color = grid[obj_coords[0][0], obj_coords[0][1]]\n\n        # Centroid calculation using scipy's center_of_mass\n        # Note: center_of_mass needs the original grid values *within the object mask*\n        # But for simple centroid (average position), we just need the mask.\n        # Let's use object coordinates directly for average position.\n        centroid_r = np.mean(obj_coords[:, 0])\n        centroid_c = np.mean(obj_coords[:, 1])\n        centroid = (centroid_r, centroid_c)\n        \n        # Alternative centroid using center_of_mass (might be better if values mattered)\n        # obj_mask = labeled_array == label_id\n        # centroid = center_of_mass(grid, labels=labeled_array, index=label_id) \n        \n        object_properties[label_id] = {\n            'bbox': bbox,\n            'area': area,\n            'centroid': centroid,\n            'color': obj_color,\n            'coords': obj_coords # Keep coords for potential later use\n        }\n        \n    return object_properties\n\ndef euclidean_distance_sq(p1: tuple[float, float], p2: tuple[float, float]) -> float:\n    \"\"\"Calculates the squared Euclidean distance between two points.\"\"\"\n    return (p1[0] - p2[0])**2 + (p1[1] - p2[1])**2\n\ndef find_closest_non_frame_object_color(r: int, c: int, non_frame_objects_data: list[dict], background_color: int) -> int:\n    \"\"\"\n    Finds the color of the closest non-frame object based on centroid distance.\n    Tie-breaking: min distance -> min color -> min centroid row -> min centroid col.\n    non_frame_objects_data: List of dictionaries, each like {'centroid': (r,c), 'color': int}.\n    \"\"\"\n    if not non_frame_objects_data:\n        # Fallback if there are no non-frame objects\n        return background_color \n\n    min_dist_sq = float('inf')\n    closest_objects_indices = []\n    target_point = (float(r), float(c))\n\n    for idx, obj_data in enumerate(non_frame_objects_data):\n        centroid = obj_data['centroid']\n        dist_sq = euclidean_distance_sq(target_point, centroid)\n\n        if dist_sq < min_dist_sq:\n            min_dist_sq = dist_sq\n            closest_objects_indices = [idx]\n        elif dist_sq == min_dist_sq:\n            closest_objects_indices.append(idx)\n\n    if not closest_objects_indices:\n         # Should not happen if non_frame_objects_data is not empty\n        return background_color\n\n    # Apply tie-breaking rules\n    tied_objects = [(non_frame_objects_data[i]['color'], \n                     non_frame_objects_data[i]['centroid'][0], # centroid row\n                     non_frame_objects_data[i]['centroid'][1], # centroid col\n                     i) # original index to retrieve color\n                    for i in closest_objects_indices]\n    \n    # Sort by: color, centroid_row, centroid_col\n    tied_objects.sort()\n\n    # Get the index of the winning object\n    winner_index = tied_objects[0][3]\n    \n    return non_frame_objects_data[winner_index]['color']\n\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Transforms the input grid according to the specified rules involving\n    identifying objects, finding the largest bounding box, extracting that frame,\n    and filling background cells based on the closest non-frame object centroid.\n    \"\"\"\n    if not input_grid or not input_grid[0]:\n        return []\n\n    input_grid_np = np.array(input_grid, dtype=int)\n    rows, cols = input_grid_np.shape\n\n    # 1. Determine the background color\n    background_color = find_background_color(input_grid_np)\n    if background_color == -1: # Handle empty grid case from helper\n        return []\n\n    # 2. Identify non-background pixels and objects\n    non_bg_mask = input_grid_np != background_color\n    \n    # Define 8-way connectivity\n    structure = np.ones((3, 3), dtype=bool)\n    labeled_array, num_features = label(non_bg_mask, structure=structure)\n\n    if num_features == 0:\n         return [] # No non-background objects found\n\n    # 3 & 4. Calculate properties (bbox, area, centroid, color) for each object\n    object_properties = calculate_object_properties(labeled_array, num_features, input_grid_np)\n    \n    if not object_properties:\n        return [] # No valid objects processed\n\n    # 5. Find the maximum bounding box area\n    max_area = 0\n    for label_id, props in object_properties.items():\n        if props['area'] > max_area:\n            max_area = props['area']\n\n    # 6. Identify frame objects (those with max area)\n    frame_object_labels = {label_id for label_id, props in object_properties.items() if props['area'] == max_area}\n\n    # 7. Determine the combined bounding box for frame objects\n    if not frame_object_labels:\n        return [] # Should not happen if max_area > 0\n\n    combined_min_r, combined_min_c = rows, cols\n    combined_max_r, combined_max_c = 0, 0 # Use 0 for max comparison start\n\n    for label_id in frame_object_labels:\n        min_r, min_c, max_r, max_c = object_properties[label_id]['bbox']\n        combined_min_r = min(combined_min_r, min_r)\n        combined_min_c = min(combined_min_c, min_c)\n        combined_max_r = max(combined_max_r, max_r) # max_r is exclusive stop index\n        combined_max_c = max(combined_max_c, max_c) # max_c is exclusive stop index\n        \n    frame_r0, frame_c0 = combined_min_r, combined_min_c\n    frame_height = combined_max_r - combined_min_r\n    frame_width = combined_max_c - combined_min_c\n\n    if frame_height <= 0 or frame_width <= 0:\n        return [] # Invalid frame dimensions\n\n    # 8. Create the output grid\n    output_grid_np = np.zeros((frame_height, frame_width), dtype=int)\n\n    # 9. Identify non-frame objects and collect their data for filling step\n    non_frame_objects_data = []\n    for label_id, props in object_properties.items():\n        if label_id not in frame_object_labels:\n            non_frame_objects_data.append({\n                'centroid': props['centroid'],\n                'color': props['color']\n                # Note: Including label_id is implicit via list index if needed later\n            })\n\n    # 10 & 11. Populate the output grid\n    for out_r in range(frame_height):\n        for out_c in range(frame_width):\n            # Corresponding input coordinates\n            in_r = frame_r0 + out_r\n            in_c = frame_c0 + out_c\n\n            # Check bounds just in case, though frame logic should prevent this\n            if 0 <= in_r < rows and 0 <= in_c < cols:\n                 input_val = input_grid_np[in_r, in_c]\n            else:\n                 # This case indicates an issue with frame calculation or input\n                 # Defaulting to background, but should ideally not happen\n                 output_grid_np[out_r, out_c] = background_color \n                 continue\n\n            if input_val != background_color:\n                # 10. Copy non-background color\n                output_grid_np[out_r, out_c] = input_val\n            else:\n                # 11. Fill background color based on the closest non-frame object centroid\n                fill_color = find_closest_non_frame_object_color(in_r, in_c, non_frame_objects_data, background_color)\n                output_grid_np[out_r, out_c] = fill_color\n\n    # 12. Convert back to list of lists and return\n    output_grid = output_grid_np.tolist()\n    return output_grid\n\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 10438,
    "candidates_token_count": 3867,
    "total_token_count": 14305,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 30.80216,
  "retries": 1
}