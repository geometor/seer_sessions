{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom scipy.ndimage import label, generate_binary_structure\nimport collections\n\n\"\"\"\nIdentifies marker pixels (color 9) in the input grid. For each connected \ncomponent of marker pixels, finds its minimum row index. For each unique minimum \nrow index found (`min_r`), defines a 5-row high slice starting at `min_r`. \nWithin this 5-row slice (or fewer rows if near the grid bottom), identifies the \nhorizontal bounding box (min/max columns) of all non-background, non-marker pixels. \nExtracts this rectangular region from the original grid using the defined rows \nand the calculated pattern columns. \n\nCollects these extracted slices, ensuring duplicates based on start row and \ncolumn bounds are not added. Sorts the unique slices based on the minimum row \nindex (`min_r`) that triggered their extraction, in descending order (highest \nrow index first). Pads slices vertically with the background color if they are \nshorter than the maximum extracted height (typically 5). Finally, concatenates \nthe sorted (and potentially padded) slices horizontally to produce the output grid. \nHandles cases like empty grids, missing markers, or no associated patterns found \nfor markers by returning a default 1x1 background grid.\n\"\"\"\n\ndef get_background_color(grid: np.ndarray) -> int:\n    \"\"\"Finds the most frequent color in the grid, assuming it's the background.\n    Returns 0 as default if the grid is empty or no color is dominant.\n    \"\"\"\n    if grid.size == 0:\n        return 0 # Default background for empty grid\n    counts = collections.Counter(grid.flat)\n    if counts:\n         # most_common(1) returns list of tuples [(value, count)]\n         return counts.most_common(1)[0][0]\n    elif grid.size > 0:\n         # Fallback if counter is empty but grid has elements (e.g., single pixel grid)\n         return grid.flat[0] \n    else:\n         return 0 # Default\n\ndef find_components_and_min_rows(grid: np.ndarray, target_color: int) -> list[int]:\n    \"\"\"\n    Finds connected components of a specific target_color and returns a list \n    of the minimum row index for each distinct component found. Uses 8-way \n    connectivity.\n    \"\"\"\n    binary_grid = (grid == target_color)\n    # Use 8-way connectivity (diagnals included)\n    structure = generate_binary_structure(2, 2) \n    labeled_grid, num_components = label(binary_grid, structure=structure)\n    \n    min_rows_per_label = {}\n    if num_components > 0:\n        # Iterate through the grid efficiently to find the first occurrence (min row) for each label\n        rows, cols = np.where(labeled_grid > 0)\n        for r, c in zip(rows, cols):\n            label_id = labeled_grid[r, c]\n            if label_id not in min_rows_per_label:\n                min_rows_per_label[label_id] = r\n                    \n    return list(min_rows_per_label.values()) # Returns a list of min_rows, one for each component\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:  \n    \"\"\"\n    Transforms the input grid based on marker pixels (color 9).\n    Extracts 5-row high slices associated with marker components, sorts them \n    by the marker's minimum row (descending), and concatenates horizontally.\n    \"\"\"\n    input_np = np.array(input_grid, dtype=np.int8)\n    h, w = input_np.shape\n\n    # Handle empty input grid\n    if h == 0 or w == 0:\n        return [[]]\n\n    # Identify marker color (fixed at 9 for this problem) and background color\n    marker_color = 9\n    background_color = get_background_color(input_np)\n\n    # Find the minimum row for each marker component\n    marker_component_min_rows = find_components_and_min_rows(input_np, marker_color)\n    \n    # If no markers found, return a 1x1 background grid as per interpretation\n    if not marker_component_min_rows:\n         # Check if grid contains only background\n         if np.all(input_np == background_color):\n              return [[int(background_color)]]\n         else:\n              # Or maybe return empty if no markers but other stuff exists?\n              # Based on examples, seems like markers are required.\n              # Returning 1x1 background seems safer.\n              return [[int(background_color)]]\n\n    extracted_regions = []\n    # Track processed regions defined by (start_row, col_min, col_max) to avoid duplicates\n    processed_regions_ids = set() \n\n    # Use unique min_rows associated with markers to define potential slice start rows\n    unique_min_rows = sorted(list(set(marker_component_min_rows)))\n\n    for m_min_r in unique_min_rows:\n        \n        # Define the row slice range (max 5 rows, respecting grid height)\n        start_row = m_min_r\n        end_row = min(start_row + 5, h) \n        \n        # Skip if the start row is beyond the grid height\n        if start_row >= h:\n             continue\n        \n        # Select the relevant rows from the input grid\n        rows_to_examine = input_np[start_row:end_row, :]\n        \n        # Create a mask for non-background, non-marker pixels within these rows\n        pattern_mask = (rows_to_examine != background_color) & (rows_to_examine != marker_color)\n        \n        # Find the column indices where such pattern pixels exist\n        pattern_cols_in_slice = np.where(pattern_mask)[1] # We only need column indices\n        \n        # If no pattern pixels found in these rows associated with this marker_min_row, skip\n        if pattern_cols_in_slice.size == 0:\n            continue \n            \n        # Determine the horizontal extent (min/max columns) of the *pattern* in this slice\n        p_min_c = np.min(pattern_cols_in_slice)\n        p_max_c = np.max(pattern_cols_in_slice)\n        \n        # Define the region identifier to check if we already extracted this exact slice\n        # Uses the actual data rows and the pattern's column bounds\n        region_id = (start_row, end_row, p_min_c, p_max_c)\n        if region_id in processed_regions_ids:\n            continue # Skip duplicate region\n        processed_regions_ids.add(region_id)\n\n        # Extract the final slice using defined rows and calculated pattern columns\n        # Note: We slice the original input_np, not rows_to_examine, to get the full slice data\n        extracted_slice = input_np[start_row:end_row, p_min_c : p_max_c + 1]\n\n        # Store the slice along with the marker row that triggered it (for sorting)\n        # Ensure the slice is not empty before storing\n        if extracted_slice.size > 0:\n             extracted_regions.append({'trigger_row': m_min_r, 'slice': extracted_slice})\n\n    # Sort the collected regions based on the marker row that triggered them, descending order\n    extracted_regions.sort(key=lambda x: x['trigger_row'], reverse=True)\n\n    # If no valid regions were extracted after filtering, return background grid\n    if not extracted_regions:\n         return [[int(background_color)]] \n\n    final_slices = [region['slice'] for region in extracted_regions]\n    \n    # Determine the target height (max height found among slices) for padding\n    max_h = 0\n    valid_heights = [s.shape[0] for s in final_slices if s.ndim == 2 and s.shape[0] > 0]\n    if valid_heights:\n        max_h = max(valid_heights)\n    elif final_slices: # Handle case where maybe only 1D arrays resulted? Should not happen.\n         pass # max_h remains 0\n\n    # Pad slices shorter than max_h at the bottom with the background color\n    padded_slices = []\n    for s in final_slices:\n         # Ensure it's a valid 2D array before padding\n        if s.ndim == 2 and s.shape[0] > 0 and s.shape[1] > 0:\n            if s.shape[0] < max_h:\n                pad_h = max_h - s.shape[0]\n                # Create padding array\n                padding = np.full((pad_h, s.shape[1]), background_color, dtype=s.dtype)\n                # Stack original slice on top of padding\n                padded_s = np.vstack((s, padding))\n                padded_slices.append(padded_s)\n            elif s.shape[0] == max_h: # Only add if height matches max_h\n                # Slice already has max height (or is the only slice)\n                padded_slices.append(s)\n            # else: slices taller than max_h? Should not happen if max_h is correct.\n            # or slices with 0 height? Should be filtered by size > 0 check.\n\n    # If after padding, no valid slices remain, return background\n    if not padded_slices:\n         # This might happen if all extracted slices had 0 height or width\n         return [[int(background_color)]] \n\n    # Perform horizontal stacking (concatenation)\n    try:\n        # Ensure all arrays in padded_slices are 2D before hstack\n        # This check might be redundant given previous filtering but adds safety\n        arrays_to_stack = [arr for arr in padded_slices if arr.ndim == 2 and arr.shape[0] > 0 and arr.shape[1] > 0]\n        if not arrays_to_stack:\n             return [[int(background_color)]] # No valid arrays left to stack\n        \n        # Verify all arrays have the same height before stacking\n        first_height = arrays_to_stack[0].shape[0]\n        if not all(arr.shape[0] == first_height for arr in arrays_to_stack):\n             # This indicates an error in padding or height calculation\n             print(f\"Error: Mismatched heights before hstack. Heights: {[arr.shape[0] for arr in arrays_to_stack]}\")\n             return [[int(background_color)]] \n             \n        output_np = np.hstack(arrays_to_stack)\n        \n    except ValueError as e:\n        # Catch potential errors during hstack (e.g., if somehow heights mismatch despite checks)\n        print(f\"Error during hstack: {e}\")\n        # Provide details for debugging\n        print(f\"Number of arrays to stack: {len(padded_slices)}\")\n        for i, arr in enumerate(padded_slices):\n            print(f\"  Slice {i} shape: {arr.shape}, dtype: {arr.dtype}\")\n            \n        # Return a default error indicator or background grid\n        return [[int(background_color)]]\n\n\n    # Convert final numpy array back to list of lists\n    return output_np.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 13129,
    "candidates_token_count": 3455,
    "total_token_count": 16584,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 26.110348,
  "retries": 1
}