{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom scipy.ndimage import label, generate_binary_structure, binary_dilation\nimport collections\n\n\"\"\"\nTransforms an input grid by identifying specific \"marker\" pixels and adjacent \"pattern\" shapes. \nIt combines each valid pattern (size > 5 pixels) with its adjacent marker(s) into a single \"object\". \nIt then extracts a 5-row high slice from the input grid, aligned vertically with the top of the combined object's bounding box and horizontally spanning the object's bounding box columns. \nThese extracted slices are sorted based on the minimum row of their associated marker(s) (descending order) and then concatenated horizontally to form the output grid. Slices are padded to a uniform height of 5 rows with the background color before concatenation.\n\nHeuristic assumptions:\n- Background color (BKG) is the most frequent color.\n- Marker color (M) is maroon(9) if BKG is azure(8); M is azure(8) if BKG is yellow(4).\n- Relevant patterns are connected components of non-BKG, non-M pixels with size > 5.\n- A pattern is relevant only if adjacent (8-way) to at least one marker component.\n\"\"\"\n\ndef get_background_color(grid: np.ndarray) -> int:\n    \"\"\"Finds the most frequent color in the grid, assuming it's the background.\"\"\"\n    if grid.size == 0:\n        return 0\n    counts = collections.Counter(grid.flat)\n    if counts:\n        return counts.most_common(1)[0][0]\n    elif grid.size > 0:\n        return grid.flat[0] # Handle single-element grid or uniform grid\n    else:\n        return 0\n\ndef find_components_and_properties(grid: np.ndarray, mask: np.ndarray) -> list[dict]:\n    \"\"\"\n    Finds connected components within a given mask and returns their properties.\n    Uses 8-way connectivity.\n    Properties: id, coords, size, bbox (min_r, min_c, max_r, max_c), min_row.\n    \"\"\"\n    structure = generate_binary_structure(2, 2)\n    labeled_grid, num_components = label(mask, structure=structure)\n    \n    components = []\n    if num_components == 0:\n        return components\n        \n    # Efficiently find coordinates for all labeled pixels\n    coords = np.array(np.where(labeled_grid > 0)).T # shape (N, 2) -> [(r1, c1), (r2, c2), ...]\n    if coords.size == 0:\n        return components\n        \n    labels = labeled_grid[coords[:, 0], coords[:, 1]] # Corresponding label for each coordinate\n\n    for label_id in range(1, num_components + 1):\n        component_mask = (labels == label_id)\n        component_coords = coords[component_mask]\n        if component_coords.size == 0:\n            continue \n\n        min_r = np.min(component_coords[:, 0])\n        min_c = np.min(component_coords[:, 1])\n        max_r = np.max(component_coords[:, 0])\n        max_c = np.max(component_coords[:, 1])\n        \n        components.append({\n            'id': label_id,\n            'coords': component_coords, # Store as numpy array N x 2\n            'size': len(component_coords),\n            'bbox': (min_r, min_c, max_r, max_c),\n            'min_row': min_r\n        })\n    return components\n\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:  \n    \"\"\"\n    Applies the transformation logic based on Hypothesis v4 (Object BBox).\n    \"\"\"\n    input_np = np.array(input_grid, dtype=np.int8)\n    h, w = input_np.shape\n\n    # Handle empty input grid\n    if h == 0 or w == 0:\n        return [[]]\n\n    # 1. Identify background color (BKG)\n    background_color = get_background_color(input_np)\n\n    # 2. Identify marker color (M) based on heuristic\n    marker_color = -1 \n    if background_color == 8:\n        marker_color = 9\n    elif background_color == 4:\n        marker_color = 8\n    \n    # Handle case where marker color couldn't be determined or isn't present\n    marker_mask = (input_np == marker_color)\n    if marker_color == -1 or not np.any(marker_mask):\n         if np.all(input_np == background_color):\n              return [[int(background_color)]]\n         else:\n              # Default return if no marker found but other colors exist\n              return [[int(background_color)]] \n\n    # 3. Find marker components\n    marker_components = find_components_and_properties(input_np, marker_mask)\n    if not marker_components:\n        return [[int(background_color)]] # No markers found\n\n    # 4. Find pattern components (non-BKG, non-M)\n    pattern_mask = (input_np != background_color) & (input_np != marker_color)\n    all_pattern_components = find_components_and_properties(input_np, pattern_mask)\n\n    # 5. Filter pattern components by size\n    filtered_patterns = [p for p in all_pattern_components if p['size'] > 5]\n\n    # 6. Associate patterns and markers, store unique slice definitions\n    slice_defs = set() # Store tuples: (trigger_m_min_r, o_min_r, o_min_c, o_max_c)\n    adjacency_structure = generate_binary_structure(2, 2)\n\n    for pattern in filtered_patterns:\n        # Create a mask for the current pattern\n        current_pattern_mask = np.zeros_like(input_np, dtype=bool)\n        current_pattern_mask[pattern['coords'][:, 0], pattern['coords'][:, 1]] = True\n        \n        # Dilate the pattern mask to find adjacent pixels\n        dilated_pattern = binary_dilation(current_pattern_mask, structure=adjacency_structure)\n        \n        # Find marker pixels adjacent to this pattern\n        adjacent_marker_mask = dilated_pattern & marker_mask\n        \n        if np.any(adjacent_marker_mask):\n            # Identify which marker components contain these adjacent pixels\n            adjacent_marker_coords = np.array(np.where(adjacent_marker_mask)).T\n            \n            # Find full marker components involved\n            involved_marker_components = []\n            involved_marker_coords_list = []\n            min_rows_of_involved_markers = []\n\n            # Need marker labeled grid to map coords to component IDs\n            marker_labeled, _ = label(marker_mask, structure=adjacency_structure)\n            adjacent_labels = set(marker_labeled[adjacent_marker_coords[:,0], adjacent_marker_coords[:,1]])\n            adjacent_labels.discard(0) # remove background label if captured\n\n            for m_comp in marker_components:\n                 if m_comp['id'] in adjacent_labels:\n                      involved_marker_components.append(m_comp)\n                      involved_marker_coords_list.append(m_comp['coords'])\n                      min_rows_of_involved_markers.append(m_comp['min_row'])\n\n            if involved_marker_components:\n                # Calculate trigger row\n                trigger_m_min_r = min(min_rows_of_involved_markers)\n                \n                # Combine coordinates of pattern and all involved markers\n                all_involved_marker_coords = np.vstack(involved_marker_coords_list)\n                combined_coords = np.vstack((pattern['coords'], all_involved_marker_coords))\n                \n                # Calculate bounding box of the combined object\n                o_min_r = np.min(combined_coords[:, 0])\n                o_min_c = np.min(combined_coords[:, 1])\n                o_max_r = np.max(combined_coords[:, 0]) # Not strictly needed for extraction\n                o_max_c = np.max(combined_coords[:, 1])\n                \n                # Store the unique definition\n                slice_defs.add((trigger_m_min_r, o_min_r, o_min_c, o_max_c))\n\n    # 7. If no valid associations found\n    if not slice_defs:\n        return [[int(background_color)]]\n\n    # 8. Extract slices based on unique definitions\n    extracted_regions = []\n    for trigger_m_min_r, o_min_r, o_min_c, o_max_c in slice_defs:\n        start_row = o_min_r\n        end_row = min(start_row + 5, h) # Extract 5 rows starting from object top\n        start_col = o_min_c\n        end_col = o_max_c + 1\n\n        # Clip slice boundaries to grid dimensions\n        start_row = max(0, start_row)\n        end_row = min(h, end_row)\n        start_col = max(0, start_col)\n        end_col = min(w, end_col)\n\n        # Ensure valid slice dimensions before extracting\n        if start_row < end_row and start_col < end_col:\n            extracted_slice = input_np[start_row:end_row, start_col:end_col]\n            if extracted_slice.size > 0:\n                extracted_regions.append({'trigger': trigger_m_min_r, 'slice': extracted_slice})\n\n    # Handle case where extraction yielded nothing valid\n    if not extracted_regions:\n         return [[int(background_color)]]\n\n    # 9. Sort slices by trigger_row descending\n    extracted_regions.sort(key=lambda x: x['trigger'], reverse=True)\n\n    # 10. Get final slices in order\n    final_slices = [region['slice'] for region in extracted_regions]\n\n    # 11. Pad slices to height 5\n    target_h = 5 \n    padded_slices = []\n    for s in final_slices:\n        if s.ndim == 2 and s.shape[0] > 0 and s.shape[1] > 0:\n            current_h = s.shape[0]\n            if current_h < target_h:\n                pad_h = target_h - current_h\n                # Ensure correct padding dimensions\n                if s.shape[1] > 0: \n                    padding = np.full((pad_h, s.shape[1]), background_color, dtype=s.dtype)\n                    padded_s = np.vstack((s, padding))\n                    padded_slices.append(padded_s)\n                # else: skip slice with 0 width? Should be caught by size>0 check\n            elif current_h == target_h:\n                padded_slices.append(s)\n            # else: slice is already taller? Clip? The logic extracts max 5 rows.\n\n    # If padding resulted in no valid slices\n    if not padded_slices:\n         return [[int(background_color)]]\n\n    # 12. Concatenate slices horizontally\n    try:\n        # Final check for consistent height before stacking (should be target_h)\n        first_height = padded_slices[0].shape[0]\n        if not all(arr.shape[0] == first_height for arr in padded_slices):\n             # This indicates an error in padding or height calculation.\n             # Attempt to find most common height or trim? For now, error out.\n             print(f\"Error: Mismatched heights before hstack. Expected {target_h}. Got: {[arr.shape[0] for arr in padded_slices]}\")\n             return [[int(background_color)]] \n             \n        output_np = np.hstack(padded_slices)\n        \n    except ValueError as e:\n        print(f\"Error during hstack: {e}\")\n        # Provide details for debugging\n        print(f\"Number of arrays to stack: {len(padded_slices)}\")\n        for i, arr in enumerate(padded_slices):\n            print(f\"  Slice {i} shape: {arr.shape}, dtype: {arr.dtype}\")\n        return [[int(background_color)]]\n    except IndexError: # Handles case where padded_slices might be empty after filtering\n         print(\"Error: No slices available for hstack.\")\n         return [[int(background_color)]]\n\n\n    # Convert final numpy array back to list of lists\n    return output_np.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 36853,
    "candidates_token_count": 3705,
    "total_token_count": 40558,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 26.882109,
  "retries": 1
}