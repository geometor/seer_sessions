{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import Counter\n\n\"\"\"\nTransformation Rule Description:\n\nThe transformation identifies 'Upper Structures' (contiguous objects of only Blue(1)/Red(2)) \nand their associated 'Bases' (contiguous non-structure, non-background objects adjacent below). \nIt also identifies isolated 'Trigger Pixels'.\n\nThe transformation follows one of three scenarios based on the colors of the identified Bases:\n\n1. Swap Case:\n   - Condition: If both Green(3) and Azure(8) Bases are found associated with any Upper Structures.\n   - Actions (Applied based on original grid state):\n     - Green(3) Bases are changed entirely to Azure(8).\n     - Azure(8) Bases are changed entirely to Green(3).\n     - If an Upper Structure was associated with a Green(3) Base, all Red(2) pixels within that structure are changed to Azure(8).\n     - If an Upper Structure was associated with an Azure(8) Base, any pixel *within that Base* located directly below a Red(2) pixel of the structure is changed to Red(2) (overriding the Base swap for that specific pixel).\n\n2. Trigger Case:\n   - Condition: If the Swap Case condition is not met, AND at least one isolated Trigger Pixel exists (single non-background, non-structure/base pixel not adjacent to a structure).\n   - Trigger Selection: Select the trigger pixel with the highest color index ('TargetColor').\n   - Actions:\n     - All identified Bases (regardless of original color) are changed entirely to the TargetColor.\n     - The selected Trigger Pixel is changed to the BackgroundColor.\n     - Anomaly Rule (Specific to Example 2): If the TriggerColor is Magenta(6), Background is Green(3), and original Base color was only Yellow(4), set pixel at (trigger_row + 4, trigger_col) to Yellow(4).\n\n3. No Action:\n   - Condition: If neither the Swap Case nor the Trigger Case conditions are met.\n   - Action: The grid remains unchanged.\n\nHelper concepts:\n- BackgroundColor: Most frequent color in the grid.\n- Object Finding/Adjacency: Includes diagonals (8-way connectivity).\n- Base Association: A Base is associated if it's adjacent (8-way) to an Upper Structure and its top row is >= the structure's top row.\n\"\"\"\n\n\ndef find_objects(grid: np.ndarray, background_color: int) -> list[tuple[int, set[tuple[int, int]]]]:\n    \"\"\"\n    Finds connected components (objects) of non-background colors using BFS with 8-way connectivity.\n    Returns a list of tuples: (color, set_of_pixel_coordinates).\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros((rows, cols), dtype=bool)\n    objects = []\n    for r in range(rows):\n        for c in range(cols):\n            if not visited[r, c] and grid[r, c] != background_color:\n                color = grid[r, c]\n                obj_pixels = set()\n                q = [(r, c)]\n                visited[r, c] = True\n                current_obj_visited_in_bfs = set([(r,c)]) # Track visited for *this specific object's BFS*\n\n                while q:\n                    row, col = q.pop(0)\n                    \n                    # Ensure we only add pixels matching the initial color of this object\n                    if grid[row, col] == color:\n                        obj_pixels.add((row, col))\n                        \n                        # Explore neighbors (8-connectivity)\n                        for dr in [-1, 0, 1]:\n                            for dc in [-1, 0, 1]:\n                                if dr == 0 and dc == 0:\n                                    continue\n                                nr, nc = row + dr, col + dc\n                                if 0 <= nr < rows and 0 <= nc < cols and \\\n                                   not visited[nr, nc] and \\\n                                   grid[nr, nc] == color and \\\n                                   (nr, nc) not in current_obj_visited_in_bfs:\n                                    visited[nr, nc] = True\n                                    current_obj_visited_in_bfs.add((nr,nc))\n                                    q.append((nr, nc))\n                                    \n                    # Mark non-matching color pixels as visited globally if they are non-background\n                    # This prevents starting new searches from them, but they aren't added to current object.\n                    elif 0 <= row < rows and 0 <= col < cols and grid[row, col] != background_color:\n                         visited[row,col] = True\n\n                if obj_pixels:\n                    objects.append((color, obj_pixels))\n            # Ensure every pixel is marked visited eventually\n            visited[r,c] = True \n    return objects\n\ndef get_bounding_box(pixels: set[tuple[int, int]]) -> tuple[int, int, int, int]:\n    \"\"\"Calculates the min/max row/col for a set of pixels.\"\"\"\n    if not pixels:\n        # Return invalid bounds if no pixels\n        return -1, -1, -1, -1 \n    min_r = min(r for r, c in pixels)\n    max_r = max(r for r, c in pixels)\n    min_c = min(c for r, c in pixels)\n    max_c = max(c for r, c in pixels)\n    return min_r, max_r, min_c, max_c\n\ndef check_adjacency(pixels1: set[tuple[int, int]], pixels2: set[tuple[int, int]]) -> bool:\n    \"\"\"Checks if any pixel in pixels1 is adjacent (8-way) to any pixel in pixels2.\"\"\"\n    if not pixels1 or not pixels2:\n        return False\n    # Optimization: Check bounding boxes first - if they don't overlap (expanded by 1), no adjacency.\n    min_r1, max_r1, min_c1, max_c1 = get_bounding_box(pixels1)\n    min_r2, max_r2, min_c2, max_c2 = get_bounding_box(pixels2)\n    if max_r1 < min_r2 - 1 or min_r1 > max_r2 + 1 or max_c1 < min_c2 - 1 or min_c1 > max_c2 + 1:\n        return False\n        \n    # Detailed check\n    for r1, c1 in pixels1:\n        for dr in [-1, 0, 1]:\n            for dc in [-1, 0, 1]:\n                if dr == 0 and dc == 0:\n                    continue\n                nr, nc = r1 + dr, c1 + dc\n                if (nr, nc) in pixels2:\n                    return True\n    return False\n\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Applies the transformation logic based on Upper Structures, Bases, and Trigger Pixels.\n    \"\"\"\n    # 1. Initialization\n    grid = np.array(input_grid, dtype=int)\n    output_grid = grid.copy()\n    rows, cols = grid.shape\n    if grid.size == 0: return []\n\n    # Determine BackgroundColor\n    colors, counts = np.unique(grid, return_counts=True)\n    if not colors.size: return []\n    background_color = colors[np.argmax(counts)]\n\n    # 2. Object Identification\n    all_objects = find_objects(grid, background_color)\n\n    # 3. Categorize Objects\n    structure_candidates = [] # list of (pixels, red_pixels)\n    base_candidates = []      # list of (color, pixels)\n    trigger_candidates = []   # list of (color, pixels, coordinates tuple) - storing coords for easier access\n\n    all_struct_pixels = set()\n    for color, pixels in all_objects:\n        is_structure_obj = all(grid[r, c] in [1, 2] for r, c in pixels) and (1 in {grid[p] for p in pixels} or 2 in {grid[p] for p in pixels})\n\n        if is_structure_obj:\n            red_pixels = {p for p in pixels if grid[p] == 2}\n            structure_candidates.append((pixels, red_pixels))\n            all_struct_pixels.update(pixels)\n        elif color not in [1, 2]: # Potential base or trigger\n            base_candidates.append((color, pixels))\n            if len(pixels) == 1:\n                 coord = list(pixels)[0]\n                 trigger_candidates.append((color, pixels, coord))\n\n    # 4. Associate Structures and Bases\n    structure_base_map = defaultdict(list) # struct_idx -> list of (base_color, base_pixels)\n    associated_base_pixels = set()\n    base_original_colors = set()\n\n    # Create a set of all structure pixels for faster adjacency checks later\n    # all_struct_pixels = set().union(*[s[0] for s in structure_candidates])\n    \n    struct_data_for_mapping = [] # Store (struct_idx, struct_pixels, struct_min_r)\n    for i, (sp, rp) in enumerate(structure_candidates):\n         min_r, _, _, _ = get_bounding_box(sp)\n         struct_data_for_mapping.append((i, sp, min_r))\n\n    for base_color, base_pixels in base_candidates:\n        if base_pixels.intersection(associated_base_pixels): continue # Already associated\n        \n        base_min_r, _, _, _ = get_bounding_box(base_pixels)\n        if base_min_r == -1: continue # Skip empty base objects if they somehow occur\n\n        associated = False\n        for struct_idx, struct_pixels, struct_min_r in struct_data_for_mapping:\n             # Check vertical position and adjacency\n             if base_min_r >= struct_min_r and check_adjacency(struct_pixels, base_pixels):\n                  structure_base_map[struct_idx].append((base_color, base_pixels))\n                  associated = True\n                  # Only add color and pixels once per base object, even if it touches multiple structures\n                  if not base_pixels.intersection(associated_base_pixels):\n                      associated_base_pixels.update(base_pixels)\n                      base_original_colors.add(base_color)\n                      \n    # 5. Confirm and Select Trigger Pixel\n    confirmed_triggers = [] # list of (color, pixels, coordinates)\n    for color, pixels, coord in trigger_candidates:\n        is_base = pixels.intersection(associated_base_pixels)\n        is_adj_to_struct = check_adjacency(pixels, all_struct_pixels)\n        \n        if not is_base and not is_adj_to_struct:\n            confirmed_triggers.append((color, pixels, coord))\n\n    selected_trigger = None # (color, pixels, coordinates)\n    if confirmed_triggers:\n        # Sort triggers by color index descending, then potentially by row/col if needed for tie-breaking (not specified)\n        confirmed_triggers.sort(key=lambda x: x[0], reverse=True)\n        selected_trigger = confirmed_triggers[0]\n        print(f\"Selected Trigger: Color {selected_trigger[0]} at {selected_trigger[2]}\")\n\n    # 6. Determine Transformation Case\n    is_swap_case = 3 in base_original_colors and 8 in base_original_colors\n    is_trigger_case = not is_swap_case and selected_trigger is not None\n\n    # 7. Execute Transformation\n    if is_swap_case:\n        print(\"Applying Swap Case\")\n        pixels_to_change = {} # Store changes: (r, c) -> new_color\n\n        # Create map of base pixel to original color for efficient lookup\n        base_pixel_original_color = {}\n        for struct_idx, associated_bases in structure_base_map.items():\n            for base_color, base_pixels in associated_bases:\n                 for bp in base_pixels:\n                      if bp not in base_pixel_original_color: # Avoid overwriting if shared\n                          base_pixel_original_color[bp] = base_color\n\n        # Pass 1: Base swaps and Structure Red changes\n        for struct_idx, associated_bases in structure_base_map.items():\n            associated_with_green_3 = any(bc == 3 for bc, bp in associated_bases)\n            \n            # Apply base swaps for bases associated with *this* structure\n            for base_color, base_pixels in associated_bases:\n                 new_base_color = -1\n                 if base_color == 3: new_base_color = 8\n                 elif base_color == 8: new_base_color = 3\n                 \n                 if new_base_color != -1:\n                      for r, c in base_pixels:\n                           pixels_to_change[(r, c)] = new_base_color # Might be overwritten below\n            \n            # Apply struct red changes if associated with Green(3)\n            if associated_with_green_3:\n                struct_pixels, red_pixels = structure_candidates[struct_idx]\n                for r, c in red_pixels:\n                    pixels_to_change[(r, c)] = 8 # Red -> Azure\n\n        # Pass 2: Override for Base pixels below Red if original base was Azure(8)\n        for bp_coord, original_color in base_pixel_original_color.items():\n            if original_color == 8:\n                br, bc = bp_coord\n                pixel_above = (br - 1, bc)\n                # Check if pixel above was originally Red(2) and part of *any* structure\n                if pixel_above in all_struct_pixels and grid[pixel_above] == 2:\n                     pixels_to_change[bp_coord] = 2 # Base Pixel below Red -> Red\n\n        # Apply all changes\n        for (r, c), new_color in pixels_to_change.items():\n            if 0 <= r < rows and 0 <= c < cols:\n                output_grid[r, c] = new_color\n\n    elif is_trigger_case:\n        print(\"Applying Trigger Case\")\n        target_color, trigger_pixels, trigger_coord = selected_trigger\n        tr, tc = trigger_coord\n\n        # Change all associated bases to target color\n        for r, c in associated_base_pixels:\n             output_grid[r, c] = target_color\n             \n        # Change selected trigger pixel to background color\n        output_grid[tr, tc] = background_color\n                \n        # Apply Anomaly Rule (Specific to Example 2 context)\n        original_base_colors_list = list(base_original_colors)\n        is_ex2_context = (target_color == 6 and \n                          background_color == 3 and\n                          len(original_base_colors_list) == 1 and \n                          original_base_colors_list[0] == 4)\n                          \n        if is_ex2_context:\n             anomaly_r, anomaly_c = tr + 4, tc\n             # Check bounds \n             if 0 <= anomaly_r < rows and 0 <= anomaly_c < cols:\n                 print(f\"Applying Example 2 Anomaly: Setting ({anomaly_r}, {anomaly_c}) to 4\")\n                 output_grid[anomaly_r, anomaly_c] = 4 # Set to Yellow\n\n    else:\n        print(\"No Swap or Trigger Case matched. No changes applied.\")\n        pass # Grid remains unchanged\n\n    # 8. Return result\n    return output_grid.tolist()\n\n# Helper defaultdict\nfrom collections import defaultdict\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 45595,
    "candidates_token_count": 4160,
    "total_token_count": 49755,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 30.500121,
  "retries": 1
}