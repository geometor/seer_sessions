{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import Counter\nfrom scipy.ndimage import label, find_objects\n\n\"\"\"\nTransforms an input grid based on identified patterns and components, selecting a mode based on colors present.\n\nThe transformation operates in one of two primary modes:\n\nMode A (Component Shift - observed in train_1, train_3): \nTriggered when the color '3' is absent from the grid or is the background color.\n1. Finds the background color (most frequent value).\n2. Finds connected components (using 4-way adjacency) of all non-background cells.\n3. Components consisting of a single cell remain static (their position does not change).\n4. Components consisting of multiple cells are shifted horizontally. The direction and magnitude of the shift\n   depend deterministically on the column index of the leftmost cell(s) of the component. \n   A specific mapping (leftmost_column -> shift_amount) is applied, which appears to be fixed for a given task instance. \n   The mappings are inferred from the examples using the background color as a heuristic:\n   - If background is 1 (like train_1): {leftmost_col=1: shift=+3, leftmost_col=4: shift=-1}\n   - If background is 3 (like train_3): {leftmost_col=1: shift=+2, leftmost_col=3: shift=-3, leftmost_col=4: shift=-1}\n   - Other background colors default to no shift for multi-cell components.\n\nMode B (Pattern Matching - observed in train_2): \nTriggered when the color '3' is present in the grid *and* is not the background color.\n1. Finds the background color (most frequent).\n2. Attempts to identify specific, predefined local patterns within the non-background cells. Each recognized pattern type has a fixed transformation (a 2D shift vector). Patterns identified from train_2:\n   - Vertical column segments containing '4' or '6' in input column 2: shift (+2 rows, 0 cols)\n   - Horizontal `[[3, 1, 3, 3]]` pattern: shift (-2 rows, 0 cols)\n   - Horizontal `[[3, 3, 3]]` pattern: shift (-3 rows, 0 cols)\n   - 3x3 block pattern `[[3, 3, 3], [3, 1, 3], [3, 3, 3]]`: shift (-1 row, -1 col)\n   - Pattern detection is performed iteratively. Once a cell is part of a transformed pattern, it is marked as processed and cannot be part of another pattern.\n3. After pattern matching, identifies any remaining non-background cells that form isolated single-cell components. These are treated as static.\n4. Any remaining non-background cells that were not part of a detected pattern and were not isolated single cells are treated as static as a fallback behavior (copied to their original position).\n\nOutput Construction:\n- The output grid is initialized with the determined background color.\n- Transformations (component shifts or pattern shifts) and static placements are applied according to the selected mode.\n- Cells are marked as processed as their output position is determined to handle overlaps and ensure each input foreground cell contributes at most once to the output.\n\"\"\"\n\ndef find_background_color(grid_arr: np.ndarray) -> int:\n    \"\"\"Finds the most frequent value in the grid.\"\"\"\n    counts = Counter(grid_arr.flatten())\n    if not counts: return 0 # Handle empty grid\n    # Assume the most frequent color is the background\n    background_color = counts.most_common(1)[0][0]\n    return background_color\n\ndef get_component_cells(labeled_array: np.ndarray, label_num: int, objects_slices: list) -> list[tuple[int, int]]:\n    \"\"\"Gets the (row, col) coordinates of cells belonging to a specific component label.\"\"\"\n    # Ensure label number is valid and slices exist\n    if label_num <= 0 or label_num > len(objects_slices): return []\n    obj_slice = objects_slices[label_num - 1]\n    # Handle potentially None slices if label was discontinuous/eliminated\n    if obj_slice is None: return [] \n    \n    # Extract the sub-array containing the component's bounding box\n    sub_array = labeled_array[obj_slice]\n    # Create a mask for the specific label within the sub-array\n    component_mask = (sub_array == label_num)\n    # Find coordinates relative to the sub-array's top-left corner\n    coords_in_slice = np.argwhere(component_mask)\n    # Adjust coordinates to be relative to the full grid using the slice start offsets\n    offset = np.array([s.start for s in obj_slice])\n    coords_global = [tuple(coord + offset) for coord in coords_in_slice]\n    return coords_global\n\ndef get_leftmost_column(component_cells: list[tuple[int, int]]) -> int:\n    \"\"\"Finds the minimum column index among all cells in a component.\"\"\"\n    if not component_cells: return -1 # Return invalid index if component is empty\n    return min(c for r, c in component_cells)\n\ndef find_and_transform_pattern(input_arr, output_arr, processed_mask, pattern, shift_r, shift_c):\n    \"\"\"Finds non-overlapping instances of a pattern and applies transformation.\"\"\"\n    H, W = input_arr.shape\n    # Ensure pattern is a numpy array\n    if not isinstance(pattern, np.ndarray): pattern = np.array(pattern)\n    pH, pW = pattern.shape\n    matches_found = 0\n    \n    # Iterate through possible top-left corners of the pattern\n    for r in range(H - pH + 1):\n        for c in range(W - pW + 1):\n            # Extract the subgrid matching pattern dimensions\n            subgrid = input_arr[r:r+pH, c:c+pW]\n            # Check if the subgrid matches the pattern shape\n            pattern_match = np.array_equal(subgrid, pattern)\n\n            if pattern_match:\n                # Check if ANY cell in this location is already processed\n                if not np.any(processed_mask[r:r+pH, c:c+pW]):\n                    # Apply transformation and mark as processed\n                    for pr in range(pH):\n                        for pc in range(pW):\n                            nr, nc = r + pr + shift_r, c + pc + shift_c\n                            # Place in output if within bounds\n                            if 0 <= nr < H and 0 <= nc < W:\n                                output_arr[nr, nc] = input_arr[r + pr, c + pc]\n                            # Mark the source cell as processed\n                            processed_mask[r + pr, c + pc] = True\n                    matches_found += 1\n    # Return True if any matches were found and processed\n    return matches_found > 0 \n\ndef find_and_transform_vertical_column(input_arr, output_arr, processed_mask, background_color, col_idx, target_values, shift_r, shift_c):\n    \"\"\"Finds vertical segments of target values in a specific column and transforms them.\"\"\"\n    H, W = input_arr.shape\n    if col_idx < 0 or col_idx >= W: return False # Skip if column index is out of bounds\n\n    col_data = input_arr[:, col_idx]\n    processed_in_col = processed_mask[:, col_idx]\n    matches_found = False\n\n    # Iterate through each cell in the specified column\n    for r in range(H):\n        # Check if cell has a target value, is not background, and is not already processed\n        if col_data[r] in target_values and col_data[r] != background_color and not processed_in_col[r]:\n             nr, nc = r + shift_r, col_idx + shift_c\n             # Place in output if within bounds\n             if 0 <= nr < H and 0 <= nc < W:\n                 output_arr[nr, nc] = input_arr[r, col_idx]\n             # Mark the source cell as processed\n             processed_mask[r, col_idx] = True\n             matches_found = True\n    # Return True if any cells in the column were processed\n    return matches_found\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:  \n    # --- Initialization ---\n    if not input_grid or not input_grid[0]: return [] # Handle empty input\n    input_arr = np.array(input_grid, dtype=int)\n    H, W = input_arr.shape\n    background_color = find_background_color(input_arr)\n    output_arr = np.full_like(input_arr, background_color)\n    processed_mask = np.zeros_like(input_arr, dtype=bool) # Tracks INPUT cells processed\n\n    # --- Determine Candidate Cells (Non-Background) ---\n    foreground_mask = (input_arr != background_color)\n\n    # --- Determine Transformation Mode ---\n    # Check if '3' exists AND is not the background color\n    foreground_colors = np.unique(input_arr[foreground_mask])\n    mode_b_trigger = (3 in foreground_colors)\n\n    # ===============================================\n    # === Mode B: Pattern Matching (Foreground 3) ===\n    # ===============================================\n    if mode_b_trigger:\n        # Define Mode B patterns and their shifts (row_shift, col_shift)\n        # Order might matter: process more specific/larger patterns first\n        patterns_to_find = [\n             # Pattern Definition                Shift (dr, dc)\n            (np.array([[3, 3, 3], \n                       [3, 1, 3], \n                       [3, 3, 3]]),             -1, -1), # 3x3 block \n            (np.array([[3, 1, 3, 3]]),             -2,  0), # Horizontal 3 1 3 3 \n            (np.array([[3, 3, 3]]),                -3,  0), # Horizontal 3 3 3 \n        ]\n        # Define vertical column pattern parameters separately\n        vertical_col_targets = {4, 6} # Values to look for\n        vertical_col_idx = 2          # Column index to check\n        vertical_col_shift_r, vertical_col_shift_c = 2, 0 # Shift for these cells\n\n        # 1. Apply transformations for defined 2D array patterns\n        for pattern, sr, sc in patterns_to_find:\n            find_and_transform_pattern(input_arr, output_arr, processed_mask, pattern, sr, sc)\n\n        # 2. Apply transformation for the specific vertical column pattern\n        find_and_transform_vertical_column(input_arr, output_arr, processed_mask, \n                                             background_color, vertical_col_idx, \n                                             vertical_col_targets, \n                                             vertical_col_shift_r, vertical_col_shift_c)\n\n        # 3. Handle isolated single cells among remaining foreground (Static)\n        # Find components among foreground cells NOT processed yet\n        remaining_foreground_mask = foreground_mask & (~processed_mask)\n        labeled_remaining, num_remaining = label(remaining_foreground_mask)\n        objects_remaining = find_objects(labeled_remaining) # Get slices for remaining components\n\n        for i in range(1, num_remaining + 1):\n            comp_cells = get_component_cells(labeled_remaining, i, objects_remaining)\n            # If the component is just a single cell\n            if len(comp_cells) == 1:\n                r, c = comp_cells[0]\n                # Double check it wasn't somehow processed\n                if not processed_mask[r,c]: \n                    output_arr[r, c] = input_arr[r, c] # Copy to same location (static)\n                    processed_mask[r, c] = True        # Mark as processed\n\n        # 4. Fallback: Treat any remaining unprocessed foreground cells as static\n        # These are cells that were foreground but not part of a pattern and not isolated singles\n        final_remaining_mask = foreground_mask & (~processed_mask)\n        output_arr[final_remaining_mask] = input_arr[final_remaining_mask]\n\n    # ============================================\n    # === Mode A: Component Shift (No Fgnd 3) ===\n    # ============================================\n    else:\n        # Find connected components among all foreground cells\n        # Structure for connectivity check (4-way)\n        structure = np.array([[0,1,0], [1,1,1], [0,1,0]], dtype=bool) \n        labeled_array, num_features = label(foreground_mask, structure=structure)\n        objects_slices = find_objects(labeled_array)\n\n        # Define shift rules based on heuristic (background color)\n        shift_rules = {} # Default: no shift\n        if background_color == 1: # Assume train_1 rules\n            shift_rules = {1: 3, 4: -1} # {leftmost_col: horizontal_shift}\n        elif background_color == 3: # Assume train_3 rules\n            shift_rules = {1: 2, 3: -3, 4: -1}\n        \n        # Iterate through each found component\n        for i in range(1, num_features + 1):\n            component_cells = get_component_cells(labeled_array, i, objects_slices)\n            if not component_cells: continue # Skip if component is empty\n\n            # Check if component was already processed (shouldn't happen in pure Mode A, but safe)\n            # Use tuple indexing for numpy boolean array\n            coords_tuple = tuple(np.array(component_cells).T)\n            if np.any(processed_mask[coords_tuple]): continue \n\n            if len(component_cells) == 1:\n                # Handle single-cell components: Static\n                r, c = component_cells[0]\n                output_arr[r, c] = input_arr[r, c]\n                processed_mask[r, c] = True # Mark the cell as processed\n            else:\n                # Handle multi-cell components: Apply horizontal shift\n                leftmost_col = get_leftmost_column(component_cells)\n                # Get the shift amount from the rules based on the leftmost column\n                shift_col = shift_rules.get(leftmost_col, 0) # Default to 0 shift if rule not found\n\n                # Apply the shift to each cell in the component\n                for r, c in component_cells:\n                     nc = c + shift_col # Calculate the new column after shifting\n                     # Check if the new coordinates are within the grid boundaries\n                     if 0 <= r < H and 0 <= nc < W:\n                         output_arr[r, nc] = input_arr[r, c] # Copy value to shifted position\n                     # Mark the original cell as processed\n                     processed_mask[r, c] = True\n\n        # Fallback (Safety net for any foreground missed in Mode A)\n        final_remaining_mask_a = foreground_mask & (~processed_mask)\n        if np.any(final_remaining_mask_a):\n             output_arr[final_remaining_mask_a] = input_arr[final_remaining_mask_a]\n\n\n    # --- Return Result ---\n    return output_arr.tolist() # Convert final numpy array back to list of lists\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 17812,
    "candidates_token_count": 9373,
    "total_token_count": 27185,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 64.334568,
  "retries": 1
}