{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\nTransforms an input grid based on identified patterns and components, selecting a mode based on colors present.\n\nThe transformation operates in one of two primary modes:\n\nMode A (Component Shift):\nTriggered when the color '3' is absent from the grid or is the background color.\n1. Finds the background color (most frequent value).\n2. Finds connected components (using 4-way adjacency) of all non-background cells.\n3. Components consisting of a single cell remain static (their position does not change).\n4. Components consisting of multiple cells are shifted horizontally. The direction and magnitude of the shift\n   depend deterministically on the column index of the leftmost cell(s) of the component.\n   A specific mapping (leftmost_column -> shift_amount) is applied, inferred heuristically from training examples based on background color:\n   - If background is 1: {leftmost_col=1: shift=+3, leftmost_col=4: shift=-1}\n   - If background is 3: {leftmost_col=1: shift=+2, leftmost_col=3: shift=-3, leftmost_col=4: shift=-1}\n   - Other background colors default to no shift for multi-cell components.\n\nMode B (Pattern Matching):\nTriggered when the color '3' is present in the grid AND is not the background color.\n1. Finds the background color (most frequent). Initializes output with background.\n2. Attempts to identify specific, predefined local patterns within the non-background cells. Each recognized pattern type has a fixed transformation (a 2D shift vector). Patterns are applied sequentially, and cells involved are marked as 'processed' to avoid reuse.\n   - Pattern: Vertical column segment in col 2 containing '4' or '6'. Action: Shift cells (+2 rows, 0 cols).\n   - Pattern: `[[3, 3, 3], [3, 1, 3], [3, 3, 3]]` (3x3 block). Action: Shift cells (-1 row, -1 col).\n   - Pattern: `[[3, 1, 3, 3]]` (Horizontal). Action: Shift cells (-2 rows, 0 cols).\n3. After pattern matching attempts, any non-background input cell that was *not* marked as processed is treated as static: its value is copied to the same location in the output grid.\n\nOutput Construction:\n- The output grid is initialized with the determined background color.\n- Transformations (Mode A shifts or Mode B pattern shifts) and static placements (Mode A single cells or Mode B fallback) are applied according to the selected mode.\n- For Mode B, a mask tracks processed input cells to handle overlaps and ensure each input foreground cell contributes at most once to the output (either via a pattern shift or the static fallback).\n\"\"\"\n\nimport numpy as np\nfrom collections import Counter\nfrom scipy.ndimage import label, find_objects\n\n# --- Helper Functions ---\n\ndef find_background_color(grid_arr: np.ndarray) -> int:\n    \"\"\"Finds the most frequent value in the grid.\"\"\"\n    counts = Counter(grid_arr.flatten())\n    if not counts: return 0 # Handle empty grid\n    background_color = counts.most_common(1)[0][0]\n    return background_color\n\ndef get_component_cells(labeled_array: np.ndarray, label_num: int, objects_slices: list) -> list[tuple[int, int]]:\n    \"\"\"Gets the (row, col) coordinates of cells belonging to a specific component label.\"\"\"\n    # Ensure label number is valid and slices exist for it\n    if label_num <= 0 or label_num > len(objects_slices) or objects_slices[label_num - 1] is None:\n        return []\n    obj_slice = objects_slices[label_num - 1]\n\n    # Extract the sub-array within the component's bounding box\n    sub_array = labeled_array[obj_slice]\n    # Create a mask for the specific label within the sub-array\n    component_mask = (sub_array == label_num)\n    # Find coordinates relative to the sub-array's top-left corner\n    coords_in_slice = np.argwhere(component_mask)\n    # Adjust coordinates to be relative to the full grid using the slice start offsets\n    offset = np.array([s.start for s in obj_slice])\n    coords_global = [tuple(coord + offset) for coord in coords_in_slice]\n    return coords_global\n\ndef get_leftmost_column(component_cells: list[tuple[int, int]]) -> int:\n    \"\"\"Finds the minimum column index among all cells in a component.\"\"\"\n    if not component_cells: return -1 # Return invalid index if component is empty\n    return min(c for r, c in component_cells)\n\ndef find_and_transform_pattern(input_arr, output_arr, processed_mask, pattern, shift_r, shift_c):\n    \"\"\"Finds non-overlapping instances of a 2D array pattern and applies transformation.\"\"\"\n    H, W = input_arr.shape\n    if not isinstance(pattern, np.ndarray): pattern = np.array(pattern)\n    pH, pW = pattern.shape\n    \n    # Iterate through all possible top-left corners for the pattern\n    for r in range(H - pH + 1):\n        for c in range(W - pW + 1):\n            # Extract the subgrid from the input array\n            subgrid = input_arr[r:r+pH, c:c+pW]\n            # Check if the subgrid exactly matches the pattern\n            pattern_match = np.array_equal(subgrid, pattern)\n\n            if pattern_match:\n                # Crucially, check if ANY cell in the source pattern location is already processed\n                if not np.any(processed_mask[r:r+pH, c:c+pW]):\n                    # Apply transformation and mark source cells as processed\n                    for pr in range(pH):\n                        for pc in range(pW):\n                            # Calculate target coordinates after shift\n                            nr, nc = r + pr + shift_r, c + pc + shift_c\n                            # Place value in output if target is within bounds\n                            if 0 <= nr < H and 0 <= nc < W:\n                                output_arr[nr, nc] = input_arr[r + pr, c + pc]\n                            # Mark the source cell as processed\n                            processed_mask[r + pr, c + pc] = True\n                    # Since we found a non-overlapping match, continue searching elsewhere\n                    # In simple cases, could 'continue' outer loop here, but let's allow multiple non-overlapping finds\n\ndef find_and_transform_vertical_column(input_arr, output_arr, processed_mask, background_color, col_idx, target_values, shift_r, shift_c):\n    \"\"\"Finds vertical segments of target values in a specific column and transforms them.\"\"\"\n    H, W = input_arr.shape\n    # Check if column index is valid\n    if col_idx < 0 or col_idx >= W: return\n\n    # Iterate through each row in the specified column\n    for r in range(H):\n        cell_value = input_arr[r, col_idx]\n        # Check conditions: target value, not background, and not already processed\n        if cell_value in target_values and cell_value != background_color and not processed_mask[r, col_idx]:\n             # Calculate target coordinates\n             nr, nc = r + shift_r, col_idx + shift_c\n             # Place value in output if target is within bounds\n             if 0 <= nr < H and 0 <= nc < W:\n                 output_arr[nr, nc] = input_arr[r, col_idx]\n             # Mark the source cell as processed\n             processed_mask[r, col_idx] = True\n\n\n# --- Main Transformation Function ---\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:\n    # --- Initialization ---\n    if not input_grid or not input_grid[0]: return [] # Handle empty input\n    input_arr = np.array(input_grid, dtype=int)\n    H, W = input_arr.shape\n    background_color = find_background_color(input_arr)\n    output_arr = np.full_like(input_arr, background_color) # Initialize output with background\n\n    # Identify all foreground cells (non-background)\n    foreground_mask = (input_arr != background_color)\n\n    # --- Determine Transformation Mode ---\n    # Check if '3' exists among foreground colors\n    foreground_colors = np.unique(input_arr[foreground_mask])\n    mode_b_trigger = (3 in foreground_colors) # True if '3' is a foreground color\n\n    # ===============================================\n    # === Mode B: Pattern Matching (Foreground 3) ===\n    # ===============================================\n    if mode_b_trigger:\n        # Initialize mask to track processed input cells for Mode B\n        processed_mask = np.zeros_like(input_arr, dtype=bool)\n\n        # --- Apply Pattern Shifts (Order: Vertical, 3x3, 3133) ---\n        # 1. Vertical Column (4/6 in col 2) shift (+2, 0)\n        find_and_transform_vertical_column(input_arr, output_arr, processed_mask,\n                                             background_color, col_idx=2,\n                                             target_values={4, 6}, shift_r=2, shift_c=0)\n\n        # 2. 3x3 Block pattern shift (-1, -1)\n        pattern_3x3 = np.array([[3, 3, 3], [3, 1, 3], [3, 3, 3]])\n        find_and_transform_pattern(input_arr, output_arr, processed_mask,\n                                     pattern_3x3, shift_r=-1, shift_c=-1)\n\n        # 3. Horizontal 3 1 3 3 pattern shift (-2, 0)\n        pattern_3133 = np.array([[3, 1, 3, 3]])\n        find_and_transform_pattern(input_arr, output_arr, processed_mask,\n                                     pattern_3133, shift_r=-2, shift_c=0)\n\n        # --- Static Fallback ---\n        # Iterate through all input cells again\n        for r in range(H):\n            for c in range(W):\n                # If it's a foreground cell AND it hasn't been processed by a pattern shift above\n                if foreground_mask[r, c] and not processed_mask[r, c]:\n                    # Place its value statically in the output at the same location\n                    output_arr[r, c] = input_arr[r, c]\n\n    # ============================================\n    # === Mode A: Component Shift (No Fgnd 3) ===\n    # ============================================\n    else:\n        # --- Find Connected Components of Foreground ---\n        # Use 4-way connectivity (neighbors share an edge)\n        structure = np.array([[0,1,0], [1,1,1], [0,1,0]], dtype=bool)\n        labeled_array, num_features = label(foreground_mask, structure=structure)\n        objects_slices = find_objects(labeled_array) # Get bounding boxes\n\n        # --- Define Shift Rules based on Background Color ---\n        shift_rules = {} # Default to no shift\n        if background_color == 1: # train_1 rules\n            shift_rules = {1: 3, 4: -1} # {leftmost_col: horizontal_shift}\n        elif background_color == 3: # train_3 rules\n            shift_rules = {1: 2, 3: -3, 4: -1}\n\n        # --- Process Each Component ---\n        for i in range(1, num_features + 1): # Iterate through component labels\n            component_cells = get_component_cells(labeled_array, i, objects_slices)\n            if not component_cells: continue # Skip if component is empty or invalid\n\n            if len(component_cells) == 1:\n                # Static placement for single-cell components\n                r, c = component_cells[0]\n                output_arr[r, c] = input_arr[r, c]\n            else:\n                # Horizontal shift for multi-cell components\n                leftmost_col = get_leftmost_column(component_cells)\n                # Get the shift amount from the rules, default to 0 if not found\n                shift_col = shift_rules.get(leftmost_col, 0)\n\n                # Apply shift to each cell in the component\n                for r, c in component_cells:\n                     # Calculate the new column after shifting\n                     nc = c + shift_col\n                     # Check if the new coordinates are within the grid boundaries\n                     if 0 <= r < H and 0 <= nc < W:\n                         # Copy the input value to the shifted position in the output\n                         output_arr[r, nc] = input_arr[r, c]\n        # Note: No explicit fallback needed for Mode A as the component processing\n        # inherently handles all foreground cells either as static or shifted.\n\n    # --- Return Result ---\n    return output_arr.tolist() # Convert final numpy array back to list of lists\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 43093,
    "candidates_token_count": 3749,
    "total_token_count": 46842,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 23.039991,
  "retries": 1
}