{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nTransformation Rule:\n1. Identify \"reference patterns\": These are small, contiguous shapes of non-white (0), non-gray (5) colors. Exclude large structures like long lines (e.g., the blue separator often seen). Store each pattern's color, dimensions (height, width), and its 'form' - the set of relative coordinates of its colored pixels from its top-left corner.\n2. Initialize the output grid as a copy of the input grid.\n3. Create a boolean mask (`processed_mask`) of the same dimensions as the grid, initialized to False. This tracks pixels successfully colored by a pattern match.\n4. Iterate through every possible top-left anchor position (r, c) in the input grid.\n5. For each anchor (r, c):\n    a. Iterate through each identified reference pattern.\n    b. Check if a sub-grid of the pattern's dimensions, starting at (r, c), can fit within the input grid boundaries.\n    c. If it fits, extract this sub-grid from the input grid.\n    d. Compare the pattern of *gray* pixels within the sub-grid to the 'form' of the reference pattern. A match occurs if:\n        i. For every relative coordinate (dr, dc) present in the reference pattern's form, the corresponding pixel `sub_grid[dr, dc]` is gray (5).\n        ii. For every relative coordinate (dr, dc) *not* present in the reference pattern's form (within the pattern's bounding box), the corresponding pixel `sub_grid[dr, dc]` is *not* gray (5).\n    e. If an exact match is found:\n        i. Get the color of the matching reference pattern.\n        ii. For each relative coordinate (dr, dc) in the reference pattern's form:\n            - Calculate the absolute coordinate `(abs_r, abs_c) = (r + dr, c + dc)`.\n            - Update the `output_grid[abs_r, abs_c]` to the pattern's color.\n            - Mark `processed_mask[abs_r, abs_c] = True`.\n        iii. Break the inner loop (stop checking other patterns for this anchor (r, c)), as a region can only match one pattern starting at a specific anchor.\n6. After checking all anchors, perform a final cleanup: Iterate through the `output_grid`. If any pixel `(r, c)` is still gray (5) AND `processed_mask[r, c]` is False, change `output_grid[r, c]` to white (0).\n7. Return the modified output grid.\n\"\"\"\n\ndef find_objects_with_details(grid, colors_to_find):\n    \"\"\"\n    Finds contiguous objects of specified colors, returning details including form.\n\n    Args:\n        grid (np.array): The input grid.\n        colors_to_find (set): A set of color values to search for.\n\n    Returns:\n        list: A list of dictionaries, where each dictionary represents an object\n              and contains:\n              'color': The color of the object.\n              'pixels': A set of (row, col) tuples for the object's pixels.\n              'min_r', 'min_c': Coordinates of the top-left corner.\n              'height', 'width': Dimensions of the bounding box.\n              'form': A set of (dr, dc) relative coordinates from the top-left.\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n\n    for r in range(rows):\n        for c in range(cols):\n            color = grid[r, c]\n            if color in colors_to_find and not visited[r, c]:\n                obj_pixels_list = []\n                q = deque([(r, c)])\n                visited[r, c] = True\n                min_r, min_c = r, c\n                max_r, max_c = r, c\n\n                # BFS to find all connected pixels\n                while q:\n                    row, col = q.popleft()\n                    obj_pixels_list.append((row, col))\n                    min_r = min(min_r, row)\n                    min_c = min(min_c, col)\n                    max_r = max(max_r, row)\n                    max_c = max(max_c, col)\n\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        if 0 <= nr < rows and 0 <= nc < cols and \\\n                           not visited[nr, nc] and grid[nr, nc] == color:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n\n                # Calculate properties\n                obj_pixels_set = set(obj_pixels_list)\n                height = max_r - min_r + 1\n                width = max_c - min_c + 1\n                form = set((p_r - min_r, p_c - min_c) for p_r, p_c in obj_pixels_set)\n\n                objects.append({\n                    'color': color,\n                    'pixels': obj_pixels_set,\n                    'min_r': min_r,\n                    'min_c': min_c,\n                    'height': height,\n                    'width': width,\n                    'form': form\n                })\n\n    return objects\n\ndef filter_reference_patterns(objects, grid_rows, grid_cols):\n    \"\"\"Filters potential objects to identify true reference patterns.\"\"\"\n    patterns = []\n    # Heuristic threshold to exclude large lines/structures\n    # Exclude if object spans full grid width/height or is just very large\n    max_reasonable_dim = max(grid_rows, grid_cols) * 0.8\n\n    for obj in objects:\n        is_separator_line = (\n            obj['color'] == 1 and # Assuming blue lines are separators\n            (obj['width'] >= max_reasonable_dim or obj['height'] >= max_reasonable_dim)\n        )\n        # Add other filtering conditions if needed (e.g., minimum size)\n        is_too_small = len(obj['pixels']) < 2 # Exclude single pixels? Maybe not needed for this task.\n\n        if not is_separator_line: # and not is_too_small:\n             patterns.append(obj)\n    return patterns\n\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the template-matching transformation rule to the input grid.\n    \"\"\"\n    rows, cols = input_grid.shape\n    output_grid = np.copy(input_grid)\n    processed_mask = np.zeros_like(input_grid, dtype=bool)\n\n    # 1. & 2. Identify and filter reference patterns\n    all_colors = set(np.unique(input_grid))\n    potential_ref_colors = all_colors - {0, 5} # Exclude white (0) and gray (5)\n    if not potential_ref_colors: # Handle case with no references\n        reference_patterns = []\n    else:\n        potential_objects = find_objects_with_details(input_grid, potential_ref_colors)\n        reference_patterns = filter_reference_patterns(potential_objects, rows, cols)\n\n    # 3. Iterate through grid anchors and try to match patterns\n    for r in range(rows):\n        for c in range(cols):\n            # Optimization: Can skip if input[r,c] is not gray?\n            # No, because a pattern might start here even if the top-left isn't gray,\n            # but the *anchor point* logic implies we only *start* checking if the anchor\n            # pixel could potentially be part of a match. Let's stick to the plan:\n            # check every r,c as a potential top-left corner.\n\n            for pattern in reference_patterns:\n                p_h, p_w = pattern['height'], pattern['width']\n                p_form = pattern['form']\n                p_color = pattern['color']\n\n                # Check bounds: Can the pattern fit starting at (r, c)?\n                if r + p_h <= rows and c + p_w <= cols:\n                    # Extract sub-grid\n                    sub_grid = input_grid[r : r + p_h, c : c + p_w]\n\n                    # Compare sub-grid's gray pixels to pattern form\n                    match = True\n                    pixels_to_color = [] # Store coords relative to (r,c) for this match\n\n                    for dr in range(p_h):\n                        for dc in range(p_w):\n                            sub_pixel_is_gray = (sub_grid[dr, dc] == 5)\n                            coord_in_form = ((dr, dc) in p_form)\n\n                            if coord_in_form:\n                                if not sub_pixel_is_gray:\n                                    match = False\n                                    break\n                                else:\n                                     # Only store the coordinates that should be colored\n                                     pixels_to_color.append((dr, dc))\n                            elif sub_pixel_is_gray: # Pixel is gray but shouldn't be based on pattern\n                                match = False\n                                break\n                        if not match:\n                            break\n\n                    # If match found, update output and mask\n                    if match:\n                        for dr, dc in pixels_to_color: # Use the stored coordinates\n                            abs_r, abs_c = r + dr, c + dc\n                            # Check if not already processed by another pattern match\n                            # This prevents overwriting parts of successful previous matches\n                            # anchored elsewhere, which might happen with overlapping patterns.\n                            # Only color if the target pixel in output is still gray\n                            if output_grid[abs_r, abs_c] == 5:\n                                output_grid[abs_r, abs_c] = p_color\n                                processed_mask[abs_r, abs_c] = True\n\n                        # Break from pattern loop for this anchor (r,c)\n                        # Assumes only one pattern can match starting at a given anchor\n                        break\n            # End pattern loop\n        # End col loop\n    # End row loop\n\n    # 4. Final cleanup: Change remaining, unprocessed gray pixels to white\n    for r in range(rows):\n        for c in range(cols):\n            if output_grid[r, c] == 5 and not processed_mask[r, c]:\n                output_grid[r, c] = 0\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 34151,
    "candidates_token_count": 2435,
    "total_token_count": 36586,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 33.372136,
  "retries": 1
}