{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque, Counter\nimport sys\n\n# Increase recursion depth for deep object searches if needed, though BFS is usually fine.\n# sys.setrecursionlimit(2000) \n\n\"\"\"\nIdentify the background color as the most frequent color in the input grid.\nFind connected components (objects) of non-background pixels using 8-connectivity (including diagonals).\nFor each object, check if it contains both azure (8) pixels and at least one yellow (4) pixel. These are 'target objects'.\nIf an object is a target object:\n  Find the location (specifically the column index) of *any* yellow (4) pixel within it. Use the first one found during traversal as the 'anchor pixel'.\n  Determine the grid's vertical midpoint column index (width // 2). Integer division is used.\n  If the anchor pixel's column index is strictly less than the midpoint column index, the entire object is shifted 3 columns to the right (+3).\n  If the anchor pixel's column index is greater than or equal to the midpoint column index, the entire object is shifted 3 columns to the left (-3).\nPixels shifted outside the grid boundaries are discarded.\nAll other objects (those not containing both azure and yellow) and the background pixels remain in their original positions.\nThe output grid is constructed by placing the shifted target objects and the unchanged non-target objects onto a grid initialized with the background color.\n\"\"\"\n\ndef find_most_frequent_color(grid_np):\n    \"\"\"\n    Determines the most frequent color in the grid.\n\n    Args:\n        grid_np (np.array): The input grid as a NumPy array.\n\n    Returns:\n        int: The color value that appears most frequently.\n    \"\"\"\n    # Handle empty or invalid input gracefully, though ARC constraints usually prevent this.\n    if grid_np.size == 0:\n        return 0 # Default to white/0 if grid is empty\n\n    counts = Counter(grid_np.flatten())\n    # most_common(1) returns a list of tuples [(color, count)], so we extract the color.\n    most_common_color = counts.most_common(1)[0][0]\n    return int(most_common_color) # Ensure it's an int\n\n\ndef find_objects(grid_np, background_color):\n    \"\"\"\n    Finds connected objects of non-background pixels using BFS and 8-connectivity.\n\n    Args:\n        grid_np (np.array): The input grid.\n        background_color (int): The color considered as background.\n\n    Returns:\n        list: A list of dictionaries, where each dictionary represents an object\n              and contains 'pixels' (list of (r, c, color)), 'has_azure',\n              'has_yellow', and 'yellow_loc' (first found (r, c) tuple).\n              Returns an empty list if no non-background objects are found.\n    \"\"\"\n    height, width = grid_np.shape\n    visited = np.zeros_like(grid_np, dtype=bool)\n    all_objects = []\n\n    for r in range(height):\n        for c in range(width):\n            # If this pixel is background or already visited, skip\n            if grid_np[r, c] == background_color or visited[r, c]:\n                continue\n\n            # Start BFS for a new object\n            current_object_pixels = []\n            q = deque([(r, c)])\n            visited[r, c] = True\n            has_azure = False\n            has_yellow = False\n            yellow_pixel_loc = None # Store the first yellow pixel found (r, c)\n\n            while q:\n                row, col = q.popleft()\n                color = grid_np[row, col]\n                current_object_pixels.append((row, col, color))\n\n                # Check object properties\n                if color == 8: # azure\n                    has_azure = True\n                if color == 4: # yellow\n                    has_yellow = True\n                    if yellow_pixel_loc is None: # Store only the first one encountered\n                         yellow_pixel_loc = (row, col)\n\n                # Explore neighbors (8-connectivity: includes diagonals)\n                for dr in [-1, 0, 1]:\n                    for dc in [-1, 0, 1]:\n                        if dr == 0 and dc == 0:\n                            continue\n                        nr, nc = row + dr, col + dc\n\n                        # Check bounds and if neighbor is part of the object (non-background and not visited)\n                        if 0 <= nr < height and 0 <= nc < width and \\\n                           grid_np[nr, nc] != background_color and \\\n                           not visited[nr, nc]:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n\n            # Store the found object and its properties if it contains any pixels\n            if current_object_pixels:\n                 all_objects.append({\n                     \"pixels\": current_object_pixels,\n                     \"has_azure\": has_azure,\n                     \"has_yellow\": has_yellow,\n                     \"yellow_loc\": yellow_pixel_loc\n                 })\n\n    return all_objects\n\n\ndef transform(input_grid):\n    \"\"\"\n    Transforms the input grid based on shifting rules applied to specific objects.\n    Objects containing both azure (8) and yellow (4) pixels are shifted horizontally\n    based on the column of a yellow pixel relative to the grid's vertical midpoint.\n    The background color is determined dynamically as the most frequent color.\n    \"\"\"\n    # Convert input to numpy array for efficient operations\n    input_np = np.array(input_grid, dtype=int)\n    height, width = input_np.shape\n\n    # Determine the background color dynamically\n    background_color = find_most_frequent_color(input_np)\n\n    # Determine midpoint column and shift amount\n    midpoint_col = width // 2\n    shift_amount = 3\n\n    # Initialize output grid with the determined background color\n    output_np = np.full_like(input_np, background_color)\n\n    # Find all connected objects of non-background colors\n    objects = find_objects(input_np, background_color)\n\n    # Process each found object\n    for obj_data in objects:\n        obj_pixels = obj_data[\"pixels\"]\n        # Check if the object is a 'target object' (contains both azure and yellow)\n        is_target_object = obj_data[\"has_azure\"] and obj_data[\"has_yellow\"]\n\n        if is_target_object and obj_data[\"yellow_loc\"] is not None:\n            # This is a target object, determine shift based on the first yellow pixel found\n            _ , anchor_col = obj_data[\"yellow_loc\"] # Get column of the yellow anchor pixel\n\n            # Determine shift direction based on anchor column relative to midpoint\n            if anchor_col < midpoint_col:\n                shift = shift_amount # Shift right\n            else:\n                shift = -shift_amount # Shift left\n\n            # Apply shift to each pixel in the object and draw it on the output grid\n            for r, c, color in obj_pixels:\n                new_c = c + shift\n                # Draw the pixel only if the new column is within the grid bounds\n                if 0 <= new_c < width:\n                     # Check row bounds too, although they don't change\n                     if 0 <= r < height:\n                        output_np[r, new_c] = color\n        else:\n            # This is not a target object (or somehow a target object without a yellow pixel - shouldn't happen based on logic),\n            # draw it in its original position\n            for r, c, color in obj_pixels:\n                 # Basic bounds check (should always be true for original positions)\n                 if 0 <= r < height and 0 <= c < width:\n                    output_np[r, c] = color\n\n    # Convert the result back to a standard list of lists format\n    return output_np.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 6270,
    "candidates_token_count": 1824,
    "total_token_count": 8094,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 159.526476
}