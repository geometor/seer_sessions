{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nIdentify connected components (objects) of non-background (non-blue/1) pixels.\nFor each object, check if it contains both azure (8) pixels and at least one yellow (4) pixel.\nIf an object meets this criteria (is a \"target object\"):\n  Find the location (column index) of a yellow (4) pixel within it (the \"anchor pixel\").\n  Determine the grid's vertical midpoint column index (width // 2).\n  If the anchor pixel's column index is less than the midpoint, the object is shifted 3 columns to the right.\n  If the anchor pixel's column index is greater than or equal to the midpoint, the object is shifted 3 columns to the left.\nAll other objects (those not containing both azure and yellow) and the background pixels remain in their original positions.\nThe output grid is constructed by placing the shifted target objects and the unchanged elements onto a background grid.\n\"\"\"\n\ndef find_objects(grid_np, background_color):\n    \"\"\"\n    Finds connected objects of non-background pixels using BFS.\n\n    Args:\n        grid_np (np.array): The input grid.\n        background_color (int): The color considered as background.\n\n    Returns:\n        list: A list of dictionaries, where each dictionary represents an object\n              and contains 'pixels' (list of (r, c, color)), 'has_azure',\n              'has_yellow', and 'yellow_loc' (first found).\n    \"\"\"\n    height, width = grid_np.shape\n    visited = set()\n    all_objects = []\n\n    for r in range(height):\n        for c in range(width):\n            # If this pixel is background or already visited, skip\n            if grid_np[r, c] == background_color or (r, c) in visited:\n                continue\n\n            # Start BFS for a new object\n            current_object_pixels = []\n            q = deque([(r, c)])\n            visited.add((r, c))\n            has_azure = False\n            has_yellow = False\n            yellow_pixel_loc = None # Store the first yellow pixel found\n\n            while q:\n                row, col = q.popleft()\n                color = grid_np[row, col]\n                current_object_pixels.append((row, col, color))\n\n                # Check object properties\n                if color == 8:\n                    has_azure = True\n                if color == 4:\n                    has_yellow = True\n                    if yellow_pixel_loc is None: # Store only the first one encountered\n                         yellow_pixel_loc = (row, col)\n\n                # Explore neighbors (8-connectivity: includes diagonals)\n                for dr in [-1, 0, 1]:\n                    for dc in [-1, 0, 1]:\n                        if dr == 0 and dc == 0:\n                            continue\n                        nr, nc = row + dr, col + dc\n\n                        # Check bounds and if neighbor is part of the object\n                        if 0 <= nr < height and 0 <= nc < width and \\\n                           grid_np[nr, nc] != background_color and \\\n                           (nr, nc) not in visited:\n                            visited.add((nr, nc))\n                            q.append((nr, nc))\n\n            # Store the found object and its properties\n            all_objects.append({\n                \"pixels\": current_object_pixels,\n                \"has_azure\": has_azure,\n                \"has_yellow\": has_yellow,\n                \"yellow_loc\": yellow_pixel_loc\n            })\n\n    return all_objects\n\n\ndef transform(input_grid):\n    \"\"\"\n    Transforms the input grid based on shifting rules applied to specific objects.\n    Objects containing both azure (8) and yellow (4) pixels are shifted horizontally.\n    The shift direction depends on the column of the yellow pixel relative to the grid's midpoint.\n    Shift is +3 columns (right) if yellow_col < midpoint, -3 columns (left) if yellow_col >= midpoint.\n    Other objects and the background remain unchanged.\n    \"\"\"\n    input_np = np.array(input_grid, dtype=int)\n    height, width = input_np.shape\n    \n    # Assuming the most frequent color is background if not specified.\n    # For train_1, background is blue (1). Let's hardcode for now based on analysis.\n    background_color = 1 \n    \n    # Determine midpoint and shift amount\n    midpoint_col = width // 2\n    shift_amount = 3\n\n    # Initialize output grid with the background color\n    output_np = np.full_like(input_np, background_color)\n\n    # Find all connected objects of non-background colors\n    objects = find_objects(input_np, background_color)\n\n    # Process each object\n    for obj_data in objects:\n        obj_pixels = obj_data[\"pixels\"]\n        is_target_object = obj_data[\"has_azure\"] and obj_data[\"has_yellow\"]\n\n        if is_target_object:\n            # This is a target object, determine shift based on yellow pixel location\n            _ , anchor_col = obj_data[\"yellow_loc\"] # Get column of the yellow pixel\n            \n            if anchor_col < midpoint_col:\n                # Shift right\n                shift = shift_amount\n            else:\n                # Shift left\n                shift = -shift_amount\n\n            # Apply shift and draw the object in the new location\n            for r, c, color in obj_pixels:\n                new_c = c + shift\n                # Draw the pixel if the new column is within grid bounds\n                if 0 <= new_c < width:\n                    output_np[r, new_c] = color\n        else:\n            # This is not a target object, draw it in its original position\n            for r, c, color in obj_pixels:\n                 # Basic bounds check (shouldn't be needed for original positions)\n                 if 0 <= r < height and 0 <= c < width:\n                    output_np[r, c] = color\n\n    # Convert the result back to a list of lists\n    return output_np.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 4664,
    "candidates_token_count": 1416,
    "total_token_count": 6080,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 29.79278
}