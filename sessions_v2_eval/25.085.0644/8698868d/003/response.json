{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import Counter, defaultdict\nimport itertools\n\n\"\"\"\nNatural Language Program:\n1.  **Analyze Input:** Scan the input grid to identify the distinct colors present.\n2.  **Identify Placeholder Color:** Determine the 'placeholder' color (P). This is the color used for internal frame patterns and often surrounds standalone 'content' shapes. It's frequently the most common color after potential background/border colors, or acts as a separator. Heuristics based on frequency and non-edge location are used.\n3.  **Find Objects:** Locate all contiguous regions of non-placeholder colors.\n4.  **Categorize Objects:**\n    a.  **Frame Objects:** Identify objects that form a rectangular border around an internal area filled entirely with the placeholder color (P). Note their border color (C_frame), bounding box, and the relative coordinates of the internal P pattern.\n    b.  **Content Objects:** Identify solid, contiguous objects of a single color (C_content) different from P, typically located within larger areas dominated by P. Note their color (C_content), bounding box, and center coordinates.\n5.  **Pair Frame and Content Objects:** Establish a one-to-one mapping between Frame objects and Content objects based primarily on proximity of their centers. Each content object is matched to the closest available frame object.\n6.  **Transform Frame Objects:** For each matched pair (Frame, Content):\n    a.  Create a new grid representing the transformed frame, using the Frame's original dimensions.\n    b.  Fill the border pixels with the Frame's border color (C_frame).\n    c.  Fill the interior pixels corresponding to the Frame's original internal P pattern with the Content object's color (C_content).\n7.  **Assemble Output:** Arrange the transformed Frame objects in a new grid, maintaining the same relative spatial arrangement they had in the input grid. The output grid's size is determined by the bounding box encompassing all transformed frames, initialized with white (0) and overwritten by the frames.\n\"\"\"\n\n# ============================================\n# Helper Functions: Finding Objects & Properties\n# ============================================\n\ndef find_contiguous_regions(grid, colors_to_find=None, ignore_colors=None):\n    \"\"\"Finds all contiguous regions for specified colors, ignoring others.\"\"\"\n    height, width = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    regions = defaultdict(list)\n\n    for r in range(height):\n        for c in range(width):\n            color = grid[r, c]\n            if visited[r, c]:\n                continue\n\n            valid_color = True\n            if colors_to_find is not None and color not in colors_to_find:\n                valid_color = False\n            if ignore_colors is not None and color in ignore_colors:\n                valid_color = False\n\n            if not valid_color:\n                visited[r,c] = True # Mark as visited even if ignored/not sought\n                continue\n\n            # Found a valid starting point for a region\n            region_coords = []\n            q = [(r, c)]\n            visited[r, c] = True\n            region_color = color\n\n            while q:\n                row, col = q.pop(0)\n                region_coords.append((row, col))\n\n                # Check neighbors (4-connectivity)\n                for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                    nr, nc = row + dr, col + dc\n                    if 0 <= nr < height and 0 <= nc < width and \\\n                       not visited[nr, nc] and grid[nr, nc] == region_color:\n                        visited[nr, nc] = True\n                        q.append((nr, nc))\n            \n            if region_coords: # Should always be true here\n                regions[region_color].append(set(region_coords))\n\n    return regions\n\ndef get_bounding_box(coords):\n    \"\"\"Calculates the bounding box (min_r, min_c, max_r, max_c) of a set of coordinates.\"\"\"\n    if not coords:\n        return None\n    rows = [r for r, c in coords]\n    cols = [c for r, c in coords]\n    return min(rows), min(cols), max(rows), max(cols)\n\ndef get_relative_coords(coords, r_offset, c_offset):\n    \"\"\"Converts absolute coordinates to relative coordinates based on an offset (e.g., top-left corner).\"\"\"\n    return set((r - r_offset, c - c_offset) for r, c in coords)\n\n# ============================================\n# Helper Functions: Analysis & Classification\n# ============================================\n\ndef determine_placeholder_color(grid, potential_frame_colors, potential_content_colors):\n    \"\"\"Heuristically determines the placeholder color.\"\"\"\n    height, width = grid.shape\n    counts = Counter(grid.flatten())\n    \n    # Exclude colors known *potentially* to be part of frames or content\n    exclude_colors = set(potential_frame_colors) | set(potential_content_colors)\n    \n    sorted_counts = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n\n    # Heuristic 1: Most frequent color that is not a potential frame/content color\n    # and forms a reasonably large connected region (suggesting background/filler)\n    for color, count in sorted_counts:\n        if color not in exclude_colors:\n             regions = find_contiguous_regions(grid, colors_to_find=[color])\n             if regions[color]:\n                 largest_region_size = max(len(r) for r in regions[color])\n                 # Check if it forms a significant background/separator region\n                 # Thresholds might need tuning based on task examples\n                 if largest_region_size > max(5, (height*width) * 0.05): \n                     return color \n\n    # Heuristic 2: Most frequent color not touching the grid edge (assuming placeholder is internal)\n    edge_colors = set(grid[0,:]) | set(grid[-1,:]) | set(grid[:,0]) | set(grid[:,-1])\n    for color, count in sorted_counts:\n        if color not in exclude_colors and color not in edge_colors:\n            return color \n\n    # Fallback 1: Most frequent color that is not a potential frame/content color (even if small regions/touching edge)\n    for color, count in sorted_counts:\n         if color not in exclude_colors:\n             return color\n\n    # Final Fallback: Most frequent color overall (this is risky but better than failing)\n    if sorted_counts:\n        return sorted_counts[0][0]\n        \n    return 0 # Absolute fallback: white\n\ndef analyze_objects(grid):\n    \"\"\"Identifies and categorizes frame and content objects, determining the placeholder color.\"\"\"\n    height, width = grid.shape\n    \n    # Initial pass: find all non-zero regions and tentatively classify\n    all_regions = find_contiguous_regions(grid, ignore_colors={0}) # Initially ignore white\n    \n    potential_frames = []\n    potential_contents = []\n    potential_frame_colors = set()\n    potential_content_colors = set()\n    all_objects_found = []\n    obj_id_counter = 0\n\n    for color, regions_list in all_regions.items():\n        for region_coords in regions_list:\n             min_r, min_c, max_r, max_c = get_bounding_box(region_coords)\n             obj_height = max_r - min_r + 1\n             obj_width = max_c - min_c + 1\n             \n             is_potential_frame = False\n             internal_coords_guess = set() # Store potential internal coordinates\n             \n             # Check if it looks like a hollow rectangle (potential frame)\n             if obj_height > 2 and obj_width > 2:\n                 is_hollow = False\n                 is_potentially_solid = False # Check if it might just be a solid block\n                 internal_non_border_pixels = 0\n                 \n                 for r in range(min_r + 1, max_r):\n                     for c in range(min_c + 1, max_c):\n                         if (r, c) not in region_coords:\n                             internal_coords_guess.add((r,c))\n                             is_hollow = True\n                         else:\n                             internal_non_border_pixels += 1\n                 \n                 # Check if the border itself is present and contiguous\n                 border_pixels_present = all((r, c) in region_coords for r,c in region_coords if r == min_r or r == max_r or c == min_c or c == max_c)\n\n                 # A potential frame is hollow and has its border pixels\n                 if is_hollow and border_pixels_present:\n                      is_potential_frame = True\n                 # If it's not hollow but has internal pixels of the same color, it's potentially content\n                 elif not is_hollow and internal_non_border_pixels > 0:\n                     is_potentially_solid = True\n                     \n             is_solid_content = not is_potential_frame # Tentative: if not a potential frame, assume content\n\n             obj_data = {\n                 \"id\": obj_id_counter,\n                 \"color\": color,\n                 \"coords\": region_coords,\n                 \"bounds\": (min_r, min_c, max_r, max_c),\n                 \"is_potential_frame\": is_potential_frame,\n                 \"internal_coords_guess\": internal_coords_guess if is_potential_frame else None,\n             }\n             all_objects_found.append(obj_data)\n             obj_id_counter += 1\n             \n             if is_potential_frame:\n                 potential_frame_colors.add(color)\n             elif is_solid_content: # Only add if it's considered content\n                 potential_content_colors.add(color)\n\n    # Determine placeholder color using potential frame/content colors\n    placeholder_color = determine_placeholder_color(grid, potential_frame_colors, potential_content_colors)\n    \n    # Final pass: Categorize using the determined placeholder color\n    frames = []\n    contents = []\n    for obj in all_objects_found:\n        is_frame_final = False\n        internal_pattern_relative = None\n        \n        if obj[\"is_potential_frame\"]:\n            # Verify internal pattern consists ONLY of the placeholder color\n            min_r, min_c, max_r, max_c = obj[\"bounds\"]\n            all_internal_are_placeholder = True\n            verified_internal_coords = set()\n            \n            # Check if there's actually an interior space\n            has_interior = (max_r - min_r > 1) and (max_c - min_c > 1)\n            \n            if has_interior:\n                for r in range(min_r + 1, max_r):\n                    for c in range(min_c + 1, max_c):\n                        # Only check pixels *not* part of the object itself\n                        if (r,c) not in obj[\"coords\"]: \n                             if grid[r,c] == placeholder_color:\n                                 verified_internal_coords.add((r,c))\n                             else:\n                                 # Found a non-placeholder color inside the potential frame boundary\n                                 all_internal_are_placeholder = False\n                                 break\n                    if not all_internal_are_placeholder: break\n\n                # A frame must have *some* internal placeholder pixels and *only* placeholder pixels\n                if all_internal_are_placeholder and verified_internal_coords: \n                    is_frame_final = True\n                    internal_pattern_relative = get_relative_coords(verified_internal_coords, min_r, min_c)\n            # If it doesn't have an interior space (e.g., 2xN or Nx2 rect), it can't be a frame by this definition\n            # else: pass # is_frame_final remains False\n\n        # Decide category\n        if is_frame_final:\n            frames.append({\n                \"color\": obj[\"color\"],\n                \"bounds\": obj[\"bounds\"],\n                \"internal_pattern\": internal_pattern_relative,\n                \"height\": obj[\"bounds\"][2] - obj[\"bounds\"][0] + 1,\n                \"width\": obj[\"bounds\"][3] - obj[\"bounds\"][1] + 1,\n                 # Use center for pairing later if needed\n                \"center\": ((obj[\"bounds\"][0] + obj[\"bounds\"][2]) / 2, (obj[\"bounds\"][1] + obj[\"bounds\"][3]) / 2) \n            })\n        elif obj[\"color\"] != placeholder_color: # Avoid classifying placeholder regions as content\n            # Add objects that are confirmed *not* frames to contents\n            min_r, min_c, max_r, max_c = obj[\"bounds\"]\n            center_r = (min_r + max_r) / 2\n            center_c = (min_c + max_c) / 2\n            contents.append({\n                \"color\": obj[\"color\"],\n                \"bounds\": obj[\"bounds\"],\n                \"center\": (center_r, center_c) # Use center for pairing\n            })\n            \n    return frames, contents, placeholder_color\n\n\n# ============================================\n# Helper Functions: Pairing & Transformation\n# ============================================\n\ndef pair_frames_contents(frames, contents):\n    \"\"\"Pairs frames and contents based on proximity of their centers.\"\"\"\n    \n    if not frames or not contents:\n        return {}\n\n    pairing = {}\n    # Use sets for efficient removal of used items\n    available_contents = { (c['color'], tuple(c['bounds'])): c for c in contents }\n    used_content_keys = set()\n\n    # Sort frames to process them in a consistent order (e.g., top-left)\n    sorted_frames = sorted(frames, key=lambda f: (f['bounds'][0], f['bounds'][1]))\n\n    for frame in sorted_frames:\n        frame_center_r, frame_center_c = frame['center']\n        frame_key = (frame['color'], tuple(frame['bounds']))\n        \n        min_dist = float('inf')\n        best_content_key = None\n        \n        # Find the closest available content object\n        for content_key, content_data in available_contents.items():\n            if content_key in used_content_keys:\n                continue \n                \n            content_center_r, content_center_c = content_data['center']\n            dist_sq = (frame_center_r - content_center_r)**2 + (frame_center_c - content_center_c)**2\n            \n            if dist_sq < min_dist:\n                min_dist = dist_sq\n                best_content_key = content_key\n        \n        # If a closest content was found, pair them and mark content as used\n        if best_content_key:\n             pairing[frame_key] = available_contents[best_content_key]\n             used_content_keys.add(best_content_key)\n\n    return pairing\n\ndef transform_frame(frame_data, content_color):\n    \"\"\"Creates the transformed frame grid.\"\"\"\n    height = frame_data['height']\n    width = frame_data['width']\n    border_color = frame_data['color']\n    internal_pattern = frame_data['internal_pattern'] # Relative coordinates\n    \n    # Initialize with border color\n    transformed = np.full((height, width), border_color, dtype=int)\n    \n    # Fill internal pattern with content color\n    if internal_pattern:\n        for r_rel, c_rel in internal_pattern:\n             # Ensure relative coords are within bounds (should be by definition if calculated correctly)\n             if 0 <= r_rel < height and 0 <= c_rel < width:\n                 transformed[r_rel, c_rel] = content_color\n                 \n    return transformed\n\n# ============================================\n# Helper Function: Output Assembly\n# ============================================\n\ndef assemble_output(transformed_frames_map, original_frames):\n    \"\"\"Assembles the final output grid, placing transformed frames at their original relative positions.\"\"\"\n    if not transformed_frames_map:\n        # Return a minimal grid if no frames were transformed\n        return np.array([[0]], dtype=int) \n\n    # Determine the bounding box encompassing all *original* frame positions\n    all_min_r, all_min_c = float('inf'), float('inf')\n    all_max_r_end, all_max_c_end = float('-inf'), float('-inf') # Track end+1 for size calculation\n    \n    frame_rel_positions = {} # Store top-left corner relative to overall min_r, min_c\n    \n    if not original_frames: # Should not happen if transformed_frames_map is populated, but safety check\n         return np.array([[0]], dtype=int)\n\n    for frame in original_frames:\n        frame_key = (frame['color'], tuple(frame['bounds']))\n        # Only consider frames that were actually transformed for layout calculation\n        if frame_key in transformed_frames_map:\n            min_r, min_c, max_r, max_c = frame['bounds']\n            h = max_r - min_r + 1\n            w = max_c - min_c + 1\n            \n            all_min_r = min(all_min_r, min_r)\n            all_min_c = min(all_min_c, min_c)\n            # Calculate where the bottom-right corner *ends*\n            all_max_r_end = max(all_max_r_end, min_r + h) \n            all_max_c_end = max(all_max_c_end, min_c + w)\n\n    # Calculate output dimensions based on the overall span\n    # If no frames were found/transformed, handle default case\n    if all_min_r == float('inf'):\n        return np.array([[0]], dtype=int) \n        \n    output_height = all_max_r_end - all_min_r\n    output_width = all_max_c_end - all_min_c\n    \n    # Store relative positions for placement\n    for frame in original_frames:\n         frame_key = (frame['color'], tuple(frame['bounds']))\n         if frame_key in transformed_frames_map:\n             rel_r = frame['bounds'][0] - all_min_r\n             rel_c = frame['bounds'][1] - all_min_c\n             frame_rel_positions[frame_key] = (rel_r, rel_c)\n\n\n    # Create output grid, initialized with white (0)\n    output_grid = np.full((output_height, output_width), 0, dtype=int) \n\n    # Place transformed frames onto the output grid\n    # Sort by original position to handle potential overlaps consistently (top-left first)\n    sorted_original_frames = sorted(original_frames, key=lambda f: (f['bounds'][0], f['bounds'][1]))\n\n    for frame in sorted_original_frames:\n        frame_key = (frame['color'], tuple(frame['bounds']))\n        if frame_key in transformed_frames_map:\n            transformed_grid = transformed_frames_map[frame_key]\n            h, w = transformed_grid.shape\n            # Ensure we have calculated relative position for this frame\n            if frame_key in frame_rel_positions:\n                rel_r, rel_c = frame_rel_positions[frame_key]\n                \n                # Ensure placement is within calculated bounds\n                if rel_r + h <= output_height and rel_c + w <= output_width:\n                     output_grid[rel_r:rel_r+h, rel_c:rel_c+w] = transformed_grid\n                else:\n                    # This case indicates an issue with layout calculation or frame dimensions\n                    print(f\"Warning: Frame {frame_key} placement exceeds calculated output bounds.\")\n                    # Optionally, clip or skip placement\n                    end_r = min(rel_r + h, output_height)\n                    end_c = min(rel_c + w, output_width)\n                    output_grid[rel_r:end_r, rel_c:end_c] = transformed_grid[0:end_r-rel_r, 0:end_c-rel_c]\n\n\n    return output_grid\n\n\n# ============================================\n# Main Transformation Function\n# ============================================\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the frame-content transformation rule to the input grid.\n    \"\"\"\n    # Convert input to numpy array for processing\n    input_grid_np = np.array(input_grid, dtype=int)\n    \n    # Step 1 & 2: Analyze grid to find frames, content objects, and placeholder color\n    # analyze_objects handles finding regions, classifying, and determining placeholder\n    frames, contents, placeholder_color = analyze_objects(input_grid_np)\n\n    # Handle cases where analysis fails or finds no relevant objects\n    if not frames or not contents:\n         print(f\"Warning: No frames ({len(frames)}) or contents ({len(contents)}) found. Placeholder: {placeholder_color}. Returning default.\")\n         # Return a minimal default grid (e.g., 1x1 white)\n         return np.array([[0]], dtype=int).tolist() \n\n    # Step 3: Pair frame objects with content objects based on proximity\n    pairing = pair_frames_contents(frames, contents)\n    \n    # Handle cases where pairing fails\n    if not pairing:\n        print(\"Warning: Could not pair frames and contents. Returning default.\")\n        return np.array([[0]], dtype=int).tolist() \n\n    # Step 4: Transform each frame based on its paired content\n    transformed_frames = {}\n    # Create a map for easy lookup of original frame data using the key from pairing\n    original_frame_map = {(f['color'], tuple(f['bounds'])): f for f in frames}\n\n    for frame_key, content_data in pairing.items():\n        # Ensure the frame from the pairing exists in our original frame list\n        if frame_key in original_frame_map:\n            original_frame_data = original_frame_map[frame_key]\n            content_color = content_data['color']\n            # Create the new grid for this transformed frame\n            transformed_grid = transform_frame(original_frame_data, content_color)\n            transformed_frames[frame_key] = transformed_grid\n        else:\n             # This indicates a mismatch between pairing keys and found frames\n             print(f\"Warning: Frame key {frame_key} from pairing not found in original frames list.\")\n\n    # Step 5: Assemble the final output grid\n    # Use the map of transformed grids and the original list of frames (for position info)\n    output_grid_np = assemble_output(transformed_frames, frames)\n\n    # Convert final numpy array back to list of lists for the required output format\n    return output_grid_np.tolist()\n\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 7199,
    "candidates_token_count": 5367,
    "total_token_count": 12566,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 42.470218
}