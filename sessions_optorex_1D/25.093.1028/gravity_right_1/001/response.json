{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport math\n\n\"\"\"\nMoves all zero digits to the beginning of the sequence while preserving the relative order of the non-zero digits.\n\"\"\"\n\ndef parse_input_string(input_str: str) -> list[int]:\n    \"\"\"Converts a space-separated string of digits into a list of integers.\"\"\"\n    return [int(digit) for digit in input_str.split()]\n\ndef format_output_list(output_list: list[int]) -> str:\n    \"\"\"Converts a list of integers back into a space-separated string.\"\"\"\n    return ' '.join(map(str, output_list))\n\ndef transform(input_str: str) -> str:\n    \"\"\"\n    Transforms an input string of space-separated digits by moving all zeros\n    to the front while maintaining the relative order of non-zero digits.\n\n    Args:\n        input_str: A string containing space-separated single-digit integers.\n\n    Returns:\n        A string containing the transformed sequence of space-separated digits.\n    \"\"\"\n    # 1. Convert the input string into a list of integer digits.\n    input_sequence = parse_input_string(input_str)\n\n    # 2. Create lists for zero and non-zero digits.\n    zeros = []\n    non_zeros = []\n\n    # 3. Iterate through the input sequence and partition digits.\n    #    Keep track of non-zeros in their original relative order.\n    for digit in input_sequence:\n        if digit == 0:\n            zeros.append(digit)\n        else:\n            non_zeros.append(digit)\n\n    # 4. Combine the list of zeros and the list of non-zeros.\n    #    The zeros come first, followed by the non-zeros in their preserved order.\n    output_sequence = zeros + non_zeros\n\n    # 5. Convert the resulting output list back into a space-separated string.\n    output_str = format_output_list(output_sequence)\n\n    return output_str\n\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 1724,
    "candidates_token_count": 450,
    "total_token_count": 2174,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 7.49864,
  "retries": 1
}