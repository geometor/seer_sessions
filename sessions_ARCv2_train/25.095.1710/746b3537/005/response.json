{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport collections # Note: collections is not strictly needed for this implementation, but kept from previous iteration.\n\n\"\"\"\nProcesses a list of lists of integers. First, removes duplicates within each \ninner list (row) while preserving the order of the first occurrence. Second, \nfilters these processed lists, keeping only those whose corresponding original \ninput list was different from the immediately preceding original input list.\n\"\"\"\n\ndef _deduplicate_ordered_list(data_list: list[int]) -> list[int]:\n    \"\"\"\n    Removes duplicate integers from a list while preserving the order of the \n    first occurrence. Helper function for the main transform.\n\n    Args:\n        data_list: A list of integers (representing a row).\n\n    Returns:\n        A new list containing only the unique integers from the input list,\n        in the order they first appeared.\n    \"\"\"\n    seen = set()\n    result = []\n    # Iterate through the input list of numbers\n    for item in data_list:\n        # Check if the number has been seen before in this specific list\n        if item not in seen:\n            # If not seen, add it to the result list\n            result.append(item)\n            # Mark the number as seen for this list\n            seen.add(item)\n    return result\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Applies a two-step transformation to the input grid:\n    1. Intra-list deduplication: Removes duplicate numbers within each list, \n       preserving order.\n    2. Inter-list filtering: Removes processed lists if their corresponding \n       original input list was identical to the immediately preceding \n       original input list.\n\n    Args:\n        input_grid: A list of lists, where each inner list contains integers.\n\n    Returns:\n        A list of lists, containing the transformed and filtered lists.\n    \"\"\"\n\n    # Step 1: Process each input row (inner list) to remove duplicates\n    # while preserving order. Store these processed rows.\n    processed_grid = []\n    for input_row in input_grid:\n        deduplicated_row = _deduplicate_ordered_list(input_row)\n        processed_grid.append(deduplicated_row)\n\n    # Step 2: Filter the processed rows based on consecutive identical *original* rows.\n    final_output_grid = []\n    # Keep track of the previous *original* input row to detect consecutive duplicates\n    previous_input_row = None\n\n    # Iterate through the original input grid along with its index\n    for i, current_input_row in enumerate(input_grid):\n        # Get the corresponding processed row from the results of Step 1\n        current_processed_row = processed_grid[i]\n\n        # Determine if this processed row should be kept:\n        # Keep if it's the very first row (index 0) OR\n        # if the current *original* row is different from the previous *original* row.\n        if i == 0 or current_input_row != previous_input_row:\n            # If the condition is met, add the processed row to the final output\n            final_output_grid.append(current_processed_row)\n\n        # Update the 'previous_input_row' for the next iteration's comparison\n        # Always store the current *original* row\n        previous_input_row = current_input_row\n\n    # Return the grid containing the filtered, processed rows\n    return final_output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 5403,
    "candidates_token_count": 1233,
    "total_token_count": 6636,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 11.959431,
  "retries": 1
}