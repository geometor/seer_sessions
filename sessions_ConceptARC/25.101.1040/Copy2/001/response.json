{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom math import floor\n\n\"\"\"\nTransformation Rule:\n1. Identify two distinct non-white objects in the input grid: an 'azure frame' (a hollow rectangle composed solely of color 8) and a 'pattern object' (composed of other non-white, non-azure colors).\n2. Determine the bounding box of the pattern object.\n3. Determine the bounding box of the hollow white space inside the azure frame. This assumes the frame is a single-pixel thick border.\n4. Calculate the top-left coordinates required to place the pattern object such that it appears centered within the hollow space.\n5. Create an output grid, initially identical to the input grid.\n6. Iterate through each pixel belonging to the identified pattern object in the input grid.\n7. For each pattern pixel, copy its color to the corresponding position in the output grid, offset by the calculated centering coordinates within the hollow space. The original pattern object and the frame remain in their initial positions.\n\"\"\"\n\ndef find_objects(grid_np: np.ndarray) -> list[dict]:\n    \"\"\"\n    Finds contiguous non-background (non-zero) objects in the grid.\n    Uses Breadth-First Search (BFS) to find connected components of non-zero pixels,\n    considering pixels connected horizontally, vertically, and diagonally.\n    Returns a list of dictionaries, each describing an object with:\n    - 'pixels': A set of (row, col) tuples belonging to the object.\n    - 'bbox': A dictionary {'min_r', 'max_r', 'min_c', 'max_c'} for the bounding box.\n    - 'colors': A set of unique color values present in the object.\n    \"\"\"\n    height, width = grid_np.shape\n    visited = np.zeros_like(grid_np, dtype=bool)\n    objects = []\n\n    for r in range(height):\n        for c in range(width):\n            # Start BFS if a non-zero pixel is found that hasn't been visited\n            if grid_np[r, c] != 0 and not visited[r, c]:\n                current_object_pixels = set()\n                q = [(r, c)] # Queue for BFS\n                visited[r, c] = True\n                min_r, min_c = r, c\n                max_r, max_c = r, c\n                colors_in_object = set()\n\n                while q:\n                    row, col = q.pop(0)\n\n                    # Ensure coordinates are valid (should be, due to checks before adding to queue)\n                    if not (0 <= row < height and 0 <= col < width):\n                        continue\n\n                    # Should not happen if starting point is non-zero and we only add non-zero neighbors\n                    # if grid_np[row, col] == 0:\n                    #     continue\n                        \n                    # Add pixel to current object\n                    current_object_pixels.add((row, col))\n                    colors_in_object.add(grid_np[row, col])\n                    min_r = min(min_r, row)\n                    min_c = min(min_c, col)\n                    max_r = max(max_r, row)\n                    max_c = max(max_c, col)\n\n                    # Explore 8 neighbors (Moore neighborhood)\n                    for dr in [-1, 0, 1]:\n                        for dc in [-1, 0, 1]:\n                            if dr == 0 and dc == 0:\n                                continue # Skip self\n                            \n                            nr, nc = row + dr, col + dc\n\n                            # Check neighbor bounds and if it's non-zero and not visited\n                            if 0 <= nr < height and 0 <= nc < width and \\\n                               grid_np[nr, nc] != 0 and not visited[nr, nc]:\n                                visited[nr, nc] = True\n                                q.append((nr, nc))\n\n                # Store the found object if it contains any pixels\n                if current_object_pixels: \n                    objects.append({\n                        'pixels': current_object_pixels,\n                        'bbox': {'min_r': min_r, 'max_r': max_r, 'min_c': min_c, 'max_c': max_c},\n                        'colors': colors_in_object\n                    })\n    return objects\n\ndef transform(input_grid: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Identifies a pattern object and a frame object (hollow azure rectangle)\n    in the input grid, and copies the pattern object into the center of the\n    hollow space within the frame.\n    \"\"\"\n    # Convert input to numpy array for easier processing\n    grid_np = np.array(input_grid, dtype=int)\n    height, width = grid_np.shape\n    \n    # Create a deep copy for the output grid using list comprehension\n    output_grid = [row[:] for row in input_grid]\n\n    # --- Identify Objects ---\n    # Find all distinct non-background objects using BFS\n    all_objects = find_objects(grid_np)\n\n    # Distinguish the frame object (contains only color 8) and the pattern object\n    frame_object = None\n    pattern_object = None\n\n    for obj in all_objects:\n        # The frame object must contain *only* the color azure (8)\n        if obj['colors'] == {8}:\n            frame_object = obj\n        # The pattern object is any other object that doesn't contain white (0)\n        # and isn't the frame object. This handles patterns with single or multiple colors.\n        elif 0 not in obj['colors']:\n             pattern_object = obj\n\n    # --- Validate Objects ---\n    # Proceed only if both a unique frame and a unique pattern object are found\n    if frame_object is None or pattern_object is None:\n        # This might happen if the input doesn't match the expected structure\n        # (e.g., missing frame, missing pattern, multiple patterns, etc.)\n        # Returning the original grid is a safe default.\n        # print(\"Warning: Could not uniquely identify frame and pattern objects.\")\n        return input_grid \n\n    # --- Calculate Pattern Object Properties ---\n    p_bbox = pattern_object['bbox']\n    p_min_r, p_min_c = p_bbox['min_r'], p_bbox['min_c']\n    p_max_r, p_max_c = p_bbox['max_r'], p_bbox['max_c']\n    # Dimensions based on bounding box\n    pattern_height = p_max_r - p_min_r + 1\n    pattern_width = p_max_c - p_min_c + 1\n\n    # --- Calculate Frame and Hollow Space Properties ---\n    f_bbox = frame_object['bbox']\n    f_min_r, f_min_c = f_bbox['min_r'], f_bbox['min_c']\n    f_max_r, f_max_c = f_bbox['max_r'], f_bbox['max_c']\n\n    # Determine the hollow space based on the frame's bounding box,\n    # assuming the frame border is 1 pixel thick.\n    hollow_top = f_min_r + 1\n    hollow_left = f_min_c + 1\n    hollow_bottom = f_max_r - 1\n    hollow_right = f_max_c - 1\n    hollow_height = hollow_bottom - hollow_top + 1\n    hollow_width = hollow_right - hollow_left + 1\n\n    # Basic validation for the hollow space dimensions\n    if hollow_height <= 0 or hollow_width <= 0:\n        # This could happen if the identified frame object isn't actually hollow\n        # or doesn't fit the expected rectangular frame structure.\n        # print(\"Warning: Frame object does not appear to have a valid hollow space.\")\n        return input_grid\n\n    # --- Calculate Centered Placement Position ---\n    # Calculate the offset needed to center the pattern's bounding box within the hollow space.\n    # Integer division (floor) handles centering appropriately for odd/even differences.\n    target_row_offset = floor((hollow_height - pattern_height) / 2)\n    target_col_offset = floor((hollow_width - pattern_width) / 2)\n\n    # Calculate the absolute top-left starting coordinate in the output grid for placing the pattern\n    target_start_row = hollow_top + target_row_offset\n    target_start_col = hollow_left + target_col_offset\n\n    # --- Copy Pattern Pixels to Output Grid ---\n    # Iterate through only the pixels identified as belonging to the pattern object\n    for r, c in pattern_object['pixels']:\n        # Calculate the pixel's position relative to the top-left corner of its *own* bounding box\n        relative_r = r - p_min_r\n        relative_c = c - p_min_c\n\n        # Calculate the target coordinate in the output grid by adding the relative position\n        # to the calculated starting position (which includes centering offsets).\n        target_r = target_start_row + relative_r\n        target_c = target_start_col + relative_c\n\n        # Get the color of the pattern pixel from the input grid\n        pixel_color = grid_np[r, c]\n\n        # Place the pixel in the output grid, ensuring the target coordinate is within grid bounds.\n        if 0 <= target_r < height and 0 <= target_c < width:\n            # Modify the list-based output_grid\n            output_grid[target_r][target_c] = pixel_color\n        else:\n            # This case indicates an issue, e.g., pattern too large for hollow space or calculation error.\n            # print(f\"Warning: Target coordinate ({target_r}, {target_c}) for pixel ({r},{c}) is out of bounds.\")\n            pass # Continue processing other pixels if possible\n\n    # Return the modified grid as a list of lists\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 3520,
    "candidates_token_count": 8763,
    "total_token_count": 12283,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-preview-03-25",
  "response_time": 61.780889,
  "retries": 1
}