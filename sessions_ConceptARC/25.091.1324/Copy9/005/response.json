{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\nFor each non-white color present in the input grid:\n1. Identify all distinct contiguous objects (pixels connected horizontally, vertically, or diagonally).\n2. Check if there is exactly one object of size 1 (a \"marker\") and at least one object of size > 1 (a \"potential source\").\n3. If these conditions are met for a color:\n    a. Select the potential source object with the largest number of pixels (the \"largest source\").\n    b. Determine the bounding box of the largest source object.\n    c. Extract the rectangular region defined by this bounding box directly from the *input* grid (this region includes all pixels within the box, regardless of color).\n    d. Find the coordinates of the single marker pixel.\n    e. Calculate the top-left coordinate (anchor) required to paste the extracted region onto the output grid such that the region's center aligns with the marker pixel's coordinates. Center calculation uses floor division on the region's dimensions.\n    f. Paste the extracted region onto an output grid (initially a copy of the input) at the calculated anchor position, overwriting any existing pixels within that target area. Ensure pasting stays within the grid boundaries.\n4. Repeat for all colors meeting the conditions.\n5. Return the final modified output grid.\n\"\"\"\n\nimport numpy as np\nfrom scipy.ndimage import label, find_objects\nimport math\n\n# --- Helper Functions ---\n\ndef find_all_objects_by_color(grid):\n    \"\"\"\n    Finds all contiguous objects (connected components including diagonals) \n    of non-background colors in the grid.\n\n    Args:\n        grid (np.ndarray): The input grid.\n\n    Returns:\n        dict: A dictionary where keys are colors (int > 0) and values are lists\n              of objects. Each object is represented as a set of coordinates\n              {(r1, c1), (r2, c2), ...}. Returns an empty dict if no \n              non-background objects are found.\n    \"\"\"\n    objects_by_color = {}\n    unique_colors = np.unique(grid[grid > 0])\n    if unique_colors.size == 0:\n        return {} \n\n    for color in unique_colors:\n        mask = (grid == color)\n        labeled_array, num_features = label(mask, structure=np.ones((3,3)))\n\n        if num_features > 0:\n            coords_slices = find_objects(labeled_array)\n            color_objects = []\n            \n            for i in range(num_features):\n                loc = coords_slices[i]\n                if loc is None or not isinstance(loc, tuple) or len(loc) != 2:\n                    continue \n                \n                object_slice = labeled_array[loc]\n                obj_mask_in_slice = (object_slice == (i + 1))\n                obj_coords_in_slice = np.argwhere(obj_mask_in_slice)\n\n                if obj_coords_in_slice.size == 0:\n                    continue\n\n                obj_coords_global = set(\n                    (r + loc[0].start, c + loc[1].start)\n                    for r, c in obj_coords_in_slice\n                )\n                \n                if obj_coords_global: \n                    color_objects.append(obj_coords_global)\n            \n            if color_objects: \n                 objects_by_color[color] = color_objects\n                 \n    return objects_by_color\n\ndef get_bounding_box(obj_coords):\n    \"\"\"\n    Calculates the bounding box (min_row, min_col, max_row, max_col) \n    for a set of object coordinates.\n\n    Args:\n        obj_coords (set): A set of (row, col) tuples representing the object's pixels.\n\n    Returns:\n        tuple: (min_row, min_col, max_row, max_col) or None if obj_coords is empty.\n    \"\"\"\n    if not obj_coords:\n        return None\n    rows = [r for r, c in obj_coords]\n    cols = [c for r, c in obj_coords]\n    return (min(rows), min(cols), max(rows), max(cols))\n\n# --- Main Transformation Function ---\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rule to the input grid.\n    \"\"\"\n    # 1. Initialize the output grid as a copy of the input grid.\n    output_grid = np.copy(input_grid)\n    height, width = input_grid.shape\n    \n    # 2. Find all distinct contiguous objects for each non-white color.\n    objects_by_color = find_all_objects_by_color(input_grid)\n\n    # 3. Iterate through each color found.\n    for color, objects in objects_by_color.items():\n        markers = []\n        potential_sources = []\n        \n        # 3a & 3b. Separate objects into markers (size 1) and potential sources (size > 1).\n        for obj_coords in objects:\n            if len(obj_coords) == 1:\n                markers.append(obj_coords)\n            elif len(obj_coords) > 1:\n                potential_sources.append(obj_coords)\n\n        # 3c. Check if conditions are met: exactly one marker and at least one source.\n        if len(markers) == 1 and len(potential_sources) >= 1:\n            \n            # --- Conditions met, proceed with transformation for this color ---\n            \n            # 3d.i. Select the largest source object by pixel count.\n            largest_source_obj_coords = max(potential_sources, key=len)\n\n            # 3d.ii. Determine the bounding box of the largest source object.\n            source_bbox = get_bounding_box(largest_source_obj_coords)\n            if source_bbox is None: \n                continue # Safety check, should not happen here\n            src_min_r, src_min_c, src_max_r, src_max_c = source_bbox\n\n            # 3d.iii. Extract the rectangular source patch from the *input* grid.\n            source_patch = input_grid[src_min_r : src_max_r + 1, src_min_c : src_max_c + 1]\n            patch_h, patch_w = source_patch.shape\n\n            # 3d.iv. Get the coordinate of the single marker pixel.\n            marker_coord = list(markers[0])[0] # markers[0] is a set like {(r, c)}\n            marker_r, marker_c = marker_coord\n\n            # 3d.v. Calculate the target top-left anchor coordinate for pasting.\n            # Center offset within the patch (relative to its top-left)\n            center_offset_r = math.floor((patch_h - 1) / 2)\n            center_offset_c = math.floor((patch_w - 1) / 2)\n            # Anchor coordinate on the output grid\n            anchor_r = marker_r - center_offset_r\n            anchor_c = marker_c - center_offset_c\n\n            # 3d.vi. Paste the source_patch onto the output grid.\n            for dr in range(patch_h): # dr is row offset within the patch\n                for dc in range(patch_w): # dc is col offset within the patch\n                    # Calculate target coordinates on the output grid\n                    target_r = anchor_r + dr\n                    target_c = anchor_c + dc\n\n                    # Check if target coordinates are within grid bounds\n                    if 0 <= target_r < height and 0 <= target_c < width:\n                        # Overwrite the output grid pixel with the corresponding patch pixel\n                        output_grid[target_r, target_c] = source_patch[dr, dc]\n\n    # 5. Return the final modified output grid.\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 14400,
    "candidates_token_count": 1835,
    "total_token_count": 16235,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 21.74516,
  "retries": 1
}