{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\nimport itertools\n\n\"\"\"\nTransforms an input grid by duplicating a composite structure (a 'container' object \nand the 'contained' objects within its bounding box) to a new location. The new \nlocation is determined by the position of an 'orphan' object, typically one that \nshares characteristics (like color) with a contained object. The process involves:\n1. Identifying all distinct objects (contiguous non-white pixels).\n2. Identifying the 'container' object, defined as an object whose bounding box \n   inclusively encloses the bounding box of at least one other object of a \n   different color.\n3. Identifying 'contained' objects enclosed within the container's bounding box.\n4. Identifying 'orphan' objects (neither container nor contained).\n5. Selecting a 'primary orphan' (often matching a contained object's color) to \n   dictate placement.\n6. Calculating the target location for the copy, maintaining a 2-pixel gap from \n   the primary orphan's original position.\n7. Creating an output grid by copying the input.\n8. Removing all orphan objects from the output grid.\n9. Extracting the pattern (container's bounding box region) from the original input.\n10. Pasting the pattern onto the output grid at the target location.\n\"\"\"\n\n# === Helper Functions ===\n\ndef find_objects(grid):\n    \"\"\"\n    Finds all contiguous objects of the same color in the grid using Breadth-First Search.\n\n    Args:\n        grid (np.array): The input grid.\n\n    Returns:\n        list: A list of dicts, where each dict represents an object and contains:\n              - 'id': A unique integer identifier for the object.\n              - 'coords': set of (row, col) coordinates.\n              - 'bbox': tuple (min_r, min_c, max_r, max_c).\n              - 'color': int color value.\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n    object_id_counter = 0\n\n    for r in range(rows):\n        for c in range(cols):\n            if grid[r, c] != 0 and not visited[r, c]: # Found unvisited non-background pixel\n                color = grid[r, c]\n                obj_coords = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                min_r, min_c, max_r, max_c = r, c, r, c # Initialize bounding box\n\n                # Perform BFS to find all connected pixels of the same color\n                while q:\n                    row, col = q.popleft()\n                    obj_coords.add((row, col))\n                    # Update bounding box\n                    min_r, min_c = min(min_r, row), min(min_c, col)\n                    max_r, max_c = max(max_r, row), max(max_c, col)\n\n                    # Check 4-directional neighbors\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        # Check bounds, visited status, and color match\n                        if 0 <= nr < rows and 0 <= nc < cols and \\\n                           not visited[nr, nc] and grid[nr, nc] == color:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n\n                # Store the found object if it has coordinates\n                if obj_coords:\n                    bounding_box = (min_r, min_c, max_r, max_c)\n                    objects.append({'id': object_id_counter, 'coords': obj_coords, 'bbox': bounding_box, 'color': color})\n                    object_id_counter += 1\n    return objects\n\ndef is_inclusively_enclosed(inner_box, outer_box):\n    \"\"\"\n    Checks if inner_box is inclusively inside outer_box (edges can touch).\n    Requires the boxes to be distinct objects (checked by caller via IDs).\n\n    Args:\n        inner_box (tuple): Bbox (min_r, min_c, max_r, max_c).\n        outer_box (tuple): Bbox (min_r, min_c, max_r, max_c).\n\n    Returns:\n        bool: True if inner_box is enclosed by outer_box, False otherwise.\n    \"\"\"\n    # An object cannot enclose itself - this check prevents identical boxes from qualifying\n    if inner_box == outer_box:\n        return False\n    min_r1, min_c1, max_r1, max_c1 = inner_box\n    min_r2, min_c2, max_r2, max_c2 = outer_box\n    # Check if all inner bounds are within or equal to outer bounds\n    return min_r1 >= min_r2 and min_c1 >= min_c2 and max_r1 <= max_r2 and max_c1 <= max_c2\n\n# === Main Transformation Function ===\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation logic to the input grid.\n    \"\"\"\n    input_np = np.array(input_grid, dtype=int)\n    rows, cols = input_np.shape\n\n    # 1. Identify all distinct objects\n    all_objects = find_objects(input_np)\n    if not all_objects:\n        return input_grid # Return original if no objects\n\n    # 2. & 3. Identify Container and Contained Objects\n    container = None\n    contained_objects_map = {} # Store {container_id: [list of contained_obj dicts]}\n    potential_containers = []\n\n    # Find all objects that enclose at least one other object of a different color\n    for obj_i in all_objects:\n        current_contained = []\n        for obj_j in all_objects:\n            # Skip self-comparison\n            if obj_i['id'] == obj_j['id']:\n                continue\n            # Check for enclosure AND different colors\n            if obj_i['color'] != obj_j['color'] and is_inclusively_enclosed(obj_j['bbox'], obj_i['bbox']):\n                 current_contained.append(obj_j) # obj_j is contained within obj_i\n\n        # If obj_i encloses any object of a different color, it's a potential container\n        if current_contained:\n             contained_objects_map[obj_i['id']] = current_contained\n             potential_containers.append(obj_i)\n\n    # Select the container (simple strategy: first found)\n    if potential_containers:\n        container = potential_containers[0]\n    else:\n        # If no object encloses another of a different color, cannot proceed\n        # print(\"Warning: No container found meeting criteria.\") # Optional debug\n        return input_grid\n\n    container_id = container['id']\n    container_bbox = container['bbox']\n    # Get the list of objects contained by the chosen container\n    contained_objects = contained_objects_map.get(container_id, [])\n    contained_ids = {obj['id'] for obj in contained_objects}\n    contained_colors = {obj['color'] for obj in contained_objects}\n\n    # 4. Identify Orphan Objects\n    orphan_objects = []\n    for obj in all_objects:\n        # An object is an orphan if it's not the container AND not contained by the container\n        if obj['id'] != container_id and obj['id'] not in contained_ids:\n            orphan_objects.append(obj)\n\n    if not orphan_objects:\n        # If only container + contained exist, cannot determine placement\n        # print(\"Warning: Container and contained objects found, but no orphans.\") # Optional debug\n        return input_grid # Needs an orphan to determine placement\n\n    # 5. Select Primary Orphan\n    primary_orphan = None\n    # Prioritize an orphan whose color matches any contained object's color\n    for orphan in orphan_objects:\n        if orphan['color'] in contained_colors:\n            primary_orphan = orphan\n            break # Use the first matching orphan found\n\n    # Fallback: If no color match, use the first orphan identified\n    if primary_orphan is None and orphan_objects:\n        primary_orphan = orphan_objects[0]\n\n    # If still no primary orphan (should only happen if orphan_objects was empty initially)\n    if primary_orphan is None:\n         # print(\"Error: Failed to select a primary orphan.\") # Optional debug\n         return input_grid # Should have been caught earlier\n\n    orphan_bbox = primary_orphan['bbox']\n\n    # 6. Calculate Target Location for the Copy\n    c_min_r, c_min_c, c_max_r, c_max_c = container_bbox\n    o_min_r, o_min_c, o_max_r, o_max_c = orphan_bbox\n    target_row, target_col = -1, -1 # Initialize target coordinates\n\n    # Determine relative position based on non-overlapping bounding boxes\n    is_below = o_min_r > c_max_r\n    is_right = o_min_c > c_max_c\n    is_above = o_max_r < c_min_r\n    is_left = o_max_c < c_min_c\n\n    # Calculate placement coordinates with a 2-pixel gap\n    if is_below:\n        target_row = o_min_r - 2 # Place top edge 2 pixels above orphan's top edge\n        target_col = c_min_c     # Align left edge with container's left edge\n    elif is_right:\n        target_row = c_min_r     # Align top edge with container's top edge\n        target_col = o_min_c - 2 # Place left edge 2 pixels left of orphan's left edge\n    elif is_above: # Added for potential future cases\n        target_row = o_max_r + 2 # Place top edge 2 pixels below orphan's bottom edge\n        target_col = c_min_c     # Align left edge\n    elif is_left: # Added for potential future cases\n        target_row = c_min_r     # Align top edge\n        target_col = o_max_c + 2 # Place left edge 2 pixels right of orphan's right edge\n    else:\n        # Handle ambiguous/overlapping cases if necessary (not seen in examples)\n        # print(f\"Warning: Ambiguous relative position between container {container_bbox} and primary orphan {orphan_bbox}.\") # Optional debug\n        return input_grid # Cannot determine placement based on rules\n\n    # 7. Create Output Grid (start with a copy of input)\n    output_np = np.copy(input_np)\n\n    # 8. Remove ALL Orphan Objects from the output grid\n    for orphan in orphan_objects:\n        for r, c in orphan['coords']:\n            # Ensure coordinates are within bounds before modifying\n            if 0 <= r < rows and 0 <= c < cols:\n                output_np[r, c] = 0 # Set orphan pixels to background color (0)\n\n    # 9. Extract the Pattern (Container BBox region) from the ORIGINAL Input Grid\n    pattern = input_np[c_min_r : c_max_r + 1, c_min_c : c_max_c + 1]\n    pattern_h, pattern_w = pattern.shape\n\n    # 10. Place the Extracted Pattern onto the Output Grid (with Clipping)\n    # Check if target coordinates and pattern dimensions are valid\n    if target_row != -1 and target_col != -1 and pattern_h > 0 and pattern_w > 0:\n        # Define the target slice range in the output grid\n        end_row = target_row + pattern_h\n        end_col = target_col + pattern_w\n\n        # Calculate actual paste boundaries, respecting grid limits (clipping)\n        paste_start_row = max(0, target_row)\n        paste_start_col = max(0, target_col)\n        paste_end_row = min(rows, end_row)\n        paste_end_col = min(cols, end_col)\n\n        # Calculate the corresponding slice from the pattern to be copied\n        pattern_start_row = max(0, -target_row) # Offset if target_row is negative\n        pattern_start_col = max(0, -target_col) # Offset if target_col is negative\n        pattern_end_row = pattern_start_row + (paste_end_row - paste_start_row)\n        pattern_end_col = pattern_start_col + (paste_end_col - paste_start_col)\n\n        # Proceed with pasting only if the calculated slices have positive dimensions\n        if paste_start_row < paste_end_row and paste_start_col < paste_end_col:\n            output_np[paste_start_row:paste_end_row, paste_start_col:paste_end_col] = \\\n                pattern[pattern_start_row:pattern_end_row, pattern_start_col:pattern_end_col]\n        # else: # Optional debug for clipping issues\n            # print(f\"Warning: Calculated placement ({target_row},{target_col}) resulted in no valid area to paste after clipping.\")\n\n    # else: # Optional debug for invalid target/pattern issues\n        # print(\"Warning: Invalid target coordinates or pattern dimensions prevented pasting.\")\n\n    # Convert the final NumPy array back to a list of lists for the required output format\n    return output_np.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 20765,
    "candidates_token_count": 3167,
    "total_token_count": 23932,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 33.272474,
  "retries": 1
}