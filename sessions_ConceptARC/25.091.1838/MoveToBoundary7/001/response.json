{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nIdentifies two non-background objects in the input grid. Determines the smaller object (by pixel count, then bounding box area) as 'mobile' and the larger as 'stationary'. Calculates the horizontal and vertical separation between their bounding boxes. The mobile object is then translated along the axis of greater separation towards the stationary object, moving a distance equal to the separation, so they become adjacent (1 pixel apart) along that axis in the output grid. The stationary object remains in place.\n\"\"\"\n\ndef _find_objects_details(grid, background_color):\n    \"\"\"\n    Finds connected components of non-background colors using BFS.\n\n    Args:\n        grid (np.array): The input grid.\n        background_color (int): The color considered background (usually 0).\n\n    Returns:\n        list: A list of dictionaries, each representing an object with\n              'color' (int) and 'pixels' (set of (r, c) tuples).\n              Returns an empty list if no non-background pixels are found.\n    \"\"\"\n    height, width = grid.shape\n    visited = np.zeros((height, width), dtype=bool)\n    objects = []\n\n    for r in range(height):\n        for c in range(width):\n            # Check if the pixel is not background and not yet visited\n            if grid[r, c] != background_color and not visited[r, c]:\n                color = grid[r, c]\n                obj_pixels = set()\n                q = deque([(r, c)]) # Initialize queue with the starting pixel\n                visited[r, c] = True # Mark starting pixel as visited\n                \n                # Start Breadth-First Search (BFS)\n                while q:\n                    row, col = q.popleft() # Get the next pixel from the queue\n                    obj_pixels.add((row, col)) # Add it to the current object's pixels\n                    \n                    # Check 4-directional neighbors (up, down, left, right)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        \n                        # Check if the neighbor is within grid bounds\n                        if 0 <= nr < height and 0 <= nc < width:\n                            # Check if the neighbor has the same color and hasn't been visited\n                            if not visited[nr, nc] and grid[nr, nc] == color:\n                                visited[nr, nc] = True # Mark neighbor as visited\n                                q.append((nr, nc)) # Add neighbor to the queue\n                                \n                # Add the found object (if it has pixels) to the list of objects\n                if obj_pixels:\n                     objects.append({'color': color, 'pixels': obj_pixels})\n    return objects\n\ndef get_bounding_box(pixels):\n    \"\"\"\n    Calculates the bounding box of a set of pixels.\n\n    Args:\n        pixels (set): A set of (row, col) pixel coordinates.\n\n    Returns:\n        tuple: (min_row, min_col, max_row, max_col).\n               Returns (-1, -1, -1, -1) if the set is empty.\n    \"\"\"\n    if not pixels:\n        # Handle the case of an empty set of pixels\n        return (-1, -1, -1, -1) \n    \n    # Extract all row and column coordinates\n    rows = [r for r, c in pixels]\n    cols = [c for r, c in pixels]\n    \n    # Find the minimum and maximum row and column values\n    min_r = min(rows)\n    min_c = min(cols)\n    max_r = max(rows)\n    max_c = max(cols)\n    \n    return (min_r, min_c, max_r, max_c)\n\ndef transform(input_grid):\n    \"\"\"\n    Transforms the input grid by identifying two objects, determining which is\n    smaller (mobile) and larger (stationary), and moving the mobile object\n    adjacent to the stationary object along the axis of greatest separation.\n\n    Args:\n        input_grid (list of lists): The input grid representation with integer color values.\n\n    Returns:\n        list of lists: The transformed grid representation.\n    \"\"\"\n    # Convert input list of lists to a NumPy array for easier manipulation\n    grid = np.array(input_grid, dtype=int)\n    height, width = grid.shape\n    background_color = 0 # Define the background color (white)\n\n    # 1. Identify all distinct, contiguous groups of non-background pixels\n    objects = _find_objects_details(grid, background_color)\n\n    # 2. Check if exactly two objects were found, as expected by the task structure.\n    if len(objects) != 2:\n        # If not exactly two objects, return the original grid unchanged.\n        # This handles edge cases or inputs not matching the pattern.\n        return input_grid\n\n    # 3. Determine which object is 'mobile' and which is 'stationary'.\n    obj1 = objects[0]\n    obj2 = objects[1]\n    obj1_pixels = obj1['pixels']\n    obj2_pixels = obj2['pixels']\n\n    mobile_obj = None\n    stationary_obj = None\n\n    # Compare by pixel count first (smaller object is mobile)\n    if len(obj1_pixels) < len(obj2_pixels):\n        mobile_obj = obj1\n        stationary_obj = obj2\n    elif len(obj2_pixels) < len(obj1_pixels):\n        mobile_obj = obj2\n        stationary_obj = obj1\n    else:\n        # If pixel counts are equal, use bounding box area as a tie-breaker\n        bb1 = get_bounding_box(obj1_pixels)\n        bb2 = get_bounding_box(obj2_pixels)\n        # Calculate area = height * width of bounding box\n        # Add 1 because bounds are inclusive (e.g., max_r=5, min_r=3 -> height=3)\n        area1 = (bb1[2] - bb1[0] + 1) * (bb1[3] - bb1[1] + 1) if bb1[0] != -1 else 0\n        area2 = (bb2[2] - bb2[0] + 1) * (bb2[3] - bb2[1] + 1) if bb2[0] != -1 else 0\n\n        # Smaller area is mobile; if areas are equal, default to obj1 being mobile\n        if area1 <= area2: \n             mobile_obj = obj1\n             stationary_obj = obj2\n        else:\n             mobile_obj = obj2\n             stationary_obj = obj1\n\n    mobile_pixels = mobile_obj['pixels']\n    mobile_color = mobile_obj['color']\n    stationary_pixels = stationary_obj['pixels'] # Needed for stationary bounding box\n\n    # 4. Get bounding boxes for both objects\n    bb_m = get_bounding_box(mobile_pixels)\n    bb_s = get_bounding_box(stationary_pixels)\n    min_r_m, min_c_m, max_r_m, max_c_m = bb_m\n    min_r_s, min_c_s, max_r_s, max_c_s = bb_s\n\n    # 5. Calculate horizontal and vertical separations (gap between boxes)\n    # Initialize separations to a negative value (indicating overlap or adjacency)\n    sep_h = -1 \n    if min_c_s > max_c_m: # Stationary is strictly right of mobile\n        sep_h = min_c_s - max_c_m - 1 # Gap = start of stationary - end of mobile - 1\n    elif min_c_m > max_c_s: # Stationary is strictly left of mobile\n        sep_h = min_c_m - max_c_s - 1 # Gap = start of mobile - end of stationary - 1\n\n    sep_v = -1 \n    if min_r_s > max_r_m: # Stationary is strictly below mobile\n        sep_v = min_r_s - max_r_m - 1 # Gap = start of stationary - end of mobile - 1\n    elif min_r_m > max_r_s: # Stationary is strictly above mobile\n        sep_v = min_r_m - max_r_s - 1 # Gap = start of mobile - end of stationary - 1\n\n    # 6. Determine movement axis: the one with the greater positive separation\n    dr, dc = 0, 0 # Initialize translation vector (delta_row, delta_col)\n    \n    # Consider only positive separations (actual gaps) for comparison\n    comp_sep_h = max(0, sep_h)\n    comp_sep_v = max(0, sep_v)\n\n    # 7. Determine direction and distance based on the larger separation\n    if comp_sep_h > comp_sep_v : \n        # Move horizontally\n        dist = sep_h # Distance to move is the size of the horizontal gap\n        dr = 0\n        if min_c_s > max_c_m: # Stationary is right -> move mobile right\n            dc = dist\n        else: # Stationary is left (min_c_m > max_c_s) -> move mobile left\n            dc = -dist\n            \n    # Check if vertical sep is greater OR if they are equal and positive\n    elif comp_sep_v >= comp_sep_h and comp_sep_v > 0 : \n        # Move vertically\n        dist = sep_v # Distance to move is the size of the vertical gap\n        dc = 0\n        if min_r_s > max_r_m: # Stationary is below -> move mobile down\n            dr = dist\n        else: # Stationary is above (min_r_m > max_r_s) -> move mobile up\n            dr = -dist\n            \n    # If both sep_h and sep_v are <= 0, objects are already adjacent or overlapping.\n    # In this case, dr and dc remain 0, and no movement occurs.\n\n    # 8. Create the output grid as a copy of the input grid\n    output_grid = grid.copy()\n\n    # 9. Erase the mobile object from its original position in the output grid\n    # Set the original pixels of the mobile object to the background color\n    for r, c in mobile_pixels:\n        output_grid["
          }
        ],
        "role": "model"
      },
      "finish_reason": 2,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 3845,
    "candidates_token_count": 2429,
    "total_token_count": 6274,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 68.882359,
  "retries": 1
}