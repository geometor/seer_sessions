{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\nimport math\n\n\"\"\"\nThe transformation identifies all distinct contiguous objects (groups of connected pixels of the same non-white color) in the input grid. \nIt calculates the average row index of all non-white pixels across the entire grid. The floor of this average determines the target starting row ('target_start_row') for the vertically aligned objects in the output grid.\nAn output grid of the same dimensions as the input is created, initialized with the background color (white, 0).\nEach non-white pixel from the input grid is then mapped to the output grid. For a pixel at (r, c) belonging to an object whose topmost row is 'obj_min_r', its new row ('new_r') is calculated as 'target_start_row + (r - obj_min_r)'. The column ('new_c') remains the same as the original column 'c'. The pixel at (new_r, new_c) in the output grid is set to the color of the original pixel. This process effectively aligns all objects vertically based on the calculated average row, preserving their internal structure and relative horizontal positions.\n\"\"\"\n\ndef find_objects(grid):\n    \"\"\"\n    Finds all contiguous objects of the same non-white color in the grid.\n\n    Args:\n        grid (np.ndarray): The input grid.\n\n    Returns:\n        list: A list of tuples, where each tuple represents an object\n              and contains (color, set_of_coordinates).\n    \"\"\"\n    height, width = grid.shape\n    visited = np.zeros((height, width), dtype=bool)\n    objects = []\n    \n    for r in range(height):\n        for c in range(width):\n            color = grid[r, c]\n            # If not background and not visited yet, start BFS\n            if color != 0 and not visited[r, c]:\n                obj_coords = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                obj_coords.add((r, c))\n                \n                while q:\n                    row, col = q.popleft()\n                    \n                    # Check 4 neighbors (up, down, left, right)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        \n                        # Check bounds and if neighbor has the same color and not visited\n                        if 0 <= nr < height and 0 <= nc < width and \\\n                           not visited[nr, nc] and grid[nr, nc] == color:\n                            visited[nr, nc] = True\n                            obj_coords.add((nr, nc))\n                            q.append((nr, nc))\n                            \n                objects.append((color, obj_coords))\n                \n    return objects\n\ndef get_object_min_row(object_coords):\n    \"\"\"\n    Calculates the minimum row index for a set of coordinates.\n\n    Args:\n        object_coords (set): A set of (row, col) tuples for an object.\n\n    Returns:\n        int: The minimum row index. Returns infinity if the set is empty.\n    \"\"\"\n    if not object_coords:\n        return float('inf')\n    return min(r for r, c in object_coords)\n\ndef transform(input_grid):\n    \"\"\"\n    Transforms the input grid by finding non-white objects, calculating a target \n    vertical alignment row based on the average row of all non-white pixels, \n    and repositioning the objects to this alignment while preserving their \n    internal structure and relative horizontal positions.\n\n    Args:\n        input_grid (np.ndarray): A 2D numpy array representing the input grid.\n\n    Returns:\n        np.ndarray: A 2D numpy array representing the transformed output grid.\n    \"\"\"\n    \n    height, width = input_grid.shape\n    output_grid = np.zeros_like(input_grid) # Initialize with background color 0\n\n    # 1. Find all non-white pixels and calculate average row\n    non_white_pixels = []\n    total_row_sum = 0\n    pixel_count = 0\n    for r in range(height):\n        for c in range(width):\n            if input_grid[r, c] != 0:\n                non_white_pixels.append(((r, c), input_grid[r, c]))\n                total_row_sum += r\n                pixel_count += 1\n\n    if pixel_count == 0:\n        return output_grid # Return empty grid if no non-white pixels\n\n    # 2. Calculate the target start row\n    average_row = total_row_sum / pixel_count\n    target_start_row = math.floor(average_row)\n\n    # 3. Find distinct objects\n    objects = find_objects(input_grid)\n\n    # Create a mapping from pixel coordinate to its object's min_row\n    pixel_to_obj_min_row = {}\n    for color, coords in objects:\n        obj_min_r = get_object_min_row(coords)\n        for coord in coords:\n            pixel_to_obj_min_row[coord] = obj_min_r\n\n    # 4. & 5. Create output grid and map pixels\n    for (r, c), color in non_white_pixels:\n        # Get the minimum row for the object this pixel belongs to\n        if (r, c) in pixel_to_obj_min_row:\n            obj_min_r = pixel_to_obj_min_row[(r, c)]\n            \n            # Calculate vertical offset within the object\n            offset = r - obj_min_r\n            \n            # Calculate new position\n            new_r = target_start_row + offset\n            new_c = c\n            \n            # Place pixel in output grid if within bounds\n            if 0 <= new_r < height and 0 <= new_c < width:\n                output_grid[new_r, new_c] = color\n        # else: # Should not happen if find_objects works correctly\n        #    print(f\"Warning: Pixel {(r,c)} not found in any object.\")\n\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 1932,
    "candidates_token_count": 1431,
    "total_token_count": 3363,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 70.347224,
  "retries": 1
}