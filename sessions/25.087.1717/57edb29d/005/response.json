{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nTransformation Rule Description:\n1. Define the border color as Yellow (4) and the background color as White (0).\n2. Identify all distinct objects within the input grid. An object is a contiguous group of pixels of the same color, where the color is neither the border color nor the background color.\n3. Determine which of these objects are \"enclosed\". An object is enclosed if:\n    a. None of its pixels touch the absolute outer edges of the grid.\n    b. All pixels immediately adjacent (up, down, left, right) to the object's pixels are either part of the object itself, the border color (Yellow/4), or the background color (White/0).\n4. Collect the color, coordinates, and bounding box (specifically the top-left corner coordinates: min_row, min_col) of each enclosed object.\n5. Examine the colors of all identified enclosed objects.\n6. Apply the selection rule:\n    a. Rule A: If the color Blue (1) is *not* present among the colors of the enclosed objects, select the enclosed object whose color is Azure (8).\n    b. Rule B: If the color Blue (1) *is* present among the colors of the enclosed objects, select the object whose bounding box top-left corner (`min_row`, `min_col`) is the minimum lexicographically (i.e., smallest `min_row`, breaking ties with the smallest `min_col`).\n7. Isolate the selected object's pixels and its bounding box dimensions.\n8. Create the output grid: its dimensions match the height and width of the selected object's bounding box. Initialize this grid with the background color (White/0).\n9. Copy the pixels from the selected object onto the output grid, preserving their color and relative positions. A pixel from the input grid at coordinates `(r, c)` belonging to the selected object is placed at coordinates `(r - min_row, c - min_col)` in the output grid, where `min_row` and `min_col` are from the selected object's bounding box.\n\"\"\"\n\n# --- Constants ---\nBORDER_COLOR = 4  # Yellow\nBACKGROUND_COLOR = 0  # White\nBLUE = 1\nAZURE = 8\n\n# --- Helper Functions ---\n\ndef is_enclosed(grid, component_coords):\n    \"\"\"\n    Checks if a component (set of coordinates) is enclosed according to the rules:\n    - Not touching the grid edge.\n    - Adjacent non-component pixels are only BORDER_COLOR or BACKGROUND_COLOR.\n    \"\"\"\n    height, width = grid.shape\n    if not component_coords:\n        return False # An empty component cannot be enclosed\n\n    # Check if any pixel touches the edge\n    for r, c in component_coords:\n        if r == 0 or r == height - 1 or c == 0 or c == width - 1:\n            return False # Touches edge, not enclosed\n\n    # Check neighbors of all component pixels\n    for r, c in component_coords:\n        for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]: # 4-directional neighbors\n            nr, nc = r + dr, c + dc\n\n            # Neighbor coordinates are guaranteed to be within bounds because\n            # we already checked that component pixels are not on the edge.\n            # Check if the neighbor is outside the component\n            if (nr, nc) not in component_coords:\n                neighbor_color = grid[nr, nc]\n                # If an adjacent pixel is *not* part of the object,\n                # it *must* be either BORDER or BACKGROUND color.\n                if neighbor_color != BORDER_COLOR and neighbor_color != BACKGROUND_COLOR:\n                    return False # Found an adjacent pixel of another color\n\n    # If all checks passed for all coordinates\n    return True\n\ndef find_enclosed_objects(grid):\n    \"\"\"\n    Finds all enclosed objects in the grid.\n    Returns a list of dictionaries, each containing object info:\n    'color', 'coords', 'bbox', 'top_left'.\n    \"\"\"\n    height, width = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    enclosed_objects = []\n\n    for r in range(height):\n        for c in range(width):\n            pixel_color = grid[r, c]\n            # Start BFS only if it's a potential object color (non-border, non-background)\n            # and hasn't been visited as part of another object yet.\n            if pixel_color != BORDER_COLOR and pixel_color != BACKGROUND_COLOR and not visited[r, c]:\n                object_color = pixel_color\n                component_coords = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                min_r, min_c, max_r, max_c = r, c, r, c\n\n                # Perform BFS to find all connected pixels of the *same* color\n                while q:\n                    curr_r, curr_c = q.popleft()\n                    component_coords.add((curr_r, curr_c))\n\n                    # Update bounding box dynamically\n                    min_r = min(min_r, curr_r)\n                    min_c = min(min_c, curr_c)\n                    max_r = max(max_r, curr_r)\n                    max_c = max(max_c, curr_c)\n\n                    # Explore neighbors\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = curr_r + dr, curr_c + dc\n\n                        # Check neighbor validity: within bounds, same color, not visited\n                        if 0 <= nr < height and 0 <= nc < width and \\\n                           grid[nr, nc] == object_color and not visited[nr, nc]:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n\n                # After finding the full component, check if it's enclosed\n                if is_enclosed(grid, component_coords):\n                     enclosed_objects.append({\n                        'color': object_color,\n                        'coords': component_coords,\n                        'bbox': (min_r, min_c, max_r, max_c),\n                        'top_left': (min_r, min_c) # Store for easier sorting\n                    })\n\n    return enclosed_objects\n\n# --- Main Transformation Function ---\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rule to the input grid.\n    \"\"\"\n    # 1-4: Find all enclosed objects and their properties\n    enclosed_objects_data = find_enclosed_objects(input_grid)\n\n    # Check if any enclosed objects were found\n    if not enclosed_objects_data:\n        # Behavior for no enclosed objects isn't strictly defined by examples.\n        # Returning an empty grid or raising an error are options.\n        # Let's raise an error for clarity during testing.\n        raise ValueError(\"No objects enclosed by the border/background were found.\")\n\n    # 5: Examine the colors of all enclosed objects.\n    enclosed_colors = {obj['color'] for obj in enclosed_objects_data}\n\n    # 6: Apply the selection rule.\n    selected_object = None\n    if BLUE not in enclosed_colors:\n        # Rule A: Blue is absent, select Azure.\n        azure_found = False\n        for obj in enclosed_objects_data:\n            if obj['color'] == AZURE:\n                selected_object = obj\n                azure_found = True\n                break\n        if not azure_found:\n             # This case implies an assumption was violated (Azure should be present if Blue isn't)\n             raise ValueError(f\"Rule conflict: Blue ({BLUE}) is absent, but required Azure ({AZURE}) object not found among enclosed objects.\")\n    else:\n        # Rule B: Blue is present, select the top-leftmost object.\n        # Sort by top_left: first by row (index 0), then by column (index 1)\n        enclosed_objects_data.sort(key=lambda x: x['top_left'])\n        # Since we know Blue is present, the list cannot be empty here.\n        selected_object = enclosed_objects_data[0]\n\n    # If selected_object is still None here, something went wrong in the logic above.\n    if selected_object is None:\n         raise ValueError(\"Could not select an object based on the rules after processing.\")\n\n    # 7: Isolate selected object properties\n    sel_color = selected_object['color']\n    sel_coords = selected_object['coords']\n    min_r, min_c, max_r, max_c = selected_object['bbox']\n\n    # 8: Create the output grid based on bounding box size\n    output_h = max_r - min_r + 1\n    output_w = max_c - min_c + 1\n    output_grid = np.full((output_h, output_w), BACKGROUND_COLOR, dtype=int)\n\n    # 9: Copy selected object pixels to the output grid with relative positioning\n    for r, c in sel_coords:\n        output_r = r - min_r\n        output_c = c - min_c\n        # Double check bounds just in case, though bbox should guarantee this\n        if 0 <= output_r < output_h and 0 <= output_c < output_w:\n             output_grid[output_r, output_c] = sel_color\n        else:\n             # This indicates an issue with coordinate mapping or bounding box calculation\n             print(f\"Warning: Coordinate ({r},{c}) mapped outside output grid bounds ({output_h}x{output_w}) during pixel copy.\")\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 15666,
    "candidates_token_count": 2253,
    "total_token_count": 17919,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 22.967349,
  "retries": null
}