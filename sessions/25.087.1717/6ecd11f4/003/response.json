{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nTransformation Rule:\n1. Find the largest contiguous object composed of a single non-white color in the input grid. Let its color be `FilterColor`.\n2. Identify all other non-white pixels in the input grid (pixels not belonging to the largest object). Let this set of coordinates be `SourceCoords`.\n3. Find the smallest bounding box that encloses all pixels in `SourceCoords`. Let the top-left corner be (min_r, min_c) and the dimensions be (height, width).\n4. Determine the set of `TargetColors` to be filtered out based on the `FilterColor`:\n    - If `FilterColor` is green (3), the `TargetColors` are {blue (1), azure (8), maroon (9)}.\n    - If `FilterColor` is blue (1), the `TargetColors` are {blue (1), red (2), yellow (4), maroon (9)}.\n    - If `FilterColor` is azure (8), the `TargetColors` are {blue (1), green (3), gray (5), orange (7)}.\n    - Otherwise, `TargetColors` is an empty set.\n5. Create a new output grid with dimensions (height, width), initialized with white (0).\n6. Iterate through each coordinate `(r, c)` in `SourceCoords`:\n    - Get the color `CurrentColor` from the input grid at `(r, c)`.\n    - Check if `CurrentColor` is present in the set of `TargetColors`.\n    - If `CurrentColor` is *not* in `TargetColors`, calculate the position in the output grid: `out_r = r - min_r`, `out_c = c - min_c`. Set the output grid cell `output_grid[out_r, out_c]` to `CurrentColor`.\n7. Return the generated output grid.\n\"\"\"\n\n\ndef find_objects(grid):\n    \"\"\"\n    Finds all contiguous objects of the same color in the grid using Breadth-First Search.\n    Args:\n        grid (np.array): Input grid.\n    Returns:\n        list: A list of objects, where each object is a dictionary containing\n              'color', 'coords' (set of (r, c) tuples), and 'size'.\n              Excludes objects with color 0 (white). Objects are found using 4-connectivity.\n    \"\"\"\n    rows, cols = grid.shape\n    visited = set()\n    objects = []\n    \n    for r in range(rows):\n        for c in range(cols):\n            # If the cell hasn't been visited and is not white\n            if (r, c) not in visited and grid[r, c] != 0:\n                color = grid[r, c]\n                obj_coords = set()\n                q = deque([(r, c)])\n                visited.add((r, c))\n                \n                # Start BFS from this cell\n                while q:\n                    row, col = q.popleft()\n                    \n                    # Check if the current cell matches the starting color\n                    # This check ensures we only grow the object with the same color\n                    if grid[row, col] == color:\n                        obj_coords.add((row, col))\n                        \n                        # Check neighbors (4-connectivity: up, down, left, right)\n                        for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                            nr, nc = row + dr, col + dc\n                            \n                            # Check if the neighbor is within bounds, not visited, and has the same color\n                            if 0 <= nr < rows and 0 <= nc < cols and \\\n                               (nr, nc) not in visited and grid[nr, nc] == color:\n                                visited.add((nr, nc))\n                                q.append((nr, nc))\n                    # Mark as visited even if color doesn't match, to prevent reprocessing starting points\n                    # that might be adjacent to different colored objects already visited.\n                    # However, the primary mechanism to avoid re-processing is the initial check.\n                    # Adding the starting point here ensures it's marked visited if it was a single pixel object.\n                    visited.add((r,c))\n\n                # Add the found object if it has any coordinates\n                if obj_coords:\n                     objects.append({\n                         'color': color,\n                         'coords': obj_coords,\n                         'size': len(obj_coords)\n                     })\n                     # Ensure all coordinates of the found object are marked as visited\n                     # This is slightly redundant as BFS should have marked them, but safe.\n                     visited.update(obj_coords) \n\n    return objects\n\ndef get_bounding_box(coords):\n    \"\"\"\n    Calculates the bounding box for a set of coordinates.\n    Args:\n        coords (set): A set of (row, col) tuples.\n    Returns:\n        tuple: (min_row, min_col, max_row, max_col), or None if coords is empty.\n    \"\"\"\n    if not coords:\n        return None\n    \n    min_row = min(r for r, c in coords)\n    min_col = min(c for r, c in coords)\n    max_row = max(r for r, c in coords)\n    max_col = max(c for r, c in coords)\n    \n    return min_row, min_col, max_row, max_col\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the color filtering transformation based on the largest object's color.\n    Filters a specific set of colors from the remaining non-white pixels,\n    cropping the result to the bounding box of those remaining pixels.\n    \"\"\"\n    input_array = np.array(input_grid, dtype=int)\n    rows, cols = input_array.shape\n\n    # 1. Find all non-white objects\n    objects = find_objects(input_array)\n    \n    # Handle edge case: no non-white objects found\n    if not objects:\n        # Return an empty grid represented as a list of lists\n        return [[]] \n        \n    # Find the largest object based on the number of pixels\n    largest_object = max(objects, key=lambda obj: obj['size'])\n    filter_color = largest_object['color']\n    large_object_coords = largest_object['coords']\n\n    # 2. Identify coordinates of the source pixels (all non-white pixels NOT in the largest object)\n    all_non_white_coords = set()\n    for r in range(rows):\n        for c in range(cols):\n            if input_array[r, c] != 0:\n                all_non_white_coords.add((r, c))\n                \n    source_coords = all_non_white_coords - large_object_coords\n\n    # Handle edge case: only the largest object exists, no other non-white pixels\n    if not source_coords:\n         # Return an empty grid represented as a list of lists\n        return [[]] \n\n    # 3. Get the bounding box of the source coordinates\n    min_r, min_c, max_r, max_c = get_bounding_box(source_coords)\n    \n    # Calculate output dimensions\n    out_height = max_r - min_r + 1\n    out_width = max_c - min_c + 1\n\n    # 4. Determine TargetColors based on FilterColor\n    target_color_map = {\n        3: {1, 8, 9},      # Green -> Filter Blue, Azure, Maroon\n        1: {1, 2, 4, 9},  # Blue -> Filter Blue, Red, Yellow, Maroon\n        8: {1, 3, 5, 7}   # Azure -> Filter Blue, Green, Gray, Orange\n    }\n    # Get the set of colors to filter, or an empty set if the filter_color is not a key\n    target_colors = target_color_map.get(filter_color, set()) \n\n    # 5. Create the output grid, initialized with white (0)\n    output_grid = np.zeros((out_height, out_width), dtype=int)\n    \n    # 6. Populate the output grid by copying non-filtered source pixels\n    for r, c in source_coords:\n        current_color = input_array[r, c]\n        # Check if the color should be kept (i.e., not in target_colors)\n        if current_color not in target_colors:\n            # Calculate the position in the output grid relative to the bounding box origin\n            out_r = r - min_r\n            out_c = c - min_c\n            # Place the color in the output grid\n            output_grid[out_r, out_c] = current_color\n\n    # 7. Return the result as a list of lists\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 8325,
    "candidates_token_count": 2041,
    "total_token_count": 10366,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 26.19684,
  "retries": null
}