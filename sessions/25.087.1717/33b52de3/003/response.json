{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nTransformation Rule:\n\n1.  **Identify Template Patterns:** Scan the input grid to find all occurrences of the specific template pattern: a 3x3 hollow square composed entirely of gray (5) pixels. Record the location (top-left corner) and pixels of each found template instance. If no templates are found, return the input grid unchanged.\n2.  **Determine Template Grid Dimensions:** Analyze the top-left corner coordinates of the found template instances. Identify the unique row coordinates and unique column coordinates. The number of unique rows is the template grid height (`tr`), and the number of unique columns is the template grid width (`tc`). Create a mapping from template grid indices `(r_idx, c_idx)` (where `0 <= r_idx < tr`, `0 <= c_idx < tc`) to the corresponding template pattern instance based on its original top-left corner matching the sorted unique rows/cols.\n3.  **Isolate Potential Key Pixels:** Create a temporary copy of the input grid. In this temporary grid, set the color of all pixels belonging to any identified template pattern instance to background (0).\n4.  **Identify Key Pattern Object:** Find all distinct contiguous objects in the temporary grid consisting of any non-background color (i.e., colors 1-9). Gray pixels (5) should not form part of these objects as they were either part of templates (now 0) or potentially other gray structures which are ignored here.\n5.  **Select the Key Pattern:** From the objects found in step 4, identify the *single* object whose bounding box height is exactly `tr` and whose bounding box width is exactly `tc`. If no such object or multiple such objects exist, return the input grid unchanged. Record the top-left corner `(key_r, key_c)` of this identified key pattern object's bounding box.\n6.  **Prepare Output:** Create the output grid as a copy of the original input grid.\n7.  **Apply Transformation:** Iterate through each template grid index `(r_idx, c_idx)` from `(0, 0)` up to `(tr-1, tc-1)`.\n    a.  Retrieve the specific template pattern instance corresponding to `(r_idx, c_idx)` using the mapping created in step 2. If no template exists at this grid index, skip.\n    b.  Get the replacement color from the *original input grid* at the location `(key_r + r_idx, key_c + c_idx)`.\n    c.  For every pixel `(px_r, px_c)` that belongs to the current template pattern instance (which will have the color gray (5) in the output grid initially), update its color in the *output grid* to the replacement color obtained in step 7b.\n8.  **Return Result:** Return the modified output grid.\n\"\"\"\n\ndef find_contiguous_objects(grid, ignore_colors=None):\n    \"\"\"\n    Finds all contiguous objects of non-ignored colors.\n\n    Args:\n        grid (np.ndarray): The input grid.\n        ignore_colors (set): A set of colors to ignore (treat as background).\n                             Defaults to {0} (background).\n\n    Returns:\n        list: A list of dictionaries, each representing an object with keys:\n              'pixels' (set of (r, c) tuples),\n              'bbox' (tuple: min_r, min_c, max_r, max_c),\n              'height' (int),\n              'width' (int),\n              'colors' (set of colors in the object).\n    \"\"\"\n    if ignore_colors is None:\n        ignore_colors = {0} # Ignore background by default\n\n    h, w = grid.shape\n    visited = np.zeros((h, w), dtype=bool)\n    objects = []\n\n    for r in range(h):\n        for c in range(w):\n            color = grid[r, c]\n            # Start BFS if pixel color is not ignored and not yet visited\n            if color not in ignore_colors and not visited[r, c]:\n                obj_pixels = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                min_r, min_c = r, c\n                max_r, max_c = r, c\n                colors_in_obj = {color}\n\n                while q:\n                    row, col = q.popleft()\n                    obj_pixels.add((row, col))\n                    min_r = min(min_r, row)\n                    min_c = min(min_c, col)\n                    max_r = max(max_r, row)\n                    max_c = max(max_c, col)\n\n                    # Explore neighbors (4-connectivity)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        if 0 <= nr < h and 0 <= nc < w and not visited[nr, nc]:\n                             neighbor_color = grid[nr, nc]\n                             # Add neighbor to queue if its color is not ignored\n                             if neighbor_color not in ignore_colors:\n                                visited[nr, nc] = True\n                                colors_in_obj.add(neighbor_color)\n                                q.append((nr, nc))\n\n                # Completed finding an object, store its details\n                bbox = (min_r, min_c, max_r, max_c)\n                height = max_r - min_r + 1\n                width = max_c - min_c + 1\n                objects.append({\n                    'pixels': obj_pixels,\n                    'bbox': bbox,\n                    'height': height,\n                    'width': width,\n                    'colors': colors_in_obj\n                })\n    return objects\n\n\ndef find_template_objects(grid):\n    \"\"\"\n    Finds all 3x3 hollow gray square template objects in the grid.\n\n    Args:\n        grid (np.ndarray): The input grid.\n\n    Returns:\n        list: A list of dictionaries, each representing a template object with keys:\n              'pixels' (set of (r, c) tuples),\n              'bbox' (tuple: min_r, min_c, max_r, max_c),\n              'color' (int: always 5 for gray).\n    \"\"\"\n    h, w = grid.shape\n    visited = np.zeros((h, w), dtype=bool)\n    template_objects = []\n    gray = 5\n\n    for r in range(h):\n        for c in range(w):\n            # Start BFS only if it's a gray pixel not yet assigned to an object\n            if grid[r, c] == gray and not visited[r, c]:\n                obj_pixels = set()\n                q = deque([(r, c)])\n                visited[r, c] = True # Mark start pixel as visited\n                min_r, min_c = r, c\n                max_r, max_c = r, c\n                is_potential_template = True # Assume it might be a template initially\n\n                component_q = deque([(r,c)]) # Queue for the current component's BFS\n\n                while component_q:\n                    row, col = component_q.popleft()\n\n                    # If a non-gray pixel is connected, it's not a pure gray object\n                    if grid[row,col] != gray:\n                         is_potential_template = False\n                         # We must continue BFS to mark all connected pixels as visited,\n                         # even if it's not a template, to avoid starting new searches\n                         # within this already explored connected component.\n\n                    obj_pixels.add((row, col))\n                    min_r = min(min_r, row)\n                    min_c = min(min_c, col)\n                    max_r = max(max_r, row)\n                    max_c = max(max_c, col)\n\n                    # Explore neighbors (4-connectivity)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        # Check bounds and if neighbor is gray and not visited\n                        if 0 <= nr < h and 0 <= nc < w and \\\n                           grid[nr, nc] == gray and not visited[nr, nc]:\n                            visited[nr, nc] = True # Mark neighbor as visited\n                            component_q.append((nr, nc)) # Add to BFS queue\n                        # If a non-gray neighbor is found but not visited,\n                        # we still need to visit it if we were continuing BFS\n                        # for non-template components, but for templates,\n                        # we only care about connected gray pixels. The is_potential_template\n                        # flag handles cases where non-gray pixels were initially connected.\n\n                # After BFS for the component is complete, check if it's a valid template\n                if is_potential_template:\n                    bbox_h = max_r - min_r + 1\n                    bbox_w = max_c - min_c + 1\n\n                    # Check if dimensions are 3x3\n                    if bbox_h == 3 and bbox_w == 3:\n                        # Check if it's exactly the hollow square pattern\n                        expected_pixels = set()\n                        for r_ in range(min_r, max_r + 1):\n                            expected_pixels.add((r_, min_c))\n                            expected_pixels.add((r_, max_c))\n                        for c_ in range(min_c + 1, max_c):\n                            expected_pixels.add((min_r, c_))\n                            expected_pixels.add((max_r, c_))\n\n                        # Compare the set of pixels found with the expected hollow square pixels\n                        if obj_pixels == expected_pixels:\n                            bbox = (min_r, min_c, max_r, max_c)\n                            template_objects.append({'pixels': obj_pixels, 'bbox': bbox, 'color': gray})\n\n    return template_objects\n\n\ndef transform(input_grid_list):\n    \"\"\"\n    Applies the transformation rule: replaces pixels in template patterns\n    using colors from a key pattern based on relative grid positions.\n    \"\"\"\n    input_grid = np.array(input_grid_list, dtype=int)\n    output_grid = np.copy(input_grid)\n    h, w = input_grid.shape\n\n    # 1. Identify Template Patterns\n    template_instances = find_template_objects(input_grid)\n\n    if not template_instances:\n        # No templates found, return original grid\n        return output_grid.tolist()\n\n    # 2. Determine Template Grid Dimensions\n    # Get top-left corners and sort them to find unique rows/cols\n    corners = sorted([(obj['bbox'][0], obj['bbox'][1], obj) for obj in template_instances])\n    template_rows = sorted(list(set(c[0] for c in corners)))\n    template_cols = sorted(list(set(c[1] for c in corners)))\n    tr = len(template_rows) # template grid height\n    tc = len(template_cols) # template grid width\n\n    # Create a mapping from template grid index (r_idx, c_idx) to the actual object\n    template_map = {}\n    corner_to_obj = {(c[0], c[1]): c[2] for c in corners}\n    row_map = {row_val: r_idx for r_idx, row_val in enumerate(template_rows)}\n    col_map = {col_val: c_idx for c_idx, col_val in enumerate(template_cols)}\n\n    for r_val, c_val, obj in corners:\n        r_idx = row_map[r_val]\n        c_idx = col_map[c_val]\n        template_map[(r_idx, c_idx)] = obj\n\n\n    # 3. Isolate Potential Key Pixels\n    temp_grid = np.copy(input_grid)\n    all_template_pixels = set().union(*(t['pixels'] for t in template_instances))\n    for r_px, c_px in all_template_pixels:\n        temp_grid[r_px, c_px] = 0 # Mark template pixels as background\n\n    # 4. Identify Key Pattern Object\n    # Find contiguous objects ignoring background (0) and original gray (5)\n    # We ignore gray (5) here because any relevant gray pixels were part of templates and are now 0.\n    # Other stray gray pixels should not be part of the key.\n    potential_keys = find_contiguous_objects(temp_grid, ignore_colors={0, 5})\n\n    # 5. Select the Key Pattern\n    matched_key = None\n    key_r, key_c = -1, -1\n    found_match = False\n    for key_candidate in potential_keys:\n        # Check if the candidate's bounding box dimensions match the template grid dimensions\n        if key_candidate['height'] == tr and key_candidate['width'] == tc:\n            # Check if we already found a match (should only be one)\n            if found_match:\n                # Ambiguous: multiple potential keys match dimensions. Return original.\n                # print(\"Warning: Multiple key patterns match template grid dimensions.\")\n                return input_grid_list # Return original grid on ambiguity/error\n\n            matched_key = key_candidate\n            key_r, key_c, _, _ = matched_key['bbox']\n            found_match = True\n            # Don't break yet, continue loop to check for ambiguity.\n\n    if not found_match:\n        # No key pattern found matching the template grid dimensions\n        # print(\"Warning: No key pattern found matching template grid dimensions.\")\n        return input_grid_list # Return original grid if no key found\n\n    # 6. Prepare Output (already done with output_grid = np.copy(input_grid))\n\n    # 7. Apply Transformation\n    for r_idx in range(tr):\n        for c_idx in range(tc):\n            # 7a. Retrieve the template instance for this grid position\n            if (r_idx, c_idx) in template_map:\n                template_obj = template_map[(r_idx, c_idx)]\n\n                # 7b. Get replacement color from the *original* grid using key's top-left and relative index\n                replacement_color = input_grid[key_r + r_idx, key_c + c_idx]\n\n                # 7c. Replace pixels in the output grid\n                for (px_r, px_c) in template_obj['pixels']:\n                    # Ensure we only replace original gray pixels\n                    if input_grid[px_r, px_c] == 5:\n                        output_grid[px_r, px_c] = replacement_color\n            # else: Handle case where template grid might be incomplete (optional, based on ARC task constraints)\n\n    # 8. Return Result\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 18429,
    "candidates_token_count": 3456,
    "total_token_count": 21885,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 41.640952,
  "retries": null
}