{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nThe transformation rule operates based on the adjacency and properties of objects (contiguous blocks of non-background color):\n\n1.  **Single Pixel Expansion:** If two single pixels (1x1 objects) of different colors (A and B) are adjacent (sharing an edge or corner):\n    a.  Identify the pixel with the *higher color index*. Let this be the 'expanding pixel' and the other be the 'static pixel'.\n    b.  The expanding pixel's color paints a 3x3 cross shape centered at its original position.\n    c.  Crucially, this painting only affects background (color 0) cells within the 3x3 cross area. The static pixel and any other non-background pixels remain untouched by this specific expansion.\n    d.  Both pixels are considered 'processed' and cannot participate in further rules.\n\n2.  **Adjacent Square Transformation:** If two solid square objects (X and Y) of the *same size* (NxN) but potentially different colors are adjacent along a full edge:\n    a.  A new (3N)x(3N) area is defined, conceptually centered where square Y was located (specifically, the top-left of the 3N area is N units above and N units left of Y's top-left corner).\n    b.  This (3N)x(3N) area in the output grid is filled entirely with the color of square X.\n    c.  Square Y (its original color and NxN size) is then painted back into the central NxN block of this area (its original position).\n    d.  Determine the relative position of X with respect to Y (Above, Below, Left, Right).\n    e.  The NxN block within the (3N)x(3N) area that is in the *opposite* direction from the center relative to X's position is filled with the background color (0). (e.g., If X was Above Y, the block Below Y's original position within the 3N area is cleared).\n    f.  Both squares X and Y are considered 'processed'. Note that X is effectively removed or overwritten by the new pattern.\n\n3.  **Default Copy:** The output grid starts as a copy of the input. Objects not participating in Rule 1 or Rule 2 remain unchanged.\n\nPriority: Rule 1 transformations are identified and applied first. Then, Rule 2 transformations are identified and applied to the *remaining* unprocessed objects.\n\"\"\"\n\nimport numpy as np\nfrom collections import deque\n\n# Helper function to find connected components (objects)\ndef find_objects(grid):\n    \"\"\"\n    Identifies distinct contiguous objects of non-background colors in the grid.\n\n    Args:\n        grid (np.ndarray): The input grid.\n\n    Returns:\n        list: A list of dictionaries, each representing an object with its properties:\n              'id': A unique identifier.\n              'color': The color of the object.\n              'pixels': A set of (row, col) tuples representing the object's pixels.\n              'bbox': A tuple (min_row, min_col, max_row, max_col) for the bounding box.\n              'shape': 'single_pixel', 'square', or 'other'.\n              'size': N if shape is 'square', 1 if 'single_pixel', None otherwise.\n    \"\"\"\n    objects = []\n    visited = set()\n    rows, cols = grid.shape\n    obj_id_counter = 0\n\n    for r in range(rows):\n        for c in range(cols):\n            if grid[r, c] != 0 and (r, c) not in visited:\n                obj_id_counter += 1\n                color = grid[r, c]\n                pixels = set()\n                q = deque([(r, c)])\n                visited.add((r, c))\n                min_r, min_c = r, c\n                max_r, max_c = r, c\n\n                while q:\n                    row, col = q.popleft()\n                    pixels.add((row, col))\n                    min_r = min(min_r, row)\n                    min_c = min(min_c, col)\n                    max_r = max(max_r, row)\n                    max_c = max(max_c, col)\n\n                    # Check neighbors (8 directions for object connectivity)\n                    for dr in [-1, 0, 1]:\n                        for dc in [-1, 0, 1]:\n                            if dr == 0 and dc == 0:\n                                continue\n                            nr, nc = row + dr, col + dc\n                            if 0 <= nr < rows and 0 <= nc < cols and \\\n                               grid[nr, nc] == color and (nr, nc) not in visited:\n                                visited.add((nr, nc))\n                                q.append((nr, nc))\n\n                # Determine shape and size\n                obj_shape = 'other'\n                obj_size = None\n                if len(pixels) == 1:\n                    obj_shape = 'single_pixel'\n                    obj_size = 1\n                else:\n                    height = max_r - min_r + 1\n                    width = max_c - min_c + 1\n                    if height == width and len(pixels) == height * width:\n                         # Check if all pixels within bbox are part of the object and have the object's color\n                         is_solid = True\n                         for br in range(min_r, max_r + 1):\n                             for bc in range(min_c, max_c + 1):\n                                 if grid[br, bc] != color: # Check the grid directly\n                                     is_solid = False\n                                     break\n                             if not is_solid:\n                                 break\n                         if is_solid:\n                            obj_shape = 'square'\n                            obj_size = height # N\n\n                objects.append({\n                    'id': obj_id_counter,\n                    'color': color,\n                    'pixels': pixels,\n                    'bbox': (min_r, min_c, max_r, max_c),\n                    'shape': obj_shape,\n                    'size': obj_size\n                })\n    return objects\n\n# Helper function to check adjacency (8 directions)\ndef are_adjacent(obj1, obj2):\n    \"\"\"Checks if two objects are adjacent (sharing edge or corner).\"\"\"\n    for r1, c1 in obj1['pixels']:\n        for dr in [-1, 0, 1]:\n            for dc in [-1, 0, 1]:\n                if dr == 0 and dc == 0:\n                    continue\n                nr, nc = r1 + dr, c1 + dc\n                # Check if the adjacent coordinate belongs to the other object\n                if (nr, nc) in obj2['pixels']:\n                    return True\n    return False\n\n# Helper function to check edge adjacency (4 directions) and if edges align\ndef have_full_edge_adjacency(obj1, obj2, n):\n    \"\"\"Checks if two NxN squares share a full edge.\"\"\"\n    if obj1['shape'] != 'square' or obj2['shape'] != 'square' or obj1['size'] != n or obj2['size'] != n:\n        return False\n\n    min_r1, min_c1, max_r1, max_c1 = obj1['bbox']\n    min_r2, min_c2, max_r2, max_c2 = obj2['bbox']\n\n    # Check vertical adjacency (obj1 above obj2)\n    if max_r1 + 1 == min_r2 and min_c1 == min_c2 and max_c1 == max_c2:\n        return True\n    # Check vertical adjacency (obj2 above obj1)\n    if max_r2 + 1 == min_r1 and min_c1 == min_c2 and max_c1 == max_c2:\n        return True\n    # Check horizontal adjacency (obj1 left of obj2)\n    if max_c1 + 1 == min_c2 and min_r1 == min_r2 and max_r1 == max_r2:\n        return True\n    # Check horizontal adjacency (obj2 left of obj1)\n    if max_c2 + 1 == min_c1 and min_r1 == min_r2 and max_r1 == max_r2:\n        return True\n\n    return False\n\n\n# Helper function to get relative position for edge-adjacent squares\ndef get_relative_position(ref_obj, other_obj):\n    \"\"\"Determines relative position (Above, Below, Left, Right) of other_obj w.r.t ref_obj for edge-adjacent squares.\"\"\"\n    ref_min_r, ref_min_c, ref_max_r, ref_max_c = ref_obj['bbox']\n    other_min_r, other_min_c, other_max_r, other_max_c = other_obj['bbox']\n\n    if other_max_r < ref_min_r: return \"Above\"\n    if other_min_r > ref_max_r: return \"Below\"\n    if other_max_c < ref_min_c: return \"Left\"\n    if other_min_r > ref_max_c: return \"Right\" # Typo correction: should be other_min_c > ref_max_c\n    if other_min_c > ref_max_c: return \"Right\"\n\n    return None # Should not happen for full edge-adjacent squares\n\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rules based on object adjacency and properties.\n\n    Args:\n        input_grid (np.ndarray): The input 2D numpy array.\n\n    Returns:\n        np.ndarray: The transformed 2D numpy array.\n    \"\"\"\n    output_grid = np.copy(input_grid)\n    rows, cols = output_grid.shape\n    objects = find_objects(input_grid)\n    processed_object_ids = set()\n    object_map = {obj['id']: obj for obj in objects}\n\n    # --- Rule 1: Single Pixel Expansion ---\n    pixel_pairs_to_process = []\n\n    # Find candidate pairs first\n    object_ids = list(object_map.keys())\n    for i in range(len(object_ids)):\n        id_a = object_ids[i]\n        obj_a = object_map[id_a]\n        if obj_a['shape'] != 'single_pixel' or id_a in processed_object_ids:\n            continue\n        for j in range(i + 1, len(object_ids)):\n            id_b = object_ids[j]\n            obj_b = object_map[id_b]\n            if obj_b['shape'] != 'single_pixel' or id_b in processed_object_ids:\n                continue\n\n            # Must be different colors and adjacent\n            if obj_a['color'] != obj_b['color'] and are_adjacent(obj_a, obj_b):\n                 pixel_pairs_to_process.append((id_a, id_b))\n\n\n    # Apply transformations for single pixels\n    for id_a, id_b in pixel_pairs_to_process:\n         # Check if either was processed in a previous pair interaction\n         if id_a not in processed_object_ids and id_b not in processed_object_ids:\n            obj_a = object_map[id_a]\n            obj_b = object_map[id_b]\n\n            # Determine which pixel expands (higher color index)\n            if obj_a['color'] > obj_b['color']:\n                expanding_obj = obj_a\n                static_obj = obj_b\n            else:\n                expanding_obj = obj_b\n                static_obj = obj_a # Keep track of the static one too\n\n            exp_color = expanding_obj['color']\n            (exp_r, exp_c) = next(iter(expanding_obj['pixels']))\n            # static_coord = next(iter(static_obj['pixels'])) # Not directly needed for painting logic below\n\n            # Define the 5 coordinates of the cross centered at (exp_r, exp_c)\n            cross_coords = [\n                (exp_r, exp_c),         # Center\n                (exp_r - 1, exp_c),     # Up\n                (exp_r + 1, exp_c),     # Down\n                (exp_r, exp_c - 1),     # Left\n                (exp_r, exp_c + 1)      # Right\n            ]\n\n            # Draw the cross, ONLY painting background cells\n            for r, c in cross_coords:\n                if 0 <= r < rows and 0 <= c < cols:\n                    # Check if the target cell is background OR the expanding pixel's original location\n                    # (Ensure the center pixel is always set/kept)\n                    if output_grid[r, c] == 0 or (r == exp_r and c == exp_c):\n                         output_grid[r, c] = exp_color\n\n            # Mark both original pixels as processed\n            processed_object_ids.add(id_a)\n            processed_object_ids.add(id_b)\n\n\n    # --- Rule 2: Adjacent Square Transformation ---\n    square_pairs_to_process = []\n    # Find candidate pairs (unprocessed objects only)\n    unprocessed_ids = [oid for oid in object_ids if oid not in processed_object_ids]\n    for i in range(len(unprocessed_ids)):\n        id_x = unprocessed_ids[i]\n        obj_x = object_map[id_x]\n        if obj_x['shape'] != 'square':\n            continue\n        for j in range(len(unprocessed_ids)): # Check all other *unprocessed* objects\n            if i == j: continue\n            id_y = unprocessed_ids[j]\n            obj_y = object_map[id_y]\n            if obj_y['shape'] != 'square':\n                continue\n\n            # Check for same size and *full* edge adjacency\n            n = obj_x['size']\n            if n is not None and obj_x['size'] == obj_y['size'] and have_full_edge_adjacency(obj_x, obj_y, n):\n                 # Add pair (ensure no duplicates like (x,y) and (y,x) if needed, though current processing handles it)\n                square_pairs_to_process.append((id_x, id_y))\n\n\n    # Apply transformations for squares\n    # Need to be careful if one square could be X in one pair and Y in another.\n    # Process pairs one by one, marking objects as processed.\n    processed_in_rule2 = set() # Track specifically for rule 2 to avoid double-processing within this rule block\n    for id_x, id_y in square_pairs_to_process:\n        # Ensure BOTH objects haven't been processed by *any* rule yet,\n        # and haven't been processed within this rule 2 block specifically.\n        if id_x not in processed_object_ids and id_y not in processed_object_ids and \\\n           id_x not in processed_in_rule2 and id_y not in processed_in_rule2:\n\n            obj_x = object_map[id_x]\n            obj_y = object_map[id_y]\n\n            n = obj_x['size'] # Guaranteed to be same as obj_y['size']\n            color_x = obj_x['color']\n            color_y = obj_y['color']\n            min_r_y, min_c_y, max_r_y, max_c_y = obj_y['bbox']\n\n            # Calculate top-left corner of the 3Nx3N area\n            area_start_r = min_r_y - n\n            area_start_c = min_c_y - n\n\n            # Fill the 3Nx3N area with color_x\n            for r in range(area_start_r, area_start_r + 3 * n):\n                for c in range(area_start_c, area_start_c + 3 * n):\n                    if 0 <= r < rows and 0 <= c < cols:\n                        output_grid[r, c] = color_x\n\n            # Place object Y (color_y) back in the center NxN block\n            for r in range(min_r_y, max_r_y + 1):\n                for c in range(min_c_y, max_c_y + 1):\n                     if 0 <= r < rows and 0 <= c < cols: # Boundary check (should be redundant if Y was valid)\n                         output_grid[r, c] = color_y\n\n            # Determine relative position of X to Y\n            relative_pos = get_relative_position(obj_y, obj_x) # Position of X relative to Y\n\n            # Calculate coordinates for the \"opposite\" NxN block to clear to background (0)\n            clear_r_start, clear_c_start = -1, -1\n            if relative_pos == \"Above\":   clear_r_start, clear_c_start = min_r_y + n, min_c_y # Below Y\n            elif relative_pos == \"Below\": clear_r_start, clear_c_start = min_r_y - n, min_c_y # Above Y\n            elif relative_pos == \"Left\":  clear_r_start, clear_c_start = min_r_y, min_c_y + n # Right of Y\n            elif relative_pos == \"Right\": clear_r_start, clear_c_start = min_r_y, min_c_y - n # Left of Y\n\n            # Clear the opposite block\n            if clear_r_start != -1:\n                for r in range(clear_r_start, clear_r_start + n):\n                    for c in range(clear_c_start, clear_c_start + n):\n                        if 0 <= r < rows and 0 <= c < cols:\n                            output_grid[r, c] = 0 # background color"
          }
        ],
        "role": "model"
      },
      "finish_reason": 2,
      "index": 0,
      "citation_metadata": {
        "citation_sources": [
          {
            "start_index": 16487,
            "end_index": 16822,
            "uri": "https://github.com/abhisheksol/competivity-programming",
            "license_": ""
          }
        ]
      },
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 11292,
    "candidates_token_count": 4190,
    "total_token_count": 15482,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 251.926774,
  "retries": null
}