{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nTransforms an input grid by:\n1. Initializing an output grid as a copy of the input.\n2. Finding a color map from marker pairs in the bottom-left corner (cols 0, 1), read bottom-up.\n3. Identifying all distinct connected non-white objects (4-connectivity).\n4. For each object whose color is a key in the color map:\n    a. Find its minimal bounding box.\n    b. Fill the bounding box area in the output grid with the mapped color.\n    c. Restore the original object pixels within the filled bounding box.\n5. Return the modified output grid.\n\"\"\"\n\ndef find_marker_pairs(grid):\n    \"\"\"\n    Finds horizontal marker pairs in the bottom-left corner (cols 0 and 1)\n    and returns a dictionary mapping left_color -> right_color.\n    It iterates from the bottom row upwards, prioritizing lower rows for mapping.\n\n    Args:\n        grid (np.ndarray): The input grid.\n\n    Returns:\n        dict: A dictionary mapping source colors to target colors.\n    \"\"\"\n    color_map = {}\n    height, width = grid.shape\n\n    # Only proceed if there are at least 2 columns for horizontal pairs\n    if width < 2:\n        return color_map\n\n    # Search columns 0 and 1, from bottom row up\n    for r in range(height - 1, -1, -1): # Iterate from bottom row up to 0\n        left_color = grid[r, 0]\n        right_color = grid[r, 1]\n\n        # Check if both are non-white (not 0)\n        if left_color != 0 and right_color != 0:\n            # If this left_color hasn't been mapped yet, add the mapping\n            if left_color not in color_map:\n                color_map[left_color] = right_color\n                \n    return color_map\n\ndef find_objects(grid):\n    \"\"\"\n    Finds all distinct non-white objects (connected components using 4-connectivity) in the grid.\n\n    Args:\n        grid (np.ndarray): The input grid.\n\n    Returns:\n        list: A list of tuples, where each tuple contains (object_color, object_coords).\n              object_coords is a set of (row, col) tuples for the pixels of that object.\n    \"\"\"\n    height, width = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n\n    for r in range(height):\n        for c in range(width):\n            # If pixel is non-white and not yet visited\n            if grid[r, c] != 0 and not visited[r, c]:\n                object_color = grid[r, c]\n                object_coords = set()\n                q = deque([(r, c)])\n                visited[r,c] = True # Mark starting point visited\n                object_coords.add((r,c))\n                \n                # Perform BFS to find all connected pixels of the same object_color\n                while q:\n                    row, col = q.popleft()\n\n                    # Add neighbors to queue (4-connectivity)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n\n                        # Bounds check\n                        if not (0 <= nr < height and 0 <= nc < width):\n                            continue\n                        \n                        # Visited check and Color check\n                        if not visited[nr, nc] and grid[nr, nc] == object_color:\n                             visited[nr, nc] = True\n                             object_coords.add((nr, nc))\n                             q.append((nr, nc))\n                \n                # Add the found object to the list if it has coordinates\n                if object_coords:\n                     objects.append((object_color, object_coords))\n\n    return objects\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rule to the input grid.\n    \n    Args:\n        input_grid (list of lists): The input grid represented as a list of lists.\n\n    Returns:\n        list of lists: The transformed grid.\n    \"\"\"\n    # Convert input list of lists to numpy array for efficient manipulation\n    input_np = np.array(input_grid, dtype=int)\n    height, width = input_np.shape\n    \n    # 1. Initialize output grid as a copy of the input\n    output_np = np.copy(input_np)\n\n    # 2. Find the color mapping from horizontal marker pairs\n    color_map = find_marker_pairs(input_np)\n\n    # 3. Identify all distinct non-white objects\n    objects = find_objects(input_np)\n\n    # 4. Process each object\n    for object_color, object_coords in objects:\n        \n        # 4a/b. Check if the object's color has a mapping\n        if object_color in color_map:\n            # 4c.i. Get the target fill color\n            fill_color = color_map[object_color]\n            \n            # Ensure object_coords is not empty before calculating bounds\n            if not object_coords:\n                continue\n\n            # 4c.ii. Calculate the minimal bounding box\n            rows = [r for r, c in object_coords]\n            cols = [c for r, c in object_coords]\n            min_r = min(rows)\n            max_r = max(rows)\n            min_c = min(cols)\n            max_c = max(cols)\n\n            # 4c.iii. Fill the entire bounding box area in the output grid with the fill_color\n            # Numpy slicing is [start:end], where end is exclusive. Add 1 to max indices.\n            output_np[min_r : max_r + 1, min_c : max_c + 1] = fill_color\n            \n            # 4c.iv. Restore the original object pixels\n            for r_obj, c_obj in object_coords:\n                output_np[r_obj, c_obj] = object_color\n\n        # 4d. If no mapping exists, do nothing (object pixels are already preserved from the initial copy)\n\n    # 5. Convert back to list of lists for the expected output format\n    return output_np.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 13153,
    "candidates_token_count": 1479,
    "total_token_count": 14632,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 16.727097,
  "retries": null
}