
## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 3 3 3 3 3 3 3 3 3 0 0
0 0 0 3 0 0 0 3 0 0 0 3 0 0
0 0 0 3 0 0 0 3 0 0 0 3 0 0
0 0 0 3 3 3 3 3 3 3 3 3 0 0
0 0 0 3 0 0 0 3 0 0 0 3 0 0
0 0 0 3 0 0 0 3 0 0 0 3 0 0
0 0 0 3 3 3 3 3 3 3 3 3 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 3 3 3 3 3 3 3 3 3 0 0
0 0 3 0 0 0 3 0 0 0 3 0 0 0
0 0 0 3 0 0 0 3 0 0 0 3 0 0
0 0 0 0 3 3 3 3 3 3 3 3 3 0
0 0 0 3 0 0 0 3 0 0 0 3 0 0
0 0 3 0 0 0 3 0 0 0 3 0 0 0
0 0 0 3 3 3 3 3 3 3 3 3 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 2 2 2 2 2 2 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 2 2 2 2 2 2 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 2 2 2 2 2 2 0 0 0 0 0
0 0 2 0 0 0 0 2 0 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 0 2 0 0 0 0 2 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 2 0 0 0 0 2 0 0 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 0 0 2 0 0 0 0 2 0 0 0 0
0 0 0 2 0 0 0 0 2 0 0 0 0 0
0 0 2 0 0 0 0 2 0 0 0 0 0 0
0 0 0 2 2 2 2 2 2 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 5 5 5 5 5 5 5 5 0 0 0
0 0 0 0 5 0 0 5 5 0 0 5 0 0 0
0 0 0 0 5 0 0 5 5 0 0 5 0 0 0
0 0 0 0 5 5 5 5 5 5 5 5 0 0 0
0 0 0 0 5 0 0 5 5 0 0 5 0 0 0
0 0 0 0 5 0 0 5 5 0 0 5 0 0 0
0 0 0 0 5 5 5 5 5 5 5 5 0 0 0
0 0 0 0 5 0 0 5 5 0 0 5 0 0 0
0 0 0 0 5 0 0 5 5 0 0 5 0 0 0
0 0 0 0 5 5 5 5 5 5 5 5 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 5 5 5 5 5 5 5 5 0 0 0 0
0 0 0 0 5 0 0 5 5 0 0 5 0 0 0
0 0 0 0 0 5 0 0 5 5 0 0 5 0 0
0 0 0 0 5 5 5 5 5 5 5 5 0 0 0
0 0 0 5 0 0 5 5 0 0 5 0 0 0 0
0 0 0 0 5 0 0 5 5 0 0 5 0 0 0
0 0 0 0 0 5 5 5 5 5 5 5 5 0 0
0 0 0 0 5 0 0 5 5 0 0 5 0 0 0
0 0 0 5 0 0 5 5 0 0 5 0 0 0 0
0 0 0 0 5 5 5 5 5 5 5 5 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_4

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 8 8 8 8 8 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 8 0 8 0 8 0 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 0 8 0 8 0 8 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 8 0 8 0 8 0 0 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 0 0 8 0 8 0 8 0 0 0 0 0
0 0 0 0 8 0 8 0 8 0 0 0 0 0 0
0 0 0 8 0 8 0 8 0 0 0 0 0 0 0
0 0 0 0 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

Okay, let's analyze the task examples.

**Perception of Task Elements:**

1.  **Grid Structure:** Both input and output grids have the same dimensions.
2.  **Background:** The background is consistently white (color 0).
3.  **Foreground Object:** Each input grid contains a single, contiguous object composed of a single non-white color (green, red, gray, or azure). These objects have complex, often grid-like or patterned internal structures with white spaces.
4.  **Transformation:** The core transformation involves modifying the horizontal position of the pixels within the foreground object. The object's color and overall vertical extent remain the same.
5.  **Row-Dependent Shift:** Observing the changes row by row reveals a pattern. Pixels in certain rows of the object shift left, some shift right, and some remain in the same horizontal position.
6.  **Shift Pattern:** Comparing the input and output objects across all examples, the horizontal shift applied to the pixels of a given row depends on the row's index relative to the topmost row of the object. The pattern of shifts repeats every four rows:
    *   Row 0 (relative to object top): No shift (shift = 0)
    *   Row 1 (relative to object top): Shift left by 1 (shift = -1)
    *   Row 2 (relative to object top): No shift (shift = 0)
    *   Row 3 (relative to object top): Shift right by 1 (shift = +1)
    *   This pattern `[0, -1, 0, +1]` continues cyclically for subsequent rows of the object (e.g., relative row 4 behaves like relative row 0, relative row 5 like relative row 1, etc.).
7.  **Pixel Mapping:** Each non-white pixel in the input grid at `(row, col)` is mapped to a new position `(row, col + shift_amount)` in the output grid, where `shift_amount` is determined by the row's relative index within the object as described above. Pixels shifted outside the grid boundaries are discarded. Pixels originally white remain white unless a non-white pixel is shifted into their position.

**YAML Facts:**


```yaml
Grid:
  Properties:
    - Size: Input and Output grids have identical dimensions.
    - BackgroundColor: Consistently white (0).
Objects:
  - Name: ForegroundObject
    Properties:
      - Type: Single contiguous component.
      - Color: A single non-white color (varies per example: green, red, gray, azure).
      - Structure: Often contains internal white spaces, forming patterns or lattice-like shapes.
      - Location: Occupies a specific region within the grid.
      - BoundingBox: Defined by min/max row and column indices.
    Relationships:
      - ContainsPixels: Composed of all non-white pixels in the input grid.
Transformation:
  Name: RowBasedHorizontalShift
  Input: ForegroundObject from the input grid.
  Output: Modified ForegroundObject placed onto an initially white output grid.
  Rule:
    - For each pixel of the ForegroundObject at (row, col) in the input:
      1. Determine the topmost row index (`object_top_row`) of the ForegroundObject.
      2. Calculate the relative row index: `relative_row = row - object_top_row`.
      3. Calculate the shift pattern index: `shift_index = relative_row % 4`.
      4. Determine the horizontal shift amount (`shift_amount`) using the pattern `[0, -1, 0, 1]` based on `shift_index`.
         - `shift_index` 0 -> `shift_amount` = 0
         - `shift_index` 1 -> `shift_amount` = -1 (left)
         - `shift_index` 2 -> `shift_amount` = 0
         - `shift_index` 3 -> `shift_amount` = +1 (right)
      5. Calculate the target column: `new_col = col + shift_amount`.
      6. Place the object's color at `(row, new_col)` in the output grid, provided `new_col` is within the grid's width boundaries.
  Properties:
    - PreservesVerticalPosition: Pixels stay in their original rows.
    - PreservesColor: The color of the object is unchanged.
    - ModifiesHorizontalPosition: Pixels shift left, right, or stay based on the row pattern.
    - ModifiesShape: The overall shape of the object is altered due to the differential row shifts.
```


**Natural Language Program:**

1.  Create a new grid (the "output grid") with the same dimensions as the input grid, and fill it entirely with the background color (white, 0).
2.  Identify the single connected group of non-white pixels in the input grid (this is the "object"). Note its color.
3.  Find the row index of the uppermost pixel belonging to the object (let this be `object_top_row`).
4.  Iterate through each pixel of the input grid at location (`row`, `column`).
5.  If the pixel at (`row`, `column`) belongs to the object (i.e., its color is not white):
    a.  Calculate the pixel's row index relative to the top of the object: `relative_row = row - object_top_row`.
    b.  Determine which step in the four-step shift cycle applies: `shift_cycle_step = relative_row modulo 4`.
    c.  Determine the horizontal shift amount based on the `shift_cycle_step`:
        *   If `shift_cycle_step` is 0, the shift is 0 columns.
        *   If `shift_cycle_step` is 1, the shift is -1 column (one step left).
        *   If `shift_cycle_step` is 2, the shift is 0 columns.
        *   If `shift_cycle_step` is 3, the shift is +1 column (one step right).
    d.  Calculate the new column for this pixel: `new_column = column + shift`.
    e.  Check if `new_column` is a valid column index within the grid's width.
    f.  If `new_column` is valid, set the pixel at (`row`, `new_column`) in the output grid to the object's color.
6.  After checking all pixels in the input grid, the output grid contains the transformed object. Return the output grid.
