
## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 8 8 8 8 8 0 0 0 0
0 0 8 0 0 0 8 0 0 0 0
0 0 8 0 0 0 8 0 0 0 0
0 0 8 0 0 0 8 0 0 0 0
0 0 8 8 8 8 8 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
8 8 8 0 0 0 0 0 0 0 0
0 0 0 8 0 0 0 0 0 0 0
8 0 0 0 8 0 0 0 0 0 0
0 8 0 0 0 8 0 0 0 0 0
0 0 8 8 8 8 8 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 6 6 6 0 0 0 0
0 0 0 0 6 0 6 0 0 0 0
0 0 0 0 6 0 6 0 0 0 0
0 0 0 0 6 0 6 0 0 0 0
0 0 0 0 6 6 6 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
6 6 6 0 0 0 0 0 0 0 0
0 6 0 6 0 0 0 0 0 0 0
0 0 6 0 6 0 0 0 0 0 0
0 0 0 6 0 6 0 0 0 0 0
0 0 0 0 6 6 6 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```


## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 3 3 3 0 0 0
0 0 0 0 0 0 0 3 0 3 0 0 0
0 0 0 0 0 0 3 3 0 3 3 0 0
0 0 0 0 0 0 3 0 0 0 3 0 0
0 0 0 0 0 0 3 3 3 3 3 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 3 3 3 0 0 0 0 0 0 0
0 0 0 0 3 0 3 0 0 0 0 0 0
0 0 0 0 3 3 0 3 3 0 0 0 0
0 0 0 0 0 3 0 0 0 3 0 0 0
0 0 0 0 0 0 3 3 3 3 3 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_4

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 2 2 2 2 0 0 0 0
0 0 0 0 2 0 0 0 2 0 0 0 0
0 0 0 0 2 2 0 0 2 0 0 0 0
0 0 0 0 0 2 0 0 2 2 0 0 0
0 0 0 0 0 2 0 0 0 2 0 0 0
0 0 0 0 0 2 2 2 2 2 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
2 2 2 2 0 0 0 0 0 0 0 0 0
2 0 0 0 2 0 0 0 0 0 0 0 0
0 2 2 0 0 2 0 0 0 0 0 0 0
0 0 0 2 0 0 2 2 0 0 0 0 0
0 0 0 0 2 0 0 0 2 0 0 0 0
0 0 0 0 0 2 2 2 2 2 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_5

**input:**
```
0 0 0 0 0 0 0
0 8 8 8 0 0 0
0 8 8 8 0 0 0
0 0 0 0 0 0 0
0 0 0 0 0 0 0
0 0 0 0 0 0 0
0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0
8 8 8 0 0 0 0
0 8 8 8 0 0 0
0 0 0 0 0 0 0
0 0 0 0 0 0 0
0 0 0 0 0 0 0
0 0 0 0 0 0 0
```

**Perception**

1.  **Input/Output Grids:** Each task example consists of an input grid and an corresponding output grid. The grids contain pixels represented by integers 0-9, corresponding to colors. White (0) appears to be the background color in all examples.
2.  **Objects:** In each input grid, there is a single contiguous object composed of non-white pixels. The shape and color of this object vary across examples (azure rectangle, magenta rectangle, green 'G', red 'R', azure rectangle).
3.  **Transformation:** The object from the input grid appears transformed in the output grid. The background remains white. The transformation seems to be a geometric shear or slant applied to the object.
4.  **Shear Pattern:** Observing the relationship between input and output objects, the transformation consistently shifts pixels horizontally to the left. The amount of shift applied to a pixel depends on its row position relative to the bottom of the object. Pixels in the bottom-most row of the object do not shift horizontally. Pixels in the row above the bottom shift left by 1 column. Pixels two rows above the bottom shift left by 2 columns, and so on. The vertical position (row) of each pixel remains unchanged.
5.  **Bounding Box:** The transformation is relative to the object itself, specifically its lowest row. The absolute position within the grid changes, but the logic depends on the object's structure.
6.  **Output Grid Construction:** The output grid is initially white. The transformed object pixels are then placed onto this grid. Pixels shifted outside the left boundary (column index < 0) are effectively removed.

**YAML Facts**


```yaml
task_description: Apply a vertical shear transformation to the single non-white object in the grid.
grid_properties:
  background_color: 0 # white
  dimensions: Variable (input and output have the same dimensions for each example)
objects:
  - role: primary
    count: 1 per grid
    attributes:
      color: Any non-zero integer (1-9)
      shape: Variable (rectangle, letter-like shapes observed)
      contiguity: Pixels of the same non-zero color form a single connected component.
relationships:
  - type: positional
    elements: [object pixel, object bounding box]
    details: The transformation of a pixel depends on its row relative to the bottom row of the object's bounding box.
actions:
  - name: find_object
    input: input_grid
    output: object_pixels_coordinates, object_color
  - name: find_bounding_box
    input: object_pixels_coordinates
    output: min_row, min_col, max_row, max_col
  - name: calculate_shear_shift
    inputs: [pixel_row, max_row]
    output: horizontal_shift
    formula: shift = max_row - pixel_row
  - name: apply_transformation
    inputs: [input_grid, object_pixels_coordinates, object_color, horizontal_shift_map]
    output: output_grid
    process: Create an empty output grid (same size, background color). For each object pixel at (r, c) in the input, calculate its shift = max_row - r. Calculate the new column new_c = c - shift. If 0 <= new_c < grid_width, place the object_color at (r, new_c) in the output grid.
```


**Natural Language Program**

1.  Identify the single contiguous block of non-white pixels in the input grid (this is the "object"). Note its color.
2.  Determine the row index of the lowest row occupied by any pixel of the object (let's call this `bottom_row_index`).
3.  Create a new output grid with the same dimensions as the input grid, initially filled entirely with the background color (white, 0).
4.  Iterate through each pixel of the identified object in the input grid, located at `(row, column)`.
5.  For each object pixel, calculate a horizontal shift amount by subtracting its `row` from the `bottom_row_index`.
6.  Calculate the target column for this pixel in the output grid by subtracting the calculated `shift` from the original `column`.
7.  If the calculated target column is within the valid column range of the grid (i.e., not less than 0), place the object's color at the location `(row, target_column)` in the output grid.
8.  The resulting grid after processing all object pixels is the final output.
