{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom scipy.ndimage import label, generate_binary_structure\nimport collections\n\n\"\"\"\nTransforms the input grid based on the number of distinct green (color 3) objects found using 8-way connectivity.\n\n- If 0 green objects: Returns the input grid unchanged.\n- If 1 green object: Keeps the original object. Calculates its bounding box height (H) and width (W). Adds copies of the object translated relative to its original position by vectors (H, -W), (H, W), and (2H, 2W).\n- If 2 or more green objects: Finds the combined bounding box enclosing each unique pair of green objects. Fills the rectangular area defined by each of these combined bounding boxes with green. The original green objects are preserved as they fall within these filled areas.\n\"\"\"\n\n# Define a structure to hold object information\nObject = collections.namedtuple('Object', ['pixels', 'bbox']) # bbox = (min_r, min_c, max_r, max_c) inclusive\n\ndef find_objects(grid, target_color):\n    \"\"\"\n    Identifies connected components (objects) of a specified color in a grid.\n    Uses 8-way connectivity.\n\n    Args:\n        grid: The input numpy array grid.\n        target_color: The integer color value to find objects of.\n\n    Returns:\n        A list of Object namedtuples. Each tuple contains:\n          - pixels: A set of (row, col) tuples for the object.\n          - bbox: A tuple (min_r, min_c, max_r, max_c) representing the\n                  inclusive bounding box.\n        Returns an empty list if no objects are found.\n    \"\"\"\n    # Create a binary mask where target_color pixels are True\n    binary_grid = (grid == target_color)\n    # Define 8-way connectivity structure\n    structure = generate_binary_structure(rank=2, connectivity=2)\n    # Label connected components\n    labeled_grid, num_labels = label(binary_grid, structure=structure)\n\n    objects = []\n    if num_labels > 0:\n        # For each label, find coordinates and calculate bounding box\n        for i in range(1, num_labels + 1):\n            coords = np.argwhere(labeled_grid == i)\n            # Ensure the component still exists (can happen with edge cases)\n            if coords.size > 0:\n                pixels = set(map(tuple, coords))\n                # Extract row and column coordinates\n                rows, cols = zip(*coords)\n                # Calculate inclusive bounding box\n                min_r, max_r = min(rows), max(rows)\n                min_c, max_c = min(cols), max(cols)\n                bbox = (min_r, min_c, max_r, max_c)\n                # Store object info\n                objects.append(Object(pixels, bbox))\n\n    return objects\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rule based on the number of green objects.\n    \"\"\"\n\n    # Define the target color\n    green_color = 3\n    # Find all distinct connected green objects\n    objects = find_objects(input_grid, green_color)\n    num_objects = len(objects)\n    # Initialize the output grid as a copy of the input\n    output_grid = np.copy(input_grid)\n    grid_h, grid_w = input_grid.shape\n\n    # --- Case 1: Single Object ---\n    if num_objects == 1:\n        the_object = objects[0]\n        pixels = the_object.pixels\n        min_r, min_c, max_r, max_c = the_object.bbox\n\n        # Calculate Height (H) and Width (W) of the bounding box\n        H = max_r - min_r + 1\n        W = max_c - min_c + 1\n\n        # Define translation vectors based on object dimensions\n        # These were derived empirically from training example 2\n        translations = [(H, -W), (H, W), (2 * H, 2 * W)]\n\n        # Apply each translation to create copies of the object\n        for dr, dc in translations:\n            for r, c in pixels:\n                # Calculate the new coordinates for the pixel\n                new_r, new_c = r + dr, c + dc\n                # Check if the new coordinates are within the grid bounds\n                if 0 <= new_r < grid_h and 0 <= new_c < grid_w:\n                    # Paint the translated pixel green\n                    output_grid[new_r, new_c] = green_color\n        # The original object remains because output_grid started as a copy\n\n    # --- Case 2: Two or More Objects ---\n    elif num_objects >= 2:\n        # Iterate through all unique pairs of distinct objects\n        for i in range(num_objects):\n            for j in range(i + 1, num_objects):\n                obj_i = objects[i]\n                obj_j = objects[j]\n\n                # Get bounding boxes for the pair of objects\n                min_r_i, min_c_i, max_r_i, max_c_i = obj_i.bbox\n                min_r_j, min_c_j, max_r_j, max_c_j = obj_j.bbox\n\n                # Calculate the combined bounding box that encloses both objects\n                comb_min_r = min(min_r_i, min_r_j)\n                comb_min_c = min(min_c_i, min_c_j)\n                comb_max_r = max(max_r_i, max_r_j)\n                comb_max_c = max(max_c_i, max_c_j)\n\n                # Fill the combined bounding box rectangle with green\n                # Clip coordinates to grid boundaries for safe slicing\n                fill_r_start = max(0, comb_min_r)\n                # +1 because numpy slicing end index is exclusive\n                fill_r_end = min(grid_h, comb_max_r + 1) \n                fill_c_start = max(0, comb_min_c)\n                 # +1 because numpy slicing end index is exclusive\n                fill_c_end = min(grid_w, comb_max_c + 1)\n\n                # Ensure the slice dimensions are valid before filling\n                if fill_r_start < fill_r_end and fill_c_start < fill_c_end:\n                     output_grid[fill_r_start:fill_r_end, fill_c_start:fill_c_end] = green_color\n\n    # --- Case 3: Zero Objects ---\n    # If num_objects is 0, no changes are made, and the original grid copy is returned.\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 15902,
    "candidates_token_count": 1570,
    "total_token_count": 17472,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 156.7734,
  "retries": null
}