{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom scipy.ndimage import label, generate_binary_structure\nimport collections\n\n\"\"\"\nTransforms the input grid based on the number of distinct green (color 3) objects found using 8-way connectivity. The transformation rule depends on the count (N) of these green objects:\n\n- If N = 0: The output grid is identical to the input grid.\n- If N = 1: \n    - The original green object is preserved.\n    - Calculate the bounding box height (H) and width (W) of the object.\n    - Three copies of the object are created by translating the original object's pixels by the vectors (H, -W), (H, W), and (2H, 2W) relative to their original positions.\n    - These translated copies are added to the output grid (painted green), staying within grid boundaries.\n- If N = 2:\n    - The original two green objects are preserved.\n    - For *each* of the two objects independently:\n        - Calculate its bounding box height (H_i) and width (W_i).\n        - Create three translated copies using vectors (H_i, -W_i), (H_i, W_i), and (2*H_i, 2*W_i).\n        - Add these six translated copies (3 per original object) to the output grid (painted green), staying within grid boundaries. \n        - *Note: This rule is derived from matching Example 3's output structure, which involves copies rather than bounding box fills, but may not perfectly replicate all features.*\n- If N >= 3:\n    - The original green objects are preserved (as they fall within the filled areas).\n    - Iterate through all unique pairs of the N green objects.\n    - For each pair, determine the minimal bounding box that encloses both objects in the pair.\n    - Fill this entire rectangular area defined by the combined bounding box with green on the output grid.\n\"\"\"\n\n# Define a structure to hold object information\n# bbox = (min_r, min_c, max_r, max_c) inclusive\nObject = collections.namedtuple('Object', ['pixels', 'bbox'])\n\ndef find_objects(grid, target_color):\n    \"\"\"\n    Identifies connected components (objects) of a specified color in a grid.\n    Uses 8-way connectivity.\n\n    Args:\n        grid: The input numpy array grid.\n        target_color: The integer color value to find objects of.\n\n    Returns:\n        A list of Object namedtuples. Each tuple contains:\n          - pixels: A set of (row, col) tuples for the object.\n          - bbox: A tuple (min_r, min_c, max_r, max_c) representing the\n                  inclusive bounding box.\n        Returns an empty list if no objects are found.\n    \"\"\"\n    # Create a binary mask where target_color pixels are True\n    binary_grid = (grid == target_color)\n    # Define 8-way connectivity structure\n    structure = generate_binary_structure(rank=2, connectivity=2)\n    # Label connected components\n    labeled_grid, num_labels = label(binary_grid, structure=structure)\n\n    objects = []\n    if num_labels > 0:\n        # For each label, find coordinates and calculate bounding box\n        for i in range(1, num_labels + 1):\n            coords = np.argwhere(labeled_grid == i)\n            # Ensure the component still exists (can happen with edge cases)\n            if coords.size > 0:\n                pixels = set(map(tuple, coords))\n                # Extract row and column coordinates\n                rows, cols = zip(*coords)\n                # Calculate inclusive bounding box\n                min_r, max_r = min(rows), max(rows)\n                min_c, max_c = min(cols), max(cols)\n                bbox = (min_r, min_c, max_r, max_c)\n                # Store object info\n                objects.append(Object(pixels, bbox))\n\n    return objects\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rule based on the number of green objects.\n    \"\"\"\n\n    # Define the target color\n    green_color = 3\n    # Find all distinct connected green objects\n    objects = find_objects(input_grid, green_color)\n    num_objects = len(objects)\n    # Initialize the output grid as a copy of the input\n    output_grid = np.copy(input_grid)\n    grid_h, grid_w = input_grid.shape\n\n    # --- Case N = 0: No Objects ---\n    if num_objects == 0:\n        return output_grid # Return unchanged grid\n\n    # --- Case N = 1: Single Object ---\n    elif num_objects == 1:\n        the_object = objects[0]\n        pixels = the_object.pixels\n        min_r, min_c, max_r, max_c = the_object.bbox\n\n        # Calculate Height (H) and Width (W) of the bounding box\n        H = max_r - min_r + 1\n        W = max_c - min_c + 1\n\n        # Define translation vectors based on object dimensions\n        translations = [(H, -W), (H, W), (2 * H, 2 * W)]\n\n        # Apply each translation to create copies of the object\n        for dr, dc in translations:\n            for r, c in pixels:\n                # Calculate the new coordinates for the pixel\n                new_r, new_c = r + dr, c + dc\n                # Check if the new coordinates are within the grid bounds\n                if 0 <= new_r < grid_h and 0 <= new_c < grid_w:\n                    # Paint the translated pixel green\n                    output_grid[new_r, new_c] = green_color\n\n    # --- Case N = 2: Two Objects ---\n    elif num_objects == 2:\n        # Apply the \"copy\" logic individually to each object\n        for each_object in objects:\n            pixels = each_object.pixels\n            min_r, min_c, max_r, max_c = each_object.bbox\n\n            # Calculate Height (H) and Width (W) for this specific object\n            H = max_r - min_r + 1\n            W = max_c - min_c + 1\n\n            # Define translation vectors for this object\n            translations = [(H, -W), (H, W), (2 * H, 2 * W)]\n\n            # Apply each translation to create copies of this object\n            for dr, dc in translations:\n                for r, c in pixels:\n                    # Calculate the new coordinates for the pixel\n                    new_r, new_c = r + dr, c + dc\n                    # Check if the new coordinates are within the grid bounds\n                    if 0 <= new_r < grid_h and 0 <= new_c < grid_w:\n                        # Paint the translated pixel green\n                        output_grid[new_r, new_c] = green_color\n\n    # --- Case N >= 3: Three or More Objects ---\n    elif num_objects >= 3:\n        # Iterate through all unique pairs of distinct objects\n        for i in range(num_objects):\n            for j in range(i + 1, num_objects):\n                obj_i = objects[i]\n                obj_j = objects[j]\n\n                # Get bounding boxes for the pair of objects\n                min_r_i, min_c_i, max_r_i, max_c_i = obj_i.bbox\n                min_r_j, min_c_j, max_r_j, max_c_j = obj_j.bbox\n\n                # Calculate the combined bounding box that encloses both objects\n                comb_min_r = min(min_r_i, min_r_j)\n                comb_min_c = min(min_c_i, min_c_j)\n                comb_max_r = max(max_r_i, max_r_j)\n                comb_max_c = max(max_c_i, max_c_j)\n\n                # Fill the combined bounding box rectangle with green\n                # Clip coordinates to grid boundaries for safe slicing\n                fill_r_start = max(0, comb_min_r)\n                # +1 because numpy slicing end index is exclusive\n                fill_r_end = min(grid_h, comb_max_r + 1)\n                fill_c_start = max(0, comb_min_c)\n                 # +1 because numpy slicing end index is exclusive\n                fill_c_end = min(grid_w, comb_max_c + 1)\n\n                # Ensure the slice dimensions are valid before filling\n                if fill_r_start < fill_r_end and fill_c_start < fill_c_end:\n                     output_grid[fill_r_start:fill_r_end, fill_c_start:fill_c_end] = green_color\n\n    # Return the modified grid\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 22559,
    "candidates_token_count": 2085,
    "total_token_count": 24644,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 27.379597,
  "retries": null
}