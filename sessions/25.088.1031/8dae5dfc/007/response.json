{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nTransforms the input grid by processing each distinct non-background object. \nFor each object, it identifies concentric layers based on the 4-way distance \nfrom each pixel within the object to the nearest pixel outside the object. \nIt then extracts the original color sequence of these layers (from outermost \nto innermost) and reverses this sequence. Finally, it recolors the object \nby applying the reversed color sequence back onto the layers (innermost \noriginal color goes to outermost layer, etc.).\n\nWorkflow:\n1. Initialize the output grid as a copy of the input grid.\n2. Identify all distinct connected components (objects) formed by non-white (0) pixels using 4-way adjacency.\n3. For each identified object:\n    a. Calculate the 4-way distance for each pixel within the object to the nearest pixel *outside* the object using a multi-source BFS starting from the exterior boundary.\n    b. Group the object's pixels into layers based on their calculated distance (Layer 1 = distance 1, Layer 2 = distance 2, etc.).\n    c. Determine the original color associated with each layer (assuming layers are mostly monochromatic based on examples). Store the sequence of colors [Color(L1), Color(L2), ..., Color(LN)].\n    d. Reverse the sequence of original colors: [Color(LN), ..., Color(L2), Color(L1)].\n    e. Update the output grid: For each layer Lk (pixels at distance k), assign the k-th color from the *reversed* sequence.\n4. Return the modified output grid.\n\"\"\"\n\ndef get_neighbors(r, c, h, w):\n    \"\"\" Get valid 4-way neighbors for a cell (coordinates only) \"\"\"\n    neighbors = []\n    moves = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n    for dr, dc in moves:\n        nr, nc = r + dr, c + dc\n        if 0 <= nr < h and 0 <= nc < w:\n            neighbors.append((nr, nc))\n    return neighbors\n\ndef find_objects(grid):\n    \"\"\" Finds connected components of non-background (0) pixels using BFS \"\"\"\n    h, w = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = [] # List to store sets of coordinates for each object\n\n    for r in range(h):\n        for c in range(w):\n            # Start BFS if we find an unvisited non-background pixel\n            if grid[r, c] != 0 and not visited[r, c]:\n                obj_coords = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                object_color = grid[r,c] # Assuming object has one dominant color for finding purposes\n\n                while q:\n                    curr_r, curr_c = q.popleft()\n                    # Check if pixel belongs to the object based on non-background status\n                    # This simpler check works if objects don't touch diagonally with different colors.\n                    # A stricter check would compare color grid[curr_r, curr_c] == object_color\n                    if grid[curr_r, curr_c] != 0:\n                        obj_coords.add((curr_r, curr_c)) # Add the pixel to the current object\n\n                        # Explore neighbors\n                        for nr, nc in get_neighbors(curr_r, curr_c, h, w):\n                            # Add neighbor to queue if it's part of the object (non-background) and not visited\n                            if grid[nr, nc] != 0 and not visited[nr, nc]:\n                                visited[nr, nc] = True\n                                q.append((nr, nc))\n                    # Mark as visited even if it's background, to avoid reprocessing\n                    visited[curr_r, curr_c] = True\n\n\n                # Add the completed object's coordinates to the list\n                if obj_coords:\n                    objects.append(obj_coords)\n    return objects\n\ndef calculate_distance_transform(grid, object_pixels):\n    \"\"\"\n    Calculates the 4-way distance from each pixel in object_pixels\n    to the nearest pixel *not* in object_pixels.\n    Uses a multi-source BFS starting from the exterior.\n    Returns a dictionary: { (r, c): distance } for pixels in object_pixels.\n    \"\"\"\n    h, w = grid.shape\n    distances = np.full((h, w), np.inf, dtype=float)\n    q = deque()\n\n    # 1. Initialize queue with exterior neighbors of the object\n    # These are the pixels right outside the object, acting as distance 0 sources\n    # for calculating distance *into* the object.\n    for r_obj, c_obj in object_pixels:\n        for nr, nc in get_neighbors(r_obj, c_obj, h, w):\n            if (nr, nc) not in object_pixels:\n                 # If this exterior neighbor hasn't been added as a source yet\n                if distances[nr, nc] == np.inf:\n                    distances[nr, nc] = 0\n                    q.append(((nr, nc), 0)) # Store coordinate and distance\n\n    # 2. Perform BFS\n    processed_in_object = set() # Keep track of object pixels whose final distance is set\n    pixel_distances = {}\n\n    while q:\n        (r, c), d = q.popleft()\n\n        # Explore neighbors\n        for nr, nc in get_neighbors(r, c, h, w):\n            # If the neighbor is *inside* the object and we haven't found a shorter path to it\n            if (nr, nc) in object_pixels and distances[nr, nc] == np.inf:\n                distances[nr, nc] = d + 1\n                pixel_distances[(nr, nc)] = d + 1\n                processed_in_object.add((nr, nc))\n                q.append(((nr, nc), d + 1))\n            # If the neighbor is *outside* the object and not yet a source\n            elif (nr, nc) not in object_pixels and distances[nr, nc] == np.inf:\n                 distances[nr, nc] = 0 # Mark as source\n                 q.append(((nr, nc), 0))\n\n\n    # Ensure all object pixels got a distance assigned\n    # This handles cases where the object might be internally disconnected from the perspective\n    # of the distance transform if BFS didn't reach it (e.g., thick object centre)\n    # It should technically reach all connected parts, but as a safeguard:\n    # This check might be overly cautious depending on BFS guarantees.\n    # for r_obj, c_obj in object_pixels:\n    #      if (r_obj, c_obj) not in pixel_distances:\n    #           # This pixel was unreachable from the exterior boundary?\n    #           # This implies it's fully surrounded by other object pixels.\n    #           # The distance calculation needs refinement if this happens.\n    #           # For now, assign a large distance or handle based on task specifics.\n    #           # Assigning np.inf might be suitable if max distance is used later.\n    #           # Let's assume BFS covers all connected components for now.\n    #           print(f\"Warning: Pixel {(r_obj, c_obj)} in object did not receive a distance.\")\n    #           # pixel_distances[(r_obj, c_obj)] = np.inf # Or some large number\n\n\n    return pixel_distances\n\n\ndef transform(input_grid_list):\n    \"\"\"\n    Transforms the input grid by swapping the colors of symmetric layers \n    within each object, where layers are defined by distance to the exterior.\n    \"\"\"\n    input_grid = np.array(input_grid_list, dtype=int)\n    output_grid = np.copy(input_grid)\n    h, w = input_grid.shape\n\n    # 1. Identify all distinct objects\n    objects = find_objects(input_grid)\n\n    # 2. Process each object\n    for obj_coords in objects:\n        if not obj_coords:\n            continue\n\n        # 2a. Calculate distance transform for pixels in the object\n        # pixel_distances is a dict: {(r, c): distance}\n        pixel_distances = calculate_distance_transform(input_grid, obj_coords)\n\n        if not pixel_distances: # If distance calculation failed or object is weird\n            print(f\"Warning: Could not calculate distances for object pixels: {obj_coords}. Skipping object.\")\n            continue\n\n        # 2b. Group pixels by distance (layers) and find max distance\n        max_dist = 0\n        layers = {} # { distance: set_of_pixels }\n        for coord, dist_float in pixel_distances.items():\n            # Convert distance to integer for layer indexing\n            dist = int(round(dist_float)) # Round just in case, though should be integers\n            if dist <= 0: # Skip distance 0 which corresponds to exterior\n                continue\n                \n            if dist not in layers:\n                layers[dist] = set()\n            layers[dist].add(coord)\n            max_dist = max(max_dist, dist)\n\n        # 2c. Extract original colors in order of layers (1 to max_dist)\n        original_colors = []\n        layer_pixels_ordered = [] # List of sets of pixels, index i corresponds to layer i+1\n        found_all_layers = True\n        for d in range(1, max_dist + 1):\n            if d in layers and layers[d]:\n                layer_set = layers[d]\n                # Get color from the first pixel found in this layer\n                first_pixel = next(iter(layer_set))\n                original_color = input_grid[first_pixel]\n                original_colors.append(original_color)\n                layer_pixels_ordered.append(layer_set)\n            else:\n                 # This might happen if a distance level is skipped, e.g., in very thin structures.\n                 # Or if the object has holes causing distance jumps.\n                 # Based on examples, layers seem contiguous. If this warning appears,\n                 # the distance/layer logic might need refinement for complex shapes.\n                 print(f\"Warning: Layer for distance {d} not found or empty in object. Max dist = {max_dist}. Object coords start: {next(iter(obj_coords)) if obj_coords else 'N/A'}\")\n                 # We need a color sequence matching the number of layers found.\n                 # Option 1: Skip this layer (breaks symmetry).\n                 # Option 2: Add a placeholder (e.g., 0) (might break color logic).\n                 # Option 3: Stop processing this object.\n                 # Let's try to continue but note the potential issue. We'll only store colors/layers we find.\n                 found_all_layers = False # Flag potential issue\n\n        if not original_colors: # No layers found\n             print(f\"Warning: No layers extracted for object: {obj_coords}. Skipping.\")\n             continue\n\n\n        # 2d. Reverse the sequence of *found* original colors\n        reversed_colors = original_colors[::-1]\n\n        # 2e. Apply reversed colors to the identified layers\n        # Ensure we have the same number of layer sets as reversed colors.\n        # This should hold if we only stored layers we found and their colors.\n        if len(layer_pixels_ordered) == len(reversed_colors):\n            for i, layer_set in enumerate(layer_pixels_ordered):\n                new_color = reversed_colors[i]\n                for r, c in layer_set:\n                    # Update the output grid\n                    output_grid[r, c] = new_color\n        else:\n             # This indicates a logic error or unexpected structure if found_all_layers was true.\n             # If found_all_layers was false, this might be expected depending on handling.\n             print(f\"Error: Mismatch between layer count ({len(layer_pixels_ordered)}) and reversed colors ({len(reversed_colors)}) for object. Transformation possibly incorrect.\")\n             # Attempt partial transformation? Or skip? Skipping is safer.\n             print(f\"Skipping recoloring for object starting at {next(iter(obj_coords)) if obj_coords else 'N/A'}\")\n\n\n    # Convert the final grid back to a list of lists\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 13403,
    "candidates_token_count": 2851,
    "total_token_count": 16254,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 48.123357,
  "retries": null
}