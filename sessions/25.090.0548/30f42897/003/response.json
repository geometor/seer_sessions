{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import Counter\n\n\"\"\"\nTransforms an input grid based on the properties of a single non-background \ncolored object found within it.\n\n1.  Identify Background and Object: Determine the background color (most frequent). \n    Find the single contiguous non-background object, its color (C), pixel coordinates, \n    bounding box (top, left, H, W).\n2.  Initialize Output: Copy the input grid.\n3.  Apply Shape-Specific Rules:\n    *   If Vertical Line (W=1):\n        *   If H=5: Add horizontal lines (length H, color C) at top-left and bottom-left.\n        *   If H=2: Add specific horizontal and vertical lines (length H, color C) \n          at locations relative to grid boundaries (derived from example 3).\n    *   If Rectangle (H>1, W>1):\n        *   Add a horizontally reflected copy of the object, placed so its \n          top-left corner is at (0, GridWidth-W).\n        *   Add a horizontal line (length W+1, color C) centered on the bottom row.\n4.  Return: The modified output grid.\n\"\"\"\n\ndef find_objects(grid, background_color):\n    \"\"\"\n    Finds contiguous objects of non-background colors in the grid.\n    Uses a simple flood fill (BFS) approach. Returns a list of objects, \n    each containing color, pixels (list of tuples), and bounding_box dict.\n    \"\"\"\n    objects = []\n    visited = np.zeros(grid.shape, dtype=bool)\n    rows, cols = grid.shape\n\n    for r in range(rows):\n        for c in range(cols):\n            # If this pixel is not background and not visited yet, start BFS\n            if grid[r, c] != background_color and not visited[r, c]:\n                color = grid[r, c]\n                obj_pixels = []\n                q = [(r, c)]\n                visited[r, c] = True\n                min_r, max_r = r, r\n                min_c, max_c = c, c\n\n                # Breadth-First Search\n                while q:\n                    row, col = q.pop(0)\n                    obj_pixels.append((row, col))\n                    min_r = min(min_r, row)\n                    max_r = max(max_r, row)\n                    min_c = min(min_c, col)\n                    max_c = max(max_c, col)\n\n                    # Check 4 neighbors (up, down, left, right)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        # Check bounds, color match, and visited status\n                        if 0 <= nr < rows and 0 <= nc < cols and \\\n                           not visited[nr, nc] and grid[nr, nc] == color:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n                \n                # Calculate bounding box\n                bounding_box = {\n                    'top': min_r, \n                    'left': min_c, \n                    'height': max_r - min_r + 1, \n                    'width': max_c - min_c + 1\n                }\n                # Store object details\n                objects.append({\n                    'color': color, \n                    'pixels': obj_pixels, \n                    'bounding_box': bounding_box\n                })\n                \n    return objects\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rules based on the detected object.\n    \"\"\"\n    # Convert input to numpy array for easier manipulation\n    input_np = np.array(input_grid, dtype=int)\n    output_grid = np.copy(input_np)\n    grid_h, grid_w = input_np.shape\n\n    # 1. Identify Background Color\n    colors, counts = np.unique(input_np, return_counts=True)\n    if not counts.size: # Handle empty grid case\n         return output_grid.tolist()\n    background_color = colors[np.argmax(counts)]\n    \n    # 2. Find the single non-background object\n    objects = find_objects(input_np, background_color)\n    \n    # Expecting exactly one non-background object based on examples\n    if len(objects) != 1:\n        # If no object or multiple objects, return copy (as per observed ARC behavior)\n        # print(f\"Warning: Found {len(objects)} objects, expected 1. Returning copy.\")\n        return output_grid.tolist() \n        \n    obj = objects[0]\n    obj_color = obj['color']\n    obj_pixels = obj['pixels']\n    bbox = obj['bounding_box']\n    H = bbox['height']\n    W = bbox['width']\n    top = bbox['top']\n    left = bbox['left']\n\n    # 3. Apply Shape-Specific Rule\n    if W == 1 and H > 0: # Vertical Line\n        if H == 5: # Rule from train_1\n            # Add horizontal line top-left\n            if 0 + H <= grid_w: # Check if line fits\n                 output_grid[0, 0:H] = obj_color\n            # Add horizontal line bottom-left\n            if 0 + H <= grid_w and grid_h > 0: # Check if line fits and grid has rows\n                 output_grid[grid_h - 1, 0:H] = obj_color\n                 \n        elif H == 2: # Rule from train_3 \n             # Add shapes based on fixed/relative positions observed in example 3\n             # Check boundaries before drawing\n             line_len = H # which is 2\n             # Horizontal lines \n             if 1 + line_len <= grid_w: output_grid[0, 1 : 1+line_len] = obj_color \n             if 5 + line_len <= grid_w: output_grid[0, 5 : 5+line_len] = obj_color \n             if grid_h > 0: # Check row exists\n                 if 0 + line_len <= grid_w: output_grid[grid_h-1, 0 : 0+line_len] = obj_color \n                 if 4 + line_len <= grid_w: output_grid[grid_h-1, 4 : 4+line_len] = obj_color \n             # Vertical lines \n             if grid_w > 0: # Check col exists\n                if 1 + line_len <= grid_h: output_grid[1 : 1+line_len, grid_w-1] = obj_color \n                if 5 + line_len <= grid_h: output_grid[5 : 5+line_len, grid_w-1] = obj_color \n        # else: (No rules for other vertical line heights)\n            # print(f\"Warning: Unhandled vertical line height H={H}.\")\n             \n    elif H > 1 and W > 1: # Rectangle (Rule from train_2, including reflection)\n        # --- Reflected Copy ---\n        target_top = 0\n        target_left = grid_w - W\n        \n        # Iterate through original object pixels to create reflected copy\n        for r, c in obj_pixels:\n            # Calculate relative coordinates within the object's bounding box\n            rel_r = r - top\n            rel_c = c - left\n            # Calculate horizontally reflected relative column\n            reflected_rel_c = (W - 1) - rel_c\n            # Calculate target coordinates in the output grid (top-right placement)\n            target_r = target_top + rel_r\n            target_c = target_left + reflected_rel_c\n            # Check boundaries before placing the pixel\n            if 0 <= target_r < grid_h and 0 <= target_c < grid_w:\n                output_grid[target_r, target_c] = obj_color\n\n        # --- Bottom Line ---\n        line_len = W + 1\n        if line_len <= grid_w and grid_h > 0: # Check if line fits and row exists\n            start_col = (grid_w - line_len) // 2\n            # Ensure start_col is non-negative (can happen if line_len > grid_w)\n            if start_col >= 0:\n                 output_grid[grid_h - 1, start_col : start_col + line_len] = obj_color\n            \n    # else: (No rules for horizontal lines H=1 or single pixels H=1,W=1)\n        # print(f\"Warning: Unhandled object shape H={H}, W={W}.\")\n\n    # 4. Final Output - convert back to list of lists\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 15171,
    "candidates_token_count": 2083,
    "total_token_count": 17254,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 25.698982,
  "retries": 1
}