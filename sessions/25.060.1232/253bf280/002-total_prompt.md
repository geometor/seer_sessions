# 253bf280 • 002 • example_8 • investigate_coder

---

## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 8 0 0 0 0 0 0 8 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=832x448 at 0x7CE423308150>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 8 3 3 3 3 3 3 8 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=832x448 at 0x7CE423308850>

## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 8 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 8 0 0
0 0 0 0 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=704x640 at 0x7CE4233084D0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 8 0 0 0 0 0 0
0 0 0 0 3 0 0 0 8 0 0
0 0 0 0 3 0 0 0 3 0 0
0 0 0 0 3 0 0 0 3 0 0
0 0 0 0 3 0 0 0 3 0 0
0 0 0 0 3 0 0 0 8 0 0
0 0 0 0 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=704x640 at 0x7CE42330A4D0>

## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0 0
0 8 0 0 0 0 0 0 0 8 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 8 0 0 0 0 8 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=704x768 at 0x7CE42330B2D0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0
0 8 3 3 3 3 3 3 3 8 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 8 3 3 3 3 8 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=704x768 at 0x7CE41B8C3950>

## train_4

**input:**
```
0 0 0 0 0 0
0 0 8 0 0 0
0 0 0 0 0 0
0 0 0 0 0 0
0 0 0 0 0 0
0 0 0 0 0 0
0 0 0 0 0 0
0 0 8 0 0 0
0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=384x576 at 0x7CE41B8C3550>

**output:**
```
0 0 0 0 0 0
0 0 8 0 0 0
0 0 3 0 0 0
0 0 3 0 0 0
0 0 3 0 0 0
0 0 3 0 0 0
0 0 3 0 0 0
0 0 8 0 0 0
0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=384x576 at 0x7CE41B94F650>

## train_5

**input:**
```
0 0 0
0 8 0
0 0 0
```

<PIL.Image.Image image mode=RGB size=192x192 at 0x7CE41B856AD0>

**output:**
```
0 0 0
0 8 0
0 0 0
```

<PIL.Image.Image image mode=RGB size=192x192 at 0x7CE41B94CE50>

## train_6

**input:**
```
0 0 0 0 0 0
0 8 0 0 0 0
0 0 0 0 0 0
0 0 0 0 8 0
0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=384x320 at 0x7CE41B94D050>

**output:**
```
0 0 0 0 0 0
0 8 0 0 0 0
0 0 0 0 0 0
0 0 0 0 8 0
0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=384x320 at 0x7CE41B9E74D0>

## train_7

**input:**
```
0 0 0 0 0 0
0 0 0 8 0 0
0 0 0 0 0 0
0 8 0 0 0 0
0 0 0 0 0 0
0 0 0 0 0 0
0 0 0 8 0 0
```

<PIL.Image.Image image mode=RGB size=384x448 at 0x7CE41B94D150>

**output:**
```
0 0 0 0 0 0
0 0 0 8 0 0
0 0 0 3 0 0
0 8 0 3 0 0
0 0 0 3 0 0
0 0 0 3 0 0
0 0 0 8 0 0
```

<PIL.Image.Image image mode=RGB size=384x448 at 0x7CE4232F2150>

## train_8

**input:**
```
0 0 0 0 0 0 0 0 0 0 0
0 0 0 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 0 0 0 8
0 8 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=704x768 at 0x7CE4232F0CD0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0
0 0 0 8 0 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 0 0
0 0 0 3 0 0 8 3 3 3 8
0 8 0 3 0 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 0 0
0 0 0 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=704x768 at 0x7CE4232F1FD0>
<PIL.Image.Image image mode=RGB size=4576x1616 at 0x7CE4232F1850>Okay, let's analyze this ARC task.

**Perception of Elements:**

The primary elements are:

*   **Grids:** 2D arrays of varying dimensions.
*   **Pixels:** Individual cells within the grids, represented by integer values (0-9).
*   **Colors:** Integers are visualized with colors, 0 is white, 3 is green, 8 is azure.
*   **Objects:** Contiguous blocks of pixels of the same color. In this case, the azure (8) pixels appear to be the primary objects.
*   **Transformations:** The azure objects seem to be either generating green (3) lines extending from them, or sometimes remaining unchanged.

**YAML Block (Facts):**


```yaml
objects:
  - name: azure_pixel
    color: azure (8)
    type: primary

  - name: green_pixel
    color: green (3)
    type: generated

actions:
  - name: extend
    agent: azure_pixel
    target: adjacent_cells
    result: create green_pixel

conditions:
    - if: azure_pixels form continuous horizontal or vertical lines
      then: extend green pixels between them, creating a filled line.
      else:
        do not change

relations:
  - type: adjacency
    between: [azure_pixel, green_pixel]
```


**Natural Language Program:**

1.  **Identify:** Locate all azure (8) pixels in the input grid.
2. **Analyze Azure Pixel Arrangement**: Determine if there are two or more azure pixels and whether they are arranged either in a straight horizontal or vertical line in the output.
3.  **Conditional Extension:**
    *   If the azure pixels exist in a horizontal or vertical line, fill the space between the azure colored pixels, inclusive of the columns/rows of the edge azure pixels, with green (3) pixels, maintaining the original azure pixel positions. If they cross (both exist in horizontal and vertical, fill both).
    *   If azure pixels are not aligned, or only one azure pixel, keep the output the same as the input.

The core concept is that azure pixels, when aligned, "bridge" or "connect" by filling the intervening space with green pixels. If not aligned or if there is only one, there are no changes.

**INSTRUCTIONS**

- generate a Python module to represent the natural language program 
- follow the template below
- all common math and science libraries are available
- create docstring only at top - but comment the workflow in the function
- use helper functions for common operations like finding objects, counting,
  measuring, moving, etc. 

remember - we are working iteratively - so this code will inform your future
self as we converge on the solution

*template:*

```python
"""
{{ natural language description of the transformation rule }}
"""

{{ imports }}

def transform(input_grid):
    # initialize output_grid

    # change output pixels 

    return output_grid

```
