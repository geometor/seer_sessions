# 23b5c85d • 002 • example_5 • investigate_coder

---

## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0
0 2 2 2 2 2 2 0 0 0
0 2 2 2 2 2 2 0 0 0
0 2 2 2 2 2 2 0 0 0
0 2 2 2 2 2 2 0 0 0
0 2 2 8 8 8 2 0 0 0
0 2 2 8 8 8 2 0 0 0
0 0 0 8 8 8 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=640x640 at 0x7FC253D0D4D0>

**output:**
```
8 8 8
8 8 8
8 8 8
```

<PIL.Image.Image image mode=RGB size=192x192 at 0x7FC253D0CF50>

## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 8 8 8 8 8 8 8 0
0 3 3 3 3 3 3 3 3 0 4 4 4 4 4 4 8 8 8 0
0 3 3 3 3 3 3 3 3 0 4 4 4 4 4 4 8 8 8 0
0 3 3 3 3 3 3 3 3 0 4 4 4 4 4 4 8 8 8 0
0 3 3 3 3 3 3 3 3 0 4 4 4 4 4 4 8 8 8 0
0 3 3 3 3 3 3 3 3 0 0 0 8 8 8 8 8 8 8 0
0 3 3 3 3 3 3 3 3 0 0 0 8 8 8 8 8 8 8 0
0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0
0 3 3 3 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0
0 3 3 3 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=1280x1280 at 0x7FC253D0C2D0>

**output:**
```
1 1 1
1 1 1
```

<PIL.Image.Image image mode=RGB size=192x128 at 0x7FC253D0F450>

## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 2 2 2 0 0 0
0 0 3 3 3 3 0 0 0 2 2 2 0 0 0
0 0 3 3 3 3 0 0 0 2 2 2 0 0 0
0 0 3 3 3 3 0 0 0 2 2 2 0 0 0
0 0 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 3 3 3 6 6 0 0 0 0 0 0 0 0
0 0 3 3 3 6 6 0 0 0 0 0 0 0 0
0 0 3 3 3 6 6 0 0 0 0 0 0 0 0
0 0 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 3 3 3 3 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=960x640 at 0x7FC253D0C150>

**output:**
```
6 6
6 6
6 6
```

<PIL.Image.Image image mode=RGB size=128x192 at 0x7FC253D0F9D0>

## train_4

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 2 2 2 2 2 2 2 2 2 2 2 2 2 0
0 2 2 2 2 2 2 2 2 2 2 2 2 2 0
0 2 2 7 7 7 7 2 2 2 2 2 2 2 0
0 2 2 7 7 7 7 2 2 2 2 2 2 2 0
0 2 2 7 7 7 7 2 2 2 2 2 2 2 0
0 2 2 2 2 2 2 2 2 2 2 2 2 2 0
0 2 2 2 2 2 2 2 2 2 2 2 2 2 0
0 2 2 2 2 2 3 3 3 3 3 3 3 2 0
0 0 0 0 0 0 3 3 3 3 3 3 3 0 0
0 0 0 0 0 0 3 3 3 3 3 3 3 0 0
0 0 0 0 0 0 3 3 3 3 3 3 3 0 0
```

<PIL.Image.Image image mode=RGB size=960x832 at 0x7FC253D0FB50>

**output:**
```
7 7 7 7
7 7 7 7
7 7 7 7
```

<PIL.Image.Image image mode=RGB size=256x192 at 0x7FC253D0C7D0>

## train_5

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 1 1 1 1 1 0 0 0 0 0 0
0 1 1 1 1 1 1 1 1 0 0 4 4 0 0
0 1 1 1 1 1 1 1 1 0 0 4 4 0 0
0 1 1 1 1 1 1 1 1 0 0 0 0 0 0
0 1 1 1 1 1 1 1 1 0 0 0 0 0 0
0 1 1 1 1 1 1 1 1 0 0 0 0 0 0
0 1 1 1 1 1 1 1 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 6 6 6 6 6 6 6 0 0 0 0
0 0 0 0 6 6 6 6 6 6 6 0 0 0 0
0 0 0 0 6 6 6 6 6 6 6 0 0 0 0
0 0 0 0 6 6 6 6 6 6 6 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=960x1152 at 0x7FC253D0F6D0>

**output:**
```
4 4
4 4
```

<PIL.Image.Image image mode=RGB size=128x128 at 0x7FC253D0F4D0>
<PIL.Image.Image image mode=RGB size=4992x1552 at 0x7FC253C822D0>Okay, I've reviewed the provided input-output pairs. Here's my analysis:

**Perception of Elements:**

The task involves identifying and extracting a specific colored object within a larger grid. The input grids contain multiple rectangular objects of different colors, often surrounded by or adjacent to background pixels (color 0, white). The output grid consistently represents a single, isolated instance of one of these colored rectangles, and *not* the largest. The extracted rectangle's dimensions and color vary across examples, indicating that size and color are likely parameters in the transformation rule. Crucially, there are often multiple objects of different colors, and the target object is *not* the largest, nor is it defined by shape.

**YAML Block (Facts):**


```yaml
task_description: |
  The task is to isolate a specific colored rectangular object from a grid containing multiple objects of different colors.
objects:
  - type: grid
    description: 2D array of integers representing colors.
    attributes:
      - height
      - width
      - cells (with color values)
  - type: rectangle
    description: A contiguous block of pixels of the same color.
    attributes:
      - color
      - top_left_corner_coordinates
      - height
      - width
relationships:
  - Rectangles are contained within the grid.
  - Rectangles can be adjacent to other rectangles or the grid boundary.
actions:
  - identify: Locate all rectangular objects within the input grid.
  - select: Choose one specific rectangle based on its color (and potentially other attributes).
  - extract: Create a new grid containing only the selected rectangle.
parameters:
  - target_color: The color of the rectangle to be extracted.
```


**Natural Language Program:**

1.  **Scan the input grid:** Examine each cell to identify distinct rectangular objects. A rectangular object is defined as a contiguous block of cells sharing the same color.

2.  **Identify candidate object:** Find a non-white (color 0) region.

3.  **Target Object:** The output is formed of a grid of the shape and color of the identified candidate object.

4. **Extract and Output:** Create a new grid containing the extracted rectangle.

In summary, the core logic is to select and copy a rectangle of a specific, consistent, color into a smaller grid. The color is not the same across all examples, but appears to be consistent within each example.

**INSTRUCTIONS**

- generate a Python module to represent the natural language program 
- follow the template below
- all common math and science libraries are available
- create docstring only at top - but comment the workflow in the function
- use helper functions for common operations like finding objects, counting,
  measuring, moving, etc. 

remember - we are working iteratively - so this code will inform your future
self as we converge on the solution

*template:*

```python
"""
{{ natural language description of the transformation rule }}
"""

{{ imports }}

def transform(input_grid):
    # initialize output_grid

    # change output pixels 

    return output_grid

```
