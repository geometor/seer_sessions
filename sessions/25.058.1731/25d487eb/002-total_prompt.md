# 25d487eb • 002 • example_3 • investigate_coder

---

## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 2 0 0 0 0 0 0 0 0 0 0 0
0 0 0 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 1 2 2 0 0 0 0 0 0 0 0 0
0 0 0 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 2 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=960x640 at 0x7C360455CED0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 2 0 0 0 0 0 0 0 0 0 0 0
0 0 0 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 1 2 2 1 1 1 1 1 1 1 1 1
0 0 0 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 2 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=960x640 at 0x7C360455DCD0>

## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 0 0 0 0 0
0 0 0 0 0 8 8 8 0 0 0 0
0 0 0 0 8 8 8 8 8 0 0 0
0 0 0 8 8 8 3 8 8 8 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=768x768 at 0x7C360455E0D0>

**output:**
```
0 0 0 0 0 0 3 0 0 0 0 0
0 0 0 0 0 0 3 0 0 0 0 0
0 0 0 0 0 0 3 0 0 0 0 0
0 0 0 0 0 0 3 0 0 0 0 0
0 0 0 0 0 0 3 0 0 0 0 0
0 0 0 0 0 0 8 0 0 0 0 0
0 0 0 0 0 8 8 8 0 0 0 0
0 0 0 0 8 8 8 8 8 0 0 0
0 0 0 8 8 8 3 8 8 8 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=768x768 at 0x7C36045030D0>

## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 3 3 2 3 3 0 0 0 0 0
0 0 0 3 3 3 0 0 0 0 0 0
0 0 0 0 3 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=768x960 at 0x7C360455FCD0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 3 3 2 3 3 0 0 0 0 0
0 0 0 3 3 3 0 0 0 0 0 0
0 0 0 0 3 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=768x960 at 0x7C3604500650>
<PIL.Image.Image image mode=RGB size=2576x1970 at 0x7C36045033D0>Okay, let's analyze this ARC task.

**Perception of Elements:**

The task involves 2D grids containing colored pixels. The colors represent different objects or parts of objects. There's a clear transformation happening between the input and output grids. The transformations seem to involve adding or extending existing objects based on some internal rule related to the shapes. In the provided training examples, the "objectness" concept is evident in compact shapes of color, but it does get interesting in train_1, train_2.

**YAML Fact Documentation:**


```yaml
facts:
  - object: shape_1
    properties:
      - color: varies (red, azure, green)
      - shape: irregular, but contiguous
      - function:  base_shape
  - object: extension
      - color: varies (blue, green,red)
      - shape: linear, vertical or horizontal
      - function: extends from base shape
  - relation: extension extends base_shape
  - action: extend
    description: "A shape is extended vertically or horizontally."
    parameters:
        - direction: infered from shape (vertical, horizontal)
        - color: based on location relative to shape
        - location: derived from the base_shape

```


**Natural Language Program:**

1.  **Identify the Base Shape:** Locate the largest contiguous, non-rectangular colored shape in the input grid. This is our "base shape". Note its original color or colors.
2.  **Determine Extension Direction:**
    *   If train example 1, the base_shape has a horizontal shape, extend horizontally.
    *   If train example 2, the base_shape has a vertical shape. Extend vertically.
    *    If train example 3, extend a vertical shape of color 2.
3.  **Extend the Shape:**
    * If the base_shape has a horizontal component and does not have a vertical component. Extend the shape horizontally across the entire grid.
	* If the base_shape has a a vertical component and a horizontal component. Add a shape to extend vertically below it.

The trick appears to be when both a horizontal and vertical component exist, extend vertically only. Also extend any shape 2 vertically.

**INSTRUCTIONS**

- generate a Python module to represent the natural language program 
- follow the template below
- all common math and science libraries are available
- create docstring only at top - but comment the workflow in the function
- use helper functions for common operations like finding objects, counting,
  measuring, moving, etc. 

remember - we are working iteratively - so this code will inform your future
self as we converge on the solution

*template:*

```python
"""
{{ natural language description of the transformation rule }}
"""

{{ imports }}

def transform(input_grid):
    # initialize output_grid

    # change output pixels 

    return output_grid

```
