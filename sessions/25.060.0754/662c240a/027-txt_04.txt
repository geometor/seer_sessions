import numpy as np

# Mock data based on task description
examples = [
    {'input': np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), 'output': np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])},
    {'input': np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]), 'output': np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])},
    {'input': np.array([[5, 5, 5], [5, 5, 5], [5, 5, 5]]), 'output': np.array([[5, 5, 5], [5, 5, 5], [5, 5, 5]])},
      {'input': np.array([[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]), 'output': np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])}
]
def grid_to_text(grid):
    return '\n'.join(''.join(str(cell) for cell in row) for row in grid)

def calculate_metrics(examples):
    metrics = []
    for i, example in enumerate(examples):
        input_grid = example['input']
        output_grid = example['output']
        input_text = grid_to_text(input_grid)
        output_text = grid_to_text(output_grid)
        
        input_shape = input_grid.shape
        output_shape = output_grid.shape

        # result = transform(input_grid.copy()) #transform is not defined
        result = input_grid[:3,:3]
        result_text = grid_to_text(result)
        
        correct = np.array_equal(result, output_grid)

        metrics.append({
            'example_index': i,
            'input_shape': input_shape,
            'output_shape': output_shape,
            'correct': correct,
            'input': input_text,
            'expected_output': output_text,
            'actual_output': result_text
        })
    return metrics

metrics = calculate_metrics(examples)

for m in metrics:
  print(m)