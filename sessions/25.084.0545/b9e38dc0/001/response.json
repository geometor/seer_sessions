{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\n1. **Identify Interior Objects:** Locate all contiguous blocks of pixels of the same color that are not on the border of the grid.\n\n2. **Process object colour changes:** For each input interior object do the following:\n    - Check the object's color in the input grid.\n    - Find the object's color in the output grid.\n    - Change all matching colours in the input grid to match the object's new colour.\n\n3. **Propagate color changes on same row or column:** For all changed interior object pixels do the following:\n    - Check the cells directly to the left and right (on the same row).\n    - If the adjacent cell is the same colour as the *original* colour of the updated object, update it.\n    - If the adjacent cell now matches the updated object, continue checking its adjacent cells.\n    - Perform the same operation on cells directly above and below.\n\n4.  **Process all remaining unchanged cells:** check the input and output examples to determine if any of the remaining unchanged cell colors map from one colour to another\n\"\"\"\n\nimport numpy as np\n\ndef find_interior_objects(grid):\n    \"\"\"Finds contiguous blocks of same-colored pixels not on the border.\"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros((rows, cols), dtype=bool)\n    objects = []\n\n    def is_interior(r, c):\n        \"\"\"Checks if a cell is within the interior of the grid.\"\"\"\n        return 0 < r < rows - 1 and 0 < c < cols - 1\n\n    def dfs(r, c, color, obj_coords):\n        \"\"\"Depth-first search to find contiguous pixels.\"\"\"\n        if (\n            r < 0 or r >= rows or c < 0 or c >= cols or\n            visited[r, c] or grid[r, c] != color or not is_interior(r,c)\n        ):\n            return\n\n        visited[r, c] = True\n        obj_coords.append((r, c))\n        dfs(r + 1, c, color, obj_coords)\n        dfs(r - 1, c, color, obj_coords)\n        dfs(r, c + 1, color, obj_coords)\n        dfs(r, c - 1, color, obj_coords)\n\n    for r in range(1, rows - 1):\n        for c in range(1, cols - 1):\n            if not visited[r, c] and is_interior(r, c):\n                obj_coords = []\n                dfs(r, c, grid[r, c], obj_coords)\n                if obj_coords:\n                    objects.append((grid[r,c], obj_coords))\n    return objects\n\ndef propagate_changes(grid, changed_pixels):\n    \"\"\" Propagates color changes horizontally and vertically.\n    \"\"\"\n    rows, cols = grid.shape\n    new_changes = set()\n\n    while changed_pixels:\n        next_changed_pixels = set()\n        for r, c, old_color, new_color in changed_pixels:\n            \n            # Check neighbors (up, down, left, right)\n            neighbors = [(r-1, c), (r+1, c), (r, c-1), (r, c+1)]\n            for nr, nc in neighbors:\n                if 0 <= nr < rows and 0 <= nc < cols and grid[nr, nc] == old_color:\n                    grid[nr, nc] = new_color\n                    next_changed_pixels.add( (nr, nc, old_color, new_color) )\n        \n        changed_pixels = next_changed_pixels\n\n    return\n\ndef transform(input_grid):\n    \"\"\"Transforms the input grid according to the observed rules.\"\"\"\n\n    # Make copies to avoid modifying the input directly.\n    input_grid = np.array(input_grid)\n    # initialize output grid\n    output_grid = np.copy(input_grid)\n\n    # find objects\n    input_objects = find_interior_objects(input_grid)\n    \n    # Create a dictionary of color mappings based on all examples.\n    color_mappings = {}\n\n    # Process interior object changes.\n    changed_pixels = set()\n    for color, coords in input_objects:\n        first_coord = coords[0]\n        \n        # get changed color for this object from examples\n        new_color = None\n        for train_input, train_output in zip(train_inputs, train_outputs):\n             train_input_grid = np.array(train_input)\n             train_output_grid = np.array(train_output)\n             if (first_coord[0] < train_input_grid.shape[0] and\n                first_coord[1] < train_input_grid.shape[1] and\n                train_input_grid[first_coord] == color):\n                 new_color = train_output_grid[first_coord]\n                 break\n    \n        # apply to output grid\n        if new_color != None:\n          for r, c in coords:\n              output_grid[r, c] = new_color\n              changed_pixels.add((r, c, color, new_color)) # store original color\n              \n    propagate_changes(output_grid, changed_pixels)\n\n    # Now that all other changes are made, map remaining colors\n    for train_input, train_output in zip(train_inputs, train_outputs):\n        train_input_grid = np.array(train_input)\n        train_output_grid = np.array(train_output)\n\n        for r in range(train_input_grid.shape[0]):\n            for c in range(train_input_grid.shape[1]):\n              input_val = train_input_grid[r,c]\n              output_val = train_output_grid[r,c]\n              if input_val != output_val:\n                color_mappings[input_val] = output_val\n\n    rows, cols = output_grid.shape\n    for r in range(rows):\n        for c in range(cols):\n            if output_grid[r,c] in color_mappings:\n                output_grid[r,c] = color_mappings[output_grid[r,c]]\n\n    return output_grid\n\n# Global variables to store training data for color mapping.\ntrain_inputs = []\ntrain_outputs = []\n\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 4396,
    "candidates_token_count": 1468,
    "total_token_count": 5864,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.0-pro-exp-02-05",
  "response_time": 20.27011
}