{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nIdentify all distinct contiguous objects of non-white pixels in the input grid.\nSeparate objects into blue (color 1) \"frame\" objects and other non-white \"content\" objects.\nFilter the content objects, keeping only those that are not adjacent (including diagonally) to any pixel of any frame object.\nDetermine the minimum bounding box enclosing all kept content objects.\nCreate an output grid sized to this bounding box.\nPlace the kept content objects into the output grid, preserving their relative positions based on the bounding box's top-left corner.\n\"\"\"\n\ndef find_objects(grid):\n    \"\"\"\n    Finds all contiguous objects of the same non-white color in the grid.\n\n    Args:\n        grid (np.array): The input grid.\n\n    Returns:\n        list: A list of tuples, where each tuple is (color, set_of_coordinates).\n              set_of_coordinates contains (row, col) tuples for pixels in the object.\n    \"\"\"\n    height, width = grid.shape\n    visited = set()\n    objects = []\n\n    for r in range(height):\n        for c in range(width):\n            if grid[r, c] != 0 and (r, c) not in visited:\n                color = grid[r, c]\n                obj_coords = set()\n                q = deque([(r, c)])\n                visited.add((r, c))\n\n                while q:\n                    row, col = q.popleft()\n                    obj_coords.add((row, col))\n\n                    # Check 4 cardinal neighbors\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        if 0 <= nr < height and 0 <= nc < width and \\\n                           grid[nr, nc] == color and (nr, nc) not in visited:\n                            visited.add((nr, nc))\n                            q.append((nr, nc))\n                \n                if obj_coords: # Ensure we found something (should always be true here)\n                     objects.append((color, obj_coords))\n\n    return objects\n\n\ndef get_neighbors(r, c, height, width):\n    \"\"\" Gets all 8 neighboring coordinates for a pixel. \"\"\"\n    neighbors = []\n    for dr in [-1, 0, 1]:\n        for dc in [-1, 0, 1]:\n            if dr == 0 and dc == 0:\n                continue\n            nr, nc = r + dr, c + dc\n            if 0 <= nr < height and 0 <= nc < width:\n                neighbors.append((nr, nc))\n    return neighbors\n\ndef transform(input_grid):\n    \"\"\"\n    Filters objects based on adjacency to blue objects and extracts them into a minimal bounding box.\n    \"\"\"\n    grid = np.array(input_grid, dtype=int)\n    height, width = grid.shape\n\n    # 1. & 2. Identify all objects and separate frame/content\n    all_objects = find_objects(grid)\n    \n    frame_objects = [obj for obj in all_objects if obj[0] == 1]\n    content_objects = [obj for obj in all_objects if obj[0] > 1] # Colors 2-9\n\n    # Create a set of all coordinates belonging to frame objects for quick lookup\n    frame_pixels = set().union(*[coords for _, coords in frame_objects])\n\n    # 3. & 4. Filter content objects: Keep those not adjacent to frame objects\n    kept_objects = []\n    for color, coords in content_objects:\n        is_adjacent_to_frame = False\n        for r, c in coords:\n            # Check 8 neighbors of each pixel in the content object\n            for nr, nc in get_neighbors(r, c, height, width):\n                if (nr, nc) in frame_pixels:\n                    is_adjacent_to_frame = True\n                    break # No need to check other neighbors for this pixel\n            if is_adjacent_to_frame:\n                break # No need to check other pixels for this object\n        \n        if not is_adjacent_to_frame:\n            kept_objects.append((color, coords))\n\n    # 5. Handle the case where no objects are kept\n    if not kept_objects:\n        # Returning a 1x1 white grid seems a reasonable default for ARC if output must exist\n        # However, the examples provided always have output objects. If test cases differ, adjust this.\n         return [[0]] \n\n    # 6. Determine the bounding box for kept objects\n    all_kept_pixels = set().union(*[coords for _, coords in kept_objects])\n    \n    # This check is technically redundant now due to the check above, but good practice\n    if not all_kept_pixels:\n         return [[0]] \n\n    min_row = min(r for r, c in all_kept_pixels)\n    max_row = max(r for r, c in all_kept_pixels)\n    min_col = min(c for r, c in all_kept_pixels)\n    max_col = max(c for r, c in all_kept_pixels)\n\n    # Calculate output grid dimensions\n    output_height = max_row - min_row + 1\n    output_width = max_col - min_col + 1\n\n    # Create and initialize the output grid\n    output_grid = np.zeros((output_height, output_width), dtype=int)\n\n    # 7. Place kept objects into the output grid, translating coordinates\n    for color, coords in kept_objects:\n        for r, c in coords:\n            # Translate coordinates relative to the bounding box's top-left corner\n            out_r = r - min_row\n            out_c = c - min_col\n            output_grid[out_r, out_c] = color\n\n    # Convert back to list of lists for the required output format\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 4047,
    "candidates_token_count": 1384,
    "total_token_count": 5431,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 27.192857,
  "retries": 1
}