
## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 8 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 8 0 0 0 0
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 8 8 4 0 0
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 4 0 0 0 0
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
8 8 8 8 8 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
8 8 8 8 8 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 0 0 0 8 0 0 0
2 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 8 8 8 4 0 0 0
2 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 2
8 8 8 8 8 8 8 2
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
```


## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 8 0 0 2
0 0 8 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 8 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 4 8 8 2
0 0 4 8 8 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 4 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 8 8 8 8 8
2 8 8 8 8 8 8 8 8 8
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 8 8 8 8 8
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```

*   **Perception:**
    *   The input grid contains a white background, two distinct vertical red lines (color 2) usually near the left and right edges, and several azure pixels (color 8) scattered between the red lines.
    *   The output grid retains the original red lines. New horizontal lines appear, primarily composed of azure (8) pixels, with some yellow (4) pixels.
    *   The azure pixels in the input act as markers or triggers. They are located on rows that are part of one of the red vertical line segments.
    *   Each input azure pixel seems to generate two horizontal lines in the output:
        1.  A line on the *same row* as the input azure pixel. This line starts from the red line on the same side as the azure pixel and extends towards the column of the azure pixel. The pixel at the azure pixel's original coordinates becomes yellow (4), and the pixels between the red line and the yellow pixel become azure (8).
        2.  A line on the *corresponding row* of the *opposite* red line segment. This line starts from the opposite red line and extends fully across the gap towards the first red line, filling the space between the two red lines (exclusive) with azure (8) pixels.
    *   The "corresponding row" is determined by the relative position within the red line segment. For example, if an azure pixel is on the 2nd row of the left red segment, the corresponding row on the right segment is the 2nd row of that segment.

*   **YAML Facts:**
    
```yaml
    elements:
      - object: background
        color: white (0)
        role: static_canvas
      - object: red_line_segment
        color: red (2)
        shape: vertical_line
        count: 2 (one left, one right)
        properties:
          - spans_multiple_rows
          - define_boundaries_for_line_drawing
        role: boundary/anchor
      - object: azure_marker
        color: azure (8)
        shape: pixel
        count: variable (>=1)
        location: within_rows_spanned_by_a_red_line_segment
        role: trigger
      - object: generated_same_side_line
        color: azure (8)
        shape: horizontal_line_segment
        role: output_element
        relationship:
          - starts_adjacent_to_source_red_line
          - extends_towards_trigger_column
          - exists_on_same_row_as_trigger
      - object: generated_yellow_endpoint
        color: yellow (4)
        shape: pixel
        role: output_element
        location: at_the_original_coordinates_of_an_azure_marker
        relationship: terminates_generated_same_side_line
      - object: generated_opposite_side_line
        color: azure (8)
        shape: horizontal_line_segment
        role: output_element
        relationship:
          - starts_adjacent_to_target_red_line
          - extends_towards_source_red_line
          - fills_space_between_red_lines
          - exists_on_row_corresponding_to_trigger_row_in_target_segment

    actions:
      - identify: locate the two vertical red line segments and their row ranges.
      - identify: locate all azure marker pixels.
      - for_each: azure marker pixel at (r, c):
          - determine: which red segment (source) row 'r' belongs to, and identify the other segment (target).
          - generate_same_side:
              - draw: horizontal line in row 'r' starting adjacent to the source red line.
              - fill: with azure (8) pixels up to, but not including, column 'c'.
              - place: yellow (4) pixel at (r, c).
          - generate_opposite_side:
              - calculate: the corresponding row 'r_target' in the target segment's row range.
              - draw: horizontal line in row 'r_target' starting adjacent to the target red line.
              - fill: with azure (8) pixels across the entire width between the two red lines (exclusive of the columns containing the red lines).
      - copy: retain the original red lines in the output.
      - maintain: keep the background white where no lines are drawn.
    ```


*   **Natural Language Program:**
    1.  Initialize the output grid as a copy of the input grid, but remove all azure (8) pixels from the copy, reverting them to white (0).
    2.  Identify the two vertical red (2) line segments. Record their column indices (`col_left`, `col_right`) and their starting and ending row indices (`row_start_left`, `row_end_left`, `row_start_right`, `row_end_right`).
    3.  Find all azure (8) pixels in the *original input* grid.
    4.  For each found azure pixel at input coordinates (`r`, `c`):
        a.  **Determine Source/Target:** Check if row `r` falls within the range [`row_start_left`, `row_end_left`].
            *   If yes, the left segment is the 'source' and the right is the 'target'. Set `source_col = col_left`, `target_col = col_right`, `source_row_start = row_start_left`, `target_row_start = row_start_right`.
            *   If no (meaning `r` is in the right segment's range), the right segment is the 'source' and the left is the 'target'. Set `source_col = col_right`, `target_col = col_left`, `source_row_start = row_start_right`, `target_row_start = row_start_left`.
        b.  **Generate Same-Side Line:**
            *   Place a yellow (4) pixel in the output grid at (`r`, `c`).
            *   Determine the range of columns to fill with azure (8):
                *   If source is left (`source_col = col_left`), fill columns from `col_left + 1` to `c - 1` in row `r` with azure (8).
                *   If source is right (`source_col = col_right`), fill columns from `c + 1` to `col_right - 1` in row `r` with azure (8).
        c.  **Generate Opposite-Side Line:**
            *   Calculate the relative row index within the source segment: `relative_row = r - source_row_start`.
            *   Calculate the corresponding row index in the target segment: `r_target = target_row_start + relative_row`.
            *   Determine the range of columns to fill with azure (8) in row `r_target`: Fill columns from `min(col_left, col_right) + 1` to `max(col_left, col_right) - 1` with azure (8).
    5.  The final output grid contains the original red lines and the newly generated yellow and azure pixels.
```python
import numpy as np
from typing import List, Tuple

"""
Transformation Rule:

1.  Identify the two vertical red (2) line segments in the input grid. Record their column indices and row ranges.
2.  Identify all azure (8) marker pixels in the input grid.
3.  Initialize the output grid as a copy of the input grid, but replace all azure (8) pixels with white (0).
4.  For each azure marker pixel at input coordinates (r, c):
    a. Determine which red line segment ('source') its row 'r' belongs to and identify the other segment ('target').
    b. On the output grid, place a yellow (4) pixel at the marker's original coordinates (r, c).
    c. Draw a horizontal azure (8) line segment in row 'r' starting from the column adjacent to the source red line and extending up to (but not including) column 'c'.
    d. Calculate the corresponding row 'r_target' in the target red line segment based on the relative position of 'r' within the source segment.
    e. Draw a horizontal azure (8) line segment in row 'r_target' that spans the full width between the two red lines (exclusive of the red line columns).
5.  The final output grid contains the original red lines, the generated yellow markers, and the two types of generated azure horizontal lines.
"""

def find_vertical_lines(grid: np.ndarray, color: int) -> List[Tuple[int, int, int]]:
    """
    Finds contiguous vertical line segments of a specific color.

    Args:
        grid: The input grid (numpy array).
        color: The color value to search for.

    Returns:
        A list of tuples, where each tuple represents a line:
        (column_index, start_row_index, end_row_index).
    """
    lines = []
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)

    for c in range(cols):
        for r in range(rows):
            if grid[r, c] == color and not visited[r, c]:
                start_r = r
                end_r = r
                visited[r, c] = True
                # Extend downwards
                curr_r = r + 1
                while curr_r < rows and grid[curr_r, c] == color:
                    visited[curr_r, c] = True
                    end_r = curr_r
                    curr_r += 1
                # Check if it's just a single point or a line segment
                # For this task, we consider single points as lines of length 1
                lines.append((c, start_r, end_r))
    return lines

def find_pixels(grid: np.ndarray, color: int) -> List[Tuple[int, int]]:
    """Finds all pixels of a specific color."""
    pixels = np.argwhere(grid == color)
    # Convert numpy array rows to tuples: [(r1, c1), (r2, c2), ...]
    return [tuple(p) for p in pixels]

def transform(input_grid: List[List[int]]) -> List[List[int]]:
    """
    Applies the transformation rule to the input grid.

    Args:
        input_grid: A 2D list representing the input grid.

    Returns:
        A 2D list representing the output grid.
    """
    input_arr = np.array(input_grid, dtype=int)
    output_arr = np.array(input_grid, dtype=int)
    rows, cols = input_arr.shape

    # Initialize output grid by removing azure markers
    output_arr[output_arr == 8] = 0

    # 1. Identify the two vertical red (2) line segments
    red_lines = find_vertical_lines(input_arr, 2)
    if len(red_lines) != 2:
        # Fallback or error handling if assumption is wrong
        # For now, return the initialized grid if structure isn't as expected
        print(f"Warning: Expected 2 red lines, found {len(red_lines)}. Returning initial state.")
        return output_arr.tolist()

    # Sort lines by column index to identify left and right
    red_lines.sort(key=lambda x: x[0])
    col_left, row_start_left, row_end_left = red_lines[0]
    col_right, row_start_right, row_end_right = red_lines[1]

    # 2. Identify all azure (8) marker pixels in the *original* input
    azure_markers = find_pixels(input_arr, 8)

    # 3 & 4. Process each azure marker
    for r, c in azure_markers:
        # a. Determine Source/Target
        source_col, target_col = -1, -1
        source_row_start, target_row_start = -1, -1
        is_left_source = False

        if row_start_left <= r <= row_end_left:
            source_col, target_col = col_left, col_right
            source_row_start, target_row_start = row_start_left, row_start_right
            is_left_source = True
        elif row_start_right <= r <= row_end_right:
            source_col, target_col = col_right, col_left
            source_row_start, target_row_start = row_start_right, row_start_left
            is_left_source = False
        else:
            # Marker not aligned with any red line's row range - skip?
            # Based on examples, this shouldn't happen.
            continue

        # b. Place yellow marker
        if 0 <= r < rows and 0 <= c < cols:
             output_arr[r, c] = 4

        # c. Draw same-side azure line
        if is_left_source:
            # Source is left red line
            fill_start_col = source_col + 1
            fill_end_col = c # Exclusive end for slicing
            if fill_start_col < fill_end_col:
                 output_arr[r, fill_start_col:fill_end_col] = 8
        else:
            # Source is right red line
            fill_start_col = c + 1
            fill_end_col = source_col # Exclusive end for slicing
            if fill_start_col < fill_end_col:
                 output_arr[r, fill_start_col:fill_end_col] = 8

        # d. Calculate target row
        relative_row = r - source_row_start
        r_target = target_row_start + relative_row

        # Check if target row is valid (should be if red lines have same height,
        # but good to check)
        # Also need to check if the corresponding target red line segment exists
        # at that row. Let's refine target row check:
        target_row_start_check, target_row_end_check = -1, -1
        if is_left_source: # Target is right
            target_row_start_check, target_row_end_check = row_start_right, row_end_right
        else: # Target is left
            target_row_start_check, target_row_end_check = row_start_left, row_end_left
            
        if not (target_row_start_check <= r_target <= target_row_end_check):
             # If the calculated target row is outside the bounds of the target red line, skip drawing
             # This might happen if red lines have different lengths - examples suggest they match up
             continue


        # e. Draw opposite-side azure line
        fill_start_col_opp = min(col_left, col_right) + 1
        fill_end_col_opp = max(col_left, col_right) # Exclusive end for slicing
        if 0 <= r_target < rows and fill_start_col_opp < fill_end_col_opp:
            output_arr[r_target, fill_start_col_opp:fill_end_col_opp] = 8

    # 5. Return the final grid
    return output_arr.tolist()
```
```python
import numpy as np
from typing import List, Tuple

"""
Transformation Rule:

1.  Initialize the output grid as a copy of the input grid, replacing all azure (8) pixels with white (0).
2.  Identify the two vertical red (2) line segments, recording their column indices (`col_left`, `col_right`) and their row spans (`row_start_left`, `row_end_left`, `row_start_right`, `row_end_right`).
3.  Find all azure (8) marker pixels in the original input grid.
4.  For each azure marker pixel at input coordinates (r, c):
    a. Determine which red line segment ('source') its row 'r' belongs to and identify the other segment ('target'). Note the source/target columns and row start/end indices.
    b. On the output grid, place a yellow (4) pixel at the marker's original coordinates (r, c).
    c. Draw a horizontal azure (8) line segment in row 'r' starting from the column adjacent to the source red line and extending up to (but not including) column 'c'.
    d. Calculate the corresponding row 'r_target' in the target red line segment based on the relative position of 'r' within the source segment.
    e. Check if 'r_target' falls within the row span of the target red line segment.
    f. If 'r_target' is valid, draw a horizontal azure (8) line segment in row 'r_target' that spans the columns strictly between the two red lines (i.e., from `min(col_left, col_right) + 1` to `max(col_left, col_right) - 1`).
    g. Additionally, set the pixel at (`r_target`, `target_col`) in the output grid to azure (8), overwriting the original red pixel at that location.
5.  The final output grid contains the modified red lines, the generated yellow markers, and the two types of generated azure horizontal lines.
"""

def find_vertical_lines(grid: np.ndarray, color: int) -> List[Tuple[int, int, int]]:
    """
    Finds contiguous vertical line segments of a specific color.

    Args:
        grid: The input grid (numpy array).
        color: The color value to search for.

    Returns:
        A list of tuples, where each tuple represents a line:
        (column_index, start_row_index, end_row_index). Returns empty list if no lines found.
    """
    lines = []
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)

    for c in range(cols):
        for r in range(rows):
            if grid[r, c] == color and not visited[r, c]:
                start_r = r
                end_r = r
                visited[r, c] = True
                # Extend downwards
                curr_r = r + 1
                while curr_r < rows and grid[curr_r, c] == color:
                    # Check for contiguity - simple vertical line check
                    visited[curr_r, c] = True
                    end_r = curr_r
                    curr_r += 1
                
                # Store the found segment
                lines.append((c, start_r, end_r))
                
                # Mark all pixels in the segment as visited (important if checking col by col)
                # This is already done within the inner loop, no need to repeat here unless logic changes
                
    # Filter out non-vertical lines if the logic were more complex (not needed here)
    # For this task, any contiguous block in a column is treated as a vertical line segment
    return lines


def find_pixels(grid: np.ndarray, color: int) -> List[Tuple[int, int]]:
    """Finds all pixels of a specific color."""
    pixels = np.argwhere(grid == color)
    # Convert numpy array rows to tuples: [(r1, c1), (r2, c2), ...]
    return [tuple(p) for p in pixels]

def transform(input_grid: List[List[int]]) -> List[List[int]]:
    """
    Applies the transformation rule to the input grid.

    Args:
        input_grid: A 2D list representing the input grid.

    Returns:
        A 2D list representing the output grid.
    """
    input_arr = np.array(input_grid, dtype=int)
    output_arr = np.array(input_grid, dtype=int)
    rows, cols = input_arr.shape

    # 1. Initialize output grid by removing azure markers
    output_arr[output_arr == 8] = 0

    # 2. Identify the two vertical red (2) line segments
    red_lines = find_vertical_lines(input_arr, 2)
    if len(red_lines) != 2:
        # Fallback or error handling if assumption is wrong
        # Return the initialized grid if structure isn't as expected
        # This might happen in edge cases or malformed inputs.
        return output_arr.tolist()

    # Sort lines by column index to identify left and right
    red_lines.sort(key=lambda x: x[0])
    col_left, row_start_left, row_end_left = red_lines[0]
    col_right, row_start_right, row_end_right = red_lines[1]

    # 3. Identify all azure (8) marker pixels in the *original* input
    azure_markers = find_pixels(input_arr, 8)

    # 4. Process each azure marker
    for r, c in azure_markers:
        # a. Determine Source/Target
        source_col, target_col = -1, -1
        source_row_start, target_row_start, target_row_end = -1, -1, -1
        is_left_source = False

        if row_start_left <= r <= row_end_left:
            source_col, target_col = col_left, col_right
            source_row_start = row_start_left
            target_row_start, target_row_end = row_start_right, row_end_right
            is_left_source = True
        elif row_start_right <= r <= row_end_right:
            source_col, target_col = col_right, col_left
            source_row_start = row_start_right
            target_row_start, target_row_end = row_start_left, row_end_left
            is_left_source = False
        else:
            # Marker not aligned with any red line's row range - skip this marker
            continue

        # b. Place yellow marker
        if 0 <= r < rows and 0 <= c < cols:
             output_arr[r, c] = 4

        # c. Draw same-side azure line segment
        if is_left_source:
            # Source is left red line
            fill_start_col = source_col + 1
            fill_end_col = c # Exclusive end for slicing/range
            if fill_start_col < fill_end_col: # Ensure start < end
                 output_arr[r, fill_start_col:fill_end_col] = 8
        else:
            # Source is right red line
            fill_start_col = c + 1
            fill_end_col = source_col # Exclusive end for slicing/range
            if fill_start_col < fill_end_col: # Ensure start < end
                 output_arr[r, fill_start_col:fill_end_col] = 8

        # d. Calculate potential target row
        relative_row = r - source_row_start
        r_target = target_row_start + relative_row

        # e. Check if target row is valid within the target segment's bounds
        if not (target_row_start <= r_target <= target_row_end):
             # If the calculated target row is outside the bounds of the target red line, skip drawing opposite line
             continue
             
        # Ensure r_target is within grid boundaries (redundant if target_row_end is valid, but safe)
        if not (0 <= r_target < rows):
             continue

        # f. Draw opposite-side azure line segment (between red lines)
        # Ensure correct order for slicing, always use min_col+1 to max_col
        fill_start_col_opp = min(col_left, col_right) + 1
        fill_end_col_opp = max(col_left, col_right) # Exclusive end for slicing
        if fill_start_col_opp < fill_end_col_opp: # Check if there's space between lines
            output_arr[r_target, fill_start_col_opp:fill_end_col_opp] = 8

        # g. Overwrite the target red pixel with azure
        if 0 <= target_col < cols: # Check if target_col is valid
             output_arr[r_target, target_col] = 8

    # 5. Return the final grid
    return output_arr.tolist()
```

Previous Code:
```python
import numpy as np
from typing import List, Tuple

"""
Transformation Rule:

1.  Initialize the output grid as a copy of the input grid, replacing all azure (8) pixels with white (0).
2.  Identify the two vertical red (2) line segments, recording their column indices (`col_left`, `col_right`) and their row spans (`row_start_left`, `row_end_left`, `row_start_right`, `row_end_right`).
3.  Find all azure (8) marker pixels in the original input grid.
4.  For each azure marker pixel at input coordinates (r, c):
    a. Determine which red line segment ('source') its row 'r' belongs to and identify the other segment ('target'). Note the source/target columns and row start/end indices.
    b. On the output grid, place a yellow (4) pixel at the marker's original coordinates (r, c).
    c. Draw a horizontal azure (8) line segment in row 'r' starting from the column adjacent to the source red line and extending up to (but not including) column 'c'.
    d. Calculate the corresponding row 'r_target' in the target red line segment based on the relative position of 'r' within the source segment.
    e. Check if 'r_target' falls within the row span of the target red line segment.
    f. If 'r_target' is valid, draw a horizontal azure (8) line segment in row 'r_target' that spans the columns strictly between the two red lines (i.e., from `min(col_left, col_right) + 1` to `max(col_left, col_right) - 1`).
    g. Additionally, set the pixel at (`r_target`, `target_col`) in the output grid to azure (8), overwriting the original red pixel at that location.
5.  The final output grid contains the modified red lines, the generated yellow markers, and the two types of generated azure horizontal lines.
"""

def find_vertical_lines(grid: np.ndarray, color: int) -> List[Tuple[int, int, int]]:
    """
    Finds contiguous vertical line segments of a specific color.

    Args:
        grid: The input grid (numpy array).
        color: The color value to search for.

    Returns:
        A list of tuples, where each tuple represents a line:
        (column_index, start_row_index, end_row_index). Returns empty list if no lines found.
    """
    lines = []
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)

    for c in range(cols):
        for r in range(rows):
            if grid[r, c] == color and not visited[r, c]:
                start_r = r
                end_r = r
                visited[r, c] = True
                # Extend downwards
                curr_r = r + 1
                while curr_r < rows and grid[curr_r, c] == color:
                    # Check for contiguity - simple vertical line check
                    visited[curr_r, c] = True
                    end_r = curr_r
                    curr_r += 1
                
                # Store the found segment
                lines.append((c, start_r, end_r))
                
                # Mark all pixels in the segment as visited (important if checking col by col)
                # This is already done within the inner loop, no need to repeat here unless logic changes
                
    # Filter out non-vertical lines if the logic were more complex (not needed here)
    # For this task, any contiguous block in a column is treated as a vertical line segment
    return lines


def find_pixels(grid: np.ndarray, color: int) -> List[Tuple[int, int]]:
    """Finds all pixels of a specific color."""
    pixels = np.argwhere(grid == color)
    # Convert numpy array rows to tuples: [(r1, c1), (r2, c2), ...]
    return [tuple(p) for p in pixels]

def transform(input_grid: List[List[int]]) -> List[List[int]]:
    """
    Applies the transformation rule to the input grid.

    Args:
        input_grid: A 2D list representing the input grid.

    Returns:
        A 2D list representing the output grid.
    """
    input_arr = np.array(input_grid, dtype=int)
    output_arr = np.array(input_grid, dtype=int)
    rows, cols = input_arr.shape

    # 1. Initialize output grid by removing azure markers
    output_arr[output_arr == 8] = 0

    # 2. Identify the two vertical red (2) line segments
    red_lines = find_vertical_lines(input_arr, 2)
    if len(red_lines) != 2:
        # Fallback or error handling if assumption is wrong
        # Return the initialized grid if structure isn't as expected
        # This might happen in edge cases or malformed inputs.
        return output_arr.tolist()

    # Sort lines by column index to identify left and right
    red_lines.sort(key=lambda x: x[0])
    col_left, row_start_left, row_end_left = red_lines[0]
    col_right, row_start_right, row_end_right = red_lines[1]

    # 3. Identify all azure (8) marker pixels in the *original* input
    azure_markers = find_pixels(input_arr, 8)

    # 4. Process each azure marker
    for r, c in azure_markers:
        # a. Determine Source/Target
        source_col, target_col = -1, -1
        source_row_start, target_row_start, target_row_end = -1, -1, -1
        is_left_source = False

        if row_start_left <= r <= row_end_left:
            source_col, target_col = col_left, col_right
            source_row_start = row_start_left
            target_row_start, target_row_end = row_start_right, row_end_right
            is_left_source = True
        elif row_start_right <= r <= row_end_right:
            source_col, target_col = col_right, col_left
            source_row_start = row_start_right
            target_row_start, target_row_end = row_start_left, row_end_left
            is_left_source = False
        else:
            # Marker not aligned with any red line's row range - skip this marker
            continue

        # b. Place yellow marker
        if 0 <= r < rows and 0 <= c < cols:
             output_arr[r, c] = 4

        # c. Draw same-side azure line segment
        if is_left_source:
            # Source is left red line
            fill_start_col = source_col + 1
            fill_end_col = c # Exclusive end for slicing/range
            if fill_start_col < fill_end_col: # Ensure start < end
                 output_arr[r, fill_start_col:fill_end_col] = 8
        else:
            # Source is right red line
            fill_start_col = c + 1
            fill_end_col = source_col # Exclusive end for slicing/range
            if fill_start_col < fill_end_col: # Ensure start < end
                 output_arr[r, fill_start_col:fill_end_col] = 8

        # d. Calculate potential target row
        relative_row = r - source_row_start
        r_target = target_row_start + relative_row

        # e. Check if target row is valid within the target segment's bounds
        if not (target_row_start <= r_target <= target_row_end):
             # If the calculated target row is outside the bounds of the target red line, skip drawing opposite line
             continue
             
        # Ensure r_target is within grid boundaries (redundant if target_row_end is valid, but safe)
        if not (0 <= r_target < rows):
             continue

        # f. Draw opposite-side azure line segment (between red lines)
        # Ensure correct order for slicing, always use min_col+1 to max_col
        fill_start_col_opp = min(col_left, col_right) + 1
        fill_end_col_opp = max(col_left, col_right) # Exclusive end for slicing
        if fill_start_col_opp < fill_end_col_opp: # Check if there's space between lines
            output_arr[r_target, fill_start_col_opp:fill_end_col_opp] = 8

        # g. Overwrite the target red pixel with azure
        if 0 <= target_col < cols: # Check if target_col is valid
             output_arr[r_target, target_col] = 8

    # 5. Return the final grid
    return output_arr.tolist()
```
Results for code_00.py:

Train Set Results:

## Example 1:
Input:
```
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 8 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 8 0 0 0 0
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```
Expected Output:
```
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 8 8 4 0 0
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 4 0 0 0 0
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
8 8 8 8 8 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
8 8 8 8 8 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```
Transformed Output:
```
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 8 8 4 0 0
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 4 0 0 0 0
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
0 8 8 8 8 8 8 8 8 8
0 0 0 0 0 0 0 0 0 2
0 8 8 8 8 8 8 8 8 8
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```
Match: False
Pixels Off: 4
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 4.0

## Example 2:
Input:
```
0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 0 0 0 8 0 0 0
2 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
```
Expected Output:
```
0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 8 8 8 4 0 0 0
2 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 2
8 8 8 8 8 8 8 2
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
```
Transformed Output:
```
0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0
2 8 8 8 4 0 0 0
2 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 2
0 8 8 8 8 8 8 8
0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
```
Match: False
Pixels Off: 2
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 2.631578947368439

## Example 3:
Input:
```
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 8 0 0 2
0 0 8 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 8 0 0 0 0 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```
Expected Output:
```
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 4 8 8 2
0 0 4 8 8 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 4 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 8 8 8 8 8
2 8 8 8 8 8 8 8 8 8
2 0 0 0 0 0 0 0 0 0
2 8 8 8 8 8 8 8 8 8
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```
Transformed Output:
```
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 4 8 8 2
0 0 4 8 8 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 4 8 8 8 8 2
0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
8 8 8 8 8 8 8 8 8 0
8 8 8 8 8 8 8 8 8 0
2 0 0 0 0 0 0 0 0 0
8 8 8 8 8 8 8 8 8 0
2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```
Match: False
Pixels Off: 6
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 6.0
## General Assessment

The previous code correctly identified the core components: red lines, azure markers, and the generation of two types of horizontal lines (same-side and opposite-side) based on the markers. The "same-side" line generation appears correct across all examples.

The failures stem from the incorrect implementation of the "opposite-side" line generation (step 4f and 4g in the previous docstring/rule). The code incorrectly determined the start and end columns for this line and incorrectly overwrote the red pixel at the target column instead of the source column on the target row.

**Strategy:**

1.  **Verify Discrepancies:** Use code execution to confirm the exact pixel differences between the expected and generated outputs for the failed examples.
2.  **Refine Opposite-Side Line Logic:** Based on the verified discrepancies, redefine the rule for drawing the opposite-side line. Specifically, determine the correct column range to fill with azure (8) in the target row (`r_target`). It should overwrite the red pixel corresponding to the *source* column but preserve the red pixel corresponding to the *target* column.
3.  **Update YAML and Natural Language Program:** Modify the documentation and program description to accurately reflect the refined logic.

## Metrics Gathering

Let's analyze the differences for each failed example.



*code_execution:*
```python
import numpy as np

def compare_grids(grid1, grid2):
    arr1 = np.array(grid1)
    arr2 = np.array(grid2)
    if arr1.shape != arr2.shape:
        print("Shapes differ:", arr1.shape, arr2.shape)
        return None
    diff = arr1 != arr2
    diff_coords = np.argwhere(diff)
    diff_info = []
    for r, c in diff_coords:
        diff_info.append({
            "coord": (r, c),
            "expected": arr1[r, c],
            "actual": arr2[r, c]
        })
    print(f"Total different pixels: {len(diff_info)}")
    # Print first few differences for brevity
    for i, d in enumerate(diff_info):
        if i >= 5 and len(diff_info) > 10: # Limit output
             print("...")
             break
        print(f"  Coord: {d['coord']}, Expected: {d['expected']}, Actual: {d['actual']}")
    return diff_info


# --- Example 1 Data ---
expected_1 = [
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 8, 8, 8, 8, 8, 8, 4, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 8, 8, 8, 8, 4, 0, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [8, 8, 8, 8, 8, 8, 8, 8, 8, 2], # Target row for (2,7)
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [8, 8, 8, 8, 8, 8, 8, 8, 8, 2], # Target row for (4,5)
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
]
transformed_1 = [
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 8, 8, 8, 8, 8, 8, 4, 0, 0], # Correct same-side
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 8, 8, 8, 8, 4, 0, 0, 0, 0], # Correct same-side
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 8, 8, 8, 8, 8, 8, 8, 8, 8], # Incorrect opposite-side
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 8, 8, 8, 8, 8, 8, 8, 8, 8], # Incorrect opposite-side
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
]

print("--- Example 1 Differences ---")
diffs_1 = compare_grids(expected_1, transformed_1)

# --- Example 2 Data ---
expected_2 = [
    [0, 0, 0, 0, 0, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0],
    [2, 8, 8, 8, 4, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 0, 2],
    [8, 8, 8, 8, 8, 8, 8, 2], # Target row for (3,4)
    [0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0]
]
transformed_2 = [
    [0, 0, 0, 0, 0, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0],
    [2, 8, 8, 8, 4, 0, 0, 0], # Correct same-side
    [2, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 0, 2],
    [0, 8, 8, 8, 8, 8, 8, 8], # Incorrect opposite-side
    [0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0]
]
print("\n--- Example 2 Differences ---")
diffs_2 = compare_grids(expected_2, transformed_2)

# --- Example 3 Data ---
expected_3 = [
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 4, 8, 8, 2],
    [0, 0, 4, 8, 8, 8, 8, 8, 8, 2],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 4, 8, 8, 8, 8, 2],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 8, 8, 8, 8, 8, 8, 8, 8, 8], # Target row for (4,6)
    [2, 8, 8, 8, 8, 8, 8, 8, 8, 8], # Target row for (5,2)
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 8, 8, 8, 8, 8, 8, 8, 8, 8], # Target row for (7,4)
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
]
transformed_3 = [
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 4, 8, 8, 2], # Correct same-side
    [0, 0, 4, 8, 8, 8, 8, 8, 8, 2], # Correct same-side
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 4, 8, 8, 8, 8, 2], # Correct same-side
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [8, 8, 8, 8, 8, 8, 8, 8, 8, 0], # Incorrect opposite-side
    [8, 8, 8, 8, 8, 8, 8, 8, 8, 0], # Incorrect opposite-side
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [8, 8, 8, 8, 8, 8, 8, 8, 8, 0], # Incorrect opposite-side
    [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
]

print("\n--- Example 3 Differences ---")
diffs_3 = compare_grids(expected_3, transformed_3)
```

*code_execution_result:*
outcome: OUTCOME_OK
```
--- Example 1 Differences ---
Total different pixels: 4
  Coord: (np.int64(12), np.int64(0)), Expected: 8, Actual: 0
  Coord: (np.int64(12), np.int64(9)), Expected: 2, Actual: 8
  Coord: (np.int64(14), np.int64(0)), Expected: 8, Actual: 0
  Coord: (np.int64(14), np.int64(9)), Expected: 2, Actual: 8

--- Example 2 Differences ---
Total different pixels: 2
  Coord: (np.int64(13), np.int64(0)), Expected: 8, Actual: 0
  Coord: (np.int64(13), np.int64(7)), Expected: 2, Actual: 8

--- Example 3 Differences ---
Total different pixels: 6
  Coord: (np.int64(14), np.int64(0)), Expected: 2, Actual: 8
  Coord: (np.int64(14), np.int64(9)), Expected: 8, Actual: 0
  Coord: (np.int64(15), np.int64(0)), Expected: 2, Actual: 8
  Coord: (np.int64(15), np.int64(9)), Expected: 8, Actual: 0
  Coord: (np.int64(17), np.int64(0)), Expected: 2, Actual: 8
  Coord: (np.int64(17), np.int64(9)), Expected: 8, Actual: 0

```
**Analysis of Differences:**

The metric gathering confirms the visual analysis:

*   **Example 1 & 2 (Left Source):**
    *   The pixel in the target row (`r_target`) at the source column (`col_left`, i.e., col 0) is expected to be azure (8) but is actually white (0) in the transformed output.
    *   The pixel in the target row (`r_target`) at the target column (`col_right`) is expected to be red (2) but is actually azure (8) in the transformed output.
*   **Example 3 (Right Source):**
    *   The pixel in the target row (`r_target`) at the target column (`col_left`, i.e., col 0) is expected to be red (2) but is actually azure (8) in the transformed output.
    *   The pixel in the target row (`r_target`) at the source column (`col_right`, i.e., col 9) is expected to be azure (8) but is actually white (0) in the transformed output.

This confirms the hypothesis: the opposite-side line should fill the target row `r_target`, starting *at* the `source_col` (inclusive) and ending *before* the `target_col` (exclusive), overwriting the original red pixel at `(r_target, source_col)` but preserving the original red pixel at `(r_target, target_col)`.

## Revised YAML Facts


```yaml
elements:
  - object: background
    color: white (0)
    role: static_canvas
  - object: red_line_segment
    color: red (2)
    shape: vertical_line
    count: 2 (one left, one right)
    properties:
      - spans_multiple_rows
      - defines_boundaries_for_line_drawing
      - defines_mapping_between_rows_via_relative_position
    role: boundary/anchor/mapping_basis
  - object: azure_marker
    color: azure (8)
    shape: pixel
    count: variable (>=1)
    location: within_rows_spanned_by_a_red_line_segment
    role: trigger
  - object: generated_same_side_line
    color: azure (8)
    shape: horizontal_line_segment
    role: output_element
    relationship:
      - starts_adjacent_to_source_red_line
      - extends_towards_trigger_column (exclusive)
      - exists_on_same_row_as_trigger
  - object: generated_yellow_endpoint
    color: yellow (4)
    shape: pixel
    role: output_element
    location: at_the_original_coordinates_of_an_azure_marker
    relationship: terminates_generated_same_side_line
  - object: generated_opposite_side_line
    color: azure (8)
    shape: horizontal_line_segment
    role: output_element
    relationship:
      - exists_on_row_corresponding_to_trigger_row_in_target_segment (r_target)
      - starts_at_source_column (inclusive, overwrites original red pixel at (r_target, source_col))
      - extends_towards_target_column (exclusive, preserves original red pixel at (r_target, target_col))
      - fills_columns_between_source_and_target (details depend on source/target orientation)

actions:
  - initialize: create output grid by copying input grid and changing all azure (8) pixels to white (0).
  - identify: locate the two vertical red line segments (color 2), recording their column index (`col_left`, `col_right`) and row ranges (`row_start_left`, `row_end_left`, `row_start_right`, `row_end_right`).
  - identify: locate all azure marker pixels (color 8) in the *original input* grid.
  - for_each: azure marker pixel at input coordinates (`r`, `c`):
      - determine: which red segment is 'source' (based on `r`) and which is 'target'. Note `source_col`, `target_col`, `source_row_start`, `target_row_start`, `target_row_end`.
      - generate_same_side:
          - place: yellow (4) pixel in the output grid at (`r`, `c`).
          - draw: horizontal line segment in row `r` with azure (8).
              - if source is left: fill columns `source_col + 1` to `c - 1`.
              - if source is right: fill columns `c + 1` to `source_col - 1`.
      - generate_opposite_side:
          - calculate: the corresponding row index `r_target = target_row_start + (r - source_row_start)`.
          - validate: check if `r_target` is within the row range `[target_row_start, target_row_end]` and within grid bounds.
          - if valid:
              - draw: horizontal line segment in row `r_target` with azure (8).
                  - if source is left (`source_col < target_col`): fill columns from `source_col` (inclusive) to `target_col` (exclusive).
                  - if source is right (`source_col > target_col`): fill columns from `target_col + 1` (inclusive) to `source_col + 1` (exclusive).
  - return: the modified output grid.

```


## Revised Natural Language Program

1.  Initialize the `output_grid` as a copy of the `input_grid`. Replace all azure (8) pixels in the `output_grid` with white (0).
2.  Identify the two vertical red (2) line segments in the `input_grid`. Record their column indices (`col_left`, `col_right`) and their starting and ending row indices (`row_start_left`, `row_end_left`, `row_start_right`, `row_end_right`). Assume `col_left < col_right`.
3.  Find the coordinates (`r`, `c`) of all azure (8) pixels in the *original* `input_grid`.
4.  For each found azure pixel at input coordinates (`r`, `c`):
    a.  **Determine Source/Target:**
        *   Check if `row_start_left <= r <= row_end_left`.
        *   If yes: `source_col = col_left`, `target_col = col_right`, `source_row_start = row_start_left`, `target_row_start = row_start_right`, `target_row_end = row_end_right`.
        *   If no (meaning `row_start_right <= r <= row_end_right`): `source_col = col_right`, `target_col = col_left`, `source_row_start = row_start_right`, `target_row_start = row_start_left`, `target_row_end = row_end_left`.
        *   If `r` does not fall into either range, skip this marker.
    b.  **Generate Same-Side Line:**
        *   Set the pixel at (`r`, `c`) in the `output_grid` to yellow (4).
        *   If the source is the left line (`source_col == col_left`): Fill columns from `source_col + 1` up to (but not including) `c` in row `r` of the `output_grid` with azure (8).
        *   If the source is the right line (`source_col == col_right`): Fill columns from `c + 1` up to (but not including) `source_col` in row `r` of the `output_grid` with azure (8).
    c.  **Generate Opposite-Side Line:**
        *   Calculate the relative row index: `relative_row = r - source_row_start`.
        *   Calculate the target row index: `r_target = target_row_start + relative_row`.
        *   Check if `r_target` is valid: `target_row_start <= r_target <= target_row_end` and `0 <= r_target < grid_height`.
        *   If `r_target` is valid:
            *   If the source is the left line (`source_col == col_left`): Fill columns from `source_col` (inclusive) up to (but not including) `target_col` in row `r_target` of the `output_grid` with azure (8).
            *   If the source is the right line (`source_col == col_right`): Fill columns from `target_col + 1` (inclusive) up to (but not including) `source_col + 1` in row `r_target` of the `output_grid` with azure (8).
5.  Return the final `output_grid`.
