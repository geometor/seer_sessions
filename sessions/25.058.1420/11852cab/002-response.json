{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\nDuplicates the vertical arms of a centrally located \"cross\" shape within a 2D grid.\n\"\"\"\n\nimport numpy as np\n\ndef find_cross_center(grid):\n    \"\"\"Finds the center row of the cross shape.\"\"\"\n    rows, cols = np.where(grid != 0)\n    if len(rows) == 0:\n        return None\n    center_row = (np.max(rows) + np.min(rows)) // 2\n    return center_row\n\ndef get_vertical_arm(grid, center_row):\n    \"\"\"Extracts the vertical arm pixels from the grid.\"\"\"\n    rows, cols = np.where(grid != 0)\n    vertical_arm_cols = []\n    for col in np.unique(cols):\n        pixels_in_col = grid[rows[cols == col], col]\n        if len(np.unique(pixels_in_col)) > 1 or len(pixels_in_col) <=2: #check if there are different colors, and at least 3 pixels\n            continue;\n\n        arm_rows = rows[cols==col]\n        \n        if center_row in arm_rows: # it's a vertical arm.\n             vertical_arm_cols.append(col)\n\n\n    return vertical_arm_cols\n            \n\ndef transform(input_grid):\n    # Initialize output_grid as a copy of the input_grid\n    output_grid = input_grid.copy()\n    rows, cols = input_grid.shape\n\n    # Find the center row of the cross\n    center_row = find_cross_center(input_grid)\n    if center_row is None:\n        return output_grid\n\n    # Get the vertical arms\n    vertical_arm_cols = get_vertical_arm(input_grid, center_row)\n\n    # Duplicate vertical arm\n    if vertical_arm_cols:\n        if center_row > 0:\n            for col in vertical_arm_cols:\n               output_grid[center_row -1, col ] = input_grid[center_row -1, col ]\n        if center_row < rows -1:\n\n            for col in vertical_arm_cols:\n               output_grid[center_row + 1, col ] = input_grid[center_row + 1, col ]\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 4584,
    "candidates_token_count": 534,
    "total_token_count": 5118,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.0-pro-exp-02-05",
  "response_time": 6.878088,
  "response_file": "002-response.json"
}