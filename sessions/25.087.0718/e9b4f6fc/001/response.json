{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nIdentifies a specific target object within the input grid, characterized by a \nuniform, single-color border enclosing an interior region. Extracts this target \nobject. Transforms the colors of the interior pixels based on the color of the \nborder (Border Color, BC), while keeping the border pixels unchanged. The \ntransformation rules depend on the BC:\n- If BC=Azure(8): Swap Red(2)<->Green(3), Swap Blue(1)<->Yellow(4).\n- If BC=Green(3): Blue(1)->Red(2), Gray(5)->Yellow(4), Azure(8)->Magenta(6).\n- If BC=Blue(1): Yellow(4)->Red(2), Azure(8)->Green(3).\nOther interior colors or colors matching the BC remain unchanged. \nThe output grid contains only the transformed target object, cropped to its \nbounding box.\n\"\"\"\n\ndef find_objects(grid):\n    \"\"\"Finds all connected components of non-background pixels.\"\"\"\n    height, width = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n    \n    for r in range(height):\n        for c in range(width):\n            if grid[r, c] != 0 and not visited[r, c]:\n                obj_pixels = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                color = grid[r, c]\n                \n                while q:\n                    row, col = q.popleft()\n                    if grid[row, col] == color: # Only include pixels of the same color initially found\n                        obj_pixels.add((row, col))\n                        # Check 8 neighbors\n                        for dr in [-1, 0, 1]:\n                            for dc in [-1, 0, 1]:\n                                if dr == 0 and dc == 0:\n                                    continue\n                                nr, nc = row + dr, col + dc\n                                if 0 <= nr < height and 0 <= nc < width and \\\n                                   grid[nr, nc] != 0 and not visited[nr, nc]:\n                                     # Check if neighbor has same color before adding to queue\n                                     if grid[nr,nc] == color:\n                                         visited[nr, nc] = True\n                                         q.append((nr, nc))\n                \n                # Re-evaluate connectivity for multi-colored objects later\n                # For now, let's group by initial color found. This might need adjustment.\n                # Let's refine find_objects to find connected non-zero regions regardless of color first.\n                \n    # --- Revised find_objects to find connected non-zero regions ---\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n    height, width = grid.shape\n    for r in range(height):\n        for c in range(width):\n            if grid[r, c] != 0 and not visited[r, c]:\n                current_object_pixels = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                current_object_pixels.add((r,c))\n\n                while q:\n                    row, col = q.popleft()\n                    \n                    # Check 8 neighbors for any non-zero color\n                    for dr in [-1, 0, 1]:\n                        for dc in [-1, 0, 1]:\n                            if dr == 0 and dc == 0:\n                                continue\n                            nr, nc = row + dr, col + dc\n                            if 0 <= nr < height and 0 <= nc < width and \\\n                               grid[nr, nc] != 0 and not visited[nr, nc]:\n                                visited[nr, nc] = True\n                                current_object_pixels.add((nr, nc))\n                                q.append((nr, nc))\n                if current_object_pixels:\n                     objects.append(current_object_pixels)\n                     \n    return objects\n\ndef get_bounding_box(obj_pixels):\n    \"\"\"Calculates the bounding box of a set of pixels.\"\"\"\n    if not obj_pixels:\n        return None\n    rows = [r for r, c in obj_pixels]\n    cols = [c for r, c in obj_pixels]\n    return min(rows), min(cols), max(rows), max(cols)\n\ndef find_target_object(grid):\n    \"\"\"Identifies the target object with a uniform border.\"\"\"\n    height, width = grid.shape\n    objects = find_objects(grid)\n    \n    target_object = None\n    target_border_color = -1\n    target_pixels = set()\n    target_bb = None\n\n    for obj_pixels in objects:\n        if not obj_pixels: continue\n\n        min_r, min_c, max_r, max_c = get_bounding_box(obj_pixels)\n        \n        border_pixels = set()\n        interior_pixels = set()\n        potential_border_colors = set()\n        \n        is_candidate = True\n        \n        # Identify potential border and interior pixels\n        for r, c in obj_pixels:\n            is_on_border = False\n            # Check 8 neighbors\n            for dr in [-1, 0, 1]:\n                for dc in [-1, 0, 1]:\n                    if dr == 0 and dc == 0:\n                        continue\n                    nr, nc = r + dr, c + dc\n                    # If neighbor is outside bounds or is background (0), it's a border pixel\n                    if not (0 <= nr < height and 0 <= nc < width) or \\\n                       (0 <= nr < height and 0 <= nc < width and grid[nr, nc] == 0) or \\\n                       (nr < min_r or nr > max_r or nc < min_c or nc > max_c): # Consider bounding box edge\n                        is_on_border = True\n                        break\n                    # Also check if neighbor is outside the current object pixel set\n                    elif (nr, nc) not in obj_pixels:\n                         is_on_border = True\n                         break\n                         \n            if is_on_border:\n                border_pixels.add((r, c))\n                potential_border_colors.add(grid[r,c])\n            else:\n                # Check if it's truly interior (all neighbours are part of the object)\n                all_neighbors_in_object = True\n                for dr in [-1, 0, 1]:\n                    for dc in [-1, 0, 1]:\n                         if dr == 0 and dc == 0: continue\n                         nr, nc = r + dr, c + dc\n                         if not (0 <= nr < height and 0 <= nc < width) or (nr, nc) not in obj_pixels:\n                             all_neighbors_in_object = False\n                             break\n                if all_neighbors_in_object:\n                    interior_pixels.add((r, c))\n                else: # It touches background or outside, so it's border\n                     border_pixels.add((r, c))\n                     potential_border_colors.add(grid[r,c])\n\n\n        # Check conditions: uniform border color and non-empty interior\n        if len(potential_border_colors) == 1 and interior_pixels:\n             border_color = potential_border_colors.pop()\n             # Final check: Ensure all border pixels actually have the border_color\n             all_border_correct_color = all(grid[r,c] == border_color for r,c in border_pixels)\n             \n             if all_border_correct_color:\n                 # Found the target object\n                 target_object = obj_pixels\n                 target_border_color = border_color\n                 target_pixels = obj_pixels # Use all pixels for cropping\n                 target_bb = (min_r, min_c, max_r, max_c)\n                 break # Assume only one such object per input based on examples\n\n    if target_object is None:\n         # Fallback or error handling if no suitable object found\n         # Based on examples, assume one always exists.\n         # If this happens, the logic needs refinement.\n         print(\"Warning: No target object found!\")\n         return None, -1, None, None, None\n\n    # Refine interior/border based on the confirmed border color\n    final_border_pixels = {p for p in target_pixels if grid[p] == target_border_color}\n    final_interior_pixels = target_pixels - final_border_pixels\n    \n    # Check if the border pixels truly enclose the interior pixels\n    # A simple check: ensure all interior pixels have neighbors ONLY within the target_pixels set\n    truly_enclosed = True\n    for r, c in final_interior_pixels:\n        all_neighbors_in_obj = True\n        for dr in [-1, 0, 1]:\n            for dc in [-1, 0, 1]:\n                if dr == 0 and dc == 0: continue\n                nr, nc = r + dr, c + dc\n                if not (0 <= nr < height and 0 <= nc < width) or (nr, nc) not in target_pixels:\n                     all_neighbors_in_obj = False\n                     break\n        if not all_neighbors_in_obj:\n             # This interior pixel touches the outside - implies border isn't fully enclosing or is malformed\n             # Reclassify this pixel as border for safety? Or is object definition wrong?\n             # Let's stick with the color based separation for now.\n             pass\n\n\n    return target_pixels, target_border_color, target_bb, final_border_pixels, final_interior_pixels\n\n\ndef transform_color(original_color, border_color):\n    \"\"\"Applies color transformation based on border color.\"\"\"\n    if border_color == 8: # Azure border\n        if original_color == 2: return 3 # Red -> Green\n        if original_color == 3: return 2 # Green -> Red\n        if original_color == 1: return 4 # Blue -> Yellow\n        if original_color == 4: return 1 # Yellow -> Blue\n    elif border_color == 3: # Green border\n        if original_color == 1: return 2 # Blue -> Red\n        if original_color == 5: return 4 # Gray -> Yellow\n        if original_color == 8: return 6 # Azure -> Magenta\n    elif border_color == 1: # Blue border\n        if original_color == 4: return 2 # Yellow -> Red\n        if original_color == 8: return 3 # Azure -> Green\n        \n    # If no specific rule applies, return the original color\n    return original_color\n\n\ndef transform(input_grid):\n    \"\"\"\n    Transforms the input grid by identifying a target object with a uniform border,\n    extracting it, and applying color transformations to its interior pixels based\n    on the border color.\n    \"\"\"\n    input_grid_np = np.array(input_grid, dtype=int)\n    \n    # 1. Find the target object, its border color, bounding box, and pixel sets\n    target_pixels, border_color, bb, border_pixel_set, interior_pixel_set = find_target_object(input_grid_np)\n\n    if target_pixels is None or bb is None:\n        # Handle error case: Maybe return input or empty grid? \n        # Based on examples, expecting one object. Let's return empty for now.\n        return np.array([[]], dtype=int) \n\n    min_r, min_c, max_r, max_c = bb\n    \n    # 2. Create the output grid based on the bounding box size\n    output_height = max_r - min_r + 1\n    output_width = max_c - min_c + 1\n    # Initialize with background color (0), though it will be overwritten\n    output_grid = np.zeros((output_height, output_width), dtype=int) \n\n    # 3. Populate the output grid, applying transformations\n    for r_idx, r in enumerate(range(min_r, max_r + 1)):\n        for c_idx, c in enumerate(range(min_c, max_c + 1)):\n            # Check if the original grid coordinate (r, c) is part of the target object\n            if (r, c) in target_pixels:\n                original_color = input_grid_np[r, c]\n                \n                # 4. Check if it's an interior pixel\n                if (r, c) in interior_pixel_set:\n                     # Apply transformation rule\n                     output_grid[r_idx, c_idx] = transform_color(original_color, border_color)\n                else: \n                     # It's a border pixel (or wasn't classified as interior), keep original color\n                     output_grid[r_idx, c_idx] = original_color\n            # else: # If the pixel wasn't part of the object, it remains 0 (background) - cropping effect\n            #    pass # Already initialized to 0\n\n    return output_grid.tolist() # Return as list of lists\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 3763,
    "candidates_token_count": 3038,
    "total_token_count": 6801,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 111.198507,
  "retries": null
}