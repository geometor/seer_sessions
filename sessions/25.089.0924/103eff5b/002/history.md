
## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 3 0 0 0 0 0 0 0 0
0 0 2 0 3 4 0 0 0 0 0 0 0
0 0 2 1 1 0 0 0 0 0 0 0 0
0 0 2 0 0 4 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 8 8 8 8 8 8 0 0 0 0 0
0 0 8 8 8 8 8 8 0 0 0 0 0
0 0 0 0 8 8 0 0 0 0 0 0 0
0 0 0 0 8 8 0 0 0 0 0 0 0
0 0 0 0 8 8 8 8 8 8 0 0 0
0 0 0 0 8 8 8 8 8 8 0 0 0
0 0 8 8 0 0 8 8 0 0 0 0 0
0 0 8 8 0 0 8 8 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 3 0 0 0 0 0 0 0 0
0 0 2 0 3 4 0 0 0 0 0 0 0
0 0 2 1 1 0 0 0 0 0 0 0 0
0 0 2 0 0 4 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 2 2 2 2 2 0 0 0 0 0
0 0 2 2 2 2 2 2 0 0 0 0 0
0 0 0 0 1 1 0 0 0 0 0 0 0
0 0 0 0 1 1 0 0 0 0 0 0 0
0 0 0 0 1 1 3 3 3 3 0 0 0
0 0 0 0 1 1 3 3 3 3 0 0 0
0 0 4 4 0 0 4 4 0 0 0 0 0
0 0 4 4 0 0 4 4 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 3 1 0 0 0 0 0 0
0 0 0 4 3 0 0 0 0 0 0 0
0 0 0 2 0 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 8 8 8 8 8 8 0 0 0 0 0
0 8 8 8 8 8 8 0 0 0 0 0
0 8 8 8 8 8 8 0 0 0 0 0
0 0 0 0 8 8 8 8 8 8 0 0
0 0 0 0 8 8 8 8 8 8 0 0
0 0 0 0 8 8 8 8 8 8 0 0
0 8 8 8 0 0 0 8 8 8 0 0
0 8 8 8 0 0 0 8 8 8 0 0
0 8 8 8 0 0 0 8 8 8 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 3 1 0 0 0 0 0 0
0 0 0 4 3 0 0 0 0 0 0 0
0 0 0 2 0 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 2 2 2 4 4 4 0 0 0 0 0
0 2 2 2 4 4 4 0 0 0 0 0
0 2 2 2 4 4 4 0 0 0 0 0
0 0 0 0 3 3 3 3 3 3 0 0
0 0 0 0 3 3 3 3 3 3 0 0
0 0 0 0 3 3 3 3 3 3 0 0
0 4 4 4 0 0 0 1 1 1 0 0
0 4 4 4 0 0 0 1 1 1 0 0
0 4 4 4 0 0 0 1 1 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
```

Okay, let's break down this task.

**Perception**

1.  **Input Structure:** The input grids are divided into two distinct regions, typically separated by several rows of white (0) pixels.
    *   The **top region** contains a small pattern composed of various colors (excluding white/0 and azure/8). This pattern seems to act as a "key" or "palette".
    *   The **bottom region** contains a larger pattern composed exclusively of azure (8) pixels against a white (0) background. This pattern acts as the area to be modified, a "lock" or "canvas".
2.  **Output Structure:** The output grid mirrors the input grid, except for the bottom region.
    *   The top "key" pattern is preserved exactly as it was in the input.
    *   The bottom "lock" pattern's shape (the positions of the originally azure pixels) is preserved, but the azure color (8) is replaced by colors drawn from the top "key" pattern.
3.  **Transformation Logic:** The core transformation lies in determining *which* color from the top pattern replaces *which* azure pixel in the bottom pattern. Observing the examples suggests a spatial relationship: each azure pixel in the bottom pattern takes on the color of the *closest* colored pixel in the top pattern.
4.  **Distance Metric:** Calculating the "closest" pixel requires a distance metric. Testing both Euclidean and Manhattan distances reveals that Manhattan distance (`|row1 - row2| + |col1 - col2|`) correctly predicts the color replacements in the examples.
5.  **Tie-breaking:** In cases where an azure pixel is equidistant (by Manhattan distance) from multiple colored pixels in the top pattern, a tie-breaking rule is needed. The examples suggest that the pixel encountered first when scanning the top pattern row-by-row, then column-by-column, determines the color.

**Facts**


```yaml
task_type: pattern_coloring
grid_properties:
  - separation: Input grid typically has a top pattern and a bottom pattern separated by white space.
  - content: Top pattern uses various colors (not white/0, not azure/8). Bottom pattern uses only azure/8 and white/0.
objects:
  - type: key_pattern
    description: The set of non-white, non-azure pixels, usually located in the upper part of the grid.
    properties: Contains multiple colors; defines the color palette for the transformation.
  - type: lock_pattern
    description: The set of azure (8) pixels, usually located in the lower part of the grid.
    properties: Composed solely of azure pixels; defines the shape to be colored.
relationships:
  - type: spatial_proximity
    from: lock_pixel (each individual azure pixel in the lock_pattern)
    to: key_pixel (each individual colored pixel in the key_pattern)
    attribute: Manhattan distance
actions:
  - action: identify_regions
    input: input_grid
    output: key_pattern_pixels, lock_pattern_pixels
  - action: copy_unchanged
    input: key_pattern_pixels, other_non_lock_pixels
    output: corresponding pixels in output_grid
  - action: determine_color
    input: lock_pixel_coords, key_pattern_pixels_coords_and_colors
    process: For a given lock pixel, calculate Manhattan distance to all key pixels. Find the minimum distance. If multiple key pixels share the minimum distance, select the one that appears first in a row-major scan of the input grid.
    output: color_to_use
  - action: replace_color
    input: lock_pixel_coords, color_to_use
    output: output_grid with the pixel at lock_pixel_coords set to color_to_use
```


**Natural Language Program**

1.  Initialize the output grid as a copy of the input grid.
2.  Identify all "key pixels" in the input grid: these are pixels that are *not* white (color 0) and *not* azure (color 8). Store their coordinates (row, column) and their color. Create a list of these key pixels, ordered by row, then by column.
3.  Identify all "lock pixels" in the input grid: these are pixels with the azure color (8). Store their coordinates (row, column).
4.  For each lock pixel identified in step 3:
    a.  Calculate the Manhattan distance from this lock pixel to every key pixel identified in step 2. The Manhattan distance between `(r1, c1)` and `(r2, c2)` is `|r1 - r2| + |c1 - c2|`.
    b.  Find the minimum Manhattan distance calculated in step 4a.
    c.  Identify all key pixels that are located at this minimum distance from the current lock pixel.
    d.  From the set of closest key pixels found in step 4c, select the one that appears earliest in the ordered list created in step 2 (this handles ties based on row-major scan order).
    e.  Get the color of the selected key pixel.
    f.  Update the output grid at the coordinates of the current lock pixel, changing its color to the color determined in step 4e.
5.  Return the final modified output grid.
```python
import numpy as np
import sys

def calculate_manhattan_distance(p1_row, p1_col, p2_row, p2_col):
    """Calculates the Manhattan distance between two points."""
    return abs(p1_row - p2_row) + abs(p1_col - p2_col)

def transform(input_grid):
    """
    Transforms the input grid based on the following rules:
    1. Identify "key" pixels (non-white, non-azure) and "lock" pixels (azure).
    2. For each lock pixel, find the closest key pixel using Manhattan distance.
    3. If there's a tie in distance, use the key pixel that appears first when scanning the grid row by row, then column by column.
    4. Replace the lock pixel's color (azure) with the color of the determined closest key pixel.
    5. Leave all other pixels unchanged.
    """
    # Convert input list of lists to a numpy array for easier indexing
    input_array = np.array(input_grid, dtype=int)
    output_array = np.copy(input_array)
    rows, cols = input_array.shape

    # 1. Identify key pixels (non-white/0, non-azure/8) and store them with original coordinates and color
    key_pixels = []
    for r in range(rows):
        for c in range(cols):
            color = input_array[r, c]
            if color != 0 and color != 8:
                key_pixels.append({'row': r, 'col': c, 'color': color})

    # 2. Identify lock pixels (azure/8)
    lock_pixels = []
    for r in range(rows):
        for c in range(cols):
            if input_array[r, c] == 8:
                lock_pixels.append({'row': r, 'col': c})

    # If there are no key pixels or no lock pixels, return the original grid
    if not key_pixels or not lock_pixels:
        return output_array.tolist()

    # 3. For each lock pixel, find the closest key pixel and update the output grid
    for lock_pixel in lock_pixels:
        lr, lc = lock_pixel['row'], lock_pixel['col']
        
        min_distance = sys.maxsize
        closest_key_color = -1 # Placeholder

        # Calculate distances to all key pixels
        distances = []
        for i, key_pixel in enumerate(key_pixels):
            kr, kc = key_pixel['row'], key_pixel['col']
            dist = calculate_manhattan_distance(lr, lc, kr, kc)
            distances.append({'distance': dist, 'index': i, 'color': key_pixel['color']})
            if dist < min_distance:
                min_distance = dist

        # Find all key pixels at the minimum distance
        closest_candidates = [d for d in distances if d['distance'] == min_distance]

        # 4. Tie-breaking: choose the candidate that appeared first in the key_pixels list (row-major order)
        # The 'index' stored in distances corresponds to the original order in key_pixels
        best_candidate = min(closest_candidates, key=lambda x: x['index'])
        closest_key_color = best_candidate['color']

        # 5. Update the output grid at the lock pixel's location
        output_array[lr, lc] = closest_key_color

    # Convert numpy array back to list of lists for the final output
    return output_array.tolist()
```
