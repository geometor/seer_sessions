{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nTransformation rule:\n1. Identify distinct contiguous shapes of non-white (0) and non-gray (5) colors in the input grid. These are \"reference shapes\". Store their relative pixel patterns (canonical forms) and their corresponding colors. The canonical form is the set of relative coordinates of the shape's pixels, normalized to start from (0,0) at the top-leftmost pixel of the shape.\n2. Identify distinct contiguous shapes of gray (5) color in the input grid. These are \"target shapes\". Store their relative pixel patterns (canonical forms) and the list of absolute pixel coordinates for each shape.\n3. Initialize the output grid as a copy of the input grid.\n4. For each identified target shape:\n    a. Compare its canonical form with the canonical forms of all reference shapes.\n    b. If a match is found with a reference shape's form, change the color of all pixels belonging to that target shape in the output grid to the color of the matching reference shape.\n    c. If no match is found with any reference shape's form, change the color of all pixels belonging to that target shape in the output grid to the background color (white, 0).\n5. Pixels that were not part of any gray target shape retain their original color from the input grid.\n\"\"\"\n\ndef find_objects(grid, colors_to_find):\n    \"\"\"\n    Finds all contiguous objects of specified colors in the grid.\n\n    Args:\n        grid (np.array): The input grid.\n        colors_to_find (set): A set of color values to search for.\n\n    Returns:\n        list: A list of dictionaries, where each dictionary represents an object\n              and contains:\n              'color': The color of the object.\n              'pixels': A list of (row, col) tuples for the object's pixels.\n              'form': A tuple of sorted (dr, dc) tuples representing the\n                      relative pixel coordinates (canonical form), normalized\n                      to the top-leftmost pixel of the object.\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros_like(grid, dtype=bool) # Keep track of visited pixels\n    objects = []\n    \n    for r in range(rows):\n        for c in range(cols):\n            color = grid[r, c]\n            # Check if the current pixel matches one of the target colors and hasn't been visited\n            if color in colors_to_find and not visited[r, c]:\n                obj_pixels = [] # Store pixels belonging to the current object\n                q = deque([(r, c)]) # Queue for BFS\n                visited[r, c] = True\n                min_r, min_c = r, c # Track the top-left corner for normalization\n                \n                # Use Breadth-First Search (BFS) to find all connected pixels of the same color\n                while q:\n                    row, col = q.popleft()\n                    obj_pixels.append((row, col))\n                    # Update the minimum row and column found so far\n                    min_r = min(min_r, row)\n                    min_c = min(min_c, col)\n                    \n                    # Explore 4 neighbors (up, down, left, right)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        # Check if neighbor is within grid bounds\n                        if 0 <= nr < rows and 0 <= nc < cols:\n                           # Check if neighbor has the same color and hasn't been visited\n                           if not visited[nr, nc] and grid[nr, nc] == color:\n                                visited[nr, nc] = True\n                                q.append((nr, nc))\n                            \n                # Calculate relative coordinates (form) normalized to the top-left corner (min_r, min_c)\n                # Sort the relative coordinates to create a canonical representation of the shape\n                relative_pixels = sorted([(p_r - min_r, p_c - min_c) for p_r, p_c in obj_pixels])\n                # Convert to tuple for hashability (use as dictionary key)\n                form = tuple(relative_pixels) \n                \n                # Store the found object's details\n                objects.append({\n                    'color': color,\n                    'pixels': obj_pixels, # Absolute coordinates\n                    'form': form          # Canonical shape representation\n                })\n                \n    return objects\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rule based on matching gray shapes to reference shapes.\n    \"\"\"\n    # Initialize output_grid as a copy of the input grid.\n    # Changes will be made directly to this copy.\n    output_grid = np.copy(input_grid)\n    rows, cols = input_grid.shape\n\n    # 1. Identify reference shapes (all non-white, non-gray colors)\n    # Determine all unique colors present in the grid\n    all_colors = set(np.unique(input_grid))\n    # Filter out white (0) and gray (5) to get the set of reference colors\n    reference_colors = all_colors - {0, 5} \n    \n    # Find all objects matching the reference colors\n    # Handle edge case where there are no reference colors\n    if not reference_colors:\n        reference_objects = []\n    else:\n        reference_objects = find_objects(input_grid, reference_colors)\n    \n    # Store reference forms and their corresponding colors in a dictionary for quick lookup\n    # The key is the canonical form (tuple of relative coordinates), value is the color.\n    reference_forms = {obj['form']: obj['color'] for obj in reference_objects}\n\n    # 2. Identify target shapes (gray color 5)\n    # Find all objects with color 5 (gray)\n    target_objects = find_objects(input_grid, {5})\n\n    # 3. Iterate through target shapes and apply transformations based on form matching\n    for target_obj in target_objects:\n        target_form = target_obj['form'] # Get the canonical form of the gray shape\n        \n        # 4a. Compare target form with reference forms\n        if target_form in reference_forms:\n            # 4b. Match found: Recolor target shape with the matched reference color\n            new_color = reference_forms[target_form]\n            for r, c in target_obj['pixels']:\n                 # Ensure coordinates are valid just in case (though BFS should keep them in bounds)\n                 if 0 <= r < rows and 0 <= c < cols: \n                     output_grid[r, c] = new_color\n        else:\n            # 4c. No match found: Erase target shape (set to white, 0)\n            new_color = 0 # Background color\n            for r, c in target_obj['pixels']:\n                 # Ensure coordinates are valid\n                 if 0 <= r < rows and 0 <= c < cols:\n                    output_grid[r, c] = new_color\n\n    # 5. Pixels not part of a gray shape retain their original color (already handled by copying input)\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 27908,
    "candidates_token_count": 1649,
    "total_token_count": 29557,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 17.824428,
  "retries": 1
}