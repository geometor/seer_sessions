
## train_1

**input:**
```
8 8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0
8 2 2 2 2 8 0 0 0 0 0 0 0 0 0 0 0
8 2 1 1 2 8 0 0 0 0 0 0 0 0 0 0 0
8 2 1 1 2 8 0 0 0 0 0 0 0 0 0 0 0
8 2 2 2 2 8 0 0 0 0 0 0 0 0 0 0 0
8 8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 6 6 6 6 6 6 6 6 6 6 6 6 0
0 0 0 0 6 3 3 3 3 3 3 3 3 3 3 6 0
0 0 0 0 6 3 4 4 4 4 4 4 4 4 3 6 0
0 0 0 0 6 3 4 2 2 2 2 2 2 4 3 6 0
0 0 0 0 6 3 4 2 1 1 1 1 2 4 3 6 0
0 0 0 0 6 3 4 2 1 1 1 1 2 4 3 6 0
0 0 0 0 6 3 4 2 2 2 2 2 2 4 3 6 0
0 0 0 0 6 3 4 4 4 4 4 4 4 4 3 6 0
0 0 0 0 6 3 3 3 3 3 3 3 3 3 3 6 0
0 0 0 0 6 6 6 6 6 6 6 6 6 6 6 6 0
```


**output:**
```
1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
1 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0
1 2 8 8 2 1 0 0 0 0 0 0 0 0 0 0 0
1 2 8 8 2 1 0 0 0 0 0 0 0 0 0 0 0
1 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0
1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0
0 0 0 0 1 2 2 2 2 2 2 2 2 2 2 1 0
0 0 0 0 1 2 4 4 4 4 4 4 4 4 2 1 0
0 0 0 0 1 2 4 3 3 3 3 3 3 4 2 1 0
0 0 0 0 1 2 4 3 6 6 6 6 3 4 2 1 0
0 0 0 0 1 2 4 3 6 6 6 6 3 4 2 1 0
0 0 0 0 1 2 4 3 3 3 3 3 3 4 2 1 0
0 0 0 0 1 2 4 4 4 4 4 4 4 4 2 1 0
0 0 0 0 1 2 2 2 2 2 2 2 2 2 2 1 0
0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0
0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0
0 0 1 1 3 3 3 3 3 3 3 3 1 1 0 0
0 0 1 1 3 8 8 8 8 8 8 3 1 1 0 0
0 0 1 1 3 8 8 8 8 8 8 3 1 1 0 0
0 0 1 1 3 8 8 2 2 8 8 3 1 1 0 0
0 0 1 1 3 8 8 2 2 8 8 3 1 1 0 0
0 0 1 1 3 8 8 8 8 8 8 3 1 1 0 0
0 0 1 1 3 8 8 8 8 8 8 3 1 1 0 0
0 0 1 1 3 3 3 3 3 3 3 3 1 1 0 0
0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0
0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0
0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0
0 0 2 2 8 8 8 8 8 8 8 8 2 2 0 0
0 0 2 2 8 3 3 3 3 3 3 8 2 2 0 0
0 0 2 2 8 3 3 3 3 3 3 8 2 2 0 0
0 0 2 2 8 3 3 1 1 3 3 8 2 2 0 0
0 0 2 2 8 3 3 1 1 3 3 8 2 2 0 0
0 0 2 2 8 3 3 3 3 3 3 8 2 2 0 0
0 0 2 2 8 3 3 3 3 3 3 8 2 2 0 0
0 0 2 2 8 8 8 8 8 8 8 8 2 2 0 0
0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0
0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_3

**input:**
```
0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 1 1 6 6 6 6 6 1 1 0 0 0 0 0 0 0
0 0 0 1 1 6 8 8 8 6 1 1 0 0 0 0 0 0 0
0 0 0 1 1 6 6 6 6 6 1 1 0 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0
0 2 4 4 4 4 4 4 4 4 4 4 2 0 0 0 0 0 0
0 2 4 1 1 1 1 1 1 1 1 4 2 0 0 0 0 0 0
0 2 4 1 8 8 8 8 8 8 1 4 2 0 0 0 0 0 0
0 2 4 1 8 8 8 8 8 8 1 4 2 0 0 0 0 0 0
0 2 4 1 1 1 1 1 1 1 1 4 2 0 0 0 0 0 0
0 2 4 4 4 4 4 4 4 4 4 4 2 0 0 0 0 0 0
0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0
```


**output:**
```
0 0 0 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0 0
0 0 0 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0 0
0 0 0 8 8 6 6 6 6 6 8 8 0 0 0 0 0 0 0
0 0 0 8 8 6 1 1 1 6 8 8 0 0 0 0 0 0 0
0 0 0 8 8 6 6 6 6 6 8 8 0 0 0 0 0 0 0
0 0 0 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0 0
0 0 0 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 8 8 8 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0
0 8 1 1 1 1 1 1 1 1 1 1 8 0 0 0 0 0 0
0 8 1 4 4 4 4 4 4 4 4 1 8 0 0 0 0 0 0
0 8 1 4 2 2 2 2 2 2 4 1 8 0 0 0 0 0 0
0 8 1 4 2 2 2 2 2 2 4 1 8 0 0 0 0 0 0
0 8 1 4 4 4 4 4 4 4 4 1 8 0 0 0 0 0 0
0 8 1 1 1 1 1 1 1 1 1 1 8 0 0 0 0 0 0
0 8 8 8 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0
```


## train_4

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 8 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0 0
0 0 8 7 7 7 7 7 7 7 7 8 0 2 2 2 2 2 2
0 0 8 7 7 7 7 7 7 7 7 8 0 2 1 1 1 1 2
0 0 8 7 7 4 4 4 4 7 7 8 0 2 1 3 3 1 2
0 0 8 7 7 4 3 3 4 7 7 8 0 2 1 3 3 1 2
0 0 8 7 7 4 3 3 4 7 7 8 0 2 1 1 1 1 2
0 0 8 7 7 4 3 3 4 7 7 8 0 2 2 2 2 2 2
0 0 8 7 7 4 3 3 4 7 7 8 0 0 0 0 0 0 0
0 0 8 7 7 4 3 3 4 7 7 8 0 0 0 0 0 0 0
0 0 8 7 7 4 4 4 4 7 7 8 0 0 0 0 0 0 0
0 0 8 7 7 7 7 7 7 7 7 8 0 0 0 0 0 0 0
0 0 8 7 7 7 7 7 7 7 7 8 0 0 0 0 0 0 0
0 0 8 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 3 3 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0
0 0 3 4 4 4 4 4 4 4 4 3 0 3 3 3 3 3 3
0 0 3 4 4 4 4 4 4 4 4 3 0 3 1 1 1 1 3
0 0 3 4 4 7 7 7 7 4 4 3 0 3 1 2 2 1 3
0 0 3 4 4 7 8 8 7 4 4 3 0 3 1 2 2 1 3
0 0 3 4 4 7 8 8 7 4 4 3 0 3 1 1 1 1 3
0 0 3 4 4 7 8 8 7 4 4 3 0 3 3 3 3 3 3
0 0 3 4 4 7 8 8 7 4 4 3 0 0 0 0 0 0 0
0 0 3 4 4 7 8 8 7 4 4 3 0 0 0 0 0 0 0
0 0 3 4 4 7 7 7 7 4 4 3 0 0 0 0 0 0 0
0 0 3 4 4 4 4 4 4 4 4 3 0 0 0 0 0 0 0
0 0 3 4 4 4 4 4 4 4 4 3 0 0 0 0 0 0 0
0 0 3 3 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

*   **Perception:**
    *   The input and output grids contain one or more distinct "objects" set against a white background (color 0).
    *   Each object consists of a series of nested, concentric frames, where each frame is a single, solid color.
    *   The frames are typically rectangular or square.
    *   The overall shape, size, and position of each object are preserved between the input and output.
    *   The transformation involves changing the colors of the frames within each object.
    *   Observing the color changes reveals a pattern: the color of the outermost frame is swapped with the color of the innermost frame, the color of the second outermost frame is swapped with the color of the second innermost frame, and so on. If an object has an odd number of frames, the middle frame's color remains unchanged.

*   **Facts:**
    
```yaml
    Objects:
      - type: Nested Frames
        properties:
          - colors: A sequence of colors, one for each frame layer, ordered from outermost to innermost.
          - shape: Geometric shape of the frames (e.g., rectangle, square). Preserved in output.
          - location: Position within the grid. Preserved in output.
          - background_color: white (0)
    Actions:
      - Identify Objects: Locate contiguous non-background color regions forming nested frames.
      - Extract Color Sequence: For each object, determine the ordered list of colors from the outermost frame to the innermost frame.
      - Reverse Color Sequence: Reverse the order of the extracted color list.
      - Apply Reversed Colors: Re-color the frames of the object in the output grid using the reversed color sequence, maintaining the original frame structure and position. The original outermost frame gets the color of the original innermost frame, the original second outermost gets the color of the original second innermost, etc.
    Relationships:
      - Frame Mapping: There is a one-to-one mapping between the input frames and output frames based on their layer position (1st layer maps to Nth layer, 2nd layer maps to (N-1)th layer, ..., Nth layer maps to 1st layer, where N is the total number of frames).
      - Color Transformation: The color of an output frame at layer 'i' (from outside) is determined by the color of the input frame at layer 'N - i + 1'.
    ```


*   **Natural Language Program:**
    1.  Identify each distinct object in the input grid. An object is a structure composed of nested, concentric frames of solid colors, surrounded by the background color (white, 0).
    2.  For each identified object:
        a.  Determine the sequence of colors of its frames, starting from the outermost frame and moving inwards to the innermost frame. Let this sequence be `C = [c1, c2, ..., cn]`, where `c1` is the outermost color and `cn` is the innermost color.
        b.  Create a reversed sequence of these colors: `C_reversed = [cn, c(n-1), ..., c1]`.
        c.  Generate the output object by keeping the original shape, size, and position of the frames, but assign the colors from the `C_reversed` sequence. The outermost frame (originally color `c1`) will now have color `cn`, the second outermost frame (originally color `c2`) will now have color `c(n-1)`, and so on, until the innermost frame (originally color `cn`) receives color `c1`.
    3.  Combine the transformed objects onto a background grid of the same dimensions as the input, filled with the background color (white, 0), to create the final output grid.
```python
import numpy as np
from scipy.ndimage import distance_transform_cdt

"""
Identifies objects composed of nested, concentric frames against a white (0) background.
For each object, determines the sequence of frame colors from outermost to innermost.
Reverses this sequence of colors.
Reconstructs the object in the output grid, preserving its shape and location, but applying the reversed color sequence to the frames.
The outermost frame layer receives the color of the original innermost frame layer, the second outermost receives the color of the second innermost, and so on.
"""

def transform(input_grid):
    """
    Transforms the input grid by reversing the color sequence of nested frames within objects.

    Args:
        input_grid (list[list[int]]): A 2D list representing the input grid.

    Returns:
        list[list[int]]: A 2D list representing the transformed output grid.
    """
    # Convert input grid to a numpy array for efficient processing
    input_array = np.array(input_grid, dtype=int)
    height, width = input_array.shape
    
    # Create an output array initialized with background color (0)
    output_array = np.zeros_like(input_array)

    # Create a boolean mask where True indicates background pixels (color 0)
    is_background = (input_array == 0)

    # Calculate the Chebyshev distance (chessboard distance) from each pixel
    # to the nearest background pixel. For non-background pixels, this effectively
    # gives the layer depth of the frame, starting from 1 for the outermost frame.
    # Background pixels will have a distance of 0.
    depth_grid = distance_transform_cdt(is_background, metric='chessboard')

    # Find the maximum depth value across the entire grid. This represents
    # the number of layers in the "deepest" object structure.
    max_depth = np.max(depth_grid)

    # If max_depth is 0, it means the grid is all background or empty.
    if max_depth == 0:
        return input_grid # Return the original grid

    # Create a map to store the original color associated with each depth layer.
    # We assume that all pixels at a given depth within a single nested structure
    # share the same color, as per the examples.
    depth_to_color = {}
    for d in range(1, max_depth + 1):
        # Find coordinates where the depth grid equals the current depth d
        coords = np.argwhere(depth_grid == d)
        if len(coords) > 0:
            # Get the color from the input array at the first coordinate found for this depth
            r, c = coords[0]
            depth_to_color[d] = input_array[r, c]
        # else: # Should not happen if max_depth >= 1, but handle defensively if needed
            # Handle case where a depth layer might theoretically exist but has no pixels (unlikely with cdt)
            # pass or assign a default/error value

    # Iterate through each pixel of the grid to build the output
    for r in range(height):
        for c in range(width):
            # Get the depth of the current pixel
            current_depth = depth_grid[r, c]

            # If the current pixel is part of a frame (depth > 0)
            if current_depth > 0:
                # Calculate the target depth for the color swap
                # Outermost (depth 1) swaps with innermost (depth max_depth)
                # Second outermost (depth 2) swaps with second innermost (depth max_depth - 1)
                # etc.
                target_depth = max_depth - current_depth + 1
                
                # Get the color corresponding to the target depth
                # Handle potential missing keys defensively, though unlikely if map built correctly
                new_color = depth_to_color.get(target_depth, 0) # Default to background if something went wrong
                
                # Assign the new color to the output grid
                output_array[r, c] = new_color
            else:
                # If it's a background pixel, keep it as background (already initialized to 0)
                pass # output_array[r, c] is already 0

    # Convert the resulting numpy array back to a list of lists
    output_grid = output_array.tolist()

    return output_grid
```
