
## train_1

**input:**
```
0 0 0 1 1 1 1 1 1 0 0 0 0 0
0 0 0 1 0 0 0 0 1 0 0 0 0 0
0 0 0 1 0 0 0 0 1 1 1 1 0 0
0 0 0 1 0 0 0 0 0 0 0 1 0 0
0 0 0 1 0 0 0 0 0 0 0 1 0 0
0 0 0 1 1 1 1 1 0 0 0 1 0 0
0 0 0 0 0 0 0 1 0 0 0 1 0 0
0 0 0 0 0 0 0 1 1 1 1 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 0
0 0 0 0 0 0 0 0 0 0 1 0 1 0
0 0 0 1 0 1 1 1 0 0 1 1 1 0
0 0 0 1 0 0 0 1 0 0 0 0 0 0
0 0 0 1 1 1 1 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 2 1 1 1 1 1 1 2 0 0 0 0
0 0 2 1 3 3 3 3 1 2 2 2 2 0
0 0 2 1 3 0 0 3 1 1 1 1 2 0
0 0 2 1 3 0 0 3 3 3 3 1 2 0
0 0 2 1 3 3 3 3 3 0 3 1 2 0
0 0 2 1 1 1 1 1 3 0 3 1 2 0
0 0 2 2 2 2 2 1 3 3 3 1 2 0
0 0 0 0 0 0 2 1 1 1 1 1 2 0
0 0 0 0 0 0 2 2 2 2 2 2 2 0
0 0 0 0 0 0 0 0 0 2 2 2 2 2
0 0 0 0 0 0 0 0 0 2 1 1 1 2
0 0 0 0 0 0 0 0 0 2 1 3 1 2
0 0 0 1 0 1 1 1 0 2 1 1 1 2
0 0 0 1 0 0 0 1 0 2 2 2 2 2
0 0 0 1 1 1 1 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0
0 1 1 1 1 1 1 0 0 0
0 1 0 0 0 0 1 0 0 0
0 1 0 0 0 0 1 0 0 0
0 1 0 0 0 0 1 0 0 0
0 1 1 1 0 1 1 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0
0 1 1 1 1 1 1 0 0 0
0 1 0 0 0 0 1 0 0 0
0 1 0 0 0 0 1 0 0 0
0 1 0 0 0 0 1 0 0 0
0 1 1 1 0 1 1 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```


## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0
0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0
0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0
0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0
1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0
0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0
0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0
0 0 2 1 1 1 1 1 1 1 2 0 0 0 0 0 0 0 0 0 0 0
0 0 2 1 3 3 3 3 3 1 2 0 0 0 0 0 0 0 0 0 0 0
0 0 2 1 3 3 3 0 3 1 2 0 0 0 0 1 1 1 1 1 0 0
0 0 2 1 1 1 3 0 3 1 2 0 0 0 0 1 0 0 0 1 0 0
0 0 2 2 2 1 3 3 3 1 2 0 0 0 1 1 0 0 0 1 0 0
0 0 0 0 2 1 1 1 1 1 2 0 0 0 1 0 0 0 0 1 0 0
0 0 0 0 2 2 2 2 2 2 2 0 0 0 1 1 0 1 0 1 0 0
1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0
0 0 0 2 2 2 2 2 2 2 0 0 0 0 1 0 0 0 0 0 0 0
0 0 0 2 2 1 1 1 1 2 0 0 0 0 1 0 1 0 0 0 0 0
0 0 0 2 1 1 3 3 1 2 0 0 0 0 1 1 1 0 0 0 0 0
0 0 0 2 1 3 3 3 1 2 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 2 1 1 1 1 1 2 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_4

**input:**
```
0 0 0 1 1 1 0 0
0 1 1 1 0 1 0 0
0 1 0 0 0 1 0 0
0 1 0 0 0 1 0 0
0 1 0 0 0 1 0 0
0 1 1 1 1 1 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
```


**output:**
```
2 2 2 1 1 1 2 0
2 1 1 1 3 1 2 0
2 1 3 3 3 1 2 0
2 1 3 0 3 1 2 0
2 1 3 3 3 1 2 0
2 1 1 1 1 1 2 0
2 2 2 2 2 2 2 0
0 0 0 0 0 0 0 0
```

Okay, let's analyze the task examples.

**Perception of Elements:**

*   The input grids contain a white (0) background and various shapes formed by blue (1) pixels.
*   The blue shapes in the input can be closed loops or open structures.
*   The output grids often introduce red (2) and green (3) pixels in relation to the blue shapes, but only when the blue shape forms a closed loop.
*   If a blue shape is not a closed loop (like in `train_2`), the output grid is identical to the input grid for that shape.
*   When a transformation occurs (for closed blue loops):
    *   Red (2) pixels appear immediately *outside* the blue (1) loop, forming a one-pixel thick border. These red pixels replace original white (0) pixels. The border seems to be placed on orthogonally adjacent white cells.
    *   Green (3) pixels fill the area *inside* the blue (1) loop, replacing the original white (0) pixels enclosed by the loop.
*   The original blue (1) shapes remain unchanged in the output.
*   Multiple independent blue shapes can exist in one grid (`train_1`, `train_3`), and the transformation rules apply individually to each closed loop.

**YAML Facts:**


```yaml
task_description: "Identify closed loops formed by blue pixels and color the areas immediately outside and inside them."
elements:
  - element: "background"
    color_name: "white"
    color_value: 0
  - element: "shape"
    color_name: "blue"
    color_value: 1
    properties:
      - "can form closed loops"
      - "can form open structures"
  - element: "outer_border"
    color_name: "red"
    color_value: 2
    properties:
      - "appears only around closed blue loops"
      - "replaces orthogonally adjacent white pixels outside the loop"
      - "is one pixel thick"
  - element: "inner_fill"
    color_name: "green"
    color_value: 3
    properties:
      - "appears only inside closed blue loops"
      - "replaces white pixels enclosed by the loop"
actions:
  - action: "identify_shapes"
    input: "input grid"
    target: "blue pixels"
    output: "sets of connected blue pixels (shapes)"
  - action: "check_closure"
    input: "blue shape"
    target: "enclosed white pixels"
    condition: "determine if the enclosed white region is bounded entirely by the blue shape (does not touch grid edge)"
    output: "boolean (is_closed_loop)"
  - action: "apply_border"
    condition: "is_closed_loop is true"
    input: "closed blue loop"
    target: "orthogonally adjacent white pixels outside the loop"
    effect: "change target pixels to red"
  - action: "apply_fill"
    condition: "is_closed_loop is true"
    input: "closed blue loop"
    target: "white pixels inside the loop"
    effect: "change target pixels to green"
relationships:
  - relationship: "spatial"
    between: ["red pixels", "blue loop"]
    details: "red pixels are orthogonally adjacent to the outside of the closed blue loop."
  - relationship: "containment"
    between: ["green pixels", "blue loop"]
    details: "green pixels are contained within the closed blue loop."
  - relationship: "conditional_transformation"
    element: "blue shape"
    condition: "shape forms a closed loop"
    effect: "red border and green fill are applied"
    alternative_effect: "no changes are applied"
```


**Natural Language Program:**

1.  Create a copy of the input grid to serve as the initial output grid.
2.  Scan the input grid to find all distinct contiguous groups (shapes) of blue (1) pixels.
3.  For each identified blue shape:
    a.  Determine if the shape forms a closed loop. This can be checked by attempting a flood fill starting from a white (0) pixel known to be adjacent to the shape. If the flood fill can reach the boundary of the grid without crossing the blue shape, the shape is not a closed loop enclosing that region. Conversely, if a flood fill initiated *within* an area surrounded by the shape cannot reach the grid boundary, it is an enclosed region, and the shape is a closed loop.
    b.  If the blue shape is identified as a closed loop:
        i.  Identify all white (0) pixels enclosed within this loop. Change the color of these pixels in the output grid to green (3).
        ii. Identify all white (0) pixels in the input grid that are orthogonally adjacent (share a side, not just a corner) to any blue (1) pixel belonging to this closed loop. Change the color of these adjacent white pixels in the output grid to red (2).
4.  If a blue shape is not a closed loop, make no changes related to it in the output grid (it remains as it was in the input).
5.  Return the final modified output grid.
```python
import numpy as np
from collections import deque

"""
Identifies closed loops formed by blue (1) pixels in the input grid.
For each closed loop found:
1. Fills the area enclosed by the loop with green (3) pixels.
2. Creates a one-pixel thick border of red (2) pixels immediately outside the loop, replacing adjacent white (0) pixels.
If a blue shape does not form a closed loop, it remains unchanged.
The background is white (0).
"""

def get_neighbors(r, c, height, width):
    """Yields valid orthogonal neighbors for a given cell."""
    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
        nr, nc = r + dr, c + dc
        if 0 <= nr < height and 0 <= nc < width:
            yield nr, nc

def find_regions(grid, target_color):
    """
    Finds connected regions of a specific color using BFS.
    Returns a list of sets, where each set contains the (r, c) coordinates of a region.
    """
    height, width = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    regions = []

    for r in range(height):
        for c in range(width):
            if grid[r, c] == target_color and not visited[r, c]:
                # Start BFS for a new region
                current_region = set()
                q = deque([(r, c)])
                visited[r, c] = True
                current_region.add((r, c))

                while q:
                    row, col = q.popleft()
                    for nr, nc in get_neighbors(row, col, height, width):
                        if grid[nr, nc] == target_color and not visited[nr, nc]:
                            visited[nr, nc] = True
                            current_region.add((nr, nc))
                            q.append((nr, nc))
                regions.append(current_region)
    return regions


def transform(input_grid):
    """
    Identifies closed blue loops, fills their interior with green, 
    and borders them externally with red.
    """
    input_grid_np = np.array(input_grid, dtype=int)
    output_grid = input_grid_np.copy()
    height, width = input_grid_np.shape

    # 1. Identify all white regions and classify them as exterior or interior
    white_regions = [] # List to store tuples: (region_pixels, is_interior)
    visited_white = np.zeros_like(input_grid_np, dtype=bool)
    exterior_white_pixels = set()

    q = deque()
    # Initialize queue with boundary white pixels
    for r in range(height):
        for c in [0, width - 1]:
             if input_grid_np[r, c] == 0 and not visited_white[r,c]:
                 q.append((r,c))
                 visited_white[r,c] = True
                 exterior_white_pixels.add((r,c))
    for c in range(width): # Use range(width) instead of range(1, width-1) to include corners
        for r in [0, height -1]:
             if input_grid_np[r, c] == 0 and not visited_white[r,c]:
                 q.append((r,c))
                 visited_white[r,c] = True
                 exterior_white_pixels.add((r,c))
                 
    # BFS for exterior white region(s)
    while q:
        r, c = q.popleft()
        for nr, nc in get_neighbors(r, c, height, width):
            if input_grid_np[nr, nc] == 0 and not visited_white[nr, nc]:
                visited_white[nr, nc] = True
                exterior_white_pixels.add((nr,nc))
                q.append((nr, nc))

    if exterior_white_pixels: # Check if there are any exterior white pixels found
         white_regions.append((exterior_white_pixels, False)) # Add the combined exterior region

    # Find interior white regions (those not visited yet)
    for r in range(height):
        for c in range(width):
            if input_grid_np[r, c] == 0 and not visited_white[r, c]:
                # Start BFS for a new interior region
                current_interior_region = set()
                q_interior = deque([(r, c)])
                visited_white[r, c] = True
                current_interior_region.add((r, c))

                while q_interior:
                    row, col = q_interior.popleft()
                    for nr, nc in get_neighbors(row, col, height, width):
                        if input_grid_np[nr, nc] == 0 and not visited_white[nr, nc]:
                            visited_white[nr, nc] = True
                            current_interior_region.add((nr, nc))
                            q_interior.append((nr, nc))
                
                if current_interior_region: # Ensure we found something
                     white_regions.append((current_interior_region, True))


    # 2. Process interior white regions (these define the closed loops)
    for region_pixels, is_interior in white_regions:
        if is_interior:
            adjacent_blue_pixels = set()
            adjacent_exterior_white_for_border = set()

            # Fill the interior region with green
            for r, c in region_pixels:
                output_grid[r, c] = 3 # Green
                # While iterating interior pixels, find adjacent blue pixels
                for nr, nc in get_neighbors(r, c, height, width):
                    if input_grid_np[nr, nc] == 1: # Blue
                        adjacent_blue_pixels.add((nr, nc))

            # Find exterior white pixels adjacent to the identified blue border
            for br, bc in adjacent_blue_pixels:
                 for nr, nc in get_neighbors(br, bc, height, width):
                     # Check if neighbor is white AND belongs to the exterior set
                     if (nr, nc) in exterior_white_pixels: 
                         adjacent_exterior_white_for_border.add((nr,nc))

            # Color the adjacent exterior white pixels red
            for r, c in adjacent_exterior_white_for_border:
                 output_grid[r, c] = 2 # Red

    return output_grid.tolist()
```
