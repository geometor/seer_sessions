
## train_1

**input:**
```
0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 8 8 8 8 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 2 2 2 4 4 4 4 2 2 2 2 2 2 0 0 0
0 0 0 2 2 2 4 4 4 4 2 2 2 2 2 2 0 0 0
0 0 0 2 2 2 4 4 4 4 2 2 2 2 2 2 0 0 0
0 0 0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0
4 4 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
0 0 0 0 0 0 4 4 4 4 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 4 4 4 4 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 4 4 4 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 4 4 4 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0
```


## train_2

**input:**
```
0 0 0 0 0 0 1 1 1 0 2 2 2 2 2 0 0 0 0
0 2 2 2 2 0 1 1 1 0 2 2 2 2 2 0 0 0 0
0 2 2 2 2 0 1 1 1 0 2 2 2 2 2 0 0 0 0
0 2 2 2 2 0 0 0 0 0 2 2 2 2 2 0 0 0 0
0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0
0 1 1 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0
0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 8 8 8 8 8 8 0 0 0 0 0 0 0 0
0 0 0 0 0 8 8 8 8 8 8 0 0 0 0 2 2 2 2
2 2 2 2 0 8 8 8 8 8 8 0 0 0 0 2 2 2 2
2 2 2 2 0 8 8 8 8 8 8 0 0 0 0 2 2 2 2
2 2 2 2 0 8 8 8 8 8 8 0 0 0 0 0 0 0 0
2 2 2 2 0 8 8 8 8 8 8 0 2 2 0 0 0 0 0
0 0 0 0 0 8 8 8 8 8 8 0 2 2 0 0 1 1 1
0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 1 1 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1
0 0 0 0 2 2 2 2 2 0 1 1 1 1 0 0 0 0 0
0 0 0 0 2 2 2 2 2 0 1 1 1 1 0 0 0 0 0
0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 4 1 1 1 4 4 2 2 2 2 0 0 0 0
0 2 2 2 2 4 1 1 1 4 4 2 2 2 2 0 0 0 0
0 2 2 2 2 4 1 1 1 4 4 2 2 2 2 0 0 0 0
0 2 2 2 2 4 4 4 4 4 4 2 2 2 2 0 0 0 0
0 0 0 0 0 4 4 4 4 4 4 2 2 2 2 0 0 0 0
0 1 1 0 0 4 4 4 4 4 4 2 2 2 2 0 0 0 0
0 1 1 0 0 4 4 4 4 4 4 0 0 0 0 0 0 0 0
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 1 1 1
0 0 0 0 0 4 4 4 4 4 4 0 2 2 0 0 1 1 1
0 0 0 0 0 4 4 4 4 4 4 0 0 0 0 0 1 1 1
0 0 0 0 2 4 4 4 4 4 1 1 1 1 0 0 0 0 0
0 0 0 0 2 4 4 4 4 4 1 1 1 1 0 0 0 0 0
0 0 0 0 2 4 4 4 4 4 0 0 0 0 0 0 0 0 0
```


## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 2 2 2 0 0 1 1 1 1 1 1 1 1 1
0 1 1 1 0 2 2 2 0 0 1 1 1 1 1 1 1 1 1
0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 0 0 8 8 8 8 8 8 8 0 0 0 0 0 0
0 1 1 1 0 0 8 8 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 0
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 0
0 0 2 2 2 2 2 2 2 0 0 0 2 2 2 2 2 2 0
0 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 2 4 4 4 4 1 1 1 1 1 1 1 1 1
0 1 1 1 0 2 4 4 4 4 1 1 1 1 1 1 1 1 1
0 1 1 1 0 0 4 4 4 4 4 4 4 0 0 0 0 0 0
0 1 1 1 0 0 4 4 4 4 4 4 4 0 0 0 0 0 0
0 1 1 1 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
0 1 1 1 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
0 0 0 0 0 0 4 4 4 4 4 4 4 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 4 4 4 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 4 4 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 4 4 4 2 2 2 2 2 0
0 0 0 0 0 0 0 0 0 0 4 4 4 2 2 2 2 2 0
0 0 2 2 2 2 2 2 2 0 4 4 4 2 2 2 2 2 0
0 0 2 2 2 2 2 2 2 0 4 4 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0
```


## train_4

**input:**
```
0 0 0 1 1 1 0 2 2 2 2 2 0 0 0 0 0 0
0 0 0 1 1 1 0 2 2 2 2 2 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0
1 1 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0
1 1 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0
1 1 0 0 8 8 8 8 0 0 0 0 0 0 0 0 0 0
1 1 0 0 8 8 8 8 0 0 0 0 0 0 0 0 0 0
1 1 0 0 8 8 8 8 0 0 0 0 0 1 1 1 0 0
0 0 0 0 8 8 8 8 0 0 0 0 0 1 1 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0
0 0 0 0 0 0 2 2 2 0 0 0 0 1 1 1 0 0
0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0
0 2 2 2 0 0 0 0 0 0 2 2 2 2 2 0 0 0
0 2 2 2 0 0 1 1 0 0 2 2 2 2 2 0 0 0
0 2 2 2 0 0 1 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 1 1 1 4 4 2 2 2 2 0 0 0 0 0 0
0 0 0 1 1 1 4 4 2 2 2 2 0 0 0 0 0 0
0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0 0
0 0 0 0 4 4 4 4 0 0 2 2 2 0 0 0 0 0
1 1 0 0 4 4 4 4 0 0 2 2 2 0 0 0 0 0
1 1 0 0 4 4 4 4 0 0 2 2 2 0 0 0 0 0
1 1 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4 4
1 1 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4 4
1 1 4 4 8 8 8 8 4 4 4 4 4 1 1 1 0 0
4 4 4 4 8 8 8 8 4 4 4 4 4 1 1 1 0 0
0 0 0 0 4 4 4 4 0 0 0 0 0 1 1 1 0 0
0 0 0 0 4 4 4 4 2 0 0 0 0 1 1 1 0 0
0 0 0 0 4 4 4 4 2 0 0 0 0 0 0 0 0 0
0 0 0 0 4 4 4 4 0 0 2 2 2 2 2 0 0 0
0 2 2 2 4 4 4 4 0 0 2 2 2 2 2 0 0 0
0 2 2 2 4 4 1 1 0 0 2 2 2 2 2 0 0 0
0 2 2 2 4 4 1 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0
```

Okay, let's break down this task.

**Perception of Elements:**

1.  **Input Grid Structure**: The input grids contain a background of white pixels (0). Scattered across the grid are several distinct rectangular objects composed of non-white pixels (colors like blue-1, red-2, azure-8).
2.  **Key Object**: A prominent feature in all inputs is a solid rectangle made of azure pixels (8). Its position varies, but it's generally somewhat central.
3.  **Other Objects**: Besides the azure rectangle, there are other rectangular blocks of blue (1) and red (2) pixels. Their number, size, and position vary across examples.
4.  **Output Grid Structure**: The output grids retain the original non-white objects (azure, blue, red) in their exact input positions and colors. The significant change is the introduction of yellow pixels (4).
5.  **Yellow Pixel Pattern**: The yellow pixels (4) appear to replace *some* of the original white pixels (0) from the input. They form a large rectangular area.
6.  **Relationship**: The yellow area seems spatially related to the locations of *all* the non-white objects in the input. Specifically, it fills the white space *within* the overall bounding box defined by all the non-white objects (including the azure one).

**YAML Facts:**


```yaml
task_description: Fill the background within the bounding box of all non-background objects with yellow, preserving the original objects.

elements:
  - element_type: background
    color: white (0)
    role: Passive space filler in input, selectively replaced in output.
  - element_type: object
    color: azure (8)
    shape: solid rectangle
    role: Primary object, always present, position retained. Contributes to bounding box calculation.
  - element_type: object
    color: blue (1)
    shape: solid rectangle(s)
    role: Secondary object(s), presence/size/position varies, positions retained. Contribute to bounding box calculation.
  - element_type: object
    color: red (2)
    shape: solid rectangle(s)
    role: Secondary object(s), presence/size/position varies, positions retained. Contribute to bounding box calculation.
  - element_type: fill_color
    color: yellow (4)
    role: Introduced in the output to replace specific background pixels.

relationships:
  - type: bounding_box
    scope: All non-white pixels in the input grid.
    purpose: Defines the area where transformations occur.
  - type: preservation
    scope: All non-white pixels from the input grid.
    action: Their color and position are maintained in the output grid.
  - type: replacement
    scope: White (0) pixels within the calculated bounding box in the input grid.
    action: These pixels are changed to yellow (4) in the output grid.

actions:
  - action: identify_non_white
    input: input grid
    output: set of coordinates for all pixels with color > 0
  - action: calculate_bounding_box
    input: set of non-white coordinates
    output: minimum row, maximum row, minimum column, maximum column
  - action: create_output_grid
    based_on: input grid (copy)
  - action: fill_background
    target: output grid
    condition: Iterate through cells within the bounding box. If the corresponding input cell is white (0).
    effect: Change the output cell color to yellow (4).
```


**Natural Language Program:**

1.  Start with the input grid.
2.  Find all pixels that are not white (color 0).
3.  Determine the smallest rectangle (the bounding box) that encloses all these non-white pixels. Identify its top-most row, bottom-most row, left-most column, and right-most column.
4.  Create a new grid, initially identical to the input grid. This will be the output grid.
5.  Examine every pixel within the calculated bounding box area (from the top row to the bottom row, and from the left column to the right column) in the *original input grid*.
6.  If a pixel within this bounding box area in the *input grid* is white (0), change the color of the corresponding pixel in the *output grid* to yellow (4).
7.  If a pixel within the bounding box area in the *input grid* is *not* white (i.e., it was part of an original object), leave the corresponding pixel in the *output grid* unchanged (it keeps its original color).
8.  Pixels outside the bounding box area remain unchanged from the input grid to the output grid.
9.  The final modified grid is the result.
```python
import numpy as np

"""
Identify all non-white (non-zero) pixels in the input grid.
Calculate the bounding box that encompasses all these non-white pixels.
Create an output grid by copying the input grid.
Iterate through each cell within the calculated bounding box in the input grid.
If a cell within the bounding box in the input grid is white (0), change the corresponding cell in the output grid to yellow (4).
Leave all original non-white pixels and all pixels outside the bounding box unchanged.
"""

def transform(input_grid):
    """
    Fills the background within the bounding box of all non-background 
    objects with yellow, preserving the original objects.

    Args:
        input_grid (np.array): A 2D numpy array representing the input grid.

    Returns:
        np.array: A 2D numpy array representing the transformed output grid.
    """
    
    # Find the coordinates of all non-white pixels
    non_white_coords = np.argwhere(input_grid > 0)

    # If there are no non-white pixels, return the input grid unchanged
    if non_white_coords.size == 0:
        return input_grid.copy()

    # Calculate the bounding box
    min_row = np.min(non_white_coords[:, 0])
    max_row = np.max(non_white_coords[:, 0])
    min_col = np.min(non_white_coords[:, 1])
    max_col = np.max(non_white_coords[:, 1])

    # Initialize the output grid as a copy of the input grid
    output_grid = input_grid.copy()
    
    # Define the fill color
    fill_color = 4 # yellow

    # Iterate through the cells within the bounding box
    for r in range(min_row, max_row + 1):
        for c in range(min_col, max_col + 1):
            # Check if the corresponding cell in the *input* grid is white (0)
            if input_grid[r, c] == 0:
                # If it is white, change the cell in the *output* grid to the fill color
                output_grid[r, c] = fill_color

    return output_grid
```

Previous Code:
```python
import numpy as np

"""
Identify all non-white (non-zero) pixels in the input grid.
Calculate the bounding box that encompasses all these non-white pixels.
Create an output grid by copying the input grid.
Iterate through each cell within the calculated bounding box in the input grid.
If a cell within the bounding box in the input grid is white (0), change the corresponding cell in the output grid to yellow (4).
Leave all original non-white pixels and all pixels outside the bounding box unchanged.
"""

def transform(input_grid):
    """
    Fills the background within the bounding box of all non-background 
    objects with yellow, preserving the original objects.

    Args:
        input_grid (np.array): A 2D numpy array representing the input grid.

    Returns:
        np.array: A 2D numpy array representing the transformed output grid.
    """
    
    # Find the coordinates of all non-white pixels
    non_white_coords = np.argwhere(input_grid > 0)

    # If there are no non-white pixels, return the input grid unchanged
    if non_white_coords.size == 0:
        return input_grid.copy()

    # Calculate the bounding box
    min_row = np.min(non_white_coords[:, 0])
    max_row = np.max(non_white_coords[:, 0])
    min_col = np.min(non_white_coords[:, 1])
    max_col = np.max(non_white_coords[:, 1])

    # Initialize the output grid as a copy of the input grid
    output_grid = input_grid.copy()
    
    # Define the fill color
    fill_color = 4 # yellow

    # Iterate through the cells within the bounding box
    for r in range(min_row, max_row + 1):
        for c in range(min_col, max_col + 1):
            # Check if the corresponding cell in the *input* grid is white (0)
            if input_grid[r, c] == 0:
                # If it is white, change the cell in the *output* grid to the fill color
                output_grid[r, c] = fill_color

    return output_grid
```
Results for code_00.py:

Train Set Results:

## Example 1:
Input:
```
0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 8 8 8 8 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Expected Output:
```
0 0 0 2 2 2 4 4 4 4 2 2 2 2 2 2 0 0 0
0 0 0 2 2 2 4 4 4 4 2 2 2 2 2 2 0 0 0
0 0 0 2 2 2 4 4 4 4 2 2 2 2 2 2 0 0 0
0 0 0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0
4 4 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
0 0 0 0 0 0 4 4 4 4 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 4 4 4 4 0 0 0 2 2 2 2 2 2
0 0 0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 4 4 4 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 4 4 4 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0
```
Transformed Output:
```
0 0 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4
0 0 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4
0 0 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4
0 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
0 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
0 0 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
0 0 4 4 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4
0 0 4 4 4 4 8 8 8 8 4 4 4 2 2 2 2 2 2
0 0 4 4 4 4 8 8 8 8 4 4 4 2 2 2 2 2 2
0 0 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2
0 0 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2
0 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
0 0 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4
0 0 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4
0 0 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Match: False
Pixels Off: 136
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 75.34626038781163

## Example 2:
Input:
```
0 0 0 0 0 0 1 1 1 0 2 2 2 2 2 0 0 0 0
0 2 2 2 2 0 1 1 1 0 2 2 2 2 2 0 0 0 0
0 2 2 2 2 0 1 1 1 0 2 2 2 2 2 0 0 0 0
0 2 2 2 2 0 0 0 0 0 2 2 2 2 2 0 0 0 0
0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0
0 1 1 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0
0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 8 8 8 8 8 8 0 0 0 0 0 0 0 0
0 0 0 0 0 8 8 8 8 8 8 0 0 0 0 2 2 2 2
2 2 2 2 0 8 8 8 8 8 8 0 0 0 0 2 2 2 2
2 2 2 2 0 8 8 8 8 8 8 0 0 0 0 2 2 2 2
2 2 2 2 0 8 8 8 8 8 8 0 0 0 0 0 0 0 0
2 2 2 2 0 8 8 8 8 8 8 0 2 2 0 0 0 0 0
0 0 0 0 0 8 8 8 8 8 8 0 2 2 0 0 1 1 1
0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 1 1 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1
0 0 0 0 2 2 2 2 2 0 1 1 1 1 0 0 0 0 0
0 0 0 0 2 2 2 2 2 0 1 1 1 1 0 0 0 0 0
0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0
```
Expected Output:
```
0 0 0 0 0 4 1 1 1 4 4 2 2 2 2 0 0 0 0
0 2 2 2 2 4 1 1 1 4 4 2 2 2 2 0 0 0 0
0 2 2 2 2 4 1 1 1 4 4 2 2 2 2 0 0 0 0
0 2 2 2 2 4 4 4 4 4 4 2 2 2 2 0 0 0 0
0 0 0 0 0 4 4 4 4 4 4 2 2 2 2 0 0 0 0
0 1 1 0 0 4 4 4 4 4 4 2 2 2 2 0 0 0 0
0 1 1 0 0 4 4 4 4 4 4 0 0 0 0 0 0 0 0
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 1 1 1
0 0 0 0 0 4 4 4 4 4 4 0 2 2 0 0 1 1 1
0 0 0 0 0 4 4 4 4 4 4 0 0 0 0 0 1 1 1
0 0 0 0 2 4 4 4 4 4 1 1 1 1 0 0 0 0 0
0 0 0 0 2 4 4 4 4 4 1 1 1 1 0 0 0 0 0
0 0 0 0 2 4 4 4 4 4 0 0 0 0 0 0 0 0 0
```
Transformed Output:
```
4 4 4 4 4 4 1 1 1 4 2 2 2 2 2 4 4 4 4
4 2 2 2 2 4 1 1 1 4 2 2 2 2 2 4 4 4 4
4 2 2 2 2 4 1 1 1 4 2 2 2 2 2 4 4 4 4
4 2 2 2 2 4 4 4 4 4 2 2 2 2 2 4 4 4 4
4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 4 4 4 4
4 1 1 4 4 4 4 4 4 4 2 2 2 2 2 4 4 4 4
4 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 4 4 4 2 2 2 2
2 2 2 2 4 8 8 8 8 8 8 4 4 4 4 2 2 2 2
2 2 2 2 4 8 8 8 8 8 8 4 4 4 4 2 2 2 2
2 2 2 2 4 8 8 8 8 8 8 4 4 4 4 4 4 4 4
2 2 2 2 4 8 8 8 8 8 8 4 2 2 4 4 4 4 4
4 4 4 4 4 8 8 8 8 8 8 4 2 2 4 4 1 1 1
4 4 4 4 4 4 4 4 4 4 4 4 2 2 4 4 1 1 1
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1
4 4 4 4 2 2 2 2 2 4 1 1 1 1 4 4 4 4 4
4 4 4 4 2 2 2 2 2 4 1 1 1 1 4 4 4 4 4
4 4 4 4 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4
```
Match: False
Pixels Off: 150
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 83.10249307479225

## Example 3:
Input:
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 2 2 2 0 0 1 1 1 1 1 1 1 1 1
0 1 1 1 0 2 2 2 0 0 1 1 1 1 1 1 1 1 1
0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 0 0 8 8 8 8 8 8 8 0 0 0 0 0 0
0 1 1 1 0 0 8 8 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 0
0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 0
0 0 2 2 2 2 2 2 2 0 0 0 2 2 2 2 2 2 0
0 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Expected Output:
```
0 0 0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0
0 0 0 0 0 2 4 4 4 4 1 1 1 1 1 1 1 1 1
0 1 1 1 0 2 4 4 4 4 1 1 1 1 1 1 1 1 1
0 1 1 1 0 0 4 4 4 4 4 4 4 0 0 0 0 0 0
0 1 1 1 0 0 4 4 4 4 4 4 4 0 0 0 0 0 0
0 1 1 1 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
0 1 1 1 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
4 4 4 4 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
0 0 0 0 0 0 4 4 4 4 4 4 4 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 4 4 4 0 0 0 0 0 0
0 0 0 1 1 1 1 1 1 1 4 4 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 4 4 4 2 2 2 2 2 0
0 0 0 0 0 0 0 0 0 0 4 4 4 2 2 2 2 2 0
0 0 2 2 2 2 2 2 2 0 4 4 4 2 2 2 2 2 0
0 0 2 2 2 2 2 2 2 0 4 4 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 4 4 4 0 0 0 0 0 0
```
Transformed Output:
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 4 4 4 4 2 2 2 4 4 1 1 1 1 1 1 1 1 1
0 1 1 1 4 2 2 2 4 4 1 1 1 1 1 1 1 1 1
0 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
0 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
0 1 1 1 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
0 1 1 1 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
0 4 4 4 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
0 4 4 4 4 4 8 8 8 8 8 8 8 4 4 4 4 4 4
0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
0 4 4 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4
0 4 4 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4
0 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 4
0 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 4
0 4 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 4
0 4 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Match: False
Pixels Off: 101
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 55.9556786703601

## Example 4:
Input:
```
0 0 0 1 1 1 0 2 2 2 2 2 0 0 0 0 0 0
0 0 0 1 1 1 0 2 2 2 2 2 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0
1 1 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0
1 1 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0
1 1 0 0 8 8 8 8 0 0 0 0 0 0 0 0 0 0
1 1 0 0 8 8 8 8 0 0 0 0 0 0 0 0 0 0
1 1 0 0 8 8 8 8 0 0 0 0 0 1 1 1 0 0
0 0 0 0 8 8 8 8 0 0 0 0 0 1 1 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0
0 0 0 0 0 0 2 2 2 0 0 0 0 1 1 1 0 0
0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0
0 2 2 2 0 0 0 0 0 0 2 2 2 2 2 0 0 0
0 2 2 2 0 0 1 1 0 0 2 2 2 2 2 0 0 0
0 2 2 2 0 0 1 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Expected Output:
```
0 0 0 1 1 1 4 4 2 2 2 2 0 0 0 0 0 0
0 0 0 1 1 1 4 4 2 2 2 2 0 0 0 0 0 0
0 0 0 0 4 4 4 4 0 0 0 0 0 0 0 0 0 0
0 0 0 0 4 4 4 4 0 0 2 2 2 0 0 0 0 0
1 1 0 0 4 4 4 4 0 0 2 2 2 0 0 0 0 0
1 1 0 0 4 4 4 4 0 0 2 2 2 0 0 0 0 0
1 1 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4 4
1 1 4 4 8 8 8 8 4 4 4 4 4 4 4 4 4 4
1 1 4 4 8 8 8 8 4 4 4 4 4 1 1 1 0 0
4 4 4 4 8 8 8 8 4 4 4 4 4 1 1 1 0 0
0 0 0 0 4 4 4 4 0 0 0 0 0 1 1 1 0 0
0 0 0 0 4 4 4 4 2 0 0 0 0 1 1 1 0 0
0 0 0 0 4 4 4 4 2 0 0 0 0 0 0 0 0 0
0 0 0 0 4 4 4 4 0 0 2 2 2 2 2 0 0 0
0 2 2 2 4 4 4 4 0 0 2 2 2 2 2 0 0 0
0 2 2 2 4 4 1 1 0 0 2 2 2 2 2 0 0 0
0 2 2 2 4 4 1 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0
```
Transformed Output:
```
4 4 4 1 1 1 4 2 2 2 2 2 4 4 4 4 0 0
4 4 4 1 1 1 4 2 2 2 2 2 4 4 4 4 0 0
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0
4 4 4 4 4 4 4 4 4 4 2 2 2 4 4 4 0 0
1 1 4 4 4 4 4 4 4 4 2 2 2 4 4 4 0 0
1 1 4 4 4 4 4 4 4 4 2 2 2 4 4 4 0 0
1 1 4 4 8 8 8 8 4 4 4 4 4 4 4 4 0 0
1 1 4 4 8 8 8 8 4 4 4 4 4 4 4 4 0 0
1 1 4 4 8 8 8 8 4 4 4 4 4 1 1 1 0 0
4 4 4 4 8 8 8 8 4 4 4 4 4 1 1 1 0 0
4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 0 0
4 4 4 4 4 4 2 2 2 4 4 4 4 1 1 1 0 0
4 4 4 4 4 4 2 2 2 4 4 4 4 4 4 4 0 0
4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 4 0 0
4 2 2 2 4 4 4 4 4 4 2 2 2 2 2 4 0 0
4 2 2 2 4 4 1 1 4 4 2 2 2 2 2 4 0 0
4 2 2 2 4 4 1 1 4 4 4 4 4 4 4 4 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Match: False
Pixels Off: 115
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 67.2514619883041
**Assessment and Strategy**

The previous code correctly identified the concept of filling white background pixels with yellow, but it incorrectly defined the *area* to be filled. It assumed the fill area was the bounding box of *all* non-white objects. The results show this fills too large an area.

Comparing the expected outputs with the transformed outputs reveals that the yellow fill (4) consistently appears in rows *or* columns that intersect with the bounding box of the *azure (8) object specifically*. The fill only replaces original white (0) pixels within this "cross" or "plus-sign" shape defined by the azure object's row and column span. Pixels outside this shape, and original non-white pixels inside the shape, are preserved.

The strategy is to:
1.  Isolate the azure (8) object.
2.  Determine its bounding box (min/max row, min/max column).
3.  Create the output grid by copying the input.
4.  Iterate through all cells of the grid.
5.  For each cell, check if its row index is within the azure object's row range *or* if its column index is within the azure object's column range.
6.  If it falls within this "cross" shape *and* the original pixel in the input grid was white (0), change the corresponding pixel in the output grid to yellow (4).
7.  Otherwise, the output pixel retains the input pixel's value.

**Metrics Gathering**

Let's verify the bounding box of the azure (8) object in each training example.


*code_execution:*
```python
import numpy as np

def get_azure_bbox(grid):
    azure_coords = np.argwhere(grid == 8)
    if azure_coords.size == 0:
        return None
    min_row = np.min(azure_coords[:, 0])
    max_row = np.max(azure_coords[:, 0])
    min_col = np.min(azure_coords[:, 1])
    max_col = np.max(azure_coords[:, 1])
    return {'min_row': min_row, 'max_row': max_row, 'min_col': min_col, 'max_col': max_col}

# Example 1 Input
grid1 = np.array([
    [0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0],
    [0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0],
    [0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,8,8,8,8,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,8,8,8,8,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,8,8,8,8,0,0,0,2,2,2,2,2,2],
    [0,0,0,0,0,0,8,8,8,8,0,0,0,2,2,2,2,2,2],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
])
bbox1 = get_azure_bbox(grid1)

# Example 2 Input
grid2 = np.array([
    [0,0,0,0,0,0,1,1,1,0,2,2,2,2,2,0,0,0,0],
    [0,2,2,2,2,0,1,1,1,0,2,2,2,2,2,0,0,0,0],
    [0,2,2,2,2,0,1,1,1,0,2,2,2,2,2,0,0,0,0],
    [0,2,2,2,2,0,0,0,0,0,2,2,2,2,2,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0],
    [0,1,1,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0],
    [0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,8,8,8,8,8,8,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,8,8,8,8,8,8,0,0,0,0,2,2,2,2],
    [2,2,2,2,0,8,8,8,8,8,8,0,0,0,0,2,2,2,2],
    [2,2,2,2,0,8,8,8,8,8,8,0,0,0,0,2,2,2,2],
    [2,2,2,2,0,8,8,8,8,8,8,0,0,0,0,0,0,0,0],
    [2,2,2,2,0,8,8,8,8,8,8,0,2,2,0,0,0,0,0],
    [0,0,0,0,0,8,8,8,8,8,8,0,2,2,0,0,1,1,1],
    [0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,1,1,1],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1],
    [0,0,0,0,2,2,2,2,2,0,1,1,1,1,0,0,0,0,0],
    [0,0,0,0,2,2,2,2,2,0,1,1,1,1,0,0,0,0,0],
    [0,0,0,0,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0]
])
bbox2 = get_azure_bbox(grid2)

# Example 3 Input
grid3 = np.array([
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,2,2,2,0,0,1,1,1,1,1,1,1,1,1],
    [0,1,1,1,0,2,2,2,0,0,1,1,1,1,1,1,1,1,1],
    [0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,1,1,1,0,0,8,8,8,8,8,8,8,0,0,0,0,0,0],
    [0,1,1,1,0,0,8,8,8,8,8,8,8,0,0,0,0,0,0],
    [0,0,0,0,0,0,8,8,8,8,8,8,8,0,0,0,0,0,0],
    [0,0,0,0,0,0,8,8,8,8,8,8,8,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],
    [0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0],
    [0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0],
    [0,0,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
])
bbox3 = get_azure_bbox(grid3)

# Example 4 Input
grid4 = np.array([
    [0,0,0,1,1,1,0,2,2,2,2,2,0,0,0,0,0,0],
    [0,0,0,1,1,1,0,2,2,2,2,2,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0],
    [1,1,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0],
    [1,1,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0],
    [1,1,0,0,8,8,8,8,0,0,0,0,0,0,0,0,0,0],
    [1,1,0,0,8,8,8,8,0,0,0,0,0,0,0,0,0,0],
    [1,1,0,0,8,8,8,8,0,0,0,0,0,1,1,1,0,0],
    [0,0,0,0,8,8,8,8,0,0,0,0,0,1,1,1,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0],
    [0,0,0,0,0,0,2,2,2,0,0,0,0,1,1,1,0,0],
    [0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0],
    [0,2,2,2,0,0,0,0,0,0,2,2,2,2,2,0,0,0],
    [0,2,2,2,0,0,1,1,0,0,2,2,2,2,2,0,0,0],
    [0,2,2,2,0,0,1,1,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
])
bbox4 = get_azure_bbox(grid4)

print(f"Example 1 Azure BBox: {bbox1}")
print(f"Example 2 Azure BBox: {bbox2}")
print(f"Example 3 Azure BBox: {bbox3}")
print(f"Example 4 Azure BBox: {bbox4}")
```

*code_execution_result:*
outcome: OUTCOME_OK
```
Example 1 Azure BBox: {'min_row': np.int64(5), 'max_row': np.int64(8), 'min_col': np.int64(6), 'max_col': np.int64(9)}
Example 2 Azure BBox: {'min_row': np.int64(7), 'max_row': np.int64(13), 'min_col': np.int64(5), 'max_col': np.int64(10)}
Example 3 Azure BBox: {'min_row': np.int64(5), 'max_row': np.int64(8), 'min_col': np.int64(6), 'max_col': np.int64(12)}
Example 4 Azure BBox: {'min_row': np.int64(6), 'max_row': np.int64(9), 'min_col': np.int64(4), 'max_col': np.int64(7)}

```
The bounding boxes for the azure object are confirmed and match the visual inspection.

**YAML Facts**


```yaml
task_description: Fill the background (white) pixels with yellow in a cross-shaped area defined by the bounding box of the single azure object, preserving all original non-white objects.

elements:
  - element_type: background
    color: white (0)
    role: Passive space filler in input, selectively replaced in output.
  - element_type: focal_object
    color: azure (8)
    shape: solid rectangle
    uniqueness: Always exactly one present.
    role: Defines the area for transformation. Position and color are preserved in output.
  - element_type: other_object
    color: blue (1)
    shape: solid rectangle(s)
    role: Secondary object(s), presence/size/position varies. Positions and colors are preserved in output. Ignored for transformation area calculation.
  - element_type: other_object
    color: red (2)
    shape: solid rectangle(s)
    role: Secondary object(s), presence/size/position varies. Positions and colors are preserved in output. Ignored for transformation area calculation.
  - element_type: fill_color
    color: yellow (4)
    role: Introduced in the output to replace specific background pixels.

relationships:
  - type: bounding_box
    scope: The single azure (8) object in the input grid.
    output_attributes: min_row, max_row, min_col, max_col
    purpose: Defines the row and column ranges for the transformation.
  - type: preservation
    scope: All non-white pixels (1, 2, 8) from the input grid.
    action: Their color and position are maintained in the output grid.
  - type: replacement
    scope: White (0) pixels in the input grid located within the transformation area.
    transformation_area: Any pixel whose row index is between min_row and max_row (inclusive) of the azure bounding box, OR whose column index is between min_col and max_col (inclusive) of the azure bounding box.
    action: These pixels are changed to yellow (4) in the output grid.

actions:
  - action: identify_focal_object
    input: input grid
    target_color: azure (8)
    output: set of coordinates for all azure pixels
  - action: calculate_focal_bounding_box
    input: set of azure coordinates
    output: min_row, max_row, min_col, max_col
  - action: create_output_grid
    based_on: input grid (copy)
  - action: fill_background_cross_shape
    target: output grid
    condition: Iterate through all grid cells (r, c). If `(min_row <= r <= max_row)` OR `(min_col <= c <= max_col)`, AND if `input_grid[r, c]` is white (0).
    effect: Change the output cell `output_grid[r, c]` color to yellow (4).
```


**Natural Language Program**

1.  Start with the input grid.
2.  Identify the rectangular object composed of azure (8) pixels. There will be exactly one such object.
3.  Determine the bounding box of this azure object: find its top-most row (`min_row`), bottom-most row (`max_row`), left-most column (`min_col`), and right-most column (`max_col`).
4.  Create a new grid, initially identical to the input grid. This will be the output grid.
5.  Iterate through each pixel position (`r`, `c`) in the grid.
6.  Check if the pixel's row `r` is within the azure object's row range (from `min_row` to `max_row`, inclusive) OR if the pixel's column `c` is within the azure object's column range (from `min_col` to `max_col`, inclusive).
7.  If the pixel position (`r`, `c`) satisfies the condition in step 6 (i.e., it lies within the horizontal or vertical band defined by the azure object) AND the color of the pixel at `(r, c)` in the *original input grid* is white (0), then change the color of the corresponding pixel `(r, c)` in the *output grid* to yellow (4).
8.  If the pixel position does not satisfy the condition in step 6, or if the original pixel color was not white, leave the corresponding pixel in the *output grid* unchanged (it retains its color from the input grid).
9.  The final modified grid is the result.
