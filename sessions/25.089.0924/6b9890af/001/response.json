{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\nTransformation Rule:\n1. Identify two non-background objects in the input grid: a hollow red (2) rectangle (the \"Frame\") and another distinct colored object (the \"Inner Shape\").\n2. Determine the bounding box of the Frame. The output grid will have the same dimensions as the Frame's bounding box.\n3. Initialize the output grid with the background color (0).\n4. Draw the Frame onto the output grid by copying the red pixels relative to the Frame's bounding box.\n5. Determine the bounding box and color of the Inner Shape. Extract the pattern of the Inner Shape relative to its bounding box.\n6. Calculate the dimensions of the hollow space inside the Frame (Frame height - 2, Frame width - 2).\n7. Calculate the integer scaling factor by dividing the inner dimensions of the Frame by the dimensions of the Inner Shape pattern (using integer division, taking the minimum of height and width scaling factors).\n8. Scale the Inner Shape pattern by the calculated scaling factor.\n9. Center the scaled Inner Shape pattern within the hollow space of the Frame in the output grid.\n10. Fill the corresponding pixels in the output grid with the Inner Shape's color, replacing the background color (0). Pixels belonging to the Frame remain unchanged.\n\"\"\"\n\nimport numpy as np\nfrom collections import deque\n\ndef find_objects(grid, exclude_colors=[0]):\n    \"\"\"\n    Finds contiguous objects of the same color in a grid.\n\n    Args:\n        grid (np.array): The input grid.\n        exclude_colors (list): List of colors to ignore (usually background).\n\n    Returns:\n        list: A list of dictionaries, each representing an object with\n              'color', 'coords' (list of (r, c) tuples), and\n              'bbox' (min_r, min_c, max_r, max_c).\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n    q = deque()\n\n    for r in range(rows):\n        for c in range(cols):\n            # Check if the cell is not visited and not an excluded color\n            if not visited[r, c] and grid[r, c] not in exclude_colors:\n                color = grid[r, c]\n                coords = []\n                q.append((r, c))\n                visited[r, c] = True\n                min_r, min_c = r, c\n                max_r, max_c = r, c\n\n                # Start Breadth-First Search (BFS)\n                while q:\n                    row, col = q.popleft()\n                    coords.append((row, col))\n                    # Update bounding box\n                    min_r = min(min_r, row)\n                    min_c = min(min_c, col)\n                    max_r = max(max_r, row)\n                    max_c = max(max_c, col)\n\n                    # Explore neighbors (4-connectivity: up, down, left, right)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        # Check bounds, visited status, and color match\n                        if 0 <= nr < rows and 0 <= nc < cols and \\\n                           not visited[nr, nc] and grid[nr, nc] == color:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n\n                # Store the found object\n                objects.append({\n                    'color': color,\n                    'coords': coords,\n                    'bbox': (min_r, min_c, max_r, max_c)\n                })\n    return objects\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the frame-and-scale transformation to the input grid.\n    \"\"\"\n    # Convert input list of lists to a NumPy array for easier manipulation\n    input_np = np.array(input_grid, dtype=int)\n    rows, cols = input_np.shape\n\n    # Find all non-background objects in the grid\n    objects = find_objects(input_np, exclude_colors=[0])\n\n    # Identify the Frame (color 2) and the Inner Shape (other non-zero color)\n    frame_obj = None\n    inner_shape_obj = None\n    for obj in objects:\n        if obj['color'] == 2:\n            frame_obj = obj\n        elif obj['color'] != 0: # Find the first non-zero, non-frame object\n            inner_shape_obj = obj\n        # Stop if both objects are found\n        if frame_obj and inner_shape_obj:\n            break\n\n    # Handle cases where expected objects are not found\n    if frame_obj is None:\n        # If no frame is found, return an empty grid or the input?\n        # Let's return an empty grid for now, as output size is undefined.\n        print(\"Error: Frame object (color 2) not found.\")\n        return []\n    if inner_shape_obj is None:\n        # If only frame found, return just the frame cropped? Let's return empty.\n        print(\"Error: Inner shape object (non-zero, non-2 color) not found.\")\n        return []\n\n\n    # --- Extract Frame details ---\n    frame_color = frame_obj['color']\n    frame_coords = frame_obj['coords']\n    frame_r_min, frame_c_min, frame_r_max, frame_c_max = frame_obj['bbox']\n    # Calculate frame dimensions based on bounding box\n    frame_h = frame_r_max - frame_r_min + 1\n    frame_w = frame_c_max - frame_c_min + 1\n\n    # --- Extract Inner Shape details ---\n    inner_shape_color = inner_shape_obj['color']\n    inner_shape_coords = inner_shape_obj['coords']\n    inner_shape_r_min, inner_shape_c_min, inner_shape_r_max, inner_shape_c_max = inner_shape_obj['bbox']\n    # Calculate inner shape dimensions based on bounding box\n    inner_shape_h = inner_shape_r_max - inner_shape_r_min + 1\n    inner_shape_w = inner_shape_c_max - inner_shape_c_min + 1\n\n    # --- Create the Inner Shape pattern grid ---\n    # This grid represents the shape relative to its own bounding box\n    inner_shape_pattern = np.zeros((inner_shape_h, inner_shape_w), dtype=int)\n    for r, c in inner_shape_coords:\n        rel_r = r - inner_shape_r_min # Row relative to pattern top\n        rel_c = c - inner_shape_c_min # Col relative to pattern left\n        inner_shape_pattern[rel_r, rel_c] = inner_shape_color\n\n    # --- Initialize Output Grid ---\n    # Output grid size is determined by the frame's bounding box size\n    output_h = frame_h\n    output_w = frame_w\n    output_grid = np.zeros((output_h, output_w), dtype=int) # Fill with background (0)\n\n    # --- Draw the Frame onto the Output Grid ---\n    # Iterate through the coordinates of the frame object\n    for r, c in frame_coords:\n        # Calculate position relative to the top-left of the frame's bounding box\n        out_r = r - frame_r_min\n        out_c = c - frame_c_min\n        # Ensure the calculated position is within the output grid bounds\n        if 0 <= out_r < output_h and 0 <= out_c < output_w:\n             output_grid[out_r, out_c] = frame_color\n\n    # --- Calculate Scaling Factor ---\n    # Determine the dimensions of the hollow area inside the frame\n    # Assumes a 1-pixel thick border for the frame\n    inner_frame_h = frame_h - 2\n    inner_frame_w = frame_w - 2\n\n    # Check if the inner area is valid (positive dimensions)\n    if inner_frame_h <= 0 or inner_frame_w <= 0:\n         # If no inner space, return the grid with just the frame\n         return output_grid.tolist()\n\n    # Avoid division by zero if inner shape has zero height or width\n    if inner_shape_h == 0 or inner_shape_w == 0:\n        # This shouldn't happen if a valid object was found, but handle defensively\n        return output_grid.tolist()\n\n    # Calculate how many times the inner shape fits into the inner frame area\n    scale_h = inner_frame_h // inner_shape_h\n    scale_w = inner_frame_w // inner_shape_w\n    # Use the minimum of the two scales to ensure the scaled shape fits entirely\n    scale = min(scale_h, scale_w)\n\n    # If the inner shape is too large to fit even once (scale = 0), return just the frame\n    if scale == 0:\n        return output_grid.tolist()\n\n    # --- Calculate Placement for Scaled Inner Shape ---\n    # Calculate the dimensions of the pattern after scaling\n    scaled_pattern_h = inner_shape_h * scale\n    scaled_pattern_w = inner_shape_w * scale\n\n    # Calculate the offset needed to center the scaled pattern within the inner frame area\n    offset_r = (inner_frame_h - scaled_pattern_h) // 2\n    offset_c = (inner_frame_w - scaled_pattern_w) // 2\n\n    # Calculate the top-left starting position of the scaled pattern in the *full* output grid\n    # Add 1 because the inner area starts at index (1, 1) due to the frame border\n    start_r = 1 + offset_r\n    start_c = 1 + offset_c\n\n    # --- Scale and Draw the Inner Shape onto the Output Grid ---\n    # Iterate through each pixel of the original inner shape pattern\n    for pr in range(inner_shape_h): # Pattern row\n        for pc in range(inner_shape_w): # Pattern column\n            # If the pattern pixel is part of the shape (not background)\n            if inner_shape_pattern[pr, pc] == inner_shape_color:\n                # Calculate the top-left corner of the scaled block in the output grid\n                block_start_r = start_r + pr * scale\n                block_start_c = start_c + pc * scale\n                # Fill the scale x scale block in the output grid\n                for r_offset in range(scale):\n                    for c_offset in range(scale):\n                        out_r = block_start_r + r_offset\n                        out_c = block_start_c + c_offset\n                        # Check bounds again for safety\n                        if 0 <= out_r < output_h and 0 <= out_c < output_w:\n                            # Only draw the inner shape color if the target pixel is currently background (0)\n                            # This prevents overwriting the frame itself.\n                            if output_grid[out_r, out_c] == 0:\n                                output_grid[out_r, out_c] = inner_shape_color\n\n    # Convert the final NumPy array back to a standard list of lists format\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 5025,
    "candidates_token_count": 2631,
    "total_token_count": 7656,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 53.344544,
  "retries": 1
}