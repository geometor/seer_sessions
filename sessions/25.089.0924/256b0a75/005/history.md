
## train_1

**input:**
```
0 4 0 0 0 0 0 4 0 0 0 0 6 0 0 0 0 0 0 1 0 0 5 0
0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 2 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 8 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 2 0 0 0 8 0 0 0 0 0 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 8 8 0 0 0 8 8 0 0 0 7 0 0 0
0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 5 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4
```


**output:**
```
0 4 0 0 0 0 0 4 0 0 4 1 6 1 1 1 1 0 0 1 0 0 5 0
0 0 0 0 0 0 0 0 0 0 4 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 0 0 0 7 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 2 0 0 9 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0
1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 2
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
2 2 2 2 2 2 2 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 1 1 1 7 7 7 7
0 0 0 9 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 7 0 0 5 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 5 0 0 0 0 3 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 3 1 1 1 1 1 7 0 0 0 0 0 0 1
0 0 0 0 0 0 0 0 0 0 3 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 3 1 1 3 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 3 1 1 3 1 1 7 0 0 0 0 0 0 4
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 0 0 0 0 0 0 8 8 0 0 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 8 0 0 0 0 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 0 0 0 0 8 0 0 0 9 0 0
0 0 0 0 0 0 0 0 0 7 7 0 0 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 7 6 7 7 4 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 6 7 7 4 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 6 7 7 7 7 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 7 6 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
2 2 2 7 7 7 7 7 7 8 8 8 8 8 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
4 4 4 4 4 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 9 9 9
7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 7 7 7 7 7 7
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 9 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
```


## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 7 0 5 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 0 0 0 0 8 8 0 0 0 0 0 6 0 0 0
0 0 0 0 0 0 8 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0
0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 0 0 0 8 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0
0 6 0 0 0 0 8 8 0 0 0 0 3 3 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 5 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 1 3 3 7 9 5 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 3 3 3 9 6 3 3 0 9 0 0 0 0 0 0 0
0 0 0 0 0 0 1 3 3 3 9 6 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 3 3 3 9 6 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 6 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 6 3 3 0 0 0 0 0 0 0 0 0
3 3 3 3 3 3 8 8 8 8 8 8 8 8 3 3 3 3 3 6 6 6 6
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
5 5 5 5 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
6 6 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
1 1 1 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
6 6 3 3 3 3 8 8 8 8 8 8 8 8 3 3 3 3 1 1 1 1 1
0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 3 1 3 0 0 0 0 0 0 0 0 0
0 5 2 0 0 0 3 3 3 3 3 3 1 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 9 1 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 9 1 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 1 3 3 9 1 3 0 0 0 0 0 0 0 0 0
```

**Perception of the Task Elements**

1.  **Input/Output Structure:** Both input and output are grids of colored pixels.
2.  **Background Color:** The predominant color is white (0), acting as the background.
3.  **Key Object - Boundary Frame:** In all examples, there's a structure made of azure (8) pixels. This structure often forms a hollow rectangle or frame-like shape, though it might not be perfectly rectangular itself (e.g., the 'U' shape in train_1).
4.  **Other Objects:** Various other colored pixels exist, sometimes forming small contiguous objects of a single color.
5.  **Transformation:** The core transformation involves identifying a rectangular region associated with the azure (8) pixels and modifying the background pixels within that region.
6.  **Region Identification:** The region appears to be the bounding box encompassing all azure (8) pixels in the input grid.
7.  **Fill Operation:** White (0) pixels strictly *inside* this bounding box are replaced with a specific "fill color" in the output.
8.  **Fill Color Determination:** The fill color is derived from the input grid. It seems to be the color of the largest contiguous object (measured by pixel count) that is composed of a single color (other than white/0 and azure/8) and is located entirely *within* the bounding box defined by the azure pixels.
9.  **Preservation:** Pixels outside the bounding box, the azure boundary pixels themselves, and any non-white pixels originally inside the bounding box remain unchanged in the output.

**YAML Facts**


```yaml
task_elements:
  - type: grid
    description: Input and output are 2D grids of pixels with integer values 0-9 representing colors.
  - type: background
    color_name: white
    color_value: 0
    description: The default background color.
  - type: boundary_object
    color_name: azure
    color_value: 8
    description: Pixels of this color define the boundary of a region.
  - type: contained_objects
    description: Contiguous blocks of pixels of a single color (not white/0 and not azure/8) found within the boundary region.
  - type: bounding_box
    description: The smallest rectangle enclosing all azure (8) pixels.
    role: Defines the area for the fill operation.
  - type: fill_color
    determination:
      - Find all contiguous objects (not white/0, not azure/8).
      - Filter for objects completely inside the bounding_box.
      - Identify the object with the largest pixel count among the filtered set.
      - The color of this largest object is the fill_color.
    role: The color used to replace background pixels within the bounding box.
transformation:
  - action: identify_boundary
    input: input_grid
    color: azure (8)
    output: set of coordinates for all azure pixels
  - action: calculate_bounding_box
    input: set of coordinates for azure pixels
    output: coordinates defining the minimum bounding rectangle (min_row, max_row, min_col, max_col)
  - action: identify_internal_objects
    input: input_grid, bounding_box
    criteria:
      - Must not be white (0) or azure (8).
      - Must be fully contained within the bounding_box coordinates.
    output: list of contained objects (color, size, location)
  - action: determine_fill_color
    input: list of contained objects
    method: Find the object with the maximum size (pixel count).
    output: color of the largest contained object
  - action: apply_fill
    target: input_grid
    region: inside the bounding_box
    condition: pixel color is white (0)
    replacement: fill_color
    output: output_grid (pixels outside the box, boundary pixels, and non-white pixels inside the box remain unchanged)

```


**Natural Language Program**

1.  Initialize the output grid as a copy of the input grid.
2.  Locate all pixels in the input grid that have the color azure (8).
3.  Determine the minimum bounding box that encloses all identified azure (8) pixels. Let this box be defined by minimum row `min_r`, maximum row `max_r`, minimum column `min_c`, and maximum column `max_c`.
4.  Identify all distinct contiguous objects in the input grid whose color is neither white (0) nor azure (8).
5.  Filter these objects, keeping only those that are located entirely within the bounds of the bounding box (i.e., all pixels of the object must have row coordinates between `min_r` and `max_r` inclusive, and column coordinates between `min_c` and `max_c` inclusive).
6.  Among the filtered objects, find the object(s) with the largest area (highest pixel count). If there's a tie, any one of the largest objects can be chosen (the examples suggest a unique largest object).
7.  Determine the color of this largest, fully contained object. This color is the "fill color".
8.  Iterate through each pixel within the bounding box (from row `min_r` to `max_r`, and column `min_c` to `max_c`).
9.  For each pixel within this bounding box, check if its color in the input grid is white (0).
10. If the pixel's color is white (0), change its color in the output grid to the determined "fill color".
11. Pixels outside the bounding box, pixels that were originally azure (8), and non-white pixels that were inside the bounding box retain their original colors in the output grid.
12. Return the modified output grid.
```python
import numpy as np
from collections import deque

"""
Transformation Rule:
1.  Identify the minimum bounding box enclosing all azure (8) pixels in the input grid.
2.  Find all contiguous objects within the input grid whose color is neither white (0) nor azure (8).
3.  Filter these objects to retain only those that are located entirely inside the calculated bounding box.
4.  Determine the color of the largest object (by pixel count) among the filtered, contained objects. This is the "fill color".
5.  Create the output grid by copying the input grid.
6.  Iterate through all pixels within the bounding box in the output grid.
7.  If a pixel's corresponding location in the input grid was white (0), change its color in the output grid to the determined "fill color".
8.  Pixels outside the bounding box, the azure (8) boundary pixels themselves, and any non-white pixels originally inside the bounding box remain unchanged.
"""

def find_objects(grid, ignore_colors=None):
    """
    Finds all contiguous objects of the same color in a grid.

    Args:
        grid (np.array): The input grid.
        ignore_colors (set, optional): A set of color values to ignore. Defaults to None.

    Returns:
        list: A list of dictionaries, where each dictionary represents an object
              and contains 'color', 'coords' (list of (r, c) tuples), and 'size'.
    """
    if ignore_colors is None:
        ignore_colors = set()
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    objects = []

    for r in range(rows):
        for c in range(cols):
            # If not visited and not an ignored color, start a search (BFS)
            if not visited[r, c] and grid[r, c] not in ignore_colors:
                color = grid[r, c]
                obj_coords = []
                q = deque([(r, c)])
                visited[r, c] = True
                current_object_visited = set([(r,c)]) # Track visited for current BFS

                while q:
                    curr_r, curr_c = q.popleft()
                    obj_coords.append((curr_r, curr_c))

                    # Check neighbors (4-connectivity: up, down, left, right)
                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                        nr, nc = curr_r + dr, curr_c + dc
                        
                        # Check bounds, color match, and if not visited in *this specific BFS*
                        if 0 <= nr < rows and 0 <= nc < cols and \
                           grid[nr, nc] == color and \
                           (nr, nc) not in current_object_visited:
                            
                            visited[nr, nc] = True # Mark globally visited
                            current_object_visited.add((nr, nc)) # Mark visited for this object search
                            q.append((nr, nc))
                            
                if obj_coords: # Add the found object to the list
                     objects.append({
                         'color': color,
                         'coords': obj_coords,
                         'size': len(obj_coords)
                     })
    return objects


def transform(input_grid: np.ndarray) -> np.ndarray:
    """
    Applies the transformation rule to the input grid.
    """
    # 1. Initialize output grid as a copy of the input
    output_grid = np.copy(input_grid)
    rows, cols = input_grid.shape

    # 2. Locate all azure (8) pixels
    azure_pixels = np.argwhere(input_grid == 8)

    # If no azure pixels are found, return the original grid
    if azure_pixels.size == 0:
        return output_grid

    # 3. Determine the minimum bounding box for azure pixels
    min_r = np.min(azure_pixels[:, 0])
    max_r = np.max(azure_pixels[:, 0])
    min_c = np.min(azure_pixels[:, 1])
    max_c = np.max(azure_pixels[:, 1])

    # 4. Identify all distinct contiguous objects (not white=0, not azure=8)
    #    Uses a helper function `find_objects`.
    objects = find_objects(input_grid, ignore_colors={0, 8})

    # 5. Filter objects to find those fully contained within the bounding box
    contained_objects = []
    for obj in objects:
        is_contained = True
        # Check if *all* pixels of the object are within the bounds
        for r, c in obj['coords']:
            if not (min_r <= r <= max_r and min_c <= c <= max_c):
                is_contained = False
                break
        if is_contained:
            contained_objects.append(obj)

    # If no objects are fully contained within the box, return the grid as is
    # (no fill color can be determined)
    if not contained_objects:
        return output_grid

    # 6. Find the largest object among the contained ones
    largest_object = max(contained_objects, key=lambda obj: obj['size'])

    # 7. Determine the fill color from the largest object
    fill_color = largest_object['color']

    # 8. Iterate through each pixel within the bounding box
    for r in range(min_r, max_r + 1):
        for c in range(min_c, max_c + 1):
            # 9. Check if the pixel in the *input* grid is white (0)
            if input_grid[r, c] == 0:
                # 10. If it is white, change its color in the *output* grid to the fill color
                output_grid[r, c] = fill_color

    # 11. Pixels outside the box, boundary pixels, and non-white pixels inside
    #     retain their original colors (already handled by copying initially and
    #     only modifying white pixels inside the box).
    return output_grid
```
```python
import numpy as np
from collections import deque

"""
Transformation Rule:
1.  Identify the minimum bounding box enclosing all azure (8) pixels.
2.  Find all contiguous objects within the input grid whose color is neither white (0) nor azure (8).
3.  Filter these objects to retain only those located entirely inside the calculated bounding box.
4.  Determine the color ('fill_color') of the largest object (by pixel count) among the filtered, contained objects.
5.  Identify all 'seed pixels': pixels within the bounding box (inclusive) that are neither white (0) nor azure (8).
6.  Create the output grid by copying the input grid.
7.  Perform a flood fill starting from the 'seed pixels'. The fill uses the 'fill_color', propagates only into white (0) pixels, and stays within the bounds of the bounding box.
8.  Pixels outside the bounding box, the azure (8) boundary pixels, and original non-white/non-azure pixels inside the box remain unchanged (except white pixels filled during the flood fill).
"""

def find_objects(grid, ignore_colors=None, connectivity=4):
    """
    Finds all contiguous objects of the same color in a grid.

    Args:
        grid (np.array): The input grid.
        ignore_colors (set, optional): A set of color values to ignore. Defaults to None.
        connectivity (int): 4 or 8 for neighbor connectivity. Defaults to 4.

    Returns:
        list: A list of dictionaries, where each dictionary represents an object
              and contains 'color', 'coords' (list of (r, c) tuples), and 'size'.
    """
    if ignore_colors is None:
        ignore_colors = set()
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    objects = []

    if connectivity == 4:
        deltas = [(0, 1), (0, -1), (1, 0), (-1, 0)]
    elif connectivity == 8:
        deltas = [(dr, dc) for dr in [-1, 0, 1] for dc in [-1, 0, 1] if not (dr == 0 and dc == 0)]
    else:
        raise ValueError("Connectivity must be 4 or 8")

    for r in range(rows):
        for c in range(cols):
            # If not visited and not an ignored color, start a search (BFS)
            if not visited[r, c] and grid[r, c] not in ignore_colors:
                color = grid[r, c]
                obj_coords = []
                q = deque([(r, c)])
                visited[r, c] = True
                # Use a separate set for current BFS to handle visited status correctly within the object search
                current_object_visited = set([(r, c)]) 

                while q:
                    curr_r, curr_c = q.popleft()
                    obj_coords.append((curr_r, curr_c))

                    # Check neighbors
                    for dr, dc in deltas:
                        nr, nc = curr_r + dr, curr_c + dc
                        
                        # Check bounds, color match, and if not visited in this specific BFS
                        if 0 <= nr < rows and 0 <= nc < cols and \
                           grid[nr, nc] == color and \
                           (nr, nc) not in current_object_visited:
                            
                            visited[nr, nc] = True # Mark globally visited
                            current_object_visited.add((nr, nc)) # Mark visited for this object search
                            q.append((nr, nc))
                            
                if obj_coords: # Add the found object to the list
                     objects.append({
                         'color': color,
                         'coords': tuple(sorted(obj_coords)), # Use tuple for potential hashing/set operations later
                         'size': len(obj_coords)
                     })
    return objects


def transform(input_grid: np.ndarray) -> np.ndarray:
    """
    Applies the flood fill transformation based on the azure boundary and largest internal object.
    """
    # 1. Create a copy of the input grid
    output_grid = np.copy(input_grid)
    rows, cols = input_grid.shape

    # 2. Find azure (8) pixels
    azure_pixels = np.argwhere(input_grid == 8)

    # If no azure pixels, return the original grid copy
    if azure_pixels.size == 0:
        return output_grid

    # 3. Calculate the bounding box
    min_r = np.min(azure_pixels[:, 0])
    max_r = np.max(azure_pixels[:, 0])
    min_c = np.min(azure_pixels[:, 1])
    max_c = np.max(azure_pixels[:, 1])

    # 4. Find all non-white/non-azure objects
    all_objects = find_objects(input_grid, ignore_colors={0, 8})

    # 5. Filter for objects fully contained within the bounding box
    contained_objects = []
    for obj in all_objects:
        is_contained = True
        for r, c in obj['coords']:
            if not (min_r <= r <= max_r and min_c <= c <= max_c):
                is_contained = False
                break
        if is_contained:
            contained_objects.append(obj)

    # 6. Determine the fill color from the largest contained object
    if not contained_objects:
        # No object fully inside determines the color, so no fill happens
        return output_grid 
        
    # Sort by size (descending), then color (ascending) as a tie-breaker if needed
    contained_objects.sort(key=lambda x: (-x['size'], x['color']))
    fill_color = contained_objects[0]['color']

    # 7. Identify seed pixels (non-white/non-azure pixels within the box)
    seed_pixels = []
    for r in range(min_r, max_r + 1):
        for c in range(min_c, max_c + 1):
            if input_grid[r, c] != 0 and input_grid[r, c] != 8:
                seed_pixels.append((r, c))

    # 8. If no seed pixels, return the grid (no starting point for fill)
    if not seed_pixels:
        return output_grid

    # 9. Perform flood fill
    q = deque(seed_pixels)
    # visited_flood tracks pixels already processed *by the flood fill*
    # Initialize with seeds because we don't want to fill seed locations
    visited_flood = set(seed_pixels) 
    
    deltas = [(0, 1), (0, -1), (1, 0), (-1, 0)] # 4-connectivity for fill

    while q:
        r, c = q.popleft()

        # Check neighbors for potential filling
        for dr, dc in deltas:
            nr, nc = r + dr, c + dc

            # Check conditions for filling the neighbor:
            # a) Within grid bounds
            if not (0 <= nr < rows and 0 <= nc < cols):
                continue
            # b) Within the bounding box
            if not (min_r <= nr <= max_r and min_c <= nc <= max_c):
                continue
            # c) Original color was white (0) in the input grid
            if input_grid[nr, nc] != 0:
                continue
            # d) Not already visited/processed by this flood fill
            if (nr, nc) in visited_flood:
                continue

            # If all conditions met, fill the neighbor
            output_grid[nr, nc] = fill_color
            visited_flood.add((nr, nc))
            q.append((nr, nc))

    # 10. Return the modified grid
    return output_grid
```

Previous Code:
```python
import numpy as np
from collections import deque

"""
Transformation Rule:
1.  Identify the minimum bounding box enclosing all azure (8) pixels.
2.  Find all contiguous objects within the input grid whose color is neither white (0) nor azure (8).
3.  Filter these objects to retain only those located entirely inside the calculated bounding box.
4.  Determine the color ('fill_color') of the largest object (by pixel count) among the filtered, contained objects.
5.  Identify all 'seed pixels': pixels within the bounding box (inclusive) that are neither white (0) nor azure (8).
6.  Create the output grid by copying the input grid.
7.  Perform a flood fill starting from the 'seed pixels'. The fill uses the 'fill_color', propagates only into white (0) pixels, and stays within the bounds of the bounding box.
8.  Pixels outside the bounding box, the azure (8) boundary pixels, and original non-white/non-azure pixels inside the box remain unchanged (except white pixels filled during the flood fill).
"""

def find_objects(grid, ignore_colors=None, connectivity=4):
    """
    Finds all contiguous objects of the same color in a grid.

    Args:
        grid (np.array): The input grid.
        ignore_colors (set, optional): A set of color values to ignore. Defaults to None.
        connectivity (int): 4 or 8 for neighbor connectivity. Defaults to 4.

    Returns:
        list: A list of dictionaries, where each dictionary represents an object
              and contains 'color', 'coords' (list of (r, c) tuples), and 'size'.
    """
    if ignore_colors is None:
        ignore_colors = set()
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    objects = []

    if connectivity == 4:
        deltas = [(0, 1), (0, -1), (1, 0), (-1, 0)]
    elif connectivity == 8:
        deltas = [(dr, dc) for dr in [-1, 0, 1] for dc in [-1, 0, 1] if not (dr == 0 and dc == 0)]
    else:
        raise ValueError("Connectivity must be 4 or 8")

    for r in range(rows):
        for c in range(cols):
            # If not visited and not an ignored color, start a search (BFS)
            if not visited[r, c] and grid[r, c] not in ignore_colors:
                color = grid[r, c]
                obj_coords = []
                q = deque([(r, c)])
                visited[r, c] = True
                # Use a separate set for current BFS to handle visited status correctly within the object search
                current_object_visited = set([(r, c)]) 

                while q:
                    curr_r, curr_c = q.popleft()
                    obj_coords.append((curr_r, curr_c))

                    # Check neighbors
                    for dr, dc in deltas:
                        nr, nc = curr_r + dr, curr_c + dc
                        
                        # Check bounds, color match, and if not visited in this specific BFS
                        if 0 <= nr < rows and 0 <= nc < cols and \
                           grid[nr, nc] == color and \
                           (nr, nc) not in current_object_visited:
                            
                            visited[nr, nc] = True # Mark globally visited
                            current_object_visited.add((nr, nc)) # Mark visited for this object search
                            q.append((nr, nc))
                            
                if obj_coords: # Add the found object to the list
                     objects.append({
                         'color': color,
                         'coords': tuple(sorted(obj_coords)), # Use tuple for potential hashing/set operations later
                         'size': len(obj_coords)
                     })
    return objects


def transform(input_grid: np.ndarray) -> np.ndarray:
    """
    Applies the flood fill transformation based on the azure boundary and largest internal object.
    """
    # 1. Create a copy of the input grid
    output_grid = np.copy(input_grid)
    rows, cols = input_grid.shape

    # 2. Find azure (8) pixels
    azure_pixels = np.argwhere(input_grid == 8)

    # If no azure pixels, return the original grid copy
    if azure_pixels.size == 0:
        return output_grid

    # 3. Calculate the bounding box
    min_r = np.min(azure_pixels[:, 0])
    max_r = np.max(azure_pixels[:, 0])
    min_c = np.min(azure_pixels[:, 1])
    max_c = np.max(azure_pixels[:, 1])

    # 4. Find all non-white/non-azure objects
    all_objects = find_objects(input_grid, ignore_colors={0, 8})

    # 5. Filter for objects fully contained within the bounding box
    contained_objects = []
    for obj in all_objects:
        is_contained = True
        for r, c in obj['coords']:
            if not (min_r <= r <= max_r and min_c <= c <= max_c):
                is_contained = False
                break
        if is_contained:
            contained_objects.append(obj)

    # 6. Determine the fill color from the largest contained object
    if not contained_objects:
        # No object fully inside determines the color, so no fill happens
        return output_grid 
        
    # Sort by size (descending), then color (ascending) as a tie-breaker if needed
    contained_objects.sort(key=lambda x: (-x['size'], x['color']))
    fill_color = contained_objects[0]['color']

    # 7. Identify seed pixels (non-white/non-azure pixels within the box)
    seed_pixels = []
    for r in range(min_r, max_r + 1):
        for c in range(min_c, max_c + 1):
            if input_grid[r, c] != 0 and input_grid[r, c] != 8:
                seed_pixels.append((r, c))

    # 8. If no seed pixels, return the grid (no starting point for fill)
    if not seed_pixels:
        return output_grid

    # 9. Perform flood fill
    q = deque(seed_pixels)
    # visited_flood tracks pixels already processed *by the flood fill*
    # Initialize with seeds because we don't want to fill seed locations
    visited_flood = set(seed_pixels) 
    
    deltas = [(0, 1), (0, -1), (1, 0), (-1, 0)] # 4-connectivity for fill

    while q:
        r, c = q.popleft()

        # Check neighbors for potential filling
        for dr, dc in deltas:
            nr, nc = r + dr, c + dc

            # Check conditions for filling the neighbor:
            # a) Within grid bounds
            if not (0 <= nr < rows and 0 <= nc < cols):
                continue
            # b) Within the bounding box
            if not (min_r <= nr <= max_r and min_c <= nc <= max_c):
                continue
            # c) Original color was white (0) in the input grid
            if input_grid[nr, nc] != 0:
                continue
            # d) Not already visited/processed by this flood fill
            if (nr, nc) in visited_flood:
                continue

            # If all conditions met, fill the neighbor
            output_grid[nr, nc] = fill_color
            visited_flood.add((nr, nc))
            q.append((nr, nc))

    # 10. Return the modified grid
    return output_grid
```
Results for code_00.py:

Train Set Results:

## Example 1:
Input:
```
0 4 0 0 0 0 0 4 0 0 0 0 6 0 0 0 0 0 0 1 0 0 5 0
0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 2 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 8 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 2 0 0 0 8 0 0 0 0 0 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 8 8 0 0 0 8 8 0 0 0 7 0 0 0
0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 5 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4
```
Expected Output:
```
0 4 0 0 0 0 0 4 0 0 4 1 6 1 1 1 1 0 0 1 0 0 5 0
0 0 0 0 0 0 0 0 0 0 4 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 0 0 0 7 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 2 0 0 9 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0
1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 2
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
2 2 2 2 2 2 2 1 1 1 8 1 1 1 1 1 8 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 1 1 1 7 7 7 7
0 0 0 9 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 7 0 0 5 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 5 0 0 0 0 3 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 3 1 1 1 1 1 7 0 0 0 0 0 0 1
0 0 0 0 0 0 0 0 0 0 3 1 1 1 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 3 1 1 3 1 1 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 3 1 1 3 1 1 7 0 0 0 0 0 0 4
```
Transformed Output:
```
0 4 0 0 0 0 0 4 0 0 0 0 6 0 0 0 0 0 0 1 0 0 5 0
0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 2 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 8 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 2
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0
0 0 0 0 0 0 2 0 0 0 8 1 1 1 1 1 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 8 8 1 1 1 8 8 0 0 0 7 0 0 0
0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 5 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4
```
Match: False
Pixels Off: 240
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 90.90909090909092

## Example 2:
Input:
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 0 0 0 0 0 0 8 8 0 0 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 8 0 0 0 0 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 0 0 0 0 8 0 0 0 9 0 0
0 0 0 0 0 0 0 0 0 7 7 0 0 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Expected Output:
```
0 0 0 0 0 0 0 0 0 7 6 7 7 4 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 6 7 7 4 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 6 7 7 7 7 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 7 6 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
2 2 2 7 7 7 7 7 7 8 8 8 8 8 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
4 4 4 4 4 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 8 7 7 7 7 8 7 7 7 9 9 9
7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 7 7 7 7 7 7
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 9 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 1 7 0 0 0 0 0 0
```
Transformed Output:
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 3 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 0 0 0 0 0 0 8 8 7 7 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 8 7 7 7 7 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 7 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 4 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 7 8 0 0 0 9 0 0
0 0 0 0 0 0 0 0 0 7 7 7 7 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Match: False
Pixels Off: 218
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 90.26915113871637

## Example 3:
Input:
```
0 0 0 0 0 0 0 0 0 7 0 5 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 0 0 0 0 8 8 0 0 0 0 0 6 0 0 0
0 0 0 0 0 0 8 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0
0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 0 0 0 8 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0
0 6 0 0 0 0 8 8 0 0 0 0 3 3 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 5 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Expected Output:
```
0 0 0 0 0 0 1 3 3 7 9 5 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 3 3 3 9 6 3 3 0 9 0 0 0 0 0 0 0
0 0 0 0 0 0 1 3 3 3 9 6 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 3 3 3 9 6 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 6 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 6 3 3 0 0 0 0 0 0 0 0 0
3 3 3 3 3 3 8 8 8 8 8 8 8 8 3 3 3 3 3 6 6 6 6
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
5 5 5 5 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
6 6 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
1 1 1 3 3 3 8 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3
6 6 3 3 3 3 8 8 8 8 8 8 8 8 3 3 3 3 1 1 1 1 1
0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 3 1 3 0 0 0 0 0 0 0 0 0
0 5 2 0 0 0 3 3 3 3 3 3 1 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 9 1 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 9 1 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 1 3 3 9 1 3 0 0 0 0 0 0 0 0 0
```
Transformed Output:
```
0 0 0 0 0 0 0 0 0 7 0 5 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 3 3 3 3 8 8 0 0 0 0 0 6 0 0 0
0 0 0 0 0 0 8 3 3 3 3 3 3 8 0 0 0 0 0 0 0 0 0
0 0 0 5 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 6 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 0 1 0 0 0 8 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0
0 6 0 0 0 0 8 8 3 3 3 3 3 3 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 5 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```
Match: False
Pixels Off: 263
Size Correct: True
Color Palette Correct: True
Color Count Correct: False
Score: 99.4328922495274
**General Assessment and Strategy**

The provided code attempted a flood-fill approach, starting from non-white/non-azure "seed" pixels within the bounding box defined by azure (8) pixels. The test results show this is incorrect, as the fill color does not propagate to all white (0) pixels within the box as expected in the target outputs.

Comparing the inputs and expected outputs again strongly suggests a simpler mechanism:
1.  Identify the bounding box of all azure (8) pixels.
2.  Determine the "fill color" by finding the largest contiguous object (by pixel count, excluding white=0 and azure=8) that is located *entirely inside* this bounding box.
3.  Create the output grid by iterating through the input grid. For every pixel *within* the bounding box coordinates (inclusive), if its color in the input is white (0), change it to the determined fill color in the output. All other pixels (outside the box, azure pixels, non-white pixels inside the box) retain their original color.

The strategy is to revert to this simpler replacement logic, ensuring the identification of the correct fill color and the correct application region (within the bounding box).

**Metrics Gathering**


*code_execution:*
```python
import numpy as np
from collections import deque

# --- find_objects function (copied from the prompt for analysis) ---
def find_objects(grid, ignore_colors=None, connectivity=4):
    if ignore_colors is None:
        ignore_colors = set()
    rows, cols = grid.shape
    visited = np.zeros_like(grid, dtype=bool)
    objects = []

    if connectivity == 4:
        deltas = [(0, 1), (0, -1), (1, 0), (-1, 0)]
    elif connectivity == 8:
        deltas = [(dr, dc) for dr in [-1, 0, 1] for dc in [-1, 0, 1] if not (dr == 0 and dc == 0)]
    else:
        raise ValueError("Connectivity must be 4 or 8")

    for r in range(rows):
        for c in range(cols):
            if not visited[r, c] and grid[r, c] not in ignore_colors:
                color = grid[r, c]
                obj_coords = []
                q = deque([(r, c)])
                visited[r, c] = True
                current_object_visited = set([(r, c)]) 

                while q:
                    curr_r, curr_c = q.popleft()
                    obj_coords.append((curr_r, curr_c))

                    for dr, dc in deltas:
                        nr, nc = curr_r + dr, curr_c + dc
                        
                        if 0 <= nr < rows and 0 <= nc < cols and \
                           grid[nr, nc] == color and \
                           (nr, nc) not in current_object_visited:
                            
                            visited[nr, nc] = True 
                            current_object_visited.add((nr, nc))
                            q.append((nr, nc))
                            
                if obj_coords:
                     objects.append({
                         'color': color,
                         'coords': tuple(sorted(obj_coords)),
                         'size': len(obj_coords)
                     })
    return objects

# --- Input Data (condensed for brevity) ---
input_1 = np.array([
    [0,4,0,0,0,0,0,4,0,0,0,0,6,0,0,0,0,0,0,1,0,0,5,0],
    [0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,2,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,8,8,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,8,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,2,0,0,0,8,0,0,0,0,0,8,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,8,8,0,0,0,8,8,0,0,0,7,0,0,0],
    [0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,5,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,4]])

input_2 = np.array([
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,3,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,2,0,0,0,0,0,0,8,8,0,0,8,8,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,8,0,0,0,0,8,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0],
    [0,0,0,0,0,0,0,0,0,7,7,0,0,8,8,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])

input_3 = np.array([
    [0,0,0,0,0,0,0,0,0,7,0,5,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,1,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,8,8,0,0,0,0,8,8,0,0,0,0,0,6,0,0,0],
    [0,0,0,0,0,0,8,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0],
    [0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,1,0,0,0,8,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0],
    [0,6,0,0,0,0,8,8,0,0,0,0,3,3,0,0,0,0,1,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],
    [0,5,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])

inputs = [input_1, input_2, input_3]
results = []

for i, input_grid in enumerate(inputs):
    report = {}
    azure_pixels = np.argwhere(input_grid == 8)
    
    if azure_pixels.size == 0:
        report['example'] = i + 1
        report['azure_pixels_found'] = False
        report['bounding_box'] = None
        report['contained_objects'] = []
        report['largest_contained_object_color'] = None
        report['fill_color'] = None
        results.append(report)
        continue
        
    report['azure_pixels_found'] = True
    min_r = np.min(azure_pixels[:, 0])
    max_r = np.max(azure_pixels[:, 0])
    min_c = np.min(azure_pixels[:, 1])
    max_c = np.max(azure_pixels[:, 1])
    bounding_box = (min_r, max_r, min_c, max_c)
    report['bounding_box'] = f"Rows {min_r}-{max_r}, Cols {min_c}-{max_c}"
    
    all_objects = find_objects(input_grid, ignore_colors={0, 8})
    
    contained_objects = []
    for obj in all_objects:
        is_contained = True
        for r, c in obj['coords']:
            if not (min_r <= r <= max_r and min_c <= c <= max_c):
                is_contained = False
                break
        if is_contained:
            contained_objects.append(obj)
            
    report['contained_objects'] = [{'color': o['color'], 'size': o['size']} for o in contained_objects]
    
    fill_color = None
    if contained_objects:
        # Sort by size (desc), then color (asc) for tie-breaking
        contained_objects.sort(key=lambda x: (-x['size'], x['color']))
        fill_color = contained_objects[0]['color']
        
    report['largest_contained_object_color'] = fill_color
    report['fill_color'] = fill_color
    results.append(report)

print(results)
```

*code_execution_result:*
outcome: OUTCOME_OK
```
[{'azure_pixels_found': True, 'bounding_box': 'Rows 4-11, Cols 10-16', 'contained_objects': [{'color': np.int64(1), 'size': 3}], 'largest_contained_object_color': np.int64(1), 'fill_color': np.int64(1)}, {'azure_pixels_found': True, 'bounding_box': 'Rows 7-14, Cols 9-14', 'contained_objects': [{'color': np.int64(7), 'size': 3}], 'largest_contained_object_color': np.int64(7), 'fill_color': np.int64(7)}, {'azure_pixels_found': True, 'bounding_box': 'Rows 6-15, Cols 6-13', 'contained_objects': [{'color': np.int64(3), 'size': 3}], 'largest_contained_object_color': np.int64(3), 'fill_color': np.int64(3)}]

```
**Analysis of Metrics:**

*   **Example 1:** Bounding box is Rows 4-11, Cols 10-16. The largest (and only) contained object has color blue (1) and size 3. Fill color is blue (1). *Correction: My manual check missed one blue pixel at (5,10) was connected to (4,10) and (4,11) via 4-connectivity if we ignore the other pixel colors during search, or it's a separate object. Let's assume the `find_objects` uses 4-connectivity and treats each colored pixel independently. Input (4,10)=1, (4,11)=1, (5,10)=1. Yes, they are connected. Size is 3. The code output is correct.*
*   **Example 2:** Bounding box is Rows 7-14, Cols 9-14. The largest (and only) contained object has color orange (7) and size 3. Fill color is orange (7).
*   **Example 3:** Bounding box is Rows 6-15, Cols 6-13. The largest contained object has color green (3) and size 3. Fill color is green (3). *Correction: Input has (14,13)=3, (15,12)=3, (15,13)=3. These form one object of size 3. The code output is correct.*

The metric analysis confirms the bounding boxes and the fill colors derived from the largest contained objects. The core issue was the application method (failed flood fill vs. direct replacement).

**YAML Facts**


```yaml
task_elements:
  - type: grid
    description: Input and output are 2D grids of pixels (0-9 colors).
  - type: background
    color_name: white
    color_value: 0
    description: The default background color.
  - type: boundary_object
    color_name: azure
    color_value: 8
    description: Contiguous or non-contiguous pixels of this color define the boundary area.
  - type: contained_objects
    description: Contiguous blocks of pixels of a single color (not white/0 and not azure/8) found within the boundary region. Must use 4-connectivity for object identification.
  - type: bounding_box
    description: The minimum bounding rectangle enclosing all azure (8) pixels (inclusive coordinates).
    role: Defines the area for the fill operation.
  - type: fill_color
    determination:
      - Find all contiguous objects (using 4-connectivity) with colors other than white (0) or azure (8).
      - Filter these objects to keep only those whose coordinates are *all* within the bounding_box (inclusive).
      - Among the filtered objects, identify the object with the largest pixel count (size). If there's a tie in size, choose the object with the numerically lowest color value.
      - The color of this selected object is the fill_color.
    role: The color used to replace background pixels within the bounding box.
transformation:
  - action: identify_boundary_pixels
    input: input_grid
    color: azure (8)
    output: list of coordinates [(r1, c1), (r2, c2), ...] for all azure pixels.
  - action: calculate_bounding_box
    input: list of azure pixel coordinates
    condition: Must contain at least one azure pixel.
    output: coordinates defining the minimum bounding rectangle (min_row, max_row, min_col, max_col). If no azure pixels, no transformation occurs.
  - action: find_all_objects
    input: input_grid
    ignore_colors: [white (0), azure (8)]
    connectivity: 4
    output: list of objects, each with {color, size, coords}.
  - action: filter_contained_objects
    input: list of objects, bounding_box
    criteria: All coordinates of an object must be within or on the bounding_box edges.
    output: list of fully contained objects.
  - action: determine_fill_color
    input: list of contained objects
    condition: List must not be empty.
    method: Find object with max size. If tie, use min color value among max-sized objects.
    output: fill_color. If no contained objects, no transformation occurs.
  - action: apply_fill_replacement
    target: input_grid (to create output_grid)
    region: All pixels (r, c) such that min_row <= r <= max_row and min_col <= c <= max_col.
    condition: The pixel at (r, c) in the *input_grid* must be white (0).
    replacement: Change the color of the pixel at (r, c) in the *output_grid* to fill_color.
    preservation: All pixels outside the bounding box, all azure (8) pixels, and all non-white pixels inside the bounding box retain their original color from the input_grid.
    output: output_grid. If no azure pixels or no contained objects found, output_grid is identical to input_grid.
```


**Natural Language Program**

1.  Create a copy of the input grid to serve as the initial output grid.
2.  Find the coordinates of all pixels in the input grid with the color azure (8).
3.  If no azure (8) pixels are found, return the unmodified output grid (which is a copy of the input).
4.  Calculate the minimum bounding box (minimum row, maximum row, minimum column, maximum column) that encloses all the found azure (8) pixels.
5.  Find all contiguous objects in the input grid using 4-way connectivity, ignoring white (0) and azure (8) pixels. Record each object's color, size (pixel count), and coordinates.
6.  Filter this list of objects, keeping only those where *all* of the object's coordinates fall within the calculated bounding box (inclusive).
7.  If no objects are fully contained within the bounding box, return the unmodified output grid.
8.  From the list of fully contained objects, select the object with the largest size. If there is a tie for the largest size, select the object with the smallest numerical color value among those tied.
9.  Identify the color of the selected object; this is the "fill color".
10. Iterate through all pixel coordinates (row `r`, column `c`) within the bounding box (from minimum row to maximum row, and minimum column to maximum column, inclusive).
11. For each coordinate (r, c) inside the bounding box, check the color of the corresponding pixel in the *input* grid.
12. If the input grid pixel at (r, c) is white (0), change the color of the pixel at (r, c) in the *output* grid to the determined "fill color".
13. Return the final output grid.
