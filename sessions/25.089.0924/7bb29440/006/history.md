
## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 4 0 0 0 0 0 0
0 1 4 1 1 0 0 0 0 0 0
0 1 1 1 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 1 1 1 1 1 1 0
0 0 0 0 1 1 1 1 1 1 0
0 0 0 0 1 1 6 1 1 1 0
0 0 0 0 1 1 1 1 1 1 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
1 1 1 1 1 1
1 1 1 1 1 1
1 1 6 1 1 1
1 1 1 1 1 1
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 4 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 4 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 6 1 0 0 0 1 1 1 1 1 0 0 0 0
0 0 1 1 6 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0
0 0 1 1 1 1 1 1 0 0 0 1 1 6 1 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 1 1 1 4 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 1 6 1 1 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0
0 0 1 1 1 1 1 1 1 0 0 1 1 1 4 1 0 0 0 0
0 0 1 1 1 1 1 4 1 0 0 1 1 1 1 1 0 0 0 0
0 0 1 1 4 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0
0 0 1 1 1 6 1 1 1 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 1 1 0 0 0 1 4 1 1 1 0 0 0
0 0 1 1 4 1 1 6 1 0 0 0 1 1 1 6 1 0 0 0
0 0 1 1 1 1 1 1 1 0 0 0 6 1 1 1 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
1 4 1 1 1
1 1 1 6 1
6 1 1 1 1
```


## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 1 6 1 4 1 0 0 0 1 1 1 1 1 1 0 0 0
0 1 1 4 1 1 1 1 1 0 0 0 1 1 6 1 1 1 0 0 0
0 1 1 1 1 4 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0
0 1 1 1 1 1 1 1 6 0 0 0 1 1 1 4 1 1 0 0 0
0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 1 6 1 1 1 1 0 0 0
0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 4 1 0 0 0
0 0 0 0 0 1 6 1 1 1 1 0 1 1 6 1 1 1 0 0 0
0 0 0 0 0 1 1 1 1 6 1 0 1 1 1 1 1 1 0 0 0
1 1 1 6 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0
6 1 1 1 0 1 1 1 4 1 1 0 0 0 0 0 0 0 0 0 0
1 4 1 6 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
1 1 1 1 0 1 6 1 1 1 1 0 0 0 1 1 1 1 4 0 0
0 0 0 0 0 1 1 1 1 4 1 0 0 0 1 4 1 1 1 0 0
0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 6 1 0 0
0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0
0 0 0 0 0 0 0 0 0 0 1 4 1 1 1 1 4 1 4 1 0
0 0 0 0 0 0 0 0 0 0 1 1 1 6 1 1 1 1 1 1 0
```


**output:**
```
1 1 1 1 4
1 4 1 1 1
1 1 1 6 1
1 1 1 1 1
```


## train_4

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 4 1 1 1 1 0 0 0
0 0 0 0 0 0 1 1 1 1 1 1 0 0 0
0 0 0 0 0 0 1 1 6 1 6 1 0 0 0
0 0 0 0 0 0 1 1 1 1 1 1 0 0 0
1 1 1 1 1 0 1 1 1 1 4 1 0 0 0
1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
1 4 1 1 1 0 0 0 0 0 0 0 0 0 0
1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
1 1 4 1 1 0 0 0 0 0 0 0 0 0 0
1 1 1 1 1 0 0 0 0 1 1 1 1 1 1
1 1 1 1 1 0 0 0 0 1 1 1 1 1 1
0 0 0 0 0 0 0 0 0 1 6 1 6 1 1
1 1 1 1 4 0 0 0 0 1 1 4 1 1 1
1 4 1 1 1 0 0 0 0 1 1 1 1 1 1
1 1 6 1 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 1 1 1 1 1 1 1 1 0 0 0
0 0 0 0 4 1 1 6 1 4 1 1 0 0 0
0 0 0 0 1 4 1 1 1 1 6 1 0 0 0
```


**output:**
```
1 1 1 1 1
1 1 1 1 1
1 4 1 1 1
1 1 1 1 1
1 1 4 1 1
1 1 1 1 1
1 1 1 1 1
```


## train_5

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 6 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0
0 4 1 6 0 0 1 6 1 1 4 1 0 0 0 0 0 0
0 0 0 0 0 0 1 1 1 6 1 1 0 0 0 0 0 0
0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1
0 1 4 1 0 0 1 6 1 1 1 1 0 1 1 1 1 1
0 6 1 1 0 0 0 0 0 0 0 0 0 1 6 1 1 1
0 1 1 6 0 0 0 0 0 0 0 0 0 1 1 1 4 1
0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 6 1 1 1 1 1 0 0 0 0 0 0
0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1
0 0 1 1 1 1 1 1 1 1 4 1 0 0 1 1 6 1
0 0 1 1 1 6 1 1 1 6 1 1 0 0 6 1 1 1
0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 4 1
0 0 1 1 1 1 1 6 1 1 1 1 0 0 0 0 0 0
0 0 1 4 1 1 1 1 1 1 1 1 0 0 0 0 0 0
0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
1 1 1 1 1
1 1 1 1 1
1 6 1 1 1
1 1 1 4 1
1 1 1 1 1
```

## Perception

1.  **Input Structure:** The input grids contain a white (0) background with multiple distinct objects composed primarily of blue (1) pixels. These blue objects are often rectangular or L-shaped but can vary.
2.  **Embedded Colors:** Within these blue objects, there are often single pixels of yellow (4) and magenta (6). Some blue objects may contain multiple instances of these colors, while others might contain none or only one type.
3.  **Output Structure:** The output grid is always a single, solid object, primarily blue (1), sometimes containing magenta (6) pixels, but never yellow (4). The output grid dimensions are smaller than the input and match the bounding box of the selected object from the input.
4.  **Transformation:** The transformation involves selecting *one* of the blue objects from the input grid and producing it as the output.
5.  **Selection Criteria:** The key seems to be the presence and count of magenta (6) pixels within the blue objects. In each example, the blue object that appears in the output is the one containing the *most* magenta (6) pixels in the input. If there's a tie in the magenta count (or if no object has magenta), the specific selection rule needs further clarification, but the provided examples seem to have a unique object with the maximum magenta count. *Correction: In train\_4, two objects have two magenta pixels. However, one object has yellow pixels and the other does not. The output corresponds to the object *without* yellow pixels in this tie-breaker case. Let's re-examine. No, that's not right. Rereading train\_4: The top-right object has (1,4), (1,6), (1,6), (1,4). The bottom-right object has (1,6), (1,6), (1,4). The bottom-left object has (1,4), (1,4), (1,6). The middle-left object has (1,4), (1,4), (1,6). The object selected for output is the bottom-right one (6x3 rectangle), containing two 6s and one 4. Let's count 6s in others: top-right has two 6s, bottom-left has one 6, middle-left has one 6. So, there's a tie between top-right and bottom-right based *only* on the count of 6s. Let's count 4s: top-right has two 4s, bottom-right has one 4. The one with fewer 4s is selected in the tie? Let's check other examples. Train 2: Top-left object has one 6, two 4s. Bottom-right object has one 6, two 4s. Middle-right object has one 6, one 4. The middle-right is selected (fewest 4s among those tied for max 6s). Train 3: Top-left: two 6s, three 4s. Top-right: two 6s, two 4s. Bottom-left: three 6s, two 4s. Bottom-middle: two 6s, two 4s. Bottom-right: one 6, three 4s. The one with the most 6s (bottom-left) is selected. Train 5: Top-left: two 6s, two 4s. Top-middle: three 6s, two 4s. Top-right: one 6, one 4. Bottom-middle: three 6s, two 4s. Bottom-right: two 6s, two 4s. There's a tie between top-middle and bottom-middle for max 6s (three each). Both also have two 4s. How is the tie broken? Let's look at the objects themselves. Top-middle is 6x4. Bottom-middle is 8x4. The output is 8x4, corresponding to the bottom-middle object. So, if counts of 6s and 4s are tied, the larger object (by area? by height? by width?) is selected. Bottom-middle has area 32, top-middle has area 24. Seems like the larger area wins in a tie. Train 4 tie-breaker check: Top-right (6x3, area 18) vs Bottom-right (6x3, area 18). Areas are the same. Let's re-examine the pixels. Top-right object pixels: (2,6) to (6,11). Bottom-right object pixels: (11,9) to (16,14). The output corresponds to the bottom-right object. Is it the lower one? Or the rightmost one? In Train 5, the winner (bottom-middle) is lower than the other tied object (top-middle). So, the tie-breaker might be: largest area, then lowest top row index.
6.  **Color Modification:** After selecting the object, any yellow (4) pixels within its bounds are changed to blue (1). Magenta (6) pixels remain unchanged. All original blue (1) pixels also remain.

## Facts


```yaml
perception:
  background_color: white (0)
  objects:
    - type: primary_shape
      color: blue (1)
      connectivity: contiguous (including diagonals for pixel membership definition, but shapes themselves are separated by background)
      properties:
        - contains_pixels:
            - yellow (4)
            - magenta (6)
        - bounding_box: defines the extent of the shape
        - pixel_count: total number of non-background pixels within the shape
        - magenta_count: count of magenta (6) pixels within the shape
        - yellow_count: count of yellow (4) pixels within the shape
        - area: calculated from bounding_box dimensions or pixel_count
        - top_row_index: the minimum row index of any pixel in the shape
  relationships:
    - multiple primary_shape objects exist in the input grid, separated by the background_color.
  actions:
    - identify: find all distinct primary_shape objects in the input.
    - analyze: for each primary_shape object, count the occurrences of magenta (6) and yellow (4) pixels, determine its area, and find its top_row_index.
    - select: choose the primary_shape object based on the following criteria, applied sequentially:
        1. Maximum magenta_count.
        2. If tied, minimum yellow_count.
        3. If still tied, maximum area (pixel_count).
        4. If still tied, maximum top_row_index (lowest object visually).
    - extract: create a new grid containing only the selected primary_shape object, cropped to its bounding box.
    - modify: within the extracted grid, change all yellow (4) pixels to blue (1).
    - output: the modified, extracted grid.
```


## Natural Language Program

1.  Identify all distinct contiguous objects composed of non-white pixels in the input grid. Consider pixels connected orthogonally or diagonally as part of the same object if they are not white. Filter these to keep only objects that contain at least one blue (1) pixel (these are the primary shapes).
2.  For each primary shape identified:
    a.  Count the number of magenta (6) pixels it contains.
    b.  Count the number of yellow (4) pixels it contains.
    c.  Calculate its area (total number of non-white pixels belonging to it).
    d.  Determine the topmost row index occupied by any of its pixels.
3.  Select the target primary shape using the following priority:
    a.  The shape with the highest count of magenta (6) pixels.
    b.  If there is a tie in magenta count, select from the tied shapes the one with the lowest count of yellow (4) pixels.
    c.  If there is still a tie, select from the tied shapes the one with the largest area (pixel count).
    d.  If there is still a tie, select from the tied shapes the one that appears lowest in the grid (i.e., has the largest topmost row index).
4.  Determine the bounding box of the selected target shape.
5.  Create a new output grid with the dimensions of the bounding box.
6.  Copy the pixels of the selected target shape from the input grid into the new output grid, maintaining their relative positions within the bounding box.
7.  Iterate through the pixels of the new output grid. If a pixel is yellow (4), change its color to blue (1). Leave all other pixels (blue (1) and magenta (6)) unchanged.
8.  The resulting grid is the final output.
```python
import numpy as np
from collections import deque

"""
Identify all distinct contiguous objects composed of non-white pixels (colors 1-9) in the input grid, considering orthogonal adjacency.
Filter these objects to keep only those containing at least one blue (1) pixel.
For each filtered object, calculate:
1. Count of magenta (6) pixels.
2. Count of yellow (4) pixels.
3. Area (total count of non-white pixels in the object).
4. Topmost row index.
Select the object based on the following criteria, applied sequentially:
1. Maximum magenta count.
2. Minimum yellow count (among ties for max magenta).
3. Maximum area (among ties for yellow count).
4. Maximum topmost row index (lowest object visually, among ties for area).
Extract the selected object based on its bounding box.
Create an output grid matching the bounding box size.
Copy the pixels of the selected object into the output grid.
Replace any yellow (4) pixels in the output grid with blue (1) pixels.
Return the final output grid.
"""

def find_objects(grid):
    """
    Finds all contiguous objects of non-white pixels in the grid using orthogonal adjacency.

    Args:
        grid (np.ndarray): The input grid.

    Returns:
        list: A list of objects, where each object is represented as a list of 
              tuples (row, col, color).
    """
    rows, cols = grid.shape
    visited = np.zeros((rows, cols), dtype=bool)
    objects = []

    for r in range(rows):
        for c in range(cols):
            if grid[r, c] != 0 and not visited[r, c]:
                # Start BFS to find a new object
                obj_pixels = []
                q = deque([(r, c)])
                visited[r, c] = True
                
                while q:
                    row, col = q.popleft()
                    color = grid[row, col]
                    obj_pixels.append((row, col, color))

                    # Check orthogonal neighbors
                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                        nr, nc = row + dr, col + dc
                        if 0 <= nr < rows and 0 <= nc < cols and \
                           grid[nr, nc] != 0 and not visited[nr, nc]:
                            visited[nr, nc] = True
                            q.append((nr, nc))
                
                # Check if the object contains at least one blue pixel
                has_blue = any(p[2] == 1 for p in obj_pixels)
                if has_blue:
                    objects.append(obj_pixels)
                    
    return objects

def analyze_object(obj_pixels):
    """
    Analyzes an object to calculate its properties for selection.

    Args:
        obj_pixels (list): List of (row, col, color) tuples for the object.

    Returns:
        dict: A dictionary containing 'magenta_count', 'yellow_count', 
              'area', 'top_row_index', and 'pixels'.
    """
    magenta_count = 0
    yellow_count = 0
    min_r = float('inf')
    
    for r, c, color in obj_pixels:
        if color == 6:
            magenta_count += 1
        elif color == 4:
            yellow_count += 1
        min_r = min(min_r, r)
        
    area = len(obj_pixels)
    
    return {
        'magenta_count': magenta_count,
        'yellow_count': yellow_count,
        'area': area,
        'top_row_index': min_r,
        'pixels': obj_pixels
    }

def get_bounding_box(obj_pixels):
    """Calculates the bounding box of an object."""
    if not obj_pixels:
        return 0, 0, 0, 0
    rows = [p[0] for p in obj_pixels]
    cols = [p[1] for p in obj_pixels]
    min_r, max_r = min(rows), max(rows)
    min_c, max_c = min(cols), max(cols)
    return min_r, min_c, max_r, max_c

def transform(input_grid):
    """
    Transforms the input grid based on the described object selection and modification rules.
    """
    # 1. Find all potential objects (non-white, containing blue)
    objects_pixels = find_objects(np.array(input_grid))

    if not objects_pixels:
        # Handle cases where no valid objects are found (return empty or original?)
        # Based on examples, there's always a valid object. If not, maybe return an empty grid?
        # Let's assume valid object exists.
        return np.array([[]]) # Or raise an error

    # 2. Analyze each object
    analyzed_objects = [analyze_object(obj) for obj in objects_pixels]

    # 3. Select the target object based on criteria
    # Sort using a stable sort is implicitly handled by applying criteria sequentially
    # Sort by magenta_count (descending)
    analyzed_objects.sort(key=lambda x: x['magenta_count'], reverse=True)
    max_magenta = analyzed_objects[0]['magenta_count']
    tied_magenta = [obj for obj in analyzed_objects if obj['magenta_count'] == max_magenta]

    # Sort by yellow_count (ascending)
    tied_magenta.sort(key=lambda x: x['yellow_count'])
    min_yellow = tied_magenta[0]['yellow_count']
    tied_yellow = [obj for obj in tied_magenta if obj['yellow_count'] == min_yellow]
    
    # Sort by area (descending)
    tied_yellow.sort(key=lambda x: x['area'], reverse=True)
    max_area = tied_yellow[0]['area']
    tied_area = [obj for obj in tied_yellow if obj['area'] == max_area]

    # Sort by top_row_index (descending - meaning lowest object)
    tied_area.sort(key=lambda x: x['top_row_index'], reverse=True)
    
    selected_object = tied_area[0]
    selected_pixels = selected_object['pixels']

    # 4. Determine bounding box
    min_r, min_c, max_r, max_c = get_bounding_box(selected_pixels)
    height = max_r - min_r + 1
    width = max_c - min_c + 1

    # 5. Create the output grid
    output_grid = np.zeros((height, width), dtype=int) # Initialize with background (0), though object pixels will overwrite

    # 6. Copy pixels, adjusting coordinates
    for r, c, color in selected_pixels:
        out_r, out_c = r - min_r, c - min_c
        # 7. Modify color if yellow
        output_grid[out_r, out_c] = 1 if color == 4 else color 

    return output_grid.tolist() # Convert back to list of lists for standard ARC format

```
```python
import numpy as np
from collections import deque

"""
Identify all distinct contiguous objects in the input grid composed of non-white (0) pixels, considering pixels connected orthogonally and diagonally (8-way connectivity). Filter this set to include only objects that contain at least one blue (1) pixel.
For each identified object:
    a. Count the total number of magenta (6) pixels it contains (magenta_count).
    b. Count the total number of yellow (4) pixels it contains (yellow_count).
    c. Calculate its total area by counting all its non-white pixels (area).
    d. Determine the topmost row index occupied by any of its pixels (top_row_index).
Select the target object using the following priority sequence:
    a. The object with the highest magenta_count.
    b. If there's a tie, select from the tied objects the one with the lowest yellow_count.
    c. If there's still a tie, select from the tied objects the one with the largest area.
    d. If there's still a tie, select from the tied objects the one that appears lowest in the grid (i.e., has the largest top_row_index).
Determine the minimum and maximum row and column indices (bounding box) of the selected target object.
Create a new output grid whose dimensions match the height and width of the bounding box.
Copy each pixel belonging to the selected target object from the input grid into the new output grid, preserving its original color and adjusting its position relative to the top-left corner of the bounding box.
The resulting grid is the final output.
"""

def find_objects_diag(grid):
    """
    Finds all contiguous objects of non-white pixels in the grid using 8-way 
    (diagonal included) connectivity, keeping only those with at least one blue pixel.

    Args:
        grid (np.ndarray): The input grid.

    Returns:
        list: A list of objects, where each object is represented as a list of 
              tuples (row, col, color).
    """
    rows, cols = grid.shape
    visited = np.zeros((rows, cols), dtype=bool)
    objects = []

    for r in range(rows):
        for c in range(cols):
            # If pixel is non-white and not visited, start BFS
            if grid[r, c] != 0 and not visited[r, c]:
                obj_pixels = []
                q = deque([(r, c)])
                visited[r, c] = True
                has_blue = False
                
                while q:
                    row, col = q.popleft()
                    color = grid[row, col]
                    # Check if object contains blue
                    if color == 1:
                        has_blue = True
                    obj_pixels.append((row, col, color))

                    # Check 8 neighbors (orthogonal and diagonal)
                    for dr in [-1, 0, 1]:
                        for dc in [-1, 0, 1]:
                            if dr == 0 and dc == 0:
                                continue # Skip self
                            nr, nc = row + dr, col + dc
                            # Check bounds, non-white color, and visited status
                            if 0 <= nr < rows and 0 <= nc < cols and \
                               grid[nr, nc] != 0 and not visited[nr, nc]:
                                visited[nr, nc] = True
                                q.append((nr, nc))
                
                # Add object to list only if it contained at least one blue pixel
                if has_blue:
                    objects.append(obj_pixels)
                    
    return objects

def analyze_object(obj_pixels):
    """
    Analyzes an object (list of pixels) to calculate its properties for selection.

    Args:
        obj_pixels (list): List of (row, col, color) tuples for the object.

    Returns:
        dict: A dictionary containing 'magenta_count', 'yellow_count', 
              'area', 'top_row_index', and the original 'pixels'.
    """
    magenta_count = 0
    yellow_count = 0
    min_r = float('inf')
    
    for r, c, color in obj_pixels:
        if color == 6:
            magenta_count += 1
        elif color == 4:
            yellow_count += 1
        min_r = min(min_r, r) # Find the topmost row index
        
    area = len(obj_pixels) # Area is the total count of pixels in the object
    
    return {
        'magenta_count': magenta_count,
        'yellow_count': yellow_count,
        'area': area,
        'top_row_index': min_r,
        'pixels': obj_pixels 
    }

def get_bounding_box(obj_pixels):
    """Calculates the bounding box (min_r, min_c, max_r, max_c) of an object."""
    if not obj_pixels:
        # Should not happen if objects are found, but handle defensively
        return 0, 0, -1, -1 
    rows = [p[0] for p in obj_pixels]
    cols = [p[1] for p in obj_pixels]
    min_r, max_r = min(rows), max(rows)
    min_c, max_c = min(cols), max(cols)
    return min_r, min_c, max_r, max_c

def transform(input_grid):
    """
    Applies the transformation rule to the input grid.
    """
    # Convert input list of lists to numpy array for easier handling
    grid_np = np.array(input_grid, dtype=int)

    # 1. Identify all distinct composite_shape objects using 8-way connectivity
    objects_pixels = find_objects_diag(grid_np)

    # Handle case where no valid objects are found
    if not objects_pixels:
        return [] # Return empty grid or handle as per specific ARC task conventions

    # 2. Analyze each object's properties
    analyzed_objects = [analyze_object(obj) for obj in objects_pixels]

    # 3. Select the target object based on sorting criteria
    # Sort key uses a tuple: (-MaxM, MinY, -MaxA, -MaxTR) 
    # Negative sign reverses order for maximization
    analyzed_objects.sort(key=lambda x: (
        -x['magenta_count'], 
         x['yellow_count'], 
        -x['area'], 
        -x['top_row_index'] 
    ))
    
    # The best object is the first one after sorting
    selected_object = analyzed_objects[0]
    selected_pixels = selected_object['pixels']

    # 4. Determine bounding box of the selected object
    min_r, min_c, max_r, max_c = get_bounding_box(selected_pixels)
    
    # Calculate output grid dimensions
    height = max_r - min_r + 1
    width = max_c - min_c + 1

    # 5. Create the output grid (initialize with background color 0)
    output_grid_np = np.zeros((height, width), dtype=int) 

    # 6. Copy pixels from the selected object to the output grid
    for r, c, color in selected_pixels:
        # Adjust coordinates to be relative to the output grid's top-left corner
        out_r, out_c = r - min_r, c - min_c
        # Preserve the original color
        output_grid_np[out_r, out_c] = color 

    # Convert the final numpy array back to a list of lists for the expected format
    output_grid = output_grid_np.tolist()

    return output_grid
```
```python
import numpy as np
from collections import deque

"""
Identify all distinct contiguous objects in the input grid composed of non-white (0) pixels, considering pixels connected orthogonally and diagonally (8-way connectivity). Filter this set to include only objects that contain at least one blue (1) pixel.
For each identified object:
    a. Count the total number of magenta (6) pixels it contains (magenta_count).
    b. Count the total number of yellow (4) pixels it contains (yellow_count).
    c. Calculate its total area by counting all its non-white pixels (area).
    d. Determine the topmost row index occupied by any of its pixels (top_row_index).
Select the target object using the following priority sequence:
    a. The object with the highest magenta_count.
    b. If there's a tie, select from the tied objects the one with the lowest yellow_count.
    c. If there's still a tie, select from the tied objects the one with the largest area.
    d. If there's still a tie, select from the tied objects the one that appears lowest in the grid (i.e., has the largest top_row_index).
Determine the minimum and maximum row and column indices (bounding box) of the selected target object.
Create a new output grid whose dimensions match the height and width of the bounding box.
Copy each pixel belonging to the selected target object from the input grid into the new output grid, preserving its original color and adjusting its position relative to the top-left corner of the bounding box.
Finally, iterate through the new output grid and change any yellow (4) pixels to blue (1). Leave all other pixel colors unchanged.
The resulting grid is the final output.
"""

def find_objects_diag(grid):
    """
    Finds all contiguous objects of non-white pixels in the grid using 8-way 
    (diagonal included) connectivity, keeping only those with at least one blue pixel.

    Args:
        grid (np.ndarray): The input grid.

    Returns:
        list: A list of objects, where each object is represented as a list of 
              tuples (row, col, color).
    """
    rows, cols = grid.shape
    visited = np.zeros((rows, cols), dtype=bool)
    objects = []

    for r in range(rows):
        for c in range(cols):
            # If pixel is non-white and not visited, start BFS
            if grid[r, c] != 0 and not visited[r, c]:
                obj_pixels = []
                q = deque([(r, c)])
                visited[r, c] = True
                has_blue = False
                
                while q:
                    row, col = q.popleft()
                    color = grid[row, col]
                    # Check if object contains blue
                    if color == 1:
                        has_blue = True
                    obj_pixels.append((row, col, color))

                    # Check 8 neighbors (orthogonal and diagonal)
                    for dr in [-1, 0, 1]:
                        for dc in [-1, 0, 1]:
                            if dr == 0 and dc == 0:
                                continue # Skip self
                            nr, nc = row + dr, col + dc
                            # Check bounds, non-white color, and visited status
                            if 0 <= nr < rows and 0 <= nc < cols and \
                               grid[nr, nc] != 0 and not visited[nr, nc]:
                                visited[nr, nc] = True
                                q.append((nr, nc))
                
                # Add object to list only if it contained at least one blue pixel
                if has_blue:
                    objects.append(obj_pixels)
                    
    return objects

def analyze_object(obj_pixels):
    """
    Analyzes an object (list of pixels) to calculate its properties for selection.

    Args:
        obj_pixels (list): List of (row, col, color) tuples for the object.

    Returns:
        dict: A dictionary containing 'magenta_count', 'yellow_count', 
              'area', 'top_row_index', and the original 'pixels'.
    """
    magenta_count = 0
    yellow_count = 0
    min_r = float('inf')
    
    for r, c, color in obj_pixels:
        if color == 6:
            magenta_count += 1
        elif color == 4:
            yellow_count += 1
        min_r = min(min_r, r) # Find the topmost row index
        
    area = len(obj_pixels) # Area is the total count of pixels in the object
    
    return {
        'magenta_count': magenta_count,
        'yellow_count': yellow_count,
        'area': area,
        'top_row_index': min_r,
        'pixels': obj_pixels 
    }

def get_bounding_box(obj_pixels):
    """Calculates the bounding box (min_r, min_c, max_r, max_c) of an object."""
    if not obj_pixels:
        # Should not happen if objects are found, but handle defensively
        return 0, 0, -1, -1 
    rows = [p[0] for p in obj_pixels]
    cols = [p[1] for p in obj_pixels]
    min_r, max_r = min(rows), max(rows)
    min_c, max_c = min(cols), max(cols)
    return min_r, min_c, max_r, max_c

def transform(input_grid):
    """
    Applies the transformation rule to the input grid.
    """
    # Convert input list of lists to numpy array for easier handling
    grid_np = np.array(input_grid, dtype=int)

    # 1. Identify all distinct composite_shape objects using 8-way connectivity
    #    that contain at least one blue pixel.
    objects_pixels = find_objects_diag(grid_np)

    # Handle case where no valid objects are found
    if not objects_pixels:
        return [] # Return empty grid 

    # 2. Analyze each object's properties (M, Y, Area, Top Row)
    analyzed_objects = [analyze_object(obj) for obj in objects_pixels]

    # 3. Select the target object based on sorting criteria:
    #    - Maximize magenta_count (negative for descending sort)
    #    - Minimize yellow_count (positive for ascending sort)
    #    - Maximize area (negative for descending sort)
    #    - Maximize top_row_index (negative for descending sort, lowest object visually)
    analyzed_objects.sort(key=lambda x: (
        -x['magenta_count'], 
         x['yellow_count'], 
        -x['area'], 
        -x['top_row_index'] 
    ))
    
    # The best object is the first one after sorting
    selected_object = analyzed_objects[0]
    selected_pixels = selected_object['pixels']

    # 4. Determine bounding box of the selected object
    min_r, min_c, max_r, max_c = get_bounding_box(selected_pixels)
    
    # Calculate output grid dimensions
    height = max_r - min_r + 1
    width = max_c - min_c + 1

    # 5. Create the output grid (initialize with background color 0)
    output_grid_np = np.zeros((height, width), dtype=int) 

    # 6. Copy pixels from the selected object to the output grid, adjusting coordinates
    for r, c, color in selected_pixels:
        # Adjust coordinates to be relative to the output grid's top-left corner
        out_r, out_c = r - min_r, c - min_c
        # Preserve the original color for now
        output_grid_np[out_r, out_c] = color 

    # 7. Modify the output grid: change yellow (4) pixels to blue (1)
    output_grid_np[output_grid_np == 4] = 1

    # Convert the final numpy array back to a list of lists for the expected format
    output_grid = output_grid_np.tolist()

    return output_grid
```
