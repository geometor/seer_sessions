
## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 8 8 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 8 8 8 8 0 0 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 8 8 0 0 0 0 0 0 0
0 0 0 0 0 8 8 8 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 8 8 8 8 8 8 8 8 8 8 0 0 0 0 0
0 0 0 8 8 8 8 8 8 8 8 8 8 8 8 0 0 0 0
0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 8 8 8 8 8 8 8 8 8 8 8 8 0 0 0 0
0 0 0 0 8 8 8 8 8 8 8 8 8 8 0 0 0 0 0
0 0 0 0 0 8 8 8 8 8 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 8 8 8 8 8 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 8 8 8 8 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 8 8 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 8 2 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 8 8 2 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 8 2 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 8 8 8 8 8 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 8 8 8 8 8 8 8 0 0 0 0
0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 0 0 0
0 0 0 0 0 0 0 0 0 0 8 8 8 8 8 8 8 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 8 8 8 8 8 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 8 8 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

Okay, let's break down the task based on the provided examples.

## Perception

1.  **Input Structure:** The input grids consist primarily of a white background (color 0) with one or more distinct objects composed of red pixels (color 2). These red objects appear as lines (horizontal or vertical) or potentially other contiguous shapes.
2.  **Output Structure:** The output grids retain the original red objects from the input. Additionally, new shapes composed of azure pixels (color 8) appear. These azure shapes surround the red objects.
3.  **Transformation:** The core transformation involves generating these azure shapes based on the properties of the red objects.
4.  **Shape Relationship:** The azure shapes resemble diamonds (or squares rotated 45 degrees) centered around the red objects. The size and extent of the azure diamond seem directly related to the corresponding red object.
5.  **Distance Metric:** The azure pixels appear to occupy locations that are within a certain *Manhattan distance* (sum of absolute differences in row and column coordinates) from the nearest red pixel of a given object.
6.  **Variable Threshold:** Comparing train_1 and train_2, the maximum distance for coloring a pixel azure changes. In train_1, the red line has 14 pixels, and the azure shape extends up to a Manhattan distance of 6. In train_2, the vertical red line (5 pixels) has an azure shape extending up to distance 2, and the horizontal red line (9 pixels) has an azure shape extending up to distance 4.
7.  **Rule Discovery:** This suggests a rule where the maximum allowed Manhattan distance (`k`) for painting azure pixels around a red object depends on the size (`L`, number of pixels) of that red object. The observed relationship is `k = floor((L - 1) / 2)`.
8.  **Process:** For each distinct red object, calculate its size `L`, determine the threshold `k`, and then color all white pixels azure if their minimum Manhattan distance to *any* pixel within *that specific* red object is greater than 0 and less than or equal to `k`.

## YAML Facts


```yaml
Initial_State:
  Grid:
    Contains:
      - Background:
          Color: white (0)
          Coverage: Most of the grid
      - Objects:
          Type: Connected Components
          Color: red (2)
          Quantity: One or more
          Shape: Primarily lines (horizontal/vertical), but can be any contiguous shape.
Final_State:
  Grid:
    Contains:
      - Background:
          Color: white (0)
      - Original_Objects:
          Type: Connected Components
          Color: red (2)
          Persistence: Unchanged from input
      - Added_Objects:
          Type: Area surrounding Original_Objects
          Color: azure (8)
          Shape: Diamond-like (related to Manhattan distance)
          Relationship_to_Original:
            - Each azure area corresponds to one red object.
            - Azure pixels occupy locations within a specific maximum Manhattan distance from the corresponding red object.
Transformation_Rule:
  Action: Add azure pixels based on red objects.
  Steps:
    - Identify distinct red (2) connected components (objects).
    - For each red object:
      - Calculate its size 'L' (pixel count).
      - Calculate a distance threshold 'k' using the formula: k = floor((L - 1) / 2).
      - Identify all pixels currently colored white (0).
      - For each white pixel:
        - Calculate the minimum Manhattan distance 'd_min' to any pixel within the current red object.
        - If 0 < d_min <= k:
          - Change the white pixel's color to azure (8).
  Properties_Used:
    - Pixel Color
    - Pixel Coordinates
    - Object Connectivity (Connected Components)
    - Object Size (Pixel Count)
    - Manhattan Distance
  Output_Color: azure (8) for added pixels.
  Input_Colors_Unaffected: red (2)
```


## Natural Language Program

1.  Create a copy of the input grid to serve as the output grid.
2.  Find all distinct connected groups (objects) of red (2) pixels in the input grid.
3.  For each identified red object:
    a. Count the number of pixels in this object. Let this count be `L`.
    b. Calculate a distance threshold `k` by taking the floor of `(L - 1) / 2`.
    c. Find the set of coordinates `(r, c)` for all pixels belonging to this red object.
    d. Iterate through every pixel location `(row, col)` in the grid.
    e. Check if the pixel at `(row, col)` in the *current output grid* is white (0).
    f. If it is white, calculate the Manhattan distance `d = |row - r| + |col - c|` for every red pixel coordinate `(r, c)` found in step 3c. Find the minimum `d_min` among these calculated distances.
    g. If `d_min` is greater than 0 AND `d_min` is less than or equal to the threshold `k` calculated in step 3b, change the color of the pixel at `(row, col)` in the output grid to azure (8).
4.  After processing all red objects, return the modified output grid.
```python
import numpy as np
from scipy.ndimage import label
import math

"""
Transformation Rule:

1. Identify all distinct connected objects composed of red pixels (color 2).
2. For each red object:
    a. Calculate its size 'L' (number of pixels).
    b. Determine a maximum Manhattan distance threshold 'k' using the formula: k = floor((L - 1) / 2).
    c. For every white pixel (color 0) in the grid, calculate its minimum Manhattan distance to any pixel within the current red object.
    d. If this minimum distance is greater than 0 and less than or equal to 'k', change the white pixel's color to azure (color 8).
3. Keep the original red pixels unchanged. Process each red object independently, updating the grid progressively.
"""

def manhattan_distance(p1, p2):
    """Calculates the Manhattan distance between two points (tuples or lists)."""
    return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])

def transform(input_grid: np.ndarray) -> np.ndarray:
    """
    Applies the transformation rule to the input grid.

    For each red object, calculates a size-dependent Manhattan distance threshold 'k'.
    Colors white pixels azure if their minimum distance to that red object is > 0 and <= k.

    Args:
        input_grid: A 2D numpy array representing the input grid.

    Returns:
        A 2D numpy array representing the transformed output grid.
    """
    # Initialize output_grid as a copy of the input
    output_grid = np.copy(input_grid)
    height, width = input_grid.shape
    
    # Define colors
    red_color = 2
    white_color = 0
    azure_color = 8

    # Find connected components (objects) of red pixels.
    # Use 8-connectivity (diagonals included) by default.
    # structure = np.array([[1,1,1], [1,1,1], [1,1,1]]) # Explicit 8-connectivity
    # labeled_array, num_features = label(input_grid == red_color, structure=structure)
    # Default connectivity for label is sufficient here (usually type 2 which is 8-connectivity for 2D)
    labeled_array, num_features = label(input_grid == red_color)

    # If no red objects are found, return the original grid copy
    if num_features == 0:
        return output_grid

    # Iterate through each identified red object (labels are 1-based)
    for i in range(1, num_features + 1):
        # Get the coordinates of all pixels belonging to the current object
        object_pixels = np.argwhere(labeled_array == i)
        
        # Skip if somehow an empty object was labeled (shouldn't happen)
        if len(object_pixels) == 0: 
            continue

        # Calculate the size 'L' of the object
        L = len(object_pixels)
        
        # Calculate the Manhattan distance threshold 'k'
        k = math.floor((L - 1) / 2)

        # If k is less than 1, no azure pixels need to be added for this object
        if k < 1:
            continue

        # Iterate through every pixel in the grid
        for r in range(height):
            for c in range(width):
                # Check if the pixel in the *current state* of the output grid is white
                if output_grid[r, c] == white_color:
                    current_pos = (r, c)
                    min_dist = float('inf')
                    
                    # Calculate the minimum Manhattan distance from the current white pixel
                    # to any pixel within the *current* red object
                    for obj_pixel_coords in object_pixels:
                        # np.argwhere returns [row, col], compatible with manhattan_distance helper
                        dist = manhattan_distance(current_pos, obj_pixel_coords)
                        min_dist = min(min_dist, dist)
                        # Optimization: if min_dist becomes 1, we know it's the minimum possible > 0
                        # but k could be large, so finding the exact minimum is needed.
                        
                    # If the minimum distance is within the calculated threshold (and > 0),
                    # change the pixel color to azure in the output grid.
                    # Note: Check is > 0 to avoid coloring the object pixels themselves if they were somehow white.
                    if 0 < min_dist <= k:
                        output_grid[r, c] = azure_color

    # Return the modified grid
    return output_grid
```
