
## train_1

**input:**
```
0 0 0 0 0 9 0 0 0 0
0 0 0 0 0 5 9 0 0 0
0 0 0 0 0 5 5 9 0 0
0 0 0 0 0 5 5 5 9 0
0 0 0 0 0 5 5 5 5 9
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
```


**output:**
```
0 0 0 0 0 9 0 0 0 0
9 0 0 0 0 0 9 0 0 0
0 9 0 0 0 0 0 9 0 0
0 0 9 0 0 0 0 0 9 0
0 0 0 9 0 0 0 0 0 9
0 0 0 0 9 0 0 0 0 0
0 0 0 0 0 9 0 0 0 0
0 0 0 0 0 0 9 0 0 0
0 0 0 0 0 0 0 9 0 0
0 0 0 0 0 0 0 0 9 0
```


## train_2

**input:**
```
7 0 0 0 0 0 0 0 0 0
0 7 0 0 0 0 0 0 0 0
0 0 7 0 0 0 0 0 0 0
0 0 0 7 5 5 0 0 0 0
0 0 0 0 7 5 0 0 0 0
0 0 0 0 0 7 0 0 0 0
0 0 0 0 0 0 7 0 0 0
0 0 0 0 0 0 0 7 0 0
0 0 0 0 0 0 0 0 7 0
0 0 0 0 0 0 0 0 0 7
```


**output:**
```
7 0 0 0 7 0 0 0 0 0
0 7 0 0 0 7 0 0 0 0
0 0 7 0 0 0 7 0 0 0
0 0 0 7 0 0 0 7 0 0
0 0 0 0 7 0 0 0 7 0
0 0 0 0 0 7 0 0 0 7
0 0 0 0 0 0 7 0 0 0
0 0 0 0 0 0 0 7 0 0
0 0 0 0 0 0 0 0 7 0
0 0 0 0 0 0 0 0 0 7
```


## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0
2 0 0 0 0 0 0 0 0 0
0 2 0 0 0 0 0 0 0 0
0 0 2 5 5 0 0 0 0 0
0 0 0 2 5 0 0 0 0 0
0 0 0 5 2 0 0 0 0 0
0 0 0 5 5 2 0 0 0 0
0 0 0 5 5 5 2 0 0 0
0 0 0 0 0 0 0 2 0 0
0 0 0 0 0 0 0 0 2 0
```


**output:**
```
0 0 0 2 0 0 0 0 0 0
2 0 0 0 2 0 0 0 0 0
0 2 0 0 0 2 0 0 0 0
0 0 2 0 0 0 2 0 0 0
0 0 0 2 0 0 0 2 0 0
0 0 0 0 2 0 0 0 2 0
2 0 0 0 0 2 0 0 0 2
0 2 0 0 0 0 2 0 0 0
0 0 2 0 0 0 0 2 0 0
0 0 0 2 0 0 0 0 2 0
```

Okay, let's analyze the task examples.

**Perception of Elements:**

1.  **Colors:** The grids use white (0) as the background. Gray (5) appears in all input examples but never in the output examples. Each example features one other distinct color: maroon (9) in example 1, orange (7) in example 2, and red (2) in example 3. Let's call these "signal" colors.
2.  **Objects:**
    *   **Signal Objects:** In each input, there's a shape (mostly diagonal lines or segments) made of the signal color.
    *   **Gray Objects:** In each input, there's a contiguous block of gray pixels. Their shape and position vary.
3.  **Transformation:**
    *   The gray pixels present in the input are always removed (changed to white) in the output.
    *   The original signal pixels from the input are always preserved in the output.
    *   New pixels of the signal color appear in the output. These new pixels form a shape that is a translated copy of the original signal shape.
4.  **Translation Determination:** The key is figuring out the translation vector (change in row `dr`, change in column `dc`) used to create the new signal pixels from the original ones. This vector seems to depend on the relationship between the gray pixels and the signal pixels. Specifically, it appears related to the coordinates of the top-leftmost gray pixel `(gr, gc)` and the top-leftmost signal pixel `(sr, sc)`.

    *   **Column Translation (`dc`):** If the top-left gray pixel's column (`gc`) is the same as the top-left signal pixel's column (`sc`), the column translation is `dc = -gc`. Otherwise (`gc != sc`), the translation is `dc = gc`.
    *   **Row Translation (`dr`):** The row translation appears to follow the formula `dr = (3 - gr - 2*sr) / 2`, using integer division (though the results are integers in the examples).

**YAML Facts:**


