{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\nTransforms the input grid based on the following rules:\n\n1.  **Initialization**: Start with an output grid identical to the input grid. Determine the background color by finding the most frequent color in the input grid.\n2.  **Object Identification**: Find all connected components (objects) of non-background colors, considering pixels connected cardinally or diagonally (8-way adjacency).\n3.  **Object Classification**: Categorize the identified objects:\n    *   **Templates**: Objects composed of more than one pixel.\n    *   **Potential Triggers**: Objects composed of exactly one pixel.\n4.  **Trigger Validation**: Identify **Actual Triggers** by checking each Potential Trigger: an Actual Trigger is a single pixel that has no non-background neighbors (including diagonals).\n5.  **Transformation Rule Application**: For each **Actual Trigger** found:\n    a.  Note the trigger's color and location.\n    b.  Identify all **Templates** that contain at least one pixel of the trigger's color.\n    c.  From these matching templates, select the **Best Template**, defined as the one with the largest number of pixels. (If multiple templates have the same largest size, the one encountered first during object identification is chosen).\n    d.  Determine the **Anchor Point** within the Best Template: find the pixel(s) matching the trigger's color; among these, select the one with the minimum row index. If there's a tie in row index, select the one with the minimum column index.\n    e.  Calculate the placement offset: `offset = trigger_location - anchor_point_location`.\n    f.  Copy all pixels from the Best Template to the output grid, applying the calculated offset to each pixel's coordinates. Ensure copied pixels stay within the grid boundaries. If multiple templates are copied, later copies overwrite earlier ones at overlapping locations.\n6.  **Final Output**: The final state of the output grid after all trigger-based template copies are completed is the result.\n\"\"\"\n\nimport numpy as np\nfrom collections import Counter\nfrom scipy.ndimage import label, find_objects as ndi_find_objects\n\ndef get_background_color(grid_np):\n    \"\"\"Finds the most frequent color in the grid, assuming it's the background.\"\"\"\n    counts = Counter(grid_np.flatten())\n    if not counts:\n        return 0 # Default background for empty grid\n    # Return the most frequent color. Ties are broken arbitrarily by Counter.\n    background_color = counts.most_common(1)[0][0]\n    return background_color\n\ndef find_all_objects(grid_np, background_color):\n    \"\"\"Finds all connected components (objects) of non-background colors using 8-way connectivity.\"\"\"\n    binary_grid = grid_np != background_color\n    # Use 8-connectivity (including diagonals)\n    structure = np.array([[1,1,1], [1,1,1], [1,1,1]], dtype=bool)\n    labeled_grid, num_labels = label(binary_grid, structure=structure)\n\n    if num_labels == 0:\n        return [] # No objects found\n\n    objects = []\n    # Get grid dimensions *before* the loop\n    rows, cols = grid_np.shape \n    object_slices = ndi_find_objects(labeled_grid) # Provides bounding boxes (slices)\n\n    for i in range(1, num_labels + 1):\n        # Check if slice exists for this label (it should if num_labels > 0)\n        if i-1 >= len(object_slices) or object_slices[i-1] is None:\n            continue # Should ideally not happen, but safety check\n\n        obj_slice = object_slices[i-1]\n        pixels = []\n        colors = set()\n        pixel_coords = set()\n        min_r_obj, max_r_obj = rows, -1 # Initialize with bounds for finding actual min/max\n        min_c_obj, max_c_obj = cols, -1\n\n        # Extract slice boundaries for iteration\n        min_r_slice, max_r_slice = obj_slice[0].start, obj_slice[0].stop\n        min_c_slice, max_c_slice = obj_slice[1].start, obj_slice[1].stop\n        \n        # Iterate only within the bounding box slice for efficiency\n        for r_rel, c_rel in np.argwhere(labeled_grid[obj_slice] == i):\n             # Convert relative slice coordinates to absolute grid coordinates\n             r = min_r_slice + r_rel\n             c = min_c_slice + c_rel\n             \n             # Check if calculated absolute coords are within grid bounds (safety)\n             if 0 <= r < rows and 0 <= c < cols:\n                 color = grid_np[r, c]\n                 pixels.append({'r': r, 'c': c, 'color': color})\n                 colors.add(color)\n                 pixel_coords.add((r, c))\n                 \n                 # Update actual min/max coordinates for the object\n                 min_r_obj = min(min_r_obj, r)\n                 max_r_obj = max(max_r_obj, r)\n                 min_c_obj = min(min_c_obj, c)\n                 max_c_obj = max(max_c_obj, c)\n\n        if pixels:\n            objects.append({\n                'id': i,\n                'pixels': pixels,\n                'coords': pixel_coords, # Set of (r, c) tuples\n                'size': len(pixels),\n                'colors': colors,\n                'bbox': (min_r_obj, min_c_obj, max_r_obj, max_c_obj) # Use calculated bounds\n            })\n\n    return objects\n\ndef is_isolated(r, c, grid_np, background_color):\n    \"\"\"Checks if a non-background pixel at (r, c) is isolated (no non-background neighbors, 8-way).\"\"\"\n    rows, cols = grid_np.shape\n    # Ensure the pixel itself isn't background (pre-condition for calling this)\n    # if grid_np[r, c] == background_color:\n    #    return False # Or raise error? Assumption is we call this on non-background pixels.\n    \n    for dr in [-1, 0, 1]:\n        for dc in [-1, 0, 1]:\n            # Skip the center pixel itself\n            if dr == 0 and dc == 0:\n                continue\n            \n            nr, nc = r + dr, c + dc\n            \n            # Check bounds\n            if 0 <= nr < rows and 0 <= nc < cols:\n                # Check if neighbor is non-background\n                if grid_np[nr, nc] != background_color:\n                    return False # Found a non-background neighbor\n                    \n    # If loop completes without finding non-background neighbors\n    return True\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the described transformation rule to the input grid.\n    \"\"\"\n    # Convert input to numpy array for easier processing\n    input_np = np.array(input_grid, dtype=int)\n    # 1. Initialization: Start with an output grid identical to the input grid.\n    output_np = np.copy(input_np)\n    rows, cols = input_np.shape\n\n    # Determine the background color\n    background_color = get_background_color(input_np)\n\n    # 2. Object Identification: Find all non-background objects\n    all_objects = find_all_objects(input_np, background_color)\n\n    # 3. Object Classification: Separate templates and potential triggers\n    templates = [obj for obj in all_objects if obj['size'] > 1]\n    potential_triggers = [obj for obj in all_objects if obj['size'] == 1]\n\n    # 4. Trigger Validation: Identify Actual Triggers (isolated single pixels)\n    actual_triggers = []\n    non_background_coords = set(tuple(p) for p in np.argwhere(input_np != background_color))\n\n    for pt in potential_triggers:\n        # Get the single pixel's info\n        pixel_info = pt['pixels'][0]\n        r, c = pixel_info['r'], pixel_info['c']\n        \n        # Check isolation: No other non-background pixel in 8 neighbors\n        is_truly_isolated = True\n        for dr in [-1, 0, 1]:\n            for dc in [-1, 0, 1]:\n                if dr == 0 and dc == 0:\n                    continue\n                nr, nc = r + dr, c + dc\n                if (nr, nc) in non_background_coords:\n                    is_truly_isolated = False\n                    break\n            if not is_truly_isolated:\n                break\n        \n        if is_truly_isolated:\n            actual_triggers.append(pt) # Add the whole object info\n\n\n    # 5. Transformation Rule Application: Process each Actual Trigger\n    for trigger in actual_triggers:\n        # a. Get trigger info\n        trigger_pixel = trigger['pixels'][0] # Only one pixel in a trigger\n        trigger_color = trigger_pixel['color']\n        target_location = (trigger_pixel['r'], trigger_pixel['c'])\n\n        # b. Identify candidate templates (must contain trigger color)\n        candidate_templates = [\n            tmpl for tmpl in templates if trigger_color in tmpl['colors']\n        ]\n\n        if not candidate_templates:\n            continue # No template found for this trigger color\n\n        # c. Select the best template (largest size)\n        # Tie-breaking: implicitly picks the first one found by find_all_objects\n        # if multiple have the same max size.\n        best_template = max(candidate_templates, key=lambda tmpl: tmpl['size'])\n\n        # d. Find the source anchor location in the best template\n        # Anchor is the top-most, then left-most pixel of the trigger_color\n        source_anchor = None\n        min_anchor_r = rows # Initialize high\n        min_anchor_c = cols # Initialize high\n        \n        anchor_candidates = []\n        for p in best_template['pixels']:\n            if p['color'] == trigger_color:\n               anchor_candidates.append((p['r'], p['c']))\n        \n        if not anchor_candidates:\n             # This condition implies a bug in candidate_templates filtering, \n             # as a template must have the trigger color to be selected.\n             # print(f\"Warning: Trigger color {trigger_color} not found in selected template {best_template['id']}. Skipping trigger at {target_location}\")\n             continue\n\n        # Find top-most row among candidates\n        min_anchor_r = min(r for r, c in anchor_candidates)\n        # Find left-most column among the top-most candidates\n        min_anchor_c = min(c for r, c in anchor_candidates if r == min_anchor_r)\n        source_anchor = (min_anchor_r, min_anchor_c)\n            \n        # e. Calculate the displacement vector\n        offset_row = target_location[0] - source_anchor[0]\n        offset_col = target_location[1] - source_anchor[1]\n\n        # f. Copy template pixels to output grid with offset\n        for p in best_template['pixels']:\n            p_loc = (p['r'], p['c'])\n            p_color = p['color']\n            \n            new_row = p_loc[0] + offset_row\n            new_col = p_loc[1] + offset_col\n\n            # Check if the new location is within the grid bounds before writing\n            if 0 <= new_row < rows and 0 <= new_col < cols:\n                output_np[new_row, new_col] = p_color\n\n    # 6. Final Output: Convert the final numpy array back to a list of lists\n    output_grid = output_np.tolist()\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 4890,
    "candidates_token_count": 2773,
    "total_token_count": 7663,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 26.377072,
  "retries": null
}