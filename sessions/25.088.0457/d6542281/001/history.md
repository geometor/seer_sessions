
## train_1

**input:**
```
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 1 4 2 2 2 2 2 2 2 2 8 2 2 2 2 2
2 2 2 2 2 1 2 2 2 2 2 2 8 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 3 2 8 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 3 8 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 3 3 3 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
```


**output:**
```
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 1 4 2 2 2 2 2 2 3 2 8 2 2 2 2 2
2 2 2 2 2 1 2 2 2 2 2 3 8 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 3 3 3 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 1 4 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2
2 2 2 2 2 2 3 2 8 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 3 8 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 3 3 3 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
```


## train_2

**input:**
```
1 1 1 1 1 1 1 1 1 1 1 1 1
1 2 2 1 1 1 1 1 1 1 1 1 1
1 2 4 1 1 1 1 1 1 1 1 1 1
1 1 1 4 2 1 1 1 1 1 1 1 1
1 1 1 2 8 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 4 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 8 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
```


**output:**
```
1 1 1 1 1 1 1 1 1 1 1 1 1
1 2 2 1 1 1 1 1 1 1 1 1 1
1 2 4 1 1 1 1 1 1 1 1 1 1
1 1 1 4 2 1 1 1 1 1 1 1 1
1 1 1 2 8 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 2 2 1 1 1 1 1 1
1 1 1 1 1 2 4 1 1 1 1 1 1
1 1 1 1 1 1 1 4 2 1 1 1 1
1 1 1 1 1 1 1 2 8 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1
```


## train_3

**input:**
```
8 8 8 8 8 8 8 8 8 8 8 8 8
1 8 8 8 8 8 8 8 8 8 8 8 8
8 2 8 1 8 8 8 8 8 8 8 8 8
8 8 2 1 8 8 8 8 8 8 2 8 8
8 1 1 3 8 8 8 8 8 8 8 2 8
8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 2 8 8 8 8 8 8 8
8 8 8 8 8 8 2 8 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8
```


**output:**
```
8 8 8 8 8 8 8 8 8 8 8 8 8
1 8 8 8 8 8 8 8 8 8 8 8 8
8 2 8 1 8 8 8 8 8 1 8 8 8
8 8 2 1 8 8 8 8 8 8 2 8 1
8 1 1 8 8 8 8 8 8 8 8 2 1
8 8 8 8 8 8 8 8 8 8 1 1 3
8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 1 8 8 8 8 8 8 8 8
8 8 8 8 8 2 8 1 8 8 8 8 8
8 8 8 8 8 8 2 1 8 8 8 8 8
8 8 8 8 8 1 1 3 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8
8 8 8 8 8 8 8 8 8 8 8 8 8
```

Okay, let's break down this task.

## Perception

1.  **Grid Structure:** The input and output are both grids of colored pixels. The size of the grid remains the same.
2.  **Background Color:** Each example has a dominant background color (Red=2 in Ex1, Blue=1 in Ex2, Azure=8 in Ex3) which remains largely unchanged in the output, except where objects are placed.
3.  **Objects:** There are distinct objects composed of contiguous non-background pixels. These objects vary in size and color composition.
4.  **Object Types:** We can observe two types of non-background elements:
    *   **Multi-pixel Objects:** Complex shapes made of two or more connected pixels, often of different colors. These seem to act as "templates".
    *   **Single-pixel Objects:** Isolated pixels of a specific color, not connected to any other non-background pixel. These seem to act as "triggers" or "anchors".
5.  **Transformation:** The core transformation appears to be a copying or stamping mechanism. The multi-pixel "template" objects are copied and placed onto the grid at locations determined by the single-pixel "trigger" objects.
6.  **Anchoring:** The placement of the copied template seems precise. It appears that a pixel of a specific color *within* the template object serves as a source anchor, and the single trigger pixel of the *same* color serves as the target anchor. The entire template object is then translated so that the source anchor aligns with the target anchor.
7.  **Multiple Copies:** If there are multiple single-pixel triggers, multiple copies of the corresponding template(s) are generated. If multiple triggers of the same color exist, they each trigger a copy. If triggers of different colors exist, they trigger copies of templates containing those colors.
8.  **Template Selection:** If multiple templates contain the required anchor color for a trigger pixel (as potentially in Ex3 with Red), the template with greater complexity (e.g., more pixels or more colors) appears to be selected. In the given examples, the most complex object containing the trigger color is always used.
9.  **Overlapping:** Copied objects can overlap with each other and with the original objects. The later copies overwrite earlier ones or the original background/objects where they overlap.
10. **Persistence:** The original template objects and trigger pixels remain in their original positions in the output grid.

## YAML Facts


```yaml
task_description: Copy template objects based on trigger pixel locations and colors.

definitions:
  background_color: The most frequent pixel color in the input grid.
  object: A contiguous group of one or more non-background pixels.
    properties:
      - pixels: List of coordinates and colors [(row, col, color), ...]
      - size: Number of pixels in the object.
      - colors: Set of unique colors present in the object.
      - bounding_box: Top-left and bottom-right coordinates.
  template_object: An object with size > 1.
  trigger_pixel: An object with size = 1 (a single pixel).
    properties:
      - location: (row, col)
      - color: pixel color

transformation_rules:
  - Identify the background_color.
  - Find all objects (contiguous non-background pixels).
  - Classify objects into template_objects (size > 1) and trigger_pixels (size = 1).
  - Initialize the output grid as a copy of the input grid.
  - For each trigger_pixel:
      - Get its location (target_row, target_col) and color (trigger_color).
      - Find candidate template_objects that contain the trigger_color.
      - Select the 'best' template_object:
          - If multiple candidates exist, choose the one with the largest size. (If sizes are equal, potentially the one with most colors, or the one appearing first in a top-to-bottom, left-to-right scan). Based on examples, largest size seems sufficient.
      - If a best template_object is found:
          - Find the 'source anchor' pixel within the best template_object: This is the pixel with the trigger_color that has the minimum row index, and minimum column index among those with the minimum row index. Let its location be (source_row, source_col).
          - Calculate the offset: (offset_row, offset_col) = (target_row - source_row, target_col - source_col).
          - For each pixel (r, c, color) in the best template_object:
              - Calculate the new position: (new_row, new_col) = (r + offset_row, c + offset_col).
              - If (new_row, new_col) is within the grid boundaries:
                  - Update the output grid at (new_row, new_col) with the pixel's color.

relationships:
  - A trigger_pixel (color C, location L_target) initiates a copy operation.
  - The operation uses a template_object that contains color C.
  - The copy is positioned by aligning the first instance of color C within the template (L_source) with the trigger pixel's location (L_target).

output_generation:
  - The final output grid contains the original objects plus all the copied template objects, potentially overlapping.
```


## Natural Language Program

1.  Identify the background color (the most common color) in the input grid.
2.  Find all distinct objects in the input grid, where an object is a contiguous group of connected pixels that are not the background color.
3.  Separate the objects into two categories:
    *   "Templates": Objects consisting of more than one pixel.
    *   "Triggers": Objects consisting of exactly one pixel.
4.  Create the initial output grid by copying the input grid exactly.
5.  For each "Trigger" pixel found:
    a.  Note its color (let's call it `trigger_color`) and its location (let's call it `target_location`).
    b.  Identify all "Template" objects that contain at least one pixel of `trigger_color`.
    c.  If there are multiple such Template objects, select the one with the largest number of pixels as the `chosen_template`. (If there's a tie in size, potentially use other criteria like the number of unique colors, or simply the first one encountered in a scan, but size seems primary based on examples). If no template contains the `trigger_color`, do nothing for this trigger.
    d.  Within the `chosen_template`, find the coordinates of the pixel that matches the `trigger_color` and has the minimum row index. If there are multiple such pixels in the minimum row, choose the one with the minimum column index. This is the `source_anchor_location`.
    e.  Calculate the displacement vector (row_offset, col_offset) needed to move the `source_anchor_location` to the `target_location`. `row_offset = target_location.row - source_anchor_location.row`, `col_offset = target_location.col - source_anchor_location.col`.
    f.  Iterate through every pixel (with color `p_color` at location `p_loc`) in the `chosen_template`. Calculate its new location: `new_loc = (p_loc.row + row_offset, p_loc.col + col_offset)`.
    g.  If `new_loc` is within the bounds of the grid, update the output grid at `new_loc` with the color `p_color`. This overwrites any previous color at that location in the output grid.
6.  After processing all "Trigger" pixels, the resulting output grid is the final answer.
