{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque, defaultdict\n\n\"\"\"\nTransformation Rule:\n1. Find all distinct connected objects (contiguous non-white pixels) in the input grid.\n2. For each object, determine its 'frame' color. The frame color is defined as the most frequent color among the object's pixels that are adjacent (4-connectivity) to the background (white, color 0). If an object has no pixels adjacent to the background or is a single pixel, its frame color is simply its most frequent color (or its only color).\n3. Identify objects that contain an 'internal pattern'. An internal pattern consists of all pixels within the object whose color is *different* from the object's frame color. Store this pattern as a dictionary mapping relative coordinates (dr, dc) from the object's top-left corner to the pattern color. An object with such a pattern is a 'template'.\n4. Identify objects that are 'solid'. A solid object consists entirely of pixels of its frame color (i.e., it has no internal pattern). These are 'targets'.\n5. Group objects by their frame color. Within each group, there should ideally be one template object and one or more target objects.\n6. For each group with a template and targets:\n    a. Get the pattern from the template object.\n    b. For each target object in the group:\n        i. Iterate through the template's pattern elements `{(dr, dc): pattern_color}`.\n        ii. Calculate the corresponding absolute coordinates `(abs_r, abs_c)` within the target's bounding box: `abs_r = target_min_r + dr`, `abs_c = target_min_c + dc`.\n        iii. Check if the calculated coordinate `(abs_r, abs_c)` exists within the *original set of pixels* defining the target object.\n        iv. If it does, change the color of the pixel at `(abs_r, abs_c)` in the output grid to `pattern_color`. This effectively copies the pattern onto the target, constrained by the target's shape.\n7. The output grid is the initial grid modified by applying the patterns to the corresponding targets.\n\"\"\"\n\ndef find_objects(grid):\n    \"\"\"\n    Finds all connected components of non-background colors using BFS.\n    Args:\n        grid (np.array): Input grid.\n    Returns:\n        list: A list of objects, where each object is a dictionary containing:\n            - 'pixels': A set of (row, col) tuples belonging to the object.\n            - 'bbox': A tuple (min_r, min_c, max_r, max_c) representing the bounding box.\n            - 'colors': A defaultdict counting the occurrences of each color in the object.\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n    \n    for r in range(rows):\n        for c in range(cols):\n            if grid[r, c] != 0 and not visited[r, c]:\n                color = grid[r, c]\n                q = deque([(r, c)])\n                visited[r, c] = True\n                pixels = set([(r, c)])\n                min_r, min_c, max_r, max_c = r, c, r, c\n                obj_colors = defaultdict(int)\n                obj_colors[color] += 1\n                \n                while q:\n                    curr_r, curr_c = q.popleft()\n                    \n                    min_r = min(min_r, curr_r)\n                    min_c = min(min_c, curr_c)\n                    max_r = max(max_r, curr_r)\n                    max_c = max(max_c, curr_c)\n                    \n                    # Check neighbors (4-connectivity)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = curr_r + dr, curr_c + dc\n                        \n                        if 0 <= nr < rows and 0 <= nc < cols and \\\n                           grid[nr, nc] != 0 and not visited[nr, nc]:\n                            visited[nr, nc] = True\n                            pixels.add((nr, nc))\n                            q.append((nr, nc))\n                            obj_colors[grid[nr, nc]] += 1\n                            \n                objects.append({\n                    'pixels': pixels,\n                    'bbox': (min_r, min_c, max_r, max_c),\n                    'colors': obj_colors\n                })\n    return objects\n\ndef get_object_properties(obj, grid):\n    \"\"\"\n    Determines the frame color, internal pattern, and solidity of an object.\n    Args:\n        obj (dict): An object dictionary from find_objects.\n        grid (np.array): The input grid.\n    Returns:\n        tuple: (frame_color, has_internal_pattern, is_solid, pattern_details)\n               pattern_details is a dict {(dr, dc): color} or None if no pattern.\n               Returns (None, False, False, None) if properties cannot be determined.\n    \"\"\"\n    pixels = obj['pixels']\n    min_r, min_c, max_r, max_c = obj['bbox']\n    obj_colors = obj['colors']\n    rows, cols = grid.shape\n    \n    if not pixels:\n        return None, False, False, None\n\n    # Determine frame color: most frequent color adjacent to background (0)\n    adjacent_to_bg_colors = defaultdict(int)\n    has_adjacent_to_bg = False\n    for r, c in pixels:\n        is_adj_to_bg = False\n        for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n            nr, nc = r + dr, c + dc\n            if not (0 <= nr < rows and 0 <= nc < cols) or grid[nr, nc] == 0:\n                is_adj_to_bg = True\n                break\n        if is_adj_to_bg:\n            adjacent_to_bg_colors[grid[r, c]] += 1\n            has_adjacent_to_bg = True\n\n    if has_adjacent_to_bg:\n        # Frame color is the most frequent among those adjacent to background\n        frame_color = max(adjacent_to_bg_colors, key=adjacent_to_bg_colors.get)\n    elif obj_colors:\n        # Fallback: most frequent color overall if no pixel is adjacent to background\n        # Or if it's a single pixel object\n         frame_color = max(obj_colors, key=obj_colors.get)\n    else:\n        # Should not happen if pixels is not empty\n        return None, False, False, None \n\n    # Extract internal pattern (pixels with color != frame_color)\n    pattern_details = {}\n    for r, c in pixels:\n        pixel_color = grid[r, c]\n        if pixel_color != frame_color:\n            dr = r - min_r\n            dc = c - min_c\n            pattern_details[(dr, dc)] = pixel_color\n            \n    has_internal_pattern = bool(pattern_details)\n    is_solid = not has_internal_pattern\n            \n    return frame_color, has_internal_pattern, is_solid, pattern_details\n\n\ndef transform(input_grid_list):\n    \"\"\"\n    Transforms the input grid based on the described pattern transfer logic.\n    Args:\n        input_grid_list (list): A list of lists representing the input grid.\n    Returns:\n        list: A list of lists representing the transformed output grid.\n    \"\"\"\n    input_grid = np.array(input_grid_list, dtype=int)\n    output_grid = np.copy(input_grid)\n    \n    # 1. Find all distinct objects\n    objects = find_objects(input_grid)\n    \n    # 2. Group objects by frame color and identify templates/targets\n    grouped_objects = defaultdict(lambda: {'template': None, 'targets': [], 'pattern': None})\n    \n    for obj in objects:\n        # 3. Determine properties for each object\n        props = get_object_properties(obj, input_grid)\n        if props:\n            frame_color, has_pattern, is_solid, pattern_details = props\n            \n            if frame_color is not None:\n                obj_data = {'bbox': obj['bbox'], 'pixels': obj['pixels']}\n                \n                # 4. Classify as template or target\n                if has_pattern:\n                    # Assume only one template per color group for simplicity\n                    if grouped_objects[frame_color]['template'] is None:\n                        grouped_objects[frame_color]['template'] = obj_data\n                        grouped_objects[frame_color]['pattern'] = pattern_details\n                    else:\n                        # Handle multiple potential templates if needed (e.g., pick largest, first found?)\n                        # Current logic: keep the first one found.\n                        pass \n                elif is_solid:\n                    # Object is solid frame color -> target\n                    grouped_objects[frame_color]['targets'].append(obj_data)\n\n    # 5. & 6. Apply patterns from templates to targets within each group\n    for frame_color, group in grouped_objects.items():\n        template = group['template']\n        pattern = group['pattern']\n        targets = group['targets']\n        \n        if template and pattern and targets:\n            # Template exists, has a pattern, and there are targets of the same frame color\n            \n            for target in targets:\n                target_min_r, target_min_c, _, _ = target['bbox']\n                target_pixels = target['pixels'] # The set of actual pixels in the target\n\n                # Iterate through the pattern elements extracted from the template\n                for (dr, dc), pattern_color in pattern.items():\n                    # Calculate the absolute position where this pattern pixel should go in the target\n                    abs_r = target_min_r + dr\n                    abs_c = target_min_c + dc\n                    \n                    # Crucial check: Apply pattern color *only if* the target position (abs_r, abs_c)\n                    # corresponds to an actual pixel within the target object's original shape.\n                    if (abs_r, abs_c) in target_pixels:\n                         # Since the target was identified as solid, input_grid[abs_r, abs_c] == frame_color.\n                         # Update the output grid at this position.\n                         output_grid[abs_r, abs_c] = pattern_color\n\n    # 7. Return the modified grid as a list of lists\n    return output_grid.tolist() \n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 19326,
    "candidates_token_count": 2481,
    "total_token_count": 21807,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 121.447802,
  "retries": null
}