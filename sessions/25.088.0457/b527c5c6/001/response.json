{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nTransformation rule:\n1. Find all red pixels (color 2) in the input grid.\n2. For each red pixel:\n   a. Identify the connected object consisting of the red pixel and all orthogonally adjacent green pixels (color 3).\n   b. Determine the local orientation of the object relative to the red pixel by checking its immediate green neighbors:\n      - If green neighbors are only horizontal (left/right), the orientation is 'horizontal'.\n      - If green neighbors are only vertical (up/down), the orientation is 'vertical'.\n   c. Determine the expansion direction based on the orientation and adjacent white pixels (color 0):\n      - If 'horizontal' orientation: check up/down from the red pixel for a white pixel. If white is above, direction is 'Up'; if white is below, direction is 'Down'.\n      - If 'vertical' orientation: check left/right from the red pixel for a white pixel. If white is left, direction is 'Left'; if white is right, direction is 'Right'.\n   d. Expand the object: For every pixel belonging to the identified object, fill the adjacent white pixels in the determined expansion direction with the original color of that object pixel, continuing until a non-white pixel or the grid boundary is encountered. This expansion happens on a copy of the input grid.\n3. Return the modified grid.\n\"\"\"\n\ndef find_connected_object(grid, start_r, start_c):\n    \"\"\"Finds the connected object of red (2) and green (3) pixels starting from (start_r, start_c).\"\"\"\n    rows, cols = grid.shape\n    q = deque([(start_r, start_c)])\n    visited = set([(start_r, start_c)])\n    obj_coords = set([(start_r, start_c)])\n    valid_colors = {2, 3} # Red and Green\n\n    while q:\n        r, c = q.popleft()\n\n        for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n            nr, nc = r + dr, c + dc\n            if 0 <= nr < rows and 0 <= nc < cols and (nr, nc) not in visited:\n                if grid[nr, nc] in valid_colors:\n                    visited.add((nr, nc))\n                    q.append((nr, nc))\n                    obj_coords.add((nr, nc))\n    return obj_coords\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the transformation rule to the input grid.\n    Finds objects marked by a red pixel, determines their expansion direction based on local structure,\n    and expands each pixel of the object into adjacent white space along that direction.\n    \"\"\"\n    input_grid_np = np.array(input_grid, dtype=int)\n    output_grid = np.copy(input_grid_np)\n    rows, cols = input_grid_np.shape\n\n    # Find all red pixels\n    red_pixels = np.argwhere(input_grid_np == 2)\n\n    # Store processed object coordinates to avoid reprocessing if multiple red pixels are part of the same logical object (shouldn't happen based on task description, but good practice).\n    processed_coords = set()\n\n    for red_r, red_c in red_pixels:\n        # Skip if this red pixel was part of an already processed object\n        if (red_r, red_c) in processed_coords:\n            continue\n\n        # 1. Identify the connected object\n        object_coords = find_connected_object(input_grid_np, red_r, red_c)\n        processed_coords.update(object_coords) # Mark all coords in this object as processed\n\n        # 2. Determine local orientation and expansion direction\n        has_horizontal_green = False\n        has_vertical_green = False\n        expansion_direction = None\n        direction_vector = (0, 0)\n\n        # Check horizontal neighbors of the red pixel\n        if (red_c > 0 and input_grid_np[red_r, red_c - 1] == 3) or \\\n           (red_c < cols - 1 and input_grid_np[red_r, red_c + 1] == 3):\n            has_horizontal_green = True\n\n        # Check vertical neighbors of the red pixel\n        if (red_r > 0 and input_grid_np[red_r - 1, red_c] == 3) or \\\n           (red_r < rows - 1 and input_grid_np[red_r + 1, red_c] == 3):\n            has_vertical_green = True\n\n        # Determine expansion direction based on orientation and adjacent white space\n        if has_horizontal_green and not has_vertical_green:\n            # Check Up\n            if red_r > 0 and input_grid_np[red_r - 1, red_c] == 0:\n                expansion_direction = 'Up'\n                direction_vector = (-1, 0)\n            # Check Down\n            elif red_r < rows - 1 and input_grid_np[red_r + 1, red_c] == 0:\n                expansion_direction = 'Down'\n                direction_vector = (1, 0)\n        elif has_vertical_green and not has_horizontal_green:\n            # Check Left\n            if red_c > 0 and input_grid_np[red_r, red_c - 1] == 0:\n                expansion_direction = 'Left'\n                direction_vector = (0, -1)\n            # Check Right\n            elif red_c < cols - 1 and input_grid_np[red_r, red_c + 1] == 0:\n                expansion_direction = 'Right'\n                direction_vector = (0, 1)\n\n        # 3. Expand the object if a direction was determined\n        if expansion_direction:\n            dr, dc = direction_vector\n            # Iterate through each pixel coordinate in the identified object\n            for obj_r, obj_c in object_coords:\n                original_color = input_grid_np[obj_r, obj_c]\n                # Start tracing from the cell adjacent in the expansion direction\n                curr_r, curr_c = obj_r + dr, obj_c + dc\n                # While within bounds and the target cell in the *output* grid is white\n                while 0 <= curr_r < rows and 0 <= curr_c < cols and output_grid[curr_r, curr_c] == 0:\n                    # Fill the white cell with the original color of the object pixel\n                    output_grid[curr_r, curr_c] = original_color\n                    # Move to the next cell in the expansion direction\n                    curr_r += dr\n                    curr_c += dc\n\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 8090,
    "candidates_token_count": 1587,
    "total_token_count": 9677,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 21.324664,
  "retries": null
}