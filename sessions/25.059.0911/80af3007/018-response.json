{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\nThe transformation extracts gray (5) shapes from the input grid and redraws them, scaled down, into a 9x9 output grid. The shapes and relative positions of the gray objects are preserved during the scaling. The scaling is done by finding a bounding box that encompasses all gray objects, and then proportionally scaling that box to fit within the 9x9 output grid.\n\"\"\"\n\nimport numpy as np\n\ndef find_objects(grid, color):\n    # Find contiguous regions of the specified color\n    objects = []\n    visited = np.zeros_like(grid, dtype=bool)\n\n    rows, cols = grid.shape\n    for r in range(rows):\n        for c in range(cols):\n            if grid[r, c] == color and not visited[r, c]:\n                obj = []\n                stack = [(r, c)]\n                while stack:\n                    curr_r, curr_c = stack.pop()\n                    if 0 <= curr_r < rows and 0 <= curr_c < cols and grid[curr_r, curr_c] == color and not visited[curr_r, curr_c]:\n                        visited[curr_r, curr_c] = True\n                        obj.append((curr_r, curr_c))\n                        stack.extend([(curr_r + 1, curr_c), (curr_r - 1, curr_c), (curr_r, curr_c + 1), (curr_r, curr_c - 1)])\n                objects.append(obj)\n    return objects\n\ndef get_encompassing_bounding_box(objects):\n    # Calculate a bounding box encompassing a *list* of objects.\n    all_coords = [coord for obj in objects for coord in obj]\n    if not all_coords:  # Handle the case where there are no objects.\n        return (0, 0, 0, 0)\n    min_r = min(r for r, c in all_coords)\n    max_r = max(r for r, c in all_coords)\n    min_c = min(c for r, c in all_coords)\n    max_c = max(c for r, c in all_coords)\n    return (min_r, min_c, max_r, max_c)\n\ndef transform(input_grid):\n    # initialize output_grid\n    output_grid = np.zeros((9, 9), dtype=int)\n\n    # Find gray objects\n    gray_objects = find_objects(input_grid, 5)\n\n    # Find encompassing bounding box\n    min_r, min_c, max_r, max_c = get_encompassing_bounding_box(gray_objects)\n\n    # Calculate scaling factors\n    bbox_height = max_r - min_r + 1\n    bbox_width = max_c - min_c + 1\n\n    if bbox_height == 0 or bbox_width == 0:  # Handle cases with no objects or a single point\n        scale = 0  # No scaling if there are no gray pixels\n    else:\n        scale = min(9 / bbox_height, 9 / bbox_width)\n\n\n    # Extract and project pattern into smaller grid, scaling based off encompassing box\n    for obj in gray_objects:\n        for r, c in obj:\n          # calculate scaled coordinates using the encompassing bounding box\n          scaled_r = int((r - min_r) * scale)\n          scaled_c = int((c - min_c) * scale)\n\n          # Check bounds (due to rounding, some coordinates might fall outside)\n          if 0 <= scaled_r < 9 and 0 <= scaled_c < 9:\n            output_grid[scaled_r, scaled_c] = 5\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 6747,
    "candidates_token_count": 860,
    "total_token_count": 7607,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.0-pro-exp-02-05",
  "response_time": 8.231047,
  "response_file": "018-response.json"
}