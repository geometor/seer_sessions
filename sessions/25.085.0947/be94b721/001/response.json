{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\ndef find_objects(grid):\n    \"\"\"\n    Finds all connected components (objects) of non-background pixels in the grid.\n\n    Args:\n        grid (np.ndarray): The input grid.\n\n    Returns:\n        list: A list of objects, where each object is a dictionary containing:\n              'color': The color of the object's pixels.\n              'coords': A set of (row, col) tuples representing the object's pixels.\n              'size': The number of pixels in the object.\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n\n    for r in range(rows):\n        for c in range(cols):\n            # Check if the pixel is not background (0) and not visited\n            if grid[r, c] != 0 and not visited[r, c]:\n                color = grid[r, c]\n                current_object_coords = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n\n                # Start BFS to find all connected pixels of the same color\n                while q:\n                    row, col = q.popleft()\n                    current_object_coords.add((row, col))\n\n                    # Check 4 neighbors (up, down, left, right)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n\n                        # Check bounds and if the neighbor is the same color and not visited\n                        if 0 <= nr < rows and 0 <= nc < cols and \\\n                           grid[nr, nc] == color and not visited[nr, nc]:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n                \n                # Store the found object\n                objects.append({\n                    'color': color,\n                    'coords': current_object_coords,\n                    'size': len(current_object_coords)\n                })\n\n    return objects\n\ndef get_bounding_box(coords):\n    \"\"\"\n    Calculates the minimum bounding box for a set of coordinates.\n\n    Args:\n        coords (set): A set of (row, col) tuples.\n\n    Returns:\n        tuple: (min_row, min_col, max_row, max_col)\n    \"\"\"\n    if not coords:\n        return 0, 0, 0, 0 # Should not happen if an object is found\n    min_row = min(r for r, c in coords)\n    min_col = min(c for r, c in coords)\n    max_row = max(r for r, c in coords)\n    max_col = max(c for r, c in coords)\n    return min_row, min_col, max_row, max_col\n\n\ndef transform(input_grid):\n    \"\"\"\n    Identifies the largest non-background object in the input grid by pixel count,\n    and returns a new grid containing only that object, cropped to its bounding box.\n\n    1. Convert input list of lists to a NumPy array.\n    2. Find all connected components (objects) of non-background pixels.\n    3. Identify the object with the maximum number of pixels (largest size).\n    4. Determine the bounding box coordinates of the largest object.\n    5. Create an output grid sized to the bounding box, filled with background color (0).\n    6. Copy the pixels of the largest object into the output grid, adjusting coordinates relative to the bounding box.\n    7. Convert the output NumPy array back to a list of lists.\n    \"\"\"\n    \n    input_np = np.array(input_grid, dtype=int)\n    \n    # Find all objects in the grid\n    objects = find_objects(input_np)\n\n    # Handle case where there are no non-background objects\n    if not objects:\n        return [[]] # Or potentially return an empty grid or input based on convention\n\n    # Find the largest object based on size (pixel count)\n    largest_object = max(objects, key=lambda obj: obj['size'])\n\n    # Get the coordinates and color of the largest object\n    largest_coords = largest_object['coords']\n    largest_color = largest_object['color'] # Actually, color is needed for placement\n\n    # Determine the bounding box of the largest object\n    min_r, min_c, max_r, max_c = get_bounding_box(largest_coords)\n\n    # Calculate the dimensions of the output grid\n    output_height = max_r - min_r + 1\n    output_width = max_c - min_c + 1\n\n    # Initialize the output grid with background color (0)\n    output_np = np.zeros((output_height, output_width), dtype=int)\n\n    # Place the largest object's pixels into the output grid\n    for r, c in largest_coords:\n        # Adjust coordinates relative to the top-left corner of the bounding box\n        output_r = r - min_r\n        output_c = c - min_c\n        output_np[output_r, output_c] = largest_color\n\n    # Convert the output NumPy array back to a list of lists\n    output_grid = output_np.tolist()\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 2728,
    "candidates_token_count": 1230,
    "total_token_count": 3958,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 14.706588
}