{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import Counter\nimport copy\n\n\"\"\"\nTransforms an input grid by identifying connected components of 'relevant' pixels, \ndetermining a representative color for each component, filtering based on color rules, \nsorting the components, and stacking them vertically in a new grid, centered horizontally.\n\n1.  **Identify Background:** Determine the `background_color` (most frequent color).\n2.  **Identify Relevant Pixels:** Mark pixels as 'relevant' if they are not the background \n    color, not Gray (5), Orange (7), or Maroon (9). If the background is Azure (8), \n    also mark Red (2) as not relevant.\n3.  **Find Conceptual Shapes:** Find connected components (4-connectivity) of relevant pixels.\n4.  **Characterize Shapes:** For each component (shape), determine its pixel set, bounding \n    box, height, width, top-left coordinate, and representative color (the original color \n    of the top-most, left-most pixel within the component).\n5.  **Filter Shapes:** (Redundant check) Ensure representative color isn't ignored.\n6.  **Sort Shapes:** Sort by top-left coordinate (row then column).\n7.  **Conditional Reverse:** Reverse sort order if background is Yellow (4).\n8.  **Determine Output Dimensions:** `output_height` = sum of shape heights, \n    `output_width` = max of shape widths. Handle empty/zero cases.\n9.  **Construct Output Grid:** Create background grid. Stack shapes vertically, centered \n    horizontally, using their representative color for all pixels of the shape.\n10. **Return:** The constructed grid.\n\"\"\"\n\nimport numpy as np\nfrom collections import Counter\n\ndef find_background_color(grid):\n    \"\"\"Finds the most frequent color in the grid.\"\"\"\n    if grid.size == 0:\n        return 0 # Default to white if grid is empty\n    counts = Counter(grid.flatten())\n    if not counts:\n        return 0\n    # If multiple colors have the same max frequency, np rules might apply,\n    # but most_common(1) usually picks one consistently.\n    # In ARC, background is typically unambiguous.\n    background_color = counts.most_common(1)[0][0]\n    return background_color\n\ndef find_conceptual_shapes(grid, background_color):\n    \"\"\"\n    Finds connected components of relevant pixels, treating all relevant colors\n    as connectable, and characterizes each component.\n    \"\"\"\n    rows, cols = grid.shape\n    if rows == 0 or cols == 0:\n        return []\n\n    always_ignored_colors = {5, 7, 9} # Gray, Orange, Maroon\n    relevant_mask = np.ones(grid.shape, dtype=bool)\n\n    # Mark background as not relevant\n    relevant_mask[grid == background_color] = False\n\n    # Mark always ignored colors as not relevant\n    for color in always_ignored_colors:\n        relevant_mask[grid == color] = False\n\n    # Mark conditional ignored colors (Red if background is Azure)\n    if background_color == 8:\n        relevant_mask[grid == 2] = False\n\n    visited = np.zeros(grid.shape, dtype=bool)\n    shapes = []\n\n    for r in range(rows):\n        for c in range(cols):\n            # Start BFS from an unvisited relevant pixel\n            if relevant_mask[r, c] and not visited[r, c]:\n                component_pixels = set()\n                q = [(r, c)]\n                visited[r, c] = True\n                min_r, min_c = r, c\n                max_r, max_c = r, c\n                \n                # Keep track of the top-leftmost pixel encountered *in this component*\n                # Initialize with the starting pixel of the search\n                top_left_most_pixel = (r, c) \n\n                while q:\n                    row, col = q.pop(0)\n                    component_pixels.add((row, col))\n                    min_r = min(min_r, row)\n                    min_c = min(min_c, col)\n                    max_r = max(max_r, row)\n                    max_c = max(max_c, col)\n\n                    # Update the top-leftmost pixel for representative color\n                    if row < top_left_most_pixel[0]:\n                        top_left_most_pixel = (row, col)\n                    elif row == top_left_most_pixel[0] and col < top_left_most_pixel[1]:\n                        top_left_most_pixel = (row, col)\n\n                    # Explore neighbors (4-connectivity)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        if 0 <= nr < rows and 0 <= nc < cols and \\\n                           relevant_mask[nr, nc] and not visited[nr, nc]:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n\n                if component_pixels:\n                    bounding_box = (min_r, min_c, max_r, max_c)\n                    height = max_r - min_r + 1\n                    width = max_c - min_c + 1\n                    # The representative color is the original color of the top-leftmost pixel found\n                    representative_color = grid[top_left_most_pixel]\n\n                    shapes.append({\n                        'pixels': component_pixels,\n                        'bbox': bounding_box,\n                        'top_left': (min_r, min_c),\n                        'height': height,\n                        'width': width,\n                        'representative_color': representative_color\n                    })\n    return shapes\n\ndef filter_shapes(shapes, background_color):\n    \"\"\"\n    Filters shapes based on their representative color.\n    (This is largely redundant if find_conceptual_shapes correctly uses the relevant_mask,\n     but serves as a safeguard or for potential future rule changes).\n    \"\"\"\n    always_ignored_colors = {5, 7, 9}\n    filtered_shapes = []\n    for shape in shapes:\n        color = shape['representative_color']\n        if color in always_ignored_colors:\n            continue\n        if background_color == 8 and color == 2:\n            continue\n        # We might also need to check if the representative color is the background\n        # although `find_conceptual_shapes` should prevent this.\n        if color == background_color: \n            continue\n            \n        filtered_shapes.append(shape)\n    return filtered_shapes\n\n\ndef transform(input_grid):\n    \"\"\"\n    Transforms the input grid according to the described logic.\n    \"\"\"\n    input_np = np.array(input_grid, dtype=int)\n    if input_np.size == 0:\n        return [[]]\n\n    # 1. Identify Background\n    background_color = find_background_color(input_np)\n\n    # 2. Find Conceptual Shapes (includes identifying relevant pixels)\n    all_shapes = find_conceptual_shapes(input_np, background_color)\n\n    # 3. Filter Shapes (Safeguard)\n    relevant_shapes = filter_shapes(all_shapes, background_color)\n\n    # 4. Handle case with no relevant shapes\n    if not relevant_shapes:\n        return [[]]\n\n    # 5. Sort Shapes by top-left (row, then column)\n    sorted_shapes = sorted(relevant_shapes, key=lambda shape: shape['top_left'])\n\n    # 6. Conditional Reverse if background is Yellow (4)\n    if background_color == 4:\n        sorted_shapes.reverse()\n\n    final_ordered_shapes = sorted_shapes\n\n    # 7. Determine Output Dimensions\n    output_height = sum(shape['height'] for shape in final_ordered_shapes)\n    # Handle cases where shapes might have zero width/height if logic changes\n    output_width = 0\n    if final_ordered_shapes:\n        output_width = max(shape['width'] for shape in final_ordered_shapes)\n\n    # Ensure valid dimensions\n    if output_height <= 0 or output_width <= 0:\n         return [[]]\n\n    # 8. Construct the output grid\n    output_grid = np.full((output_height, output_width), background_color, dtype=int)\n\n    current_row = 0\n    # 9. Iterate through sorted shapes and place them in the output grid\n    for shape in final_ordered_shapes:\n        h = shape['height']\n        w = shape['width']\n        min_r, min_c, _, _ = shape['bbox']\n        representative_color = shape['representative_color']\n        pixels = shape['pixels']\n\n        # Calculate starting column for horizontal centering\n        start_col = (output_width - w) // 2\n\n        # Place the shape's pixels onto the output grid slice using the representative color\n        for r, c in pixels:\n            rel_r = r - min_r  # Relative row within the shape's bounding box\n            rel_c = c - min_c  # Relative col within the shape's bounding box\n\n            target_r = current_row + rel_r\n            target_c = start_col + rel_c\n\n            # Check bounds before writing\n            if 0 <= target_r < output_height and 0 <= target_c < output_width:\n                output_grid[target_r, target_c] = representative_color\n            # else: # Optional: Log if a pixel falls out of bounds\n                # print(f\"Warning: Pixel ({r},{c}) mapped to ({target_r},{target_c}) outside bounds ({output_height}x{output_width})\")\n\n\n        # Move to the starting row for the next shape\n        current_row += h\n\n    # 10. Return as list of lists\n    return output_grid.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 19053,
    "candidates_token_count": 2303,
    "total_token_count": 21356,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 25.672034,
  "retries": null
}