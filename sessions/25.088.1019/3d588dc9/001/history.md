
## train_1

**input:**
```
7 7 7 7 1 1 1 7 7 7 7 7 7 7 7 7
7 7 7 7 7 1 1 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 1 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 0 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 0 7 7 7 7 7 7 7 7 7 7 7 7
7 7 0 0 0 7 7 7 7 7 3 7 7 7 7 7
7 7 0 0 0 7 7 7 7 7 7 7 7 7 7 7
7 7 0 0 0 7 7 7 7 7 7 7 7 7 7 7
7 7 0 0 0 7 7 7 7 7 5 5 5 5 5 5
7 7 7 7 7 7 7 7 7 7 7 5 5 5 5 5
7 7 7 7 7 7 7 7 7 7 7 7 5 5 5 5
7 7 7 7 7 7 7 7 7 7 7 7 7 5 5 5
7 7 7 7 7 0 0 0 0 7 7 7 7 7 7 7
7 7 7 7 7 0 0 0 0 0 0 7 7 7 7 7
7 7 7 7 7 0 0 0 0 7 7 7 7 7 7 7
```


**output:**
```
7 7 7 7 1 1 1 7 7 7 7 7 7 7 7 7
7 7 7 7 7 1 1 7 7 8 7 7 7 7 7 7
7 7 7 7 7 7 1 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 0 0 6 7 7 7 7 7 3 7 7 7 7 7
7 7 0 0 6 7 7 7 7 7 7 7 7 7 7 7
7 7 0 0 6 7 7 7 7 7 7 7 7 7 7 7
7 7 0 0 6 7 7 7 7 7 5 5 5 5 5 5
7 7 7 7 7 7 7 7 7 7 7 5 5 5 5 5
7 7 7 7 7 7 7 7 7 7 7 7 5 5 5 5
7 7 7 7 7 7 7 7 7 7 7 7 7 5 5 5
7 7 7 7 7 0 0 0 0 7 7 7 7 7 7 7
7 7 7 7 7 0 0 0 0 0 0 7 7 7 7 7
7 7 7 7 7 0 0 0 0 7 7 7 7 7 7 7
```


## train_2

**input:**
```
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
9 9 9 9 7 7 7 0 0 0 0 7 7 7 7 7
9 9 9 7 7 7 7 0 0 0 0 0 0 7 7 7
9 9 7 7 7 7 7 0 0 0 0 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
5 5 5 5 5 5 5 5 7 7 7 7 7 7 7 0
5 5 5 5 5 5 5 7 7 0 0 0 0 7 7 7
5 5 5 5 5 5 7 7 7 0 0 0 0 0 0 7
5 5 5 5 5 7 7 7 7 0 0 0 0 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 9 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
```


**output:**
```
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
9 9 9 9 7 7 7 0 0 0 0 7 7 7 7 7
9 9 9 7 7 7 7 0 0 0 0 0 0 7 7 7
9 9 7 7 7 7 7 0 0 0 0 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
5 5 5 5 5 5 5 5 7 7 7 7 7 7 7 0
5 5 5 5 5 5 5 7 7 6 0 0 0 7 7 7
5 5 5 5 5 5 7 7 7 6 0 0 0 7 7 7
5 5 5 5 5 7 7 7 7 6 0 0 0 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 9 7 7 7 7 7 7 7 7 7 7 7 7 7 7
7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
```

*   **Perception of task elements:**
    *   The input and output grids share the same dimensions and the background color (orange, 7).
    *   Several objects of different colors (blue, azure, white, green, gray, maroon) exist on the orange background.
    *   The transformation specifically targets certain white (0) objects. Other objects remain unchanged.
    *   In each example, there is one pixel whose color is unique in the grid (excluding the background orange and the target white). In `train_1`, this is a green (3) pixel. In `train_2`, this is a maroon (9) pixel.
    *   The white object that gets modified appears to be the one "closest" to this unique pixel.
    *   The modification involves changing the color of one edge column of the target white object to magenta (6).
    *   If the unique pixel is horizontally to the right of the closest white object, the rightmost column of that white object changes color.
    *   If the unique pixel is horizontally to the left of the closest white object, the leftmost column of that white object changes color.
    *   The unique pixel's vertical position relative to the target white object does not seem to prevent the interaction, but proximity seems to select which white object is affected when multiple are present.

*   **YAML Facts:**
    
```yaml
    task_description: Modifies a specific white object based on the location of a unique colored pixel.
    
    elements:
      - type: background
        color: 7 (orange)
        property: static
      - type: object
        color: 0 (white)
        property: target_object
        relationship: potentially multiple instances per grid
      - type: object
        color: non-zero, non-background
        property: potential_activator
        relationship: find the instance with a color unique to the grid
      - type: color
        value: 6 (magenta)
        property: modification_color
    
    transformation:
      - action: identify_unique_pixel
        constraints:
          - color != 0 (white)
          - color != 7 (orange, background)
          - count(color) == 1 in the grid
        variable: unique_pixel (P)
      - action: identify_objects
        constraints:
          - color == 0 (white)
        variable: white_objects (list O)
      - action: find_closest_object
        input_variables: [unique_pixel, white_objects]
        method: calculate distance (e.g., Manhattan) from unique_pixel to each white_object's bounding box. Select the white_object with the minimum distance.
        variable: target_white_object (T)
      - action: determine_relative_position
        input_variables: [unique_pixel, target_white_object]
        conditions:
          - if unique_pixel.column > target_white_object.max_column: relative_pos = right
          - if unique_pixel.column < target_white_object.min_column: relative_pos = left
          - else: relative_pos = none
      - action: modify_object
        input_variables: [target_white_object, relative_pos]
        output_grid: copy of input grid
        steps:
          - if relative_pos == right:
              find all pixels (r, c) in target_white_object where c == target_white_object.max_column
              change color of these pixels to 6 (magenta) in the output grid.
          - if relative_pos == left:
              find all pixels (r, c) in target_white_object where c == target_white_object.min_column
              change color of these pixels to 6 (magenta) in the output grid.
    ```


*   **Natural Language Program:**
    1.  Initialize the output grid as a copy of the input grid.
    2.  Identify the background color (dominant color, orange-7 in examples).
    3.  Count the occurrences of each color in the input grid, excluding the background color and white (0).
    4.  Find the pixel (P) whose color count is exactly 1. This is the 'unique activating pixel'. If no such pixel exists, make no changes.
    5.  Identify all distinct contiguous objects composed of white (0) pixels.
    6.  For each white object (O), determine its bounding box (min/max row and column).
    7.  Calculate the distance (e.g., minimum Manhattan distance) between the unique activating pixel (P) and each white object (O). The distance can be measured from P to the nearest pixel within O or the nearest point on O's bounding box.
    8.  Select the white object (T) that has the minimum distance to P.
    9.  Compare the column index of P (P.col) with the minimum and maximum column indices of T's bounding box (T.min_col, T.max_col).
    10. If P.col is greater than T.max_col (P is to the right of T), iterate through all pixels belonging to T located in column T.max_col and change their color to magenta (6) in the output grid.
    11. If P.col is less than T.min_col (P is to the left of T), iterate through all pixels belonging to T located in column T.min_col and change their color to magenta (6) in the output grid.
    12. Return the modified output grid.
