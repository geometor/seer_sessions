{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\nimport numpy as np\nfrom collections import deque\n\n\"\"\"\nReflects one object through the geometric center of another object.\n\nThe transformation identifies the two distinct non-white objects in the input grid.\nIt determines which object acts as the \"pivot\" and which is \"mobile\" based on size and color.\nThe smaller object is the pivot. If sizes are equal, the object with the higher color index is the pivot.\nThe geometric center of the pivot object's bounding box is calculated.\nThe mobile object is then reflected point-by-point through this center.\nThe reflected points are added to the output grid, preserving the original two objects.\n\"\"\"\n\ndef find_objects(grid):\n    \"\"\"\n    Finds all contiguous objects of non-background colors in the grid.\n\n    Args:\n        grid (np.ndarray): The input grid.\n\n    Returns:\n        list: A list of dictionaries, where each dictionary represents an object\n              with keys: 'color', 'pixels', 'size', 'bounding_box'.\n              Returns an empty list if no objects are found.\n    \"\"\"\n    height, width = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    objects = []\n    \n    for r in range(height):\n        for c in range(width):\n            # If pixel is non-background and not visited yet\n            if grid[r, c] != 0 and not visited[r, c]:\n                color = grid[r, c]\n                obj_pixels = set()\n                q = deque([(r, c)])\n                visited[r, c] = True\n                min_r, max_r = r, r\n                min_c, max_c = c, c\n\n                # Breadth-First Search (BFS) to find connected pixels of the same color\n                while q:\n                    row, col = q.popleft()\n                    obj_pixels.add((row, col))\n                    min_r = min(min_r, row)\n                    max_r = max(max_r, row)\n                    min_c = min(min_c, col)\n                    max_c = max(max_c, col)\n\n                    # Check neighbors (4-connectivity: up, down, left, right)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        nr, nc = row + dr, col + dc\n                        if 0 <= nr < height and 0 <= nc < width and \\\n                           not visited[nr, nc] and grid[nr, nc] == color:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n                            \n                objects.append({\n                    'color': color,\n                    'pixels': obj_pixels,\n                    'size': len(obj_pixels),\n                    'bounding_box': (min_r, max_r, min_c, max_c)\n                })\n                \n    # Ensure exactly two objects are found as per problem constraints\n    if len(objects) != 2:\n        # This case might indicate an issue or an unexpected input format based on examples\n        # For robustness, we could raise an error or return an empty/copied grid\n        # For now, proceed assuming 2 objects are always present in valid inputs\n        pass \n        \n    return objects\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the object reflection transformation to the input grid.\n\n    Args:\n        input_grid (list of lists): The input grid represented as a list of lists.\n\n    Returns:\n        list of lists: The transformed grid.\n    \"\"\"\n    # Convert input to numpy array for easier manipulation\n    input_np = np.array(input_grid, dtype=int)\n    output_np = np.copy(input_np)\n    height, width = input_np.shape\n\n    # 1. Identify the two distinct non-white objects\n    objects = find_objects(input_np)\n    \n    # If not exactly two objects found, return the original grid (or handle error)\n    if len(objects) != 2:\n        print(\"Warning: Expected 2 objects, found:\", len(objects))\n        return input_grid # Return original grid if assumption fails\n\n    obj1, obj2 = objects[0], objects[1]\n\n    # 2. Determine pivot and mobile objects\n    pivot_obj = None\n    mobile_obj = None\n    \n    # Rule: Smaller object is pivot\n    if obj1['size'] < obj2['size']:\n        pivot_obj = obj1\n        mobile_obj = obj2\n    elif obj2['size'] < obj1['size']:\n        pivot_obj = obj2\n        mobile_obj = obj1\n    else: # Sizes are equal\n        # Rule: Higher color index is pivot\n        if obj1['color'] > obj2['color']:\n            pivot_obj = obj1\n            mobile_obj = obj2\n        else: # obj2['color'] >= obj1['color'] (includes equal colors, obj2 becomes pivot)\n            pivot_obj = obj2\n            mobile_obj = obj1\n\n    # 3. Calculate the center of reflection using the pivot's bounding box\n    r_min, r_max, c_min, c_max = pivot_obj['bounding_box']\n    # Using sum coordinates for integer reflection math\n    sum_r = r_min + r_max \n    sum_c = c_min + c_max \n\n    # 4. Reflect the mobile object through the pivot's center\n    mobile_color = mobile_obj['color']\n    for r, c in mobile_obj['pixels']:\n        # Calculate reflected coordinates\n        r_reflected = sum_r - r\n        c_reflected = sum_c - c\n\n        # 5. Update the output grid if reflected coordinates are within bounds\n        if 0 <= r_reflected < height and 0 <= c_reflected < width:\n            output_np[r_reflected, c_reflected] = mobile_color\n\n    # Convert the result back to a list of lists\n    return output_np.tolist()\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 4909,
    "candidates_token_count": 1394,
    "total_token_count": 6303,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 19.363157,
  "retries": null
}