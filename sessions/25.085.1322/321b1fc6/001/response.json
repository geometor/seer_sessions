{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\nThe transformation identifies specific objects in the input grid based on color and uses them to define a pattern and target locations.\n\n1.  **Initialization**: Create an output grid of the same dimensions as the input, filled with the background color (white, 0).\n2.  **Object Identification**:\n    *   Identify all connected components (objects) of Azure color (8). These are the 'markers'.\n    *   Identify all connected components (objects) of any color other than white (0) or azure (8). These are the 'source objects'.\n3.  **Pattern Template Determination**:\n    *   If no source objects exist, return the empty output grid.\n    *   Examine the source objects. Check if they are all identical in shape and color pattern relative to their top-left bounding box corners.\n    *   If all source objects are identical (or if there's only one), select the one whose top-left corner has the minimum row index, and then the minimum column index. Extract the pattern (colors within its bounding box relative to the top-left) as the 'pattern template'.\n    *   If the source objects are not identical, determine the minimal bounding box that encloses *all* pixels of *all* source objects combined. Extract the rectangular subgrid from the *input grid* corresponding to this combined bounding box. This subgrid (including any background pixels within it) becomes the 'pattern template'.\n4.  **Stamping**:\n    *   For each identified marker object:\n        *   Find the coordinate (row, column) of its top-left pixel (minimum row, then minimum column).\n        *   Overlay the 'pattern template' onto the output grid, aligning the top-left corner of the template with the marker's top-left coordinate. Pixels from the template overwrite existing pixels in the output grid. Handle boundary conditions (if the pattern extends beyond the grid limits, clip it).\n5.  **Return**: Return the modified output grid.\n\"\"\"\n\nimport numpy as np\nfrom scipy.ndimage import label, find_objects, center_of_mass\nfrom collections import defaultdict\n\ndef find_connected_components(grid, target_colors):\n    \"\"\"\n    Finds all connected components for a specific set of colors in the grid.\n\n    Args:\n        grid (np.array): The input grid.\n        target_colors (set): A set of integer colors to find objects for.\n\n    Returns:\n        list: A list of dictionaries, where each dictionary represents an object\n              and contains 'color', 'pixels' (list of (r, c) tuples),\n              'bbox' (slice tuple from find_objects), 'top_left' (r, c),\n              'relative_pattern' (np.array). Returns empty list if no objects found.\n    \"\"\"\n    objects = []\n    mask = np.isin(grid, list(target_colors))\n    if not np.any(mask):\n        return objects\n\n    labeled_array, num_features = label(mask)\n\n    found_locs = find_objects(labeled_array)\n\n    for i in range(num_features):\n        obj_slice = found_locs[i]\n        obj_coords_local = np.argwhere(labeled_array[obj_slice] == (i + 1))\n        obj_coords_global = obj_coords_local + np.array([obj_slice[0].start, obj_slice[1].start])\n\n        # Determine the single color of the object\n        # Check the first pixel's color; connectivity ensures they are the same\n        # if finding components for *one* color at a time.\n        # If finding components across *multiple* allowed colors (like source objects),\n        # need to handle multi-color components differently or ensure connectivity is by *single* color.\n        # Re-thinking: The problem implies source objects can be multi-colored patterns themselves (train_2).\n        # But connectivity is usually defined by *same* color.\n        # Let's assume connectivity means same-color neighbours.\n        # If a source \"pattern\" is multi-colored, it's actually multiple single-color objects.\n        # The natural language suggests grouping based on non-0, non-8.\n\n        # Let's find objects color by color first, then group non-0/non-8 later if needed.\n        # Or find all non-0 connected areas first, then filter.\n\n        # Simpler approach: Find objects for *each* target color separately.\n\n        obj_pixels = []\n        min_r, min_c = float('inf'), float('inf')\n        max_r, max_c = float('-inf'), float('-inf')\n        first_pixel_coord = tuple(obj_coords_global[0])\n        obj_color = grid[first_pixel_coord]\n\n        # Verify all pixels in this component have the same color if assumption holds\n        is_single_color = True\n        for r, c in obj_coords_global:\n            if grid[r, c] != obj_color:\n                is_single_color = False # This shouldn't happen with standard 'label' usage per color mask\n                break\n            obj_pixels.append((r, c))\n            min_r = min(min_r, r)\n            min_c = min(min_c, c)\n            max_r = max(max_r, r)\n            max_c = max(max_c, c)\n\n        if not is_single_color:\n            # Handle error or refine object finding if components can span multiple target colors\n            # For now, assume connectivity implies single color from target_colors\n            print(f\"Warning: Component {i+1} seems multi-colored. Unexpected.\")\n            continue\n\n        # Create relative pattern based on bounding box\n        bbox_slice = (slice(min_r, max_r + 1), slice(min_c, max_c + 1))\n        relative_pattern = grid[bbox_slice].copy()\n        # Mask out pixels not belonging to this specific object within its bbox\n        mask_in_bbox = np.zeros_like(relative_pattern, dtype=bool)\n        for r, c in obj_pixels:\n            mask_in_bbox[r - min_r, c - min_c] = True\n        relative_pattern[~mask_in_bbox] = 0 # Set non-object pixels within bbox to background\n\n\n        objects.append({\n            'color': obj_color,\n            'pixels': obj_pixels,\n            'bbox': bbox_slice, # Use calculated bbox\n            'top_left': (min_r, min_c),\n            'relative_pattern': relative_pattern\n        })\n\n    return objects\n\ndef find_all_objects(grid):\n    \"\"\" Finds all non-background objects, separated by color. \"\"\"\n    all_objs = []\n    colors_present = np.unique(grid)\n    for color in colors_present:\n        if color == 0:\n            continue\n        # Create mask for the current color\n        mask = (grid == color)\n        labeled_array, num_features = label(mask)\n        found_locs = find_objects(labeled_array)\n\n        for i in range(num_features):\n            obj_slice = found_locs[i]\n            obj_coords_local = np.argwhere(labeled_array[obj_slice] == (i + 1))\n            obj_coords_global = obj_coords_local + np.array([obj_slice[0].start, obj_slice[1].start])\n\n            obj_pixels = []\n            min_r, min_c = float('inf'), float('inf')\n            max_r, max_c = float('-inf'), float('-inf')\n            for r, c in obj_coords_global:\n                obj_pixels.append((r, c))\n                min_r = min(min_r, r)\n                min_c = min(min_c, c)\n                max_r = max(max_r, r)\n                max_c = max(max_c, c)\n\n            bbox_slice = (slice(min_r, max_r + 1), slice(min_c, max_c + 1))\n            # Extract the object shape within its bounding box\n            obj_pattern = np.zeros((max_r - min_r + 1, max_c - min_c + 1), dtype=grid.dtype)\n            for r, c in obj_pixels:\n                obj_pattern[r - min_r, c - min_c] = color\n\n            all_objs.append({\n                'color': color,\n                'pixels': obj_pixels,\n                'bbox': bbox_slice,\n                'top_left': (min_r, min_c),\n                'relative_pattern': obj_pattern\n            })\n    return all_objs\n\ndef get_combined_bounding_box(objects):\n    \"\"\" Calculates the minimal bounding box containing all pixels of given objects. \"\"\"\n    if not objects:\n        return None\n    min_r, min_c = float('inf'), float('inf')\n    max_r, max_c = float('-inf'), float('-inf')\n    for obj in objects:\n        for r, c in obj['pixels']:\n            min_r = min(min_r, r)\n            min_c = min(min_c, c)\n            max_r = max(max_r, r)\n            max_c = max(max_c, c)\n    if min_r == float('inf'): # No pixels found\n        return None\n    return slice(min_r, max_r + 1), slice(min_c, max_c + 1)\n\ndef are_patterns_identical(pattern1, pattern2):\n    \"\"\" Checks if two numpy arrays representing patterns are identical. \"\"\"\n    if pattern1.shape != pattern2.shape:\n        return False\n    return np.array_equal(pattern1, pattern2)\n\ndef stamp_pattern(output_grid, pattern, top_left_coord):\n    \"\"\" Overlays the pattern onto the output grid at the specified coordinate. \"\"\"\n    r_start, c_start = top_left_coord\n    p_h, p_w = pattern.shape\n    g_h, g_w = output_grid.shape\n\n    # Calculate the intersection of the pattern bounds and grid bounds\n    r_end = min(r_start + p_h, g_h)\n    c_end = min(c_start + p_w, g_w)\n\n    # Calculate slices for pattern and grid\n    p_r_slice = slice(0, r_end - r_start)\n    p_c_slice = slice(0, c_end - c_start)\n    g_r_slice = slice(r_start, r_end)\n    g_c_slice = slice(c_start, c_end)\n\n    # Ensure slices are valid (not negative range)\n    if g_r_slice.start < g_r_slice.stop and g_c_slice.start < g_c_slice.stop:\n         # Apply the pattern: only non-background pixels from the pattern overwrite\n        pattern_part = pattern[p_r_slice, p_c_slice]\n        target_area = output_grid[g_r_slice, g_c_slice]\n        \n        # If the pattern template came from a combined bounding box, it might contain 0s\n        # that should be stamped. If it came from a single object definition, 0s represent\n        # areas outside the object. Let's refine this: always stamp non-zero?\n        # The examples suggest stamping the whole template, including background 0s if present (train_1 combined pattern).\n        \n        # Update: Let's stamp everything from the pattern template.\n        output_grid[g_r_slice, g_c_slice] = pattern_part\n        \n        # # Alternative: Only stamp non-zero pixels from pattern\n        # non_zero_mask = pattern_part != 0\n        # target_area[non_zero_mask] = pattern_part[non_zero_mask]\n        # output_grid[g_r_slice, g_c_slice] = target_area\n\n\ndef transform(input_grid):\n    \"\"\"\n    Applies the pattern stamping transformation.\n    \"\"\"\n    input_grid = np.array(input_grid, dtype=int)\n    output_grid = np.zeros_like(input_grid)\n    grid_h, grid_w = input_grid.shape\n\n    # 1. Find all objects\n    all_objects = find_all_objects(input_grid)\n\n    # 2. Separate markers (color 8) and source objects (others, non-0)\n    marker_objects = [obj for obj in all_objects if obj['color'] == 8]\n    source_objects = [obj for obj in all_objects if obj['color'] != 8 and obj['color'] != 0]\n\n    # Handle edge case: No source objects\n    if not source_objects:\n        return output_grid.tolist() # Return empty grid if no pattern source\n\n    # Handle edge case: No marker objects\n    if not marker_objects:\n         # If no markers, what should happen? The examples don't cover this.\n         # Assume output is empty grid.\n         return output_grid.tolist()\n\n    # 3. Determine Pattern Template\n    pattern_template = None\n    if len(source_objects) == 1:\n        # Single source object: its relative pattern is the template\n        pattern_template = source_objects[0]['relative_pattern']\n    else:\n        # Multiple source objects: check if they are identical\n        first_pattern = source_objects[0]['relative_pattern']\n        all_identical = True\n        for i in range(1, len(source_objects)):\n            if not are_patterns_identical(first_pattern, source_objects[i]['relative_pattern']):\n                all_identical = False\n                break\n\n        if all_identical:\n            # Find the top-leftmost source object\n            top_leftmost_obj = min(source_objects, key=lambda obj: (obj['top_left'][0], obj['top_left'][1]))\n            pattern_template = top_leftmost_obj['relative_pattern']\n        else:\n            # Not identical: use combined bounding box from input grid\n            combined_bbox = get_combined_bounding_box(source_objects)\n            if combined_bbox:\n                pattern_template = input_grid[combined_bbox]\n            else: # Should not happen if source_objects is not empty\n                 return output_grid.tolist()\n\n\n    if pattern_template is None: # Should not happen if source_objects exist\n         return output_grid.tolist()\n\n\n    # 4. Stamping Process\n    for marker in marker_objects:\n        marker_tl = marker['top_left']\n        stamp_pattern(output_grid, pattern_template, marker_tl)\n\n    # 5. Return final grid\n    return output_grid.tolist()\n\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 3319,
    "candidates_token_count": 3443,
    "total_token_count": 6762,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.5-pro-exp-03-25",
  "response_time": 97.173706,
  "retries": null
}