{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "```python\n\"\"\"\nTransforms an input grid by changing certain red pixels to yellow based on their position relative to white pixels and then propagating the yellow color to the row below.\n\"\"\"\n\nimport numpy as np\n\ndef get_red_pixels(grid):\n    # use where to find red pixels\n    red_pixels = np.where(grid == 2)\n    # combine and return list of (row, col)\n    return list(zip(red_pixels[0], red_pixels[1]))\n\ndef transform(input_grid):\n    output_grid = np.copy(input_grid)\n    rows, cols = output_grid.shape\n\n    red_pixels = get_red_pixels(input_grid)\n    \n    # create dictionary, keys are row, values are column\n    red_pixels_by_row = {}\n    for r, c in red_pixels:\n        if r not in red_pixels_by_row:\n            red_pixels_by_row[r] = []\n        red_pixels_by_row[r].append(c)\n\n    # sort red pixels by column\n    for row in red_pixels_by_row:\n      red_pixels_by_row[row].sort()\n\n    for row in red_pixels_by_row:\n      col_indices = red_pixels_by_row[row]\n      for i in range(len(col_indices)):\n          current_col = col_indices[i]\n          # check if all next are 0 until next 2 or end\n          next_red_index = -1\n          all_white = True\n          for j in range(current_col + 1, cols):\n            if output_grid[row, j] == 2:\n              next_red_index = j\n              break;\n            elif output_grid[row,j] != 0:\n              all_white = False\n              break\n          \n          if all_white and next_red_index != -1:\n            output_grid[row, next_red_index] = 4\n\n    # propagate yellow color down\n    for r in range(rows - 1):\n        for c in range(cols):\n            if output_grid[r, c] == 4:\n                output_grid[r + 1, c] = 4\n\n    return output_grid\n```"
          }
        ],
        "role": "model"
      },
      "finish_reason": 1,
      "index": 0,
      "safety_ratings": [],
      "token_count": 0,
      "grounding_attributions": [],
      "avg_logprobs": 0.0
    }
  ],
  "usage_metadata": {
    "prompt_token_count": 2107,
    "candidates_token_count": 531,
    "total_token_count": 2638,
    "cached_content_token_count": 0
  },
  "model_version": "gemini-2.0-pro-exp-02-05",
  "response_time": 6.701722,
  "response_file": "008-response.json"
}