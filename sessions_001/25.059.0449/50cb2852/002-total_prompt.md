# 50cb2852 • 002 • example_3 • investigate_coder

---

## train_1

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 2 2 2 2 0 0 0 1 1 1 0 0
0 0 2 2 2 2 2 0 0 0 1 1 1 0 0
0 0 2 2 2 2 2 0 0 0 1 1 1 0 0
0 0 2 2 2 2 2 0 0 0 0 0 0 0 0
0 0 2 2 2 2 2 0 0 0 0 0 0 0 0
0 0 2 2 2 2 2 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 3 3 3 3 3 3 3
0 0 0 0 0 0 0 0 3 3 3 3 3 3 3
0 0 0 0 0 0 0 0 3 3 3 3 3 3 3
0 0 0 0 0 0 0 0 3 3 3 3 3 3 3
0 0 0 0 0 0 0 0 3 3 3 3 3 3 3
```

<PIL.Image.Image image mode=RGB size=960x832 at 0x744068E011D0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 2 2 2 2 0 0 0 1 1 1 0 0
0 0 2 8 8 8 2 0 0 0 1 8 1 0 0
0 0 2 8 8 8 2 0 0 0 1 1 1 0 0
0 0 2 8 8 8 2 0 0 0 0 0 0 0 0
0 0 2 8 8 8 2 0 0 0 0 0 0 0 0
0 0 2 2 2 2 2 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 3 3 3 3 3 3 3
0 0 0 0 0 0 0 0 3 8 8 8 8 8 3
0 0 0 0 0 0 0 0 3 8 8 8 8 8 3
0 0 0 0 0 0 0 0 3 8 8 8 8 8 3
0 0 0 0 0 0 0 0 3 3 3 3 3 3 3
```

<PIL.Image.Image image mode=RGB size=960x832 at 0x744068E00650>

## train_2

**input:**
```
0 0 0 0 0 0 0 0 0 0 0
0 2 2 2 2 0 0 0 0 0 0
0 2 2 2 2 0 0 0 0 0 0
0 2 2 2 2 0 0 0 0 0 0
0 2 2 2 2 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 1 0 0 0
0 0 1 1 1 1 1 1 0 0 0
0 0 1 1 1 1 1 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=704x768 at 0x744068E009D0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0
0 2 2 2 2 0 0 0 0 0 0
0 2 8 8 2 0 0 0 0 0 0
0 2 8 8 2 0 0 0 0 0 0
0 2 2 2 2 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 1 0 0 0
0 0 1 8 8 8 8 1 0 0 0
0 0 1 1 1 1 1 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=704x768 at 0x744068E00150>

## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 2 2 2 2 0 0 0
3 3 3 3 0 0 2 2 2 2 0 0 0
3 3 3 3 0 0 2 2 2 2 0 0 0
3 3 3 3 0 0 2 2 2 2 0 0 0
3 3 3 3 0 0 2 2 2 2 0 0 0
0 0 0 0 0 0 2 2 2 2 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 1 1 1 0 0 0
0 0 1 1 1 1 1 1 1 1 0 0 0
0 0 1 1 1 1 1 1 1 1 0 0 0
0 0 1 1 1 1 1 1 1 1 0 0 0
```

<PIL.Image.Image image mode=RGB size=832x768 at 0x744068E01250>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 2 2 2 2 0 0 0
3 3 3 3 0 0 2 8 8 2 0 0 0
3 8 8 3 0 0 2 8 8 2 0 0 0
3 8 8 3 0 0 2 8 8 2 0 0 0
3 3 3 3 0 0 2 8 8 2 0 0 0
0 0 0 0 0 0 2 2 2 2 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 1 1 1 1 1 1 1 0 0 0
0 0 1 8 8 8 8 8 8 1 0 0 0
0 0 1 8 8 8 8 8 8 1 0 0 0
0 0 1 1 1 1 1 1 1 1 0 0 0
```

<PIL.Image.Image image mode=RGB size=832x768 at 0x7440707180D0>
<PIL.Image.Image image mode=RGB size=2576x1714 at 0x744068E60850>Okay, here's my analysis of the provided input-output examples, focusing on perception, object identification, and the transformation rule.

**Perception of Elements:**

The task involves 2D grids containing colored squares (objects). The colors used are red (2), blue (1), green (3), and azure (8).  The background is consistently white (0). The key transformation appears to be the insertion of an azure (8) outline within existing colored rectangles. The outlines are always one pixel thick, and the original shape is maintained.

**YAML Fact Documentation:**


```yaml
facts:
  - objects:
      - type: rectangle
        properties:
          - color: [red, blue, green]
          - size: variable
          - outline: azure (8)
        actions:
          - create_outline:
              color: azure
              thickness: 1
  - background:
      - color: white (0)
      - state: unchanged
  - relationships:
      - spatial: objects are distinct and non-overlapping
      - transformation: original colored rectangles have an azure outline added
```


**Natural Language Program:**

1.  **Identify Rectangles:** Scan the input grid and identify all contiguous rectangular regions of the same color (excluding white/0). Consider each of these regions as a separate object.

2.  **Create Inner Outline:** For each identified rectangle:
    *   Determine the boundaries of the rectangle.
    *   Inset a new rectangle inside, reducing height and width by two.
    * Change the color of this inset rectangle to azure (8).
    * If original width or height equal to one or two, skip inset - keep original.

3.  **Output:** The output grid is the same as the input grid, but with the identified rectangles now containing an azure outline. The background (white/0) remains unchanged.

**INSTRUCTIONS**

- generate a Python module to represent the natural language program 
- follow the template below
- all common math and science libraries are available
- create docstring only at top - but comment the workflow in the function
- use helper functions for common operations like finding objects, counting,
  measuring, moving, etc. 

remember - we are working iteratively - so this code will inform your future
self as we converge on the solution

*template:*

```python
"""
{{ natural language description of the transformation rule }}
"""

{{ imports }}

def transform(input_grid):
    # initialize output_grid

    # change output pixels 

    return output_grid

```
