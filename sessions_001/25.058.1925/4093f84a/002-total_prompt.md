# 4093f84a • 002 • example_3 • investigate_coder

---

## train_1

**input:**
```
0 0 0 0 0 0 0 0 2 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 2 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5
0 0 0 0 0 0 0 0 0 2 0 0 0 0
0 2 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 2 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 2 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=896x896 at 0x78E5F2073350>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 5 0 0 0 0 0 5 0 5 0 0 0
5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5
0 5 0 0 5 0 0 0 0 5 0 5 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=896x896 at 0x78E5F218FED0>

## train_2

**input:**
```
0 0 0 0 5 5 5 5 5 0 0 0 3 0
0 0 0 0 5 5 5 5 5 3 0 0 0 0
0 0 0 3 5 5 5 5 5 0 0 3 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
3 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 0 3 0 3 0
0 3 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 3 0 5 5 5 5 5 0 0 0 3 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 0 3 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=896x896 at 0x78E5F267B6D0>

**output:**
```
0 0 0 0 5 5 5 5 5 5 0 0 0 0
0 0 0 0 5 5 5 5 5 5 0 0 0 0
0 0 0 5 5 5 5 5 5 5 0 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 5 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 5 5 0 0 0
0 0 0 5 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 5 5 5 5 5 5 5 0 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
0 0 0 0 5 5 5 5 5 5 0 0 0 0
0 0 0 0 5 5 5 5 5 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=896x896 at 0x78E5F218F3D0>

## train_3

**input:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 1 0 0 0 0 1 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 1 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5
0 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 1 0 0
0 0 0 1 0 0 0 0 1 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=896x896 at 0x78E5F218F850>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 5 0 0 0 0 0 0
0 0 0 5 0 0 0 5 5 0 0 0 5 0
5 5 5 5 5 5 5 5 5 5 5 5 5 5
5 5 5 5 5 5 5 5 5 5 5 5 5 5
0 5 0 5 0 0 0 0 5 0 0 5 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=896x896 at 0x78E5F218F4D0>
<PIL.Image.Image image mode=RGB size=2768x1842 at 0x78E5F21D3950>Okay, let's analyze the provided examples to understand the transformation.

**Perception of Elements:**

The task involves 2D grids with single-digit integer values (0-9) representing different colors. There's a consistent band of '5' (gray) pixels across all inputs, separating two regions of the grid.  Above and below this gray band, other colored pixels (non-gray, non-white) appear.  The transformation seems to involve replacing these non-gray, non-white pixels with gray ('5') pixels, and the placement or pattern seems critical.

**YAML Block (Facts):**


```yaml
objects:
  - grid:
      type: 2D array
      elements: integers (0-9)
      properties:
        height: constant within each example
        width: constant within each example
  - pixel:
      type: element within grid
      properties:
          color: determined by integer value
          location: row and column index
  - gray_band:
      type: contiguous block of pixels
      properties:
          color: gray (5)
          shape: horizontal band
          location: spans entire width, fixed rows

actions:
  - replace_color:
      input: pixel location, original color
      output: new color (gray) at same location
  - identify_pattern:
     input: location, color
     output: a flag if location/color matches the replace criteria

relationships:
  - spatial: pixels are adjacent, gray band separates upper and lower regions.
  - conditional: replacement happens based on a color and a location pattern related to the gray band

```


**Natural Language Program:**

1. **Identify the Gray Band:** Locate the horizontal band of contiguous gray (5) pixels that spans the entire width of the grid. This band acts as a key reference.

2. **Locate Non-Gray Pixels:** In the regions *above* and *below* the gray band, identify all pixels that are *not* gray (5) and *not* white (0).

3.  **Mirror and Replace with Gray:**
    *   For the pixels identified in the areas above and below the grey band, if you had a red(2), blue(1) or green(3) pixel in the input, replace them with gray(5) pixels.

In summary, the transformation replaces specific colored pixels with gray pixels, based on their position relative to the central, constant gray band, mirroring pixels of one color to another position with another color. The key is the replacement and mirror across the gray band.

**INSTRUCTIONS**

- generate a Python module to represent the natural language program 
- follow the template below
- all common math and science libraries are available
- create docstring only at top - but comment the workflow in the function
- use helper functions for common operations like finding objects, counting,
  measuring, moving, etc. 

remember - we are working iteratively - so this code will inform your future
self as we converge on the solution

*template:*

```python
"""
{{ natural language description of the transformation rule }}
"""

{{ imports }}

def transform(input_grid):
    # initialize output_grid

    # change output pixels 

    return output_grid

```
