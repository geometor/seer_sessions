# 91714a58 • 002 • example_3 • investigate_coder

---

## train_1

**input:**
```
0 0 0 0 1 1 4 0 2 0 0 0 0 2 0 5
0 0 0 3 5 0 0 0 9 9 8 0 4 0 5 8
1 0 8 2 8 0 0 6 0 8 5 0 0 0 8 0
0 0 0 2 2 2 0 0 0 0 0 6 0 0 0 0
0 0 1 2 2 2 0 0 1 9 5 0 0 2 0 4
0 4 0 2 2 2 0 2 0 0 7 0 0 0 0 0
3 0 6 2 2 2 0 0 0 3 5 0 7 0 0 0
7 0 4 6 0 0 4 7 7 3 0 2 0 0 7 1
0 7 0 0 0 0 0 9 7 7 0 0 0 8 5 2
1 5 6 4 9 3 0 3 0 0 0 0 0 9 4 6
0 2 4 0 0 0 0 0 0 0 2 0 1 6 0 0
0 0 0 5 0 0 0 0 0 0 0 0 0 0 2 4
0 0 6 0 0 0 0 0 6 0 0 2 0 0 0 0
0 3 0 0 7 0 2 0 7 9 0 0 0 0 0 0
0 0 5 0 7 0 0 0 0 0 0 0 6 5 3 0
1 0 0 9 0 0 0 2 0 0 0 1 0 0 9 0
```

<PIL.Image.Image image mode=RGB size=1024x1024 at 0x7F2DF79E03D0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=1024x1024 at 0x7F2DF795D6D0>

## train_2

**input:**
```
0 0 7 0 0 6 0 6 0 0 0 7 3 0 0 0
0 0 3 0 0 1 0 0 8 0 0 2 0 0 0 0
0 0 0 0 3 9 0 0 0 0 0 0 0 8 0 8
2 2 0 2 9 0 0 0 0 1 0 2 0 0 0 0
0 5 2 0 0 7 0 6 0 0 0 3 0 0 1 0
4 4 0 3 9 0 0 0 0 7 0 2 0 0 0 0
8 0 0 0 0 6 0 0 0 8 0 0 3 0 0 0
0 9 0 0 0 4 8 0 0 0 7 0 0 0 0 0
0 0 9 5 0 0 0 0 4 6 0 1 4 0 0 0
0 0 0 0 0 0 0 0 3 1 0 8 0 5 9 4
0 9 3 9 0 3 0 0 5 6 7 0 5 0 0 0
0 0 6 6 6 6 6 6 6 0 0 0 0 7 0 0
0 4 6 6 6 6 6 6 6 0 0 4 4 6 0 2
0 5 0 0 0 0 4 5 3 0 8 0 0 0 6 9
0 0 9 7 5 0 0 0 0 0 0 0 1 0 7 1
0 8 0 0 0 0 0 1 0 3 0 0 3 8 7 0
```

<PIL.Image.Image image mode=RGB size=1024x1024 at 0x7F2DF795FDD0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 6 6 6 6 6 6 6 0 0 0 0 0 0 0
0 0 6 6 6 6 6 6 6 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=1024x1024 at 0x7F2DF794F750>

## train_3

**input:**
```
3 0 0 0 0 0 6 2 0 0 0 5 0 0 0 3
0 7 0 0 0 0 9 0 0 0 0 0 0 0 5 0
0 0 0 0 0 8 8 0 7 7 7 0 0 0 0 4
0 2 0 0 0 0 0 0 7 7 7 0 2 0 5 0
0 8 0 0 9 6 1 7 7 7 7 0 0 0 0 0
5 0 0 0 0 3 6 0 6 0 0 3 3 0 0 0
0 4 0 2 0 0 0 0 0 0 0 0 0 0 4 0
9 0 0 0 0 0 0 0 0 3 0 8 0 0 0 0
0 0 3 0 0 0 0 6 0 9 0 0 0 0 0 0
9 0 0 0 1 0 0 3 0 8 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 3 3 0 0 7 0
0 0 0 0 0 0 0 4 0 0 0 0 0 5 0 0
4 0 0 1 7 0 3 0 0 7 5 0 0 0 0 0
0 0 0 0 0 1 7 2 0 0 5 0 0 1 0 4
0 0 0 0 0 0 0 3 0 0 2 0 0 0 0 0
0 2 0 0 0 7 9 0 0 0 5 0 2 0 3 0
```

<PIL.Image.Image image mode=RGB size=1024x1024 at 0x7F2DF7982AD0>

**output:**
```
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 7 7 7 0 0 0 0 0
0 0 0 0 0 0 0 0 7 7 7 0 0 0 0 0
0 0 0 0 0 0 0 0 7 7 7 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

<PIL.Image.Image image mode=RGB size=1024x1024 at 0x7F2DF794FF50>
<PIL.Image.Image image mode=RGB size=3200x2128 at 0x7F2DF79E0750>Okay, here's my analysis of the provided examples, focusing on perception, object identification, and the transformation rule:

**Perception of Elements:**

The task involves 2D grids (input and output) of varying sizes, where each cell contains a single-digit integer representing a color. The most obvious difference between the input and output grids is that the output grids mostly consist of zeros (white), with only a small, solid-colored rectangular block remaining in some cases. The position and color of this remaining block vary.

**YAML Block (Facts):**


```yaml
objects:
  - name: input_grid
    type: 2D array
    properties:
      - colors: [0-9] # Representing different colors
      - dimensions: variable
  - name: output_grid
    type: 2D array
    properties:
      - colors: [0-9] # Mostly 0, with a single colored block
      - dimensions: same as input_grid
  - name: colored_block
    type: rectangle
    properties:
      - color: single color (varies)
      - position: variable (within the grid)
      - dimensions: variable

actions:
  - name: identify_largest_block
    description: Find the largest contiguous block of the same color. Contiguous means horizontally or vertically adjacent, not diagonally.
  - name: clear_other_pixels
    description: Set all grid cells *not* part of the identified block to 0 (white).
  - name: preserve_block
        description: Retain identified largest block.
relationships:
  - input_grid_to_output_grid: "The output grid is derived from the input grid by preserving only one largest solid-colored rectangular block and setting all other cells to 0."
```


**Natural Language Program:**

1.  **Identify Largest Solid-Colored Block:** Examine the input grid. Find the largest rectangular block of pixels that are all of the same color and are contiguously connected (horizontally or vertically, but *not* diagonally). If there are multiple blocks of the same largest size, other information not contained in these inputs are used.
2.  **Clear Other Pixels:** Create the output grid, initially filled entirely with 0 (white).
3.  **Preserve the Identified Block:** Copy the pixels of the largest identified solid-colored block from the input grid to the *exact same position* in the output grid. All other pixels in the output grid remain 0.

In summary, the transformation rule is to find the largest, solid-colored, rectangular, contiguous block within the input grid and preserve it in the output grid, setting all other pixels to white (0).

**INSTRUCTIONS**

- generate a Python module to represent the natural language program 
- follow the template below
- all common math and science libraries are available
- create docstring only at top - but comment the workflow in the function
- use helper functions for common operations like finding objects, counting,
  measuring, moving, etc. 

remember - we are working iteratively - so this code will inform your future
self as we converge on the solution

*template:*

```python
"""
{{ natural language description of the transformation rule }}
"""

{{ imports }}

def transform(input_grid):
    # initialize output_grid

    # change output pixels 

    return output_grid

```
